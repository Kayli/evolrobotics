

--- Evolutionary Robotics course. Lecture 02..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning
everyone welcome
back I'm glad to see that some of you
have come back most of you have come
back great awesome all right so like
Tuesday we're going to spend a few
minutes going over the logistics uh to
make sure we're all on the same page and
then we'll get back to the topic we all
know and love robotics uh there was a
question here about the readings um you
can do the readings for that day uh
before before lecture you can do them
after lecture doesn't matter uh the
lecture the reading will not necessarily
prepare you for that day lecture so
before after doesn't
matter any other questions about the
syllabus things we went over on Tuesday
so when we're trying to submit a
homework assignment yes so do we make a
Reddit post if we if we already just
like have a Reddit account do we make a
Reddit post and just like throw our name
on it somewhere got it okay there's a
question about how to submit assign
ments let's talk about that I realize
it's obscenely confusing uh as usual
part of that is because of my fa uh from
my fault okay we got a lot of moving
pieces we've got bright space actually
no we've got a Google sheet everything
more or less can be found here on the
schedule or the or on bright space as
you can see here uh last Tuesday I
assigned all of the undergraduates here
assignment one as you can see this link
will take you to brightspace it should
take you to assignment one uh in
brightspace there are links in
brightspace that'll take you to Reddit
and walk you through everything you need
to do for that assignment when you
complete assignment one and all the
other assignments you will have in hand
one or more screenshots or one or more
videos in this uh in this course you're
going to show us rather than tell us
that you completed an assignment we we
are not going to look at any of your
code uh if you come to see the TA or me
and you say my code is crashing please
debug it for us uh for me we will
politely return your laptop to you we
are not in the business of debugging
your code for you we will work backward
with you from your screenshots and
videos if something shows up that is a
Miss okay so how do you show us rather
than tell us as I mentioned at the end
of every assignment you're going to
generate screenshots and YouTube videos
if or or videos if you would prefer not
to leave a digital footprint you can
upload those images and videos directly
to Bright space and not leave anything
on YouTube imager Reddit that's
perfectly fine all
good uh that's fine if you do want to
leave a digital footprint if you want to
put stuff up on Reddit imag or YouTube
that's fine as well you would uh put
stuff on imager and YouTube which
obviously generates links you would
create a Reddit post I here's my
solution to assignment one and in that
Reddit post you would put the links to
your images and videos and then finally
you take that Reddit link and embed it
back into bright
space option a option b both are fine
with us okay and so when we just put
that Reddit Link in bright space that's
the association between our name and the
post exactly because when you submit OB
all we really care about is your
submission in bright space obviously
that's non anonymized we know who it's
coming from so the reason for all the
online stuff is we can see each other's
work and com good point yeah so why why
why would you submit something online so
that everyone can see your submission
and you can see everyone else's as I
mentioned last time you're working your
way through these assignments and
ultimately a final project on your own
but I would I would encourage you to
socialize your work along the way here's
my solution to assignment I my robot
seems to be limping it's falling down
everybody else's robot uh that I see
here on Reddit is not falling down does
anybody have any suggestions I'm hoping
that you can generate a little bit of
dialogue on Reddit or whatever online
space you want to use that's perfectly
fine so there are are 64 of you taking
this course and there will be anywhere
from a dozen to several hundred people
also shadowing you just on the net
obviously all the assignments are on
Reddit I post that we're running
evolutionary robotics yet again this
spring and people will follow along at
their own pace so some of the quote
unquote students you might be
interacting with in the subreddit are
not necessarily in this course that's
why you might choose to submit your work
online but again completely
optional all
good okay a couple other housekeeping
notes um uh if you missed the first few
minutes of class on Tuesday or you are
newly enrolled in this class and you
missed Tuesday's lecture you can go back
uh and find the recording of Tuesday's
lecture and all the logistics are
described there how this course runs
yeah
okay so walking around continue to walk
around the schedule uh here's the quiz
posted for the undergraduates which I
posted uh Tuesday around midday
hopefully all of you took that quiz by
11:59 p.m. here's the quiz for The
Graduate students uh as I mentioned
here's the recording here's the reading
from last time and as you can see all of
the undergrads you're working on
assignment one some of you may have
already finished that graduate students
you should be working working on
assignments one and two which are
due uh at 11:59 p.m. this coming
Monday one additional detail about
submitting your work on bright space
which I didn't know about on Tuesday is
uh it's forcing you to upload a file my
apologies about that I see that most of
you just uploaded your screenshot or a
video that's perfectly fine we will be
very forgiving with what you submit
this week I'm hoping that when I set up
assignments uh three and four you you
don't have to upload a file you should
just be able to upload a Reddit link or
if you want to not leave a digital
footprint you should be able to directly
upload screenshots and videos we will
see I will work on that and report back
on
Tuesday okay anything else about uh the
mechanics of the course you want to talk
about okay uh let's talk about
assignment one and two itself uh for
those of you that have tackled
assignment one you might find that it's
surprisingly easy there's not a lot of
steps um in assignment one you're
installing the underlying physics engine
that we're going to be using for this
course which is called pybullet that's
it's just a publicly available physics
engine hopefully over the years we've
worked out all the installation issues
for Mac Linux uh Windows has any run
anyone run into any installation
issues a couple of people okay um so if
you're having installation issues please
please please come and see the teaching
assistant or myself as soon as possible
so we can resolve that hopefully for
most of you installation was very smooth
sailing and off you go yeah okay that's
the first part of assignment one the
second part of assignment two is now now
making sure that you did install the
install the physics engine correctly by
creating a m a minimal simulation at the
end of assignment one you should have a
window that pops up on your laptop that
shows you a virtual world that has
nothing in it except an infinite flat
plane how many people have got that far
so far most of you okay great all right
so obviously that's the foundation we
want to just make sure that we have our
physics engine up and running and
assignments 2 through 10 you're going to
be adding stuff to that simulation and
then eventually wrapping that simulation
in an evolutionary algorithm it's going
to be evolving robots in that simulator
all good okay anything else about
logistics questions comments okay so we
are going to finish lecture one uh now
and then we will move on to lecture two
a short history of AI I see that I've
already fumbled with the numbering
scheme here I will fix that after class
okay off we go okay I think this is as
far as we got uh last time uh we were
talking about the Y of evolutionary
robotics or the why of Robotics in
general why create autonomously train or
design autonomous machines one reason
for doing this is the four
RS the four not the four RS the four D's
typically we want to create robots to do
jobs that are dull
distant distant meaning on another
planet dull dirty distant and I'm
missing one of the four RS danger
Dangerous thank you those are the four
D's dangerous dull dirty and distant
okay okay so we did a little bit of the
why last time let's do a little bit of
the
what this what what this what on the
screen at the moment was one of the
questions for the quiz last time my
apologies we didn't get to it on Tuesday
okay four things generally speaking you
need if you're going to autonomously
evolve autonomous machines we obviously
need the task environment itself what
ultimately is the D what is the Environ
in which we're going to deploy a robot
to do some job obviously we need the
robot
itself that robot is an autonomous
machine it's not remote controlled which
means at every point in time our
autonomous machine regardless of whether
it's a physical robot or a virtual Robot
Operating in a virtual world is going to
be receiving sensory
information it's going to be using that
brain or that artificial neural network
like your biological neural network up
here that's going to take in sensory
information transform it somehow maybe
combine it with past experience and past
memories and then send commands to the
motors so that the robot can act that is
what allows it to be
autonomous how exactly should the
robot's brain transform sensation into
action that is a notoriously difficult
process to solve so in this course we
are not going to solve that problem
manually we're going to let an
evolutionary algorithm solve it for us
okay here's an old experiment one of my
old
experiments where you can sort of see
this evolutionary process sped
up what's the task environment here very
briefly the ground with a blue cube in
it a ground with a blue cube in it okay
not not very difficult not not very
complex that's the environment what do
you think the task is we're already
evolving this robot to do something
picking up the cube pick up the cube
right not that complicated okay so
there's the task environment you can
obviously see the robot you cannot see
its brain or its artificial neural
network but at every frame in this video
the robot is receiving sensory
information that is flowing through an
AS n inside the robot and thatn is
outputting commands to the motors which
cause the robot to move yeah so you can
see task environment see the robot can't
see its brain and you obviously can't
really see The evolutionary process I'm
showing you snapshots during this
evolutionary
process as I mentioned uh last time in a
nutshell what this evolutionary
algorithm is doing at in this experiment
is evolving not just one brain but a
population of different brains slightly
different ways in which the robot
transforms sensation into action we have
a whole stack of these brains each one
is downloaded into the virtual robot one
after the other which causes the robot
to do a bunch of different things such
as kind of pick up the block or fumble
the block for each one of those brains
that's downloaded into the robot The
evolutionary algorithm is watching the
virtual robot and assigning a score how
well does the robot do at lifting the
block the brains that cause the robot to
do a poor job of picking up the block
those brains are
deleted the surviving brains which
caused the robot to do a slightly better
job of picking up the block survived the
evolutionary algorithm randomly chooses
some of those surviving brains makes
copies of those brains and introduces
slight changes to those
brains which when those New Brains are
dropped into the robot cause the robot
to interact with its environment in a
slightly different way something like
this The evolutionary algorithm
designing the architecture of the brain
the weights of the brain or both great
question so the question is is the
evolutionary algorithm designing the
architecture of the brain how many
neurons how few neurons which synapses
connect which neurons together that's
known as the architecture of the brain
or the architecture of the neural
network or is it tuning the strength of
those synapses or those connections
between neurons do we have a fixed
architecture that we decide and the only
thing we let the evolutionary algorithm
do is Tinker with the strength of those
connections we're going to get to that
some of you have not heard these terms
before the short answer is in this video
it's the latter we have fixed the
architecture actually we I ran this
experiment years ago I set the number of
neurons inside the brain of this robot I
said which neurons are connected
together with synapses and the only
thing the evolutionary algorithm is
doing is strengthening or weakening the
C connections between these
neurons which for our purposes today has
an effect on the robot it causes it to
react to its sensory stimulation in
slightly different ways
so far so
good are you also setting like what the
what success like what parameters go
into like a successful attempt yes I am
setting what goes into a successful
attempt so obviously we're trying to
stay still at the 10,000 foot view in
this first week of the semester we're
going to spend the whole rest of this
course talking about all these four
components but it's a good question so
if we dive inside the evolutionary
algorithm which as the name implies it's
an algorithm it's just a computer
program somewhere in that computer
program is a mathematical
expression that the evolutionary
algorithm takes and applies to each one
of these short video sequences that you
see and that equation is going to result
in a single number which is how well the
robot did at picking up the block and I
wrote that success equation which is
known as a fitness function Fitness
function it's a function that takes in
the behavior of the robot and gives back
a scaler a single floating Point number
how well did the robot do it lifting the
block yes question here how long did
each attempt take how long did each
attempt take let's see so I ran this
experiment in 2008 so it's getting
pretty dated uh it was a standard
desktop machine at that time you can see
how long each attempt takes in the video
it's it's about a second half a second
for each attempt on a 2008 machine I
think it took longer to run on the
machine than it actually takes to
visualize it one of the things we're
going to talk about when we talk about
physics engines which simulate our task
environment are different ways of
measuring time when you're looking at
this video you're looking at animation
time right I could run this animation
faster
slower there's simulation time which is
how much time is passing inside the
simulation from the robot's perspective
which is a little bit
confusing simulating that short video
sequence on a laptop takes it about a
certain amount of time in wall clock
time it t it took my 2008 desktop a
certain amount of time to generate that
half second video I probably confused
most of you at this point right so
there's time from the perspective of the
the robot the time it takes the laptop
to run the simulation and the time I
choose to run the resulting
animation more questions do you think
with today's technology would be like an
instant it's way way faster you're all
going to get to this point uh I think at
about assignment four or five and you'll
see for yourself absolutely no matter
how crappy your laptop is in 2023 it's
going to run you're going to be able to
simulate something of this complexity
way faster than what you're seeing right
now okay so again in a nutshell I just
walked you through an evolutionary
algorithm simulate a whole bunch of
things evaluate how well the robots do
delete the bad ones make randomly
modified copies of the good ones what
you're seeing in this video on the left
I'm not showing you any of the bad ones
at every generation in The evolutionary
algorithm every time I repeat this
process of simulating every bot deleting
the bad ones randomly copying the good
ones that's one generation then we do it
again and again and again so what you're
seeing each half second video here
you're seeing the best brain in the
population during that generation so
what you're watching is actually
snapshots over evolutionary time where
you're seeing the the Champion the one
that has the highest floating point
value of Fitness in the population at
that time so far so good okay so what's
happening is it working looks like it's
getting better looks like it's getting
better yeah it's getting there getting
there okay what I'm going to show you in
the next video is exactly the same
experiment but we're going to speed
things up even
faster we're going to plot evolutionary
time on the horizontal axis here and I'm
going to use a big G to represent
Generations on the vertical axis I'm
going to plot Fitness which is how good
the robot is doing at grasping the
object I'm going to pause for a moment
here what you saw in the video on the
left is the champion the best robot in
the in the population in the first
generation second generation third
generation fourth generation fifth
generation it's getting better and
better Fitness is going up and up it's
getting better and better at grasping
the block until at some point and this
is some arbitrary threshold of Fitness
that I set I said once a brain evolves
that causes the robot to do the job well
enough
something's going to happen um if we
only see the best brain in each
generation is there how do you determine
like the dimin point of what a larger
population would to great question so we
could use 100 brains we could use a
population of 200 brains 300 brains and
maybe this curve Fitness would increase
faster this is a good point we'll come
back to this when we talk about
evolutionary algorithms you mentioned
diminishing right there's a diminishing
return after a while generating or
evolving a larger and larger population
of brains only gets you so much more
Fitness it's a really good point we'll
come back to that when we talk about
evolutionary algorithms for our purposes
today you've seen in this left video
that at some point the robot does a good
enough job of picking up the block and
when it does in this
experiment something changes
what happens at the the point in
evolutionary time when Fitness is
sufficiently
high the the changes get pretty small
the changes get pretty small not uh kind
of moving the block moving the block so
the code is set up the evolutionary
algorithm is set up so that when a brain
appears in the evolving population that
causes the robot to grasp and pull the
block onto its back the code makes a
change to the task environment it places
the block a little bit further away from
robot what do you think happens to this
particular brain that was successfully
able to lift the block when the block
was close to the robot what happens to
that brain a little less
this absolutely and you don't see this
in this video because I'm skipping ahead
so quickly
Fitness function stays the
same of all the brain that causes the
robot to grasp the object and lift it so
over this entire experiment which we
haven't finished describing yet the
fitness function stays the same it's
always the
same what is changing over evolutionary
time is the given population of brains
again we're not seeing those but those
are evolving and changing over time and
every once in a while we're also
changing the task environment question
it's not necessarily obvious that you
would want to change the task
environment is that because like that's
how we observe Evolution happening in
our world is that sort of as our as we
evolve our environment changes because
we evolve that's a fantastic question
right so if I can boil down your
question to why why did the experiment
in this case choose to put put this
additional detail into this experiment
why keep moving the block slightly
further away from the robot you can
probably guess from watching this video
on the right ultimately what we want the
robot to do which is go get the trash
can pick it up and then do something
with it right so why didn't we just
start the experiment with putting the
block really far
away we didn't do that why
not
because it would have been a harder
first lead to get it to move all that
distance rather than to get it to do
something closer to it absolutely right
I'm going to administer you I've changed
my mind I'm going to give you a final
exam in evolutionary robotics right not
a very smart thing for me to do you're
not ready for it yet right so there's an
additional twist in this experiment
which again we'll talk about uh later in
the course it's called
scaffolding
we do this all the time with our
children we make their environments easy
so they can start to learn a task and
then once they start to demonstrate
competence we make things a little bit
more difficult we put training wheels on
the bicycle and once we as parents or
caregivers see that they're getting
better at riding the bicycle take off
the training wheels so once you've kind
of move started moving the block away
and I'm sure it's going to move in other
way later does it still perform well on
like the initial that's a great that's a
great question so the one the robots
you're seeing in the right hand video if
we were to put them back in the original
environment would they do a good job and
the short answer is sometimes yes
sometimes no how might you improve this
evolutionary algorithm so that they
quote unquote don't forget they're still
good at the original thing that is a
fantastic question it is still an open
question in robotics and Ai and we'll
probably come back to that as well great
question super
difficult okay so what's happening over
here when we move the block Fitness
drops but evolution finds a new set of
brains that cause the robot to pick up
that block then we move the block again
and this is what you're
seeing tell me about the evolving
behaviors
what's going on here let's put on our
scientist
ha give me some
observations it's like always able to
grab no matter how far ahead it is yep
okay so it's doing kind of what we said
right it's able to grasp the block even
as the block moves further and further
away what it seems to be doing ising
together two activities in that attempts
to
grab it's it in this case you can
actually see the strategy that evolution
is converging on which is as you say to
chain together or connect stepping with
grasping that behavior is not specified
in the fitness function the only thing I
asked for was grab the block and lift it
onto your back it's a it's a side effect
of the evolutionary process you could re
re rewind this evolutionary type uh
evolutionary tape and evolve brains
again and you may or may not get that
specific
behavior other
observations I'm just
curious maybe this is how you drew the
graph but it seems like even when you
change the toas environment the uh
Fitness never drops back to zero oh okay
so I what I'm showing you in the video
on the right I'm sorry I should have
explained that you're only seeing the
behaviors you're seeing all the quote
unquote successful ones the ones that
got Above This Fitness threshold you're
not seeing all of these some of these do
actually drop back down to zero and it
has to kind of improve others don't drop
as as far there's some interesting Rich
evolutionary Dynamics going on but in
this first week we're hiding those
details from you um in the real world
it's sometimes like instead of survival
with is surv wasn't good enough ah okay
so like did you notice when you were
running this that like before you
reached the success parameter you would
get different ways of picking up the
block and moving and then that would
guide the rest of the iterations that's
a yes okay so that many good points in
there first point that you brought up is
that an evolutionary algorithm and
biological evolution is not an
Optimizer major rookie mistake is to
think of these processes as optimizing
meaning they find the best solution
human beings are wonderful wonderful
creatures as we all know we are not
perfect what what biological evolution
is and an evolutionary algorithm is a is
a
satisficer be good enough be good enough
to survive long enough to produce
Offspring and feed them and you're good
in this simple case be good enough to
grasp the block and lift it onto your
back this good beyond that we don't know
we don't know even in this simple
experiment what the optimal behavior is
for all we know this robot could
actually leap directly to the block and
lift it really really fast onto its back
who knows maybe that's the optimal
solution we don't know and in most
experiments we can't know
did you ever consider like penalizing
the extra movement in some ways to try
to like get rid of the like to to like
make it more efficient in its movements
great point so we could add to the
fitness function a penalty actually
minus sign we could remove we could
remove points if the robot as you
mentioned is moving
inefficiently what else could we
penalize aside from extraneous
motion taking a longer of time take a
longer amount of time to get there what
else what else is the robot doing that
in retrospect maybe we didn't want it to
do we want it to grasp and lift the
block flip it flip it okay yeah maybe
this is a very fragile scientific
instrument right we've dropped carefully
scientific instrument onto the surface
of Mars and we sent this Rover later and
it's throwing scientific instruments all
over the place right it's it's a good
way to solve the problem get the object
onto its back as quickly as possible but
in retrospect maybe not what we
wanted okay this is I would argue the
biggest problem in Ai and Robotics at
the moment it's known by different names
in this course we're going to refer to
it as perverse
instantiation The evolutionary algorithm
is instantiating what we want it to do
as a behavior
but it's in in many cases and I could
see some of you laughing which is the
point it's instantiating it in a way
perversely in many ways as you'll see
with your own evolved robots evolved
robots are like teenagers they do what
you ask them to do but in the way in
retrospect you absolutely did not want
them to do it it's hilarious when we're
watching virtual creatures not so
hilarious when we're trying to train an
autonomous vehicle to move in a densely
populated area it's also known as the
value alignment problem it's usually
known as the value alignment problem in
AI in robotics it's usually known as
perverse instantiation they generally
mean the same thing we want a robot to
obey not just what we said but the
spirit behind what we
said okay one last observation I hope I
can extract from all of you about this
video on the right what else strikes you
about this
I
don't function
of up especially in the first video the
robot kept lifting up it back right leg
okay every time it grabed and I don't
know if that would have destabilizing or
it
wasil or great question so there's a
little hitch in the back right leg is
that helping Locomotion is it hindering
and it's something that the evolutionary
algorithm just hasn't ironed out of the
locomoter gate yet there's a gazillion
of these things that pop up all the time
all that matters from The evolutionary
algorithm's point of view is that the
behavior is good
enough okay in the interest of time
you'll probably notice that there is a
diversity of solutions and again some of
them are a little bit more perverse than
others one of the uh one of the
advantages of evolutionary algorithms
compared to a lot of other AI uh optim
ization methods is diversity The
evolutionary algorithm can give you back
not just one solution to your problem
but a large number of them that are
diverse that is diversity is one
possible way to start to combat perverse
instantiation hopefully in that diverse
set of solutions there are one or a few
that do that cause the robot to do what
you wanted and in retrospect the way you
would have wanted the robot to do it
tricky thing to
do okay let's move
on okay I I interspersed uh some of
these cool videos with a little bit more
Logistics so my apologies we're going to
do a little bit more and then back to
robotics okay attendance again it's a
bit of a pain I collected data over the
years if you can't read uh if you can't
read the uh the text here that's fine
we've got percent grade on the
horizontal axis every Point here
represents a student who took this class
in 2015 16 17 and 18 for a total of 164
students the vertical axis is how many
classes they missed the higher the point
is the less time they spent uh in class
and you can see that the students that
did well tended to come to class so come
to class okay all right uh a little bit
about me um as I mentioned I actually
work in this field of evolutionary
robotics I love teaching this course
it's what I spend my time doing uh I
went to school as a computer science
undergraduate uh in Canada I went to go
work for a year and found that my happy
place was not in a cubicle so I came
back to school I did a master's degree
uh in England in a master's program
called evolutionary and adaptive systems
the acronym for this course is e a y
the easy course it is absolutely not an
easy course for the undergraduates that
are taking this class and you're
considering a master's program and if
you find anything we're talking about in
this course interesting this program
still exists I highly highly recommend
it uh I did my PhD uh for four years uh
in Switzerland uh working in a robotics
lab um thus evolutionary robotics I
spent three years after my pH HD working
in a mechanical engineering an aerospace
engineering department at Cornell where
we were developing replying some of
these evolutionary ideas to some of the
things NASA cares about and we'll come
back to that in a few weeks and I've
been here uh since 2006 okay all right I
would usually ask about you when I
started this course there were 12 of you
and we had time to go around the circle
and do that we now have 64 of you I'm
afraid we don't I hope I get to know
some of you better in office hours come
see me and let's chat expectations I ask
you a lot of questions in class I can
see that you're already very responsive
so great feedback so far Common Sense uh
you have to submit assignment one and
two bright space is forcing you to
upload a file upload a file will work
around it common sense okay as I already
mentioned last time regular but not
necessarily perfect attendance you're
going to do a lot of coding in this
class you're going to do a lot of coding
especially towards the end of this
course use GitHub teach yourself GitHub
work hard keep on top of things and
you'll be fine okay I expect
memorization of key Concepts I have
absolutely no way to enforce this
there's no closed book final exam uh I
don't think there's any need to put you
through that painful uh process do as we
go try your best to absorb the key
Concepts job interviews do tend to be
closed book a lot of the interesting and
high-paying jobs that are out there you
got to in the interview you have to
stand at the Whiteboard and talk about
what you did for example in this class
and you got to be able to Rattle off
some of these Concepts and connect them
to whatever you did in this class okay
you're going to have lots of
opportunities as you've probably figured
out to be creative in this class
especially in your final project I
expect uh at this level a lot of self-
learning if you don't know GitHub teach
yourself GitHub we're going to use a lot
of different python libraries in this
course Matt plot lib numpy
scipi uh we're not going to we're not
going to go through them in class if you
come across something you don't know
there's this thing called Google get on
Google Google it and I'm pretty sure
there'll be a thousand tutorials for you
to make your way through okay positive
attitude when working with me the Tao
fellow students goes without saying okay
I already mentioned this uh things you
cannot expect why is my program clashing
crashing I don't know you don't know um
as I just mentioned we're not going to
help you learn python or installing
software you should be able to work that
out with one exception if you're having
problems installing Pi bullet this week
come and see us and we will help you
with that yeah
okay uh okay um what you can expect from
me or the TA when you come to office out
hours we will help with specific
programming questions but we'll assume
you've kind of tried your best to figure
figure out an answer online first I
leave this example here as a historical
artifact um the first students who took
this course had to program everything in
C++ a couple years after that it was
half C++ and half python now it's all
python assuming this class still exists
5 years from now I'm sure it'll be
something completely uh different
that connects with the last thing you
can expect in this class is that there's
going to be an emphasis on Concepts
rather than specific tools programming
languages GitHub Google Drive all these
things they come and go but Core
Concepts like Evolution scaffolding
these ideas have been around for a very
long time and they will continue
probably to be around for a very long
time I do not expect you in this course
as we start moving through the course to
remember every detail of every
experiment we see that's not my point uh
that's not my goal in this course it's
to use all of these examples you're
going to see to reinforce some of the
Core Concepts in this class that we're
going to see over and over again in
different
guises okay uh conceptual issues so
there's certain conceptual issues that
might arise in in prog in coding up
these assignments that you haven't seen
before like
objectoriented uh programming for the
grad students we going to get to
differentiable physics engine starting
in week six there are some pretty hairy
conceptual things underlying some of
these things those things I love to talk
about come come to office hours and we
can discuss okay clarification about
assignments and Projects please
absolutely ask me two or three of you
already started in on assignment one
right after class on Tuesday and you
immediately found things that I did
wrong thank you for stumbling over those
things on behalf of your fellow students
I fix them as quickly as I can and send
out an announcement to the rest of the
class you can uh you can teams DM me you
can email me you can raise your hand at
the beginning of class doesn't matter
please raise any clarification issues
we'll try and ire those things out as
quickly as
possible okay we've already kind of
talked about this all of these all of
the assignments are embedded at the top
level in bright space they direct you to
Reddit you're generating images or
videos you can dump them here if you
want or and then embed them in Reddit
submit your Reddit link back in
brightspace or you can go brightspace
Reddit generate images and videos and
embed them right back in your bright
space
submission okay as promised um at
starting in week 11 everyone will get
started on a final project I'm not going
to read all of this as I said last time
you can at the end of your 10
programming Pro uh projects 10
programming assignments you can pick
some aspect of that code base and
elaborate it you could make your Fitness
function more complicated grab the block
lift it onto your back and walk as far
as you can with the block and then maybe
put it down or evolve to climb up some
steps or what have you so I put some
links to a few uh assignments a few
final projects from previous year
students uh here's a best of a highlight
[Music]
reel
e
okay all right turn the lights back on
all right um I I challenge you to count
the number of examples of perverse
instantiation you see in this class you
should already be on to your second hand
right at this point okay just a typical
example of the kinds of things that are
possible within four weeks of effort one
of the things um that I want even if
you're already starting to think about
final projects uh a challenge in week 11
is going to be coming up with an idea
that's doable within four
weeks few of you are going to have a
good way to estimate that come and see
me in the TA or send us a message about
what you're thinking and we'll help
calibrate that for you yeah one of the
other things I want you to remember from
that highlight reel is you're going to
have two minutes or maybe two and a half
minutes during the final exam period to
convince us
that something actually evolved the best
way to do that is to show a before and
after video here's what some random
brains cause the robot to do in your
task environment and here's what some
evolved brains cause the robot to do
hopefully most of you within about five
or six seconds could see immediately
that these particular students
evolutionary algorithms were working
that's what the TA and I are going to be
looking for in those two or two and a
half minutes that's the most important
thing okay
questions so far so good all
right okay all right now I promise I'm
done with all the logistics of the
course back to the why now we're going
to talk up till now we've been kind of
talking about the why of Robotics in
general why are we going to evolve
robots rather than to use all the other
high-powered uh machine learning
Machinery that's out there um I'm going
to show you four different reasons the
first one is that creating a controller
or a brain for a robot is a very
difficult thing to do programming a
brain for the robot so that it always
transforms sensation into action in the
right way for the robot to do whatever
it is you want it to do super super hard
now admittedly there are they do they
now exist machine learning algorithms
that are not evolutionary algorithms
that can also do this for our purposes
we're going to use Evolution to do this
just as an illustration of how hard it
is to actually program a brain for a
robot I want you to consider the nonap
robot which you see uh in the bottom
left I mentioned that I was at Cornell
before here and we were working on a
project for NASA this was one part of
that
project the non-ipad is called the nped
because it's got nine legs as you see in
the bottom left but they're non legs
nine legs that are kind of arranged in a
nonobvious
way the non-ipad is built from two
Stewart platforms here's a gif of a
Stewart platform in Action a Stewart
platform as you can see has a bottom and
a top and the bottom and the top are
connected together with 1 two 3 three
four five and the sixth is behind there
six
Pistons there at every frame of this gif
there are six numbers going to those
Pistons telling the Piston whether to
compress or
extend as those six Pistons expand and
contract they cause the upper and lower
plate to move and twist relative to one
another that's a steuart platform I
don't expect you to remember all the
details of a steart
platform we take one steart platform we
attach it end to end there's one steart
platform there's the other one and we
have the non AED each Steward platform
has six Pistons if we have two Steward
platforms that means we have 12
Pistons imagine you were in control of
the non AED we want this non-ipad to
walk from the left side of this wooden
cage to the right side side of this
wooden cage as fast as
possible let's assume that you're going
to actually manually program a
controller for this non-ipad at every
let's say one second one second two
seconds 3 seconds at every second you
got to figure out which 12 numbers to
send to those 12
Pistons I'm going to make things easier
for you you can choose either a number
you can choose either minus one which
tells that piston to compress so in this
example here um someone is written down
a matrix which tells the second piston
or the second motor attached to the
Piston to compress in the first second
and then in the second second to expand
the plus one up here tells the first
piston to extend stay extended at the
second second stay extended at second 3
four five compress at second uh the 6th
second and so on so we've simplified
things greatly for you here the brain of
this robot is a binary
Matrix okay what is
it we want the robot to move from the
left side of the wooden cage to the
right side of the wooden cage what
should the 12 Pistons
do
this is not a rhetorical question can
you do
it I feel like you might want all of the
ones like on the right to expand okay so
all the ones at the right here which for
our purposes let's assume this is the
front of the non-ipad so we want all
these six to expand okay you want those
ones to contract as the left ones expand
maybe and kind of like slink along okay
so maybe do something like a Slinky
right ex expand the front part of the
body shrink the back shrink the front
expand the back expand the front we're
going to talk about biomechanics in a
few weeks time what I think you're
describing is actually a really good
guess because it is the simplest form of
motion in the animal kingdom it's known
as
peristalsis an earthworm as it pushes
its way through the Earth the front part
of its body expands and pushes the Earth
out of the way then it sort of holds the
sides of that new tunnel with its body
shrinks its back which means since it's
anchored at the front the back part of
the earthworm comes forward the front
part contracts the back part expands the
front part extends forward and pushes
into the Earth then expands the back
part contracts and that pumping motion
is known as peristalsis a really good
solution which might potenti work for
nonap that peristaltic strategy was
discovered by Mother Nature a very very
long time ago and she's repurposed that
strategy many many times in many many
different species it's in you also you
also peristal not to move we use these
things to move where is peristalsis in
you is it like your intestines and stuff
down them absolutely right the moment
moment you swallow something the muscle
the muscles in your throat comp expand
and contract and push not earth out of
the way but food down into your stomach
okay bit of a digression okay great
guess as you can get as you can imagine
since there's so much lead up to this
it's not so simple as that okay here we
go I'm going to turn off the lights
again
for
that's the best we could do by
hand that's us this is the evolutionary
algorithm
okay there were hundreds I'm going to
turn the lights back on those were the a
few of the hundreds and hundreds of
different Gates that this uh particular
robot came up
with uh the evolution we did this
experiment in
2004 uh we couldn't run Electronics we
couldn't run everything on board the
robot so we're evolving the brains on a
laptop and then the brain would reach
through an ethernet cable to control the
12 Pistons inside the belly of the
nanopet it's a little hard to see
there's a little pressurized Air
Canister which comes from a a paint gun
paintball gun which is supplying
compressed air to the 12 Pistons uh
myself and another graduate student sat
next to this robot in its cage for 18
hours and I my job was to hit enter
every 30 seconds after the evolutionary
algorithm had tried out one brain on the
robot it's quite an experiment I still
uh still have flashbacks okay all right
so just a reminder yes question um why
is there nine legs why is there nine
legs use three of them good point hint
this is a a prototype for NASA why the
nine legs so that in a non environment
one of the things that keeps NASA
Engineers awake at night is what happens
if a Rober slips on some scree and ends
up on its back as far as we know there's
no one there to put it back on its
wheels or legs the nped in theory should
be able to roll down a pretty long slope
and no matter which way it lands it can
keep
going was there like a gyroscope on it
to deter no gyroscope no sensors this
was a very stripped down initial
prototype as I mentioned we're just The
evolutionary algorithm was evolving
matrices was evolving binary matrices
that just control how the robot moves no
sensors okay all
right okay typically speaking most
nonevolutionary
algorithms which we're going to I'm
going to uh use different synonyms for
now training algorithms things that
train the robot by the by that very verb
training it implies that the body is
fixed and the algorithm is only altering
the brain of the robot that is as I
mentioned before not what evolution does
evolution doesn't train animals or
plants with fixed body plans Mother
Nature is continuously tinkering with
body and brain we're going to see some
evolutionary algorithms in which the
evolutionary algorithm is only tinkering
with the brain the real interesting
stuff in my opinion will be towards the
end of the semester where we see
evolutionary algorithms gradually
tinkering with more and more of the body
and brain of the robot yeah okay as of
uh Monday this was probably sort of the
state-ofthe-art in autonomous robotics
this is Google's Palm eobot which has
been the beneficiary of a lot of
computational resources from Google to
train the heck out of this machine so
that it can do things like obey the
command bring me the green star uh bring
me the green
star
okay I don't know how carefully
orchestrated this video is I don't know
how close this particular robot is to a
practical reality as you can imagine the
big AI compan compies keep a lot of this
under very close that knowledge under
very close
WS what would happen if the command we
issued to this particular robot was I
think I dropped something behind the
drawers inside the cabinet can you
please look inside and see if there's
something back there I obviously cooked
this example so that the body of this
robot cannot obey from what I can see
from the video its arm and hand is too
big to get back there and its camera
which is up here he's probably not able
to do it now with enough training maybe
this robot could figure out how to go
grab a dental mirror and put it kind of
under and sort of do something like this
but what happens if the robot comes back
and says I know what you want me to do I
can't do
it imagine that robot goes and say say
that to a 3D printer and the 3D printer
prints out a little small robot the big
robot grabs that little small 3D printed
robot and drops it behind the drawers
yeah what should be the body of that
small robot so that it can get behind
the drawers and be recoverable by the
big
robot I don't know that's I my personal
opinion about where evolutionary
robotics could fit into
the future landscape of AI and Robotics
there are going to be a lot of cases I
think where it's going to be useful to
design automatically design in silico a
robot's body and train it print it and
deploy it out there into the world we'll
see to be
seen
okay again uh apologies you're going to
see a lot of my old experiments for now
here's a very old experiment of mine
where the evolution algorithm is
evolving body and brain the fitness
function is what in this
case what did I ask the evolutionary
algorithm to evolve the robots to
do dance maybe they're doing a good job
of
that walk somewhere walk somewhere walk
in which
direction into the distance away exactly
there's a bilaterally symmetric robot
the left side of its body looks like the
right side of its body but it didn't do
what we wanted it to do so it's going to
be
deleted then there are these things that
are not bilaterally symmetric the left
side of the body does not look like the
right side of the body but it is doing
what we want it to
do more perverse instantiation again
we'll talk about biomechanics one of the
good ways to move in a particular
Direction in an efficient way is to be
bilaterally symmetric the left side of
your body looks like the right side of
your body one of the fun things about
working with evolutionary algorithms is
they often ReDiscover things that mother
nature already discovered several
billion years ago things that work
sometimes the evolutionary algorithm
comes up with things that mother nature
never discovered like
Wheels we'll see some examples of that
later okay so two reasons why you might
want to uh evolve robots rather than
train them as Nate mentioned uh a couple
minutes back one of the common
approaches in AI is to fix the
architecture of the brain of the robot
the the robot has a bunch of neurons
represented by circles here and then
it's got a bunch of synapses which are
represented by these arrows connecting
these neurons together if you make these
connections stronger or weaker you alter
the way you alter the way in which
sensation is transformed into
action but how do we know that six
neurons and 1 2 3 4 5 six 7 8 how do we
know that six neurons and eight synapses
is the right architecture for the brain
of the robot short answer is we don't
know that's another non-intuitive thing
so maybe we expand the evolutionary
algorithm so it also starts to Tinker
with the AR architecture of the neural
network we're gradually expanding the
stuffo broadening the stuff that the
evolutionary algorithm can Tinker
with think about Google's palmy robot
that I just showed you no matter how
sophisticated a neural architecture we
come up with for that robot it can't
reach behind the
drawers so maybe we expand the
evolutionary algorithm further so now it
can tinker
not just with the strength of
connections between neurons it can also
Tinker with neural architecture and it
can also Tinker with body plan which is
what biological evolution does it
Tinkers with all of these things
simultaneously okay another rationale
for why we might want to evolve robots
rather than just fix their bodies and
train their brains is Mother Nature has
given us an example that Evolution can
produce very competent and generally
safe autonomous
machines okay A little detail about
evolutionary algorithms and machine
learning uh there's a lot of jargon I'm
going to try and throw as little jargon
at you as possible one of the big
challenges in robotics is lack of
supervision and here's what I mean by
that here's yet another experiment of me
trying to evolve a bipedal robot to
walk and after a few
steps after a few steps it falls over
inside uh inside the brain of that robot
where did the mistake arise why did it
fall over after six steps how do we work
backward from the behavioral failure to
identify where the problem
is um GNA guess that like it sees that
either like the gate isn't completely
correct with like walking and it makes
it less stable or that it just like you
could invalidly think that it just took
too many steps and it already achieved
the goal by taking less steps okay yeah
it's a it's a good start maybe the
evolutionary algorithm can identify
something in the gate that was wrong the
robot took too big a step and then it's
it became unstable and fell over but we
we can't stop at Behavior we have to
work backward to the cause of the
behavior the way in which the robot was
transforming sensation into action to
fix that Upstream problem so that the
next time we simulate the robot it'll
take more
steps okay in the interest of time the
answer is it's super hard to do it's
hard to go back and say this number in
the brain of the nonap was the problem
or this particular synapse should have
been slightly stronger or slightly
weaker and if it was the robot would
take more steps it's hard to have a
supervisor inside the computer it's hard
to have an actual piece of code called a
supervisor that watches problems with
the behavior and knows where the problem
is it supervises by saying fix this
super super hard problem
it's kind of an open problem it's on the
brink of being solved until it's solved
well Evolution doesn't care Evolution or
the fitness function just gives back one
number this brain caused the biped to
take seven steps this brain caused the
robot to only take six steps Evolution
doesn't know or care why this brain
produced slightly better Behavior than
this brain it just throws this brain
away and makes randomly modified copies
of this
one evolutionary algorithms require no
supervision that's another reason why
we're using an evolutionary
algorithm so far so good
okay okay we're almost done lecture one
we'll finish with this video the
interest of time I'm going to speed it
up a little
bit here's an evolution AR algorithm
that's tuning the muscul of the
body and the brain of the
robot this is a much more sophisticated
physics engine uh that we're going to be
using in this class this is just to give
you a sense for what's
possible another way to visualize the
evolutionary algorithm how progress is
being made
when this video came out in 2006 there
was an immediate meme that went viral
which is if ever there was a video that
summarized a case of the Mondays that
that's it okay all right all right again
my apologies we're a little bit behind
we're gon to move on we're going to
spend the next six
minutes introducing
uh starting a very short history of AI
it's fascinating subject there could be
an entire course on this so my apologies
we're going to go very fast in this
history of AI we're going to go back
we're going to start a couple centuries
in the past with kohito
ergosum who said
it I promised you there'd be some
philosophy in this class here it
is
cart you'll remember as I mentioned last
time that going forward you're going to
see a few slides in which uh there's a
prompt for you to annotate this is from
Rene decart's discourse on method it is
one of the most beautiful and subtle
arguments in all of Western thought so
I'm going to do some violence to that
subtle argument Now by boiling it down
into six bullet points in English Okay I
think therefore I am let's just say that
we could rephrase this is as do I exist
am I real hard to actually know if you
think about it but for dayart there
seemed to be something asking the
question answering the question is hard
but something if the question is there
something must be asking the question so
for Renee that thing whatever that thing
is he was is going to call it the eye
that's the thing that's asking the
question for Renee this IE was probably
the soul something like uh the soul that
for deart he could be sure he had
confidence that it existed because it's
the thing that's asking the question
that's what he could be sure of this
stuff that seems to be there that he
couldn't be so sure of so for deart
there seemed to be this division between
I and everything else including the
body this Crea this conclusion that mind
or Soul or self or I is separate from
this thing which we'll call a body is
separate is known as cartisian dualism
it basically carve these two things in
half which is also often known as the
mind problem because it causes a lot of
problems when we try and think through
these ideas what could this possibly
have to do with the class on
robotics why would we start a history of
AI
here seems an odd place to
start because we need a mind and a body
for a robot we need a mind and a body
for robot robot the fact that you
phrased the statement in that way is a
legacy of cartisian dualism right we
tend to think of I've already mention
brain and body of the robot I'm I'm
doing it
too I've mentioned already in this class
the field of Robotics and AI what
distinguishes these two
Fields body one one field AI throws away
the body I don't care about the body the
thing that really matters is this thing
robotic is say no no no no no you can't
throw away the body it matters the very
structure in the way we try and create
intelligent machines as a global Society
is fund hasn't fundamentally been
influenced and biased by cartisian
thought okay got two minutes left so
we're going to jump from 1637 to 1936
we're going to jump forward 29 9 years
hopefully for most of you we're in a
little bit more familiar
territory this is the turing machine
anybody want to Hazard a one or two
sentence description of what a touring
machine is it's a model for General
computation it's a model for General
computation what are the basic building
blocks of a touring machine there's like
a pointer a big TI and a set of
instructions excellent y three things
okay so a set of instructions which is
the tape that's the input to the turing
machine the turing machine moves over a
tape or moves the tape through itself
and reads stuff off the tape internally
cogitates and then writes stuff back
onto the tape when we think about our
own behavior we often think about
sensation coming in grinding away at
that that incoming sensory information
maybe mixing it with our past
experiences and memories and then and
producing actions as a result we are
also influenced in thinking about how we
think by
touring and the way we should go about
thinking about robots like us it's
obvious robots should take in sensory
information grind away internally on
that information and then produce
actions as a result there are other ways
to think about intelligent action this
is only one way most of us tend to fall
into this way of thinking because of our
Western inheritance this and this okay
the only point I want to make here with
this before we break is that there are
some very old ideas in Western thought
that influence the way we think about
trying to create useful and safe
machines maybe ultimately the way to
make safe and intelligent machines is to
militate against these VI
come up with new ways of approaching the
creation of intelligent machines maybe
some of these old ideas are actually
holding us back we'll come back to that
later thanks very much you have quiz
number two due at 11:59 p.m. tonight
undergraduates you're working on
assignment 1 graduate students you're
working on assignment 1 and two I'll see
you all again on Tuesday thank you


--- Evolutionary Robotics course. Lecture 03. AI history, contd..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everybody let's Dive
Right Back In welcome to week uh two
just a little bit of logistics and
scheduling to get us oriented where
we've been where we are where we're
going uh those taking the class for
undergraduate credit you submitted
assignment one by last night by 11:59
p.m. all good I know there are a couple
of you that are still struggling with
installation issues it's my fault not
yours we have tried over the years to
iron out all the installation issues
with pie bullet but there is always some
combination of platform and operating
system that doesn't seem to agree with
piy bullet my fault if you are
struggling and you have not struggling
with installation issues and you have
not talked to fya or myself please
please do come and see me we have a work
around you can do everything in the
browser uh it's all good okay any other
other questions about the assignment so
far so far so good okay so as promised
uh today I will just say a very few uh
words about the assignment that you're
now working on which is assignment two
for the undergrads and graduate students
if you're running ahead that's perfectly
fine you can see I've hot linked all the
way up to assignment uh four in the
subreddit at the bottom of each learning
module as you've now probably figured
out there's a link that points to the
next learning module and then the next
one and the next one feel free to run
ahead uh if you want um that's perfectly
fine okay so hopefully by assignment one
we've got all the installation issues
out of the way uh you've been able to
you've been able to download and uh be
able to call the pybullet library which
is the physics engine we're going to be
using for this course so by the end of
assignment one you should in essence
have a blank page on which you're going
to build up everything else in the
coming assignments and particularly in
assignment two you're going to start to
implement uh links which is the
particular term that this particular
physics engine uses for the objects that
make up the body parts of your robot and
the objects that make up the task
environment in which your robot operates
lyns is a horribly chosen word for this
um think sausage links not links in a
chain so the sausage links are the
objects themselves in assignment three
you're going to be adding joints to your
simulation which like your knee joints
and elbow joints are the things that
connect links together very confusing
right joints link links together I
didn't come up with these terms so we'll
do the best we can yeah okay all right
um we're going to talk about in
assignment three when the undergraduates
get to this uh next week we're going to
spend a little bit of time talking about
joints because again this particular
physics engine Pi bullet uses a
particular way of uh referencing
positions of links and joints in space
which can be a little bit confusing so
next week when we talk about next
Tuesday I'll talk a little bit about
absolute and relative coordinate frames
for the undergraduates that are running
ahead and get to assignment three and
start to implement joints
please go ahead and do so if you want if
you get confused don't worry all will be
clarified on Tuesday okay that's
assignment three um in assignment four
for The Graduate students you're pushing
on and adding another necessary
component to your robot which are the
sensors there are various kinds of
sensors you can add to the physics
engine at this point you're dealing with
pi bullet which is the physics engine
itself links and joints are things that
are built into the physics engine as the
name physics engine implies it's not
necessarily about robotics so everything
you're going to be doing from assignment
four onward is adding stuff or you're
coding up stuff or adding stuff to the
physics engine to enable the physics
engine to simulate
robots okay all right so assignment uh
for you're adding sensors after that
assignment five you're going to be
adding Motors these are the things that
are going to apply forces to the joints
to allow your robot to start moving and
in later assignments you're going to be
adding
neurons to your robot and synapses to
your
robot for now all you really need to
know is that the neurons and synapses as
the name names imply is going to be the
brain of your robot neurons and synapses
are going to connect the robot sensors
to its
motors which allow the robot to which is
going to allow your robot to sense think
act sense think act sense think act and
around and around and around we go so
over the next month or so for the
undergraduates you're going to be
gradually adding these pieces when you
get confused you get stuck in the weeds
pull back and remember that you're
implementing these the six basic
components that make up your Ro robot
links joints sensors Motors neurons and
synapses okay just to sort of Orient you
where you're heading any other questions
about the assignments before we push
on okay uh just to remind you again uh
you're not submitting code to us you're
not bringing broken code to the TA or
myself we don't know why your code isn't
running you're submitting uh screenshots
and videos at the end of assignment at
the end of assignment two you should
have the 25 Towers looking like this as
you can see I'm moving the virtual
camera a little bit just allowing the
teaching assistant to be able to see
that everything is implemented correctly
right this is what we're looking at to
assess whether or not you've implemented
uh your assignments correctly or not as
I mentioned last time as I mentioned
last time uh you can upload an mp4
directly to us if you don't want to
leave a digital footprint if you don't
mind leaving a digital footprint take
your screenshot your resulting video
Drop It on YouTube send us the YouTube
link or embed the YouTube link in
YouTube send us the Reddit link we don't
mind I think I've set up the assignments
now where uploading uh uploading a file
to brightspace is optional so URLs is
fine Direct uploads also fine are the
links and Joints the only physical
objects in the engine yep great question
so are the links and Joints the only
physical objects the answer is actually
it's only the links so what you're
seeing in this picture here should be 25
towers with 1 2 3 four five however many
that is let's say 10 block 10 links per
Tower so there's a total of 250 links in
that simulation there are no joints as
you can see all of the cubes are moving
independently of one another none of
them are connected together with
something that holds those pair of
objects or pair of links
together does that answer your question
oh so the so the links are like the
separate objects which are yet to be
connected to the main body object uh
okay good point so let let me try and
clarify this again links is what you're
looking at is a piie bullet simulation
we're not at we're not at robots yet
different physics engines simulate
physics in different ways in P bullet
this particular physics engine every the
only building block the only thing that
you can construct stuff with in py
bullet are
links okay and this point we're building
up the environment of the robot it's not
even a robot yet it's just stuff we're
putting into the virtual environment
which in this case is 25 towers with 10
links per Tower we've ask the P bullet
simulation here to simulate
250 separate
links these are the physical objects as
you can see their their cubes you can
also add uh links that are spheres
rectangular solids prisms we're not
going to deal with any of those in this
class everything's going to be made up
of these uh
links when we go to make the robot which
you're going to do as you move forward
the robot is also going to be made up of
links you're going to make a link called
uh lower right arm upper right arm lower
left arm upper left arm you're going to
start to build up the robot out of links
in the exact same way that I'm building
up this set of towers out of independent
links as
well in the case of the robot we're
going to then start to connect these
links together with joints and now we're
going to have some segmented creature
that's made up of a bunch of links
connected did with
joints so the links are physical objects
the joints are not physical objects
they're not anything you're going to
actually see in the pie bullet
simulation they're just going to joints
are going to constrain the movement of
the links the objects right luckily my
lower arm cannot move towards the door
while my upper arm stays here that's
what my elbow joint is for it constrains
the relative motion of my upper and
lower arm it keeps them together that's
exactly what joints do in a physics
engine as well they connect pairs of
objects together and they allow those
objects or those links to move but that
movement is constrained they can't move
like this they can't move like this they
can move like
this that's a little bit more than I
wanted to say about joints I'll go back
through that again next to Tuesday but
just to sort of get this all clear in
your head the building blocks basic
building blocks in the physics engine
are links all of this stuff is going to
help you to build your
robot any other questions about that yes
kind of just using those components how
like powerful is just using those those
links and Joints like can you make like
a hand that functions like a hand just
using those okay great question so how
uh how complicated a body plan can we
make could we make a human hand there's
250 parts there are a lot of bones in
your hand but I'm pretty sure there's
less than 250 so yes you can make a
pretty complicated robot body plan if
you want the limitation is not the
physics engine itself it's your laptop
your device this takes as you can
imagine quite a bit of computation and
memory that's usually the limiting
factor in this class uh the robots
you're going to be making have no more
than nine parts so we're going to keep
things pretty simple but if you want to
make a human hand and arm as for your
final project perfectly fine and a
reasonable idea for final project other
questions no
okay all right so that's assignments
back to uh lecture material we're
pushing on and hopefully going to almost
finish up uh our introductory section
for this course uh we started last time
in on a short history of AI I hope we'll
get through all of that today and we'll
move on to lecture three about embodied
cognition again history of AI
fascinating topic we could use a
whole uh course to talk about this last
time we started in the
1600s with Renee deart who unfortunately
for all of us uh operating in the
western world
cleaved body from brain and that idea
has permeated all the way down to the
present day where we as a society are
now trying to create intelligent
machines some of us are doing it with AI
and some of us are doing it with
robotics body no
body okay we then jumped 300 years
forward into the early uh early 20th
century we talked about Allan Turing and
specifically the Turing tape um the
Turing tape summarized more or less we
have this thing this machine turing
machine that can move back and forth
across an infinite tape and it can read
stuff off the tape so this machine can
take
input this machine can then take what it
just read and combine it with its own
internal state it can do a little bit of
internal
processing and then the tape can do do
something the tape uh the machine can
move the tape forward and back or the
machine can move itself forward or
backward along the tape so this idea of
input first input first then processing
then output is another uh inheritance we
have from the past in the way we think
about computers input processing and
output it also has affected the way we
think think about ourselves you are all
sitting here looking at this slide
listening to my voice perhaps paying
attention perhaps combining it with
stuff I said a few minutes ago or last
week and then I see some of you actually
writing stuff down input processing
output it's obvious that that's the way
machines should work it's obvious it's
the way we work so it's obvious that's
the way we should make
robots as you will see as we continue on
this course it is absolutely not that
obvious seems that obvious that's the
way a lot of our intellectual ancestors
have thought about this problem before I
invite you I challenge you to try and
think about the nature of intelligence
differently in this course and I will
help you do that as we go okay let's
keep moving forward let's jump another
20 years forward in to uh 19 in the
1950s so 67 years ago just down the road
from here in New Hampshire uh a bunch of
researchers uh wrote a proposal to the
government and they asked for a few
thousand from the government to con to
uh convene a two-month 10-man study this
is the
1950s um and they wanted these
researchers wanted to study this
interesting idea of maybe now that these
things called computers existed thanks
to Turing and others uh during the 30s
and 40s now that there were these new
things called computers maybe we could
make them intelligent so they asked for
funding to get together over the summer
and study this idea this proposal was
funded they did get together what was it
they were proposing to do they wanted to
meet uh at Dartmouth and proceed on the
basis of the following conjecture so
they had an idea and they wanted to
spend two months testing it the idea was
that every aspect of learning or any
other feature of intelligence that
humans have can in principle be
described precisely we can write down
exactly what human thinking is and these
were mostly mathematicians if we could
write something down very very
formally then the rest is easy the rest
is engineering then we could simply
create something to simulate it inside a
computer okay so they said we're going
to try and do we'd like to try and do
this and we'll make an effort to make uh
machines that again do all these things
that make up intelligence use language
form abstractions and Concepts basically
do math solve kinds of problems that are
now only reserved for humans and also by
the way will uh make these computers
also get better at doing these things on
their own we'll show them how to improve
themselves or learn we're pretty sure
that we can make a good dent in this
problem if one or more of these problems
are tackled by a carefully selected
group of scientists guess who this
carefully selected group of scientists
were the 10 guys the 10 guys that are
writing this proposal exactly right
should take us about two months and
we'll make intelligent and learning
computers at about the same level as
humans this conference actually did take
place how did they do not so good not so
good okay these were some pretty bright
fellows as we'll see uh in a moment not
so easy at the beginning in the
1950s again thanks to some of the things
that had happened in the 30s and 40s
suddenly there were these new things
called Adam bombs there were these new
things called computers holy cow you
could make some pretty powerful computer
uh some pretty powerful technology in a
very short period of time so making
smart machines in the ' 50s also should
be no problem 67 years later we are
still working on this problem and we can
argue in this course whether or not
we've made any significant advances what
humans be counted as maches ah great
question are humans Turing machines I
will leave that for you to think about
yeah this is not a psychology course
we're going to do a little bit of
Neuroscience I hope what you see in this
course will cause you to think
differently about your own intelligent
behavior and you can come to your own
conclusions about whether or not you or
we are intell are touring
machines okay why am I telling you this
particular historical detail it's a
reminder that even from the beginning
and even some very very very intelligent
people under estimated how difficult it
is to make machines intelligent and I
would personally argue that
underestimation is still happening okay
so who were these 10 people here they
are anybody recognize any names on this
list it's okay if you
don't um John McCarthy John
McCarthy how do you know John McCarthy
why does that name ring a bell if you
remember I don't remember exactly I've
just heard him in other areas of science
okay John McCarthy was the one that
actually came up with the term
artificial intelligence we can argue
about who is actually the founding uh
the founding person of AI McCarthy is
definitely one of the candidates Turing
probably
another
is is that a different McCarthy from the
like cold war yes not that McCarthy yes
I don't know if they're related good
good question other names you recognize
on this list
anyone how about Claude Shannon any
mathematicians here I see somebody
nodding their heads who is Claude
Shannon information Theory founder of
information Theory we live in the
information age what exactly is
information it turns out that you can
actually formally Define what
information is and uh Claude Shannon did
it in his master's thesis not not bad
not bad okay some other names on this
list as I mentioned John McCarthy was
actually the organizer the one who wrote
this proposal and invented this term
artificial intelligence uh Marvin Minsky
went on to co- found the MIT AI lab
which is still in existence next time
you're in Cambridge MTH
stopped by the stata center uh that's
where the MIT AI lab is more or less the
mecca for all things uh AI unfortunately
Professor Minsky was involved with
Epstein um it's an unfortunate uh case
worth mentioning Claude Shannon father
of information Theory uh Herbert Simon
um was actually an economist but did a
lot of important work uh in AI back in
the early in the 1960s received a Nobel
priz for it uh Herbert Simon's very last
doctoral student Professor Chris skolka
you might have taken a class with him
here at UVM so there's a connection uh
there okay just some interesting names
if you're interested in the history of
AI absolutely go and Google these these
names okay um few people involved at the
beginning there are obviously many many
more people involved in AI today not
everyone has the same goals so what is
it that we as a community of those who
study Ai and Robotics what is it that
we're trying to do you'll find all sorts
of different goals I would argue that
one way to organize all these goals is
into sort of scientific goals number one
and two and then number three is an
engineering goal so one of the things uh
folks try to do by creating Ai and
Robotics is to try and actually
understand biological systems we just
talked about neurons and synapses if we
think we understand neurons or synapses
or we have questions about how they
might work why don't we try and code
them up and simulate them inside an
intelligent machine and see how well
that intelligent machine does so one way
of thinking about robotics is a robot is
just another scientific tool like a
microscope or a telescope it allows us
to ask and try and test new questions
about the nature of biological uh
intelligence so you might for example
come up with the following scientific
hypothesis or question how do simple
animals translate the detection of light
into phototaxis phototaxis is the name
for the behavior of moving towards a
light source so you might have an idea
of what kind of neurons and synapses do
that you code up those neurons and
synapses into a simple uh into a simple
Lego
robot and if the Lego robot is able to
successfully move towards the light
maybe that's evidence in favor of your
hypothesis maybe that is how animals
actually perform phototaxis you can use
a robot to
instantiate a scientific hypothesis I
think this is how animals do Behavior X
so put that mechanism into a robot robot
and if that robot does behave your X
that's that suggests maybe at least
that's one way to do it not necessarily
how animals do it or organisms do it but
it's some support for your hypothesis
okay if you can do that then we then we
start to have animals and machines that
are sort of doing similar behaviors
maybe we can abstract away all the
biological details of how Mother Nature
does it neurons and synapses are
fantastically complicated machines but
maybe we can abstract away some of those
details same thing with robots we can
abstract away transistors and capacitors
and silicon chips and all the rest and
get to the nitty-gritty what is the
basic mechanism that allows a machine to
act intelligently that mechanism may be
embodied in a biological way in this way
or it might be embodied in a mechanical
away in this way right we're trying to
get away get get rid of all the details
and understand intelligence in
principle okay if we can do that if we
can abstract away all these biological
details again maybe we can then take
that basic idea and instantiate it or
create it in machines that's more or
less what you're doing in these first 10
assignments yeah okay there are others
working in Ai and Robotics who have
other goals that don't sort of fit into
this framework I again invite you over
the uh span of this course to come up
with your own goals why are you here why
are you interested in intelligent
machines what do you hope to
achieve okay moving forward in time
again continuing our AI history here
moving into the
1960s uh Joseph weisen bomb between 64
and 66 introduced the Eliza program this
was a uh an electronic psycho analyst
which caused shock waves shock waves
through society when it was published
because suddenly you had a computer that
could help people with their mental
problems um I am feeling terrible Eliza
would respond almost instantaneously
with why do you feel terrible this was
shocking to people at the time it was
most everyone concluded in 1966 that
that was it for Psychotherapy all the
human counselors were going to be fired
and replaced with machines this is it
these researchers had been working on
this problem for 10 years at this point
so it had taken longer than expected but
now now it's been solved go play around
if you don't believe me go play around
with Eliza this is it we now have
computers that are as smart as a
psychotherapist that's about as smart as
you need to be right that was it does
this social phenomenon sound
familiar
okay public perception of AI is a tricky
tricky thing how did Eliza work Eliza
had about 200 300 lines of code which
was basically just this huge hairy messy
if then else if then else nested set of
if then else statements that was looking
for particular combinations of verbs and
nouns and subjects and objects and if it
found that pattern it would just
rearrange the nouns and verbs and Tack
on a question mark at the end you can
actually go play around with Eliza on
the web somewhere it's pretty good it's
amazing what you can do with 200 or 300
lines of
code okay all right we're going to just
jump backwards a little bit uh to the
1950s we talked about touring uh Alan
turing's turing machine an abstract
depiction of a minimal computer Turing
is more famous of course for the Turing
test as shown
here
sit
down I'm kind of nervous when I take
test just please don't
move I already have
sh that's the hotel what where I live
nice place I guess that part of the test
no just warming up that's all it's not
fancy you're in a desert walking along
in the sand all the test now yes you're
in a desert walking along the sand when
all of a sudden you what a desert
doesn't make any difference what desert
is completely hypothetical but I my be
maybe you're fed up maybe you want to be
by yourself who knows you look down you
see a tauris it's crawling toward ttis
what's
that okay lights's coming back
on okay here's someone uh conducting the
touring test this individual uh who is
receiving the test is going to fail the
test in a few minutes but that's not the
worst thing that happens in this
particular scene it's a little bit more
unfort fortunate for the person who's
actually administering the
test where is this clip
from okay good mandatory homework if you
have not seen this movie this weekend
that's mandatory homework okay okay
touring test all joking aside there was
a lot of arguments in starting in the'
40s into the 50s about what exactly is
intelligence we want to make intelligent
machines we need to somehow formally
Define what it is okay let's formally
Define
intelligence tricky it's very tricky
again arguably we're still working on
this and we may or may not have made any
progress on just defining what
intelligence is Turing believed that we
would never be able to formally Define
intelligence so better instead to
operationalize it operations actions we
know will'll know it when we see it he
formulated the idea of the Turing test
you hide a computer behind a screen you
hide a human behind a screen and you
allow a human to talk to whoever or
whatever is behind the screen and if the
human asking the questions cannot tell
whether or not they're talking to a
machine or a human being then that
machine has passed the Turing test and
that's it that's the definition of
intelligence for most people that's not
very
satisfying seem like a satisfying
definition to
you doesn't feel very
good I feel like it brings up other
question about like why is it that we
can
decide
goes the exact same question before
which was is intelligence what is
intelligence why is it that is it about
our brains that even DET that's it
exactly right so if if you pass the
Turing test all of you so far have been
acting relatively intelligent you've
been asking great questions most of you
have passed the quiz I assume most most
of you are going to pass the assignment
I'm giving you the touring
test throughout the spring you all seem
to be
passing how do I know what what I can't
Define what it is that actually makes
you intelligence It's Tricky it seems
the Turing test seems slippery it evades
actually formally defining what
intelligence is yeah I was I feel like
gbt definitely like you know if I was
having a conversation with ch gbt I
would probably somewhat believe it was a
person and I definitely don't think it's
intelligent
okay okay I'm missing that slide yes so
for a lot of people it seems that chat
GPT has passed the Turing test therefore
at least according to Turing and the
Turing test chat GPT is intelligence is
intelligent period we're done again for
a lot of people not very satisfying
somehow isn't there also like this thing
where humans try to put Humanity onto
like different animals or different
objects so it makes it so that like
certain certain like algorithms like
this that respond in a similar way to
like how you would hear other people
respond they have like some sort of
similar feature to humans which makes it
seem like they're intelligent because
people just think that humans are
intelligent a great point right so the
person administering the test is also
somehow involved in the test itself you
mentioned this uh human bias to project
human qualities or that we tend to see
human qualities in nonhuman things like
animals like in chat GPT lyan replicants
what is this human bias called there's a
name for
it anthropomorphizing anthropomorphizing
anthr human promiz imposing the the
shape or the form or the behavior of
humans on things that don't have it so
we're biased as well this is what makes
defining
intelligence difficult we're sort of
part of the equation yeah so it's all
kind of very confusing I don't think
we're going to come up with any answers
today all I'm trying to emphasize is
that this is a confusing thing to talk
about also I think it's interesting like
the chat GP stuff because like different
people have different opinions on it
learning language is like you learn all
these like formal rules and then you
actually go to like the country where
they begin it's completely different
absolutely absolutely right Chachi PT is
like someone or something that's trying
on English right seems pretty good at it
actually but there's some idiosyncrasies
that seem not a little bit off okay one
last point and then we'll move on
Emily I know recently a lot
of
question
Des asking compter okay I just been
hearing that a lot recently I and the
fact that a lot of people have coded
into those maches that they're not
allowed to in in response to
our okay don't
know yeah it's a great point so there
there's a a new idea that if you ask the
machine straight up are you a machine it
has to give you an honest answer it has
to confess that it's machines we're now
talking about has to the machine has to
do it now we're moving from philosophy
into uh uh into policy maybe we should
regulate these machines so that they
have to admit whether or not they are a
replicant if we don't do that maybe this
is the kind of problems we're going to
run into in the years to come right that
is a very important question there are
obviously a ton of important policy
questions now uh open AI sort of caught
Everybody by surprise by deploying a
machine that seems to pass the Turing
test spectacularly well what do we as a
society want to do with that reality
we'll come back to those sets of
questions uh again and again in this
course okay let's push on a lot of
people had a problem with turing's test
one person in particular that had a
problem with this was the philosopher
John surl I know you can't read the text
in the back of the room no problem I'm
going to uh describe this to you so John
surl came up with his own thought
experiment this is a hypothetical
situation surl believed that this
hypothetical situation
disproves the Turing test it proves that
the Turing test does not measure
intelligence here we go all right here's
the hypothetical
situation we have a room we have a door
and there's a slot in the door the
people outside the room cannot see into
the room inside the room is an English
speaker who does not who cannot speak or
cannot read Mandarin cannot understand
or write Chinese the people outside the
room are native are fluent uh in Chinese
they write down in Chinese a question
and they pass that question written down
on a piece of paper through the slot in
the door the human speaker inside the
room gets that piece of paper looks at
it and it's just a whole bunch of
squiggles it means absolutely nothing
it's a whole bunch of
indecipherable uh
squiggles they turn to this huge book
inside the room this book is written in
English so the English speaker can
obviously read this book and the book
says if you see this set of squiggles
followed by this set of squiggles and
this set of squiggles take another piece
of paper and write this sequence of
squiggles on it if instead you see this
set of squiggles write this set of
squiggles and pass it back through the
door this book is a huge huge huge set
of if then else statements so far so
good surl argued that you could in
theory make such a book it would be very
very very very big but you could do it
so that any question that the Chinese
speakers wrote on a piece of paper and
passed through after a few minutes if
they received a piece of paper back from
uh the room that it would be a concise
brilliant uh piercing response to their
question the people therefore outside
the room would be led to the conclusion
that either the room or the person
inside it understands Chinese is
intelligent they've passed the Turing
test but how can this person pass the
test this person is a human so
presumably intelligent but this person
is not understanding
Chinese so we have a system that is not
clearly non-intelligent doesn't
understand Chinese at all but it's
passing the Turing test it's projecting
the fact that it does understand Chinese
therefore according to surl you can have
non-intelligent things things that don't
understand English passing the Turing
test therefore the Turing test is
fed great great question so now we've
moved on from the description of the
Chinese room thought experiment to
possible rebuttal to the Chinese room
that's fine we're going to talk about
that in a moment just remember for our
purposes right now we're viewing the
Chinese room as sur's rebuttal to the
Turing test surl said the Turing test is
not a good way to measure intelligence
for this reason there are challenges to
the Chinese room thought experiment
itself and you've brought up one of them
which is that wait a second the person
in the room is intelligent
you'll notice that in this hypothetical
thought experiment the only thing the
human is doing is looking at symbols
referring to a book doing some pattern
matching finding those symbols and then
doing what the instructions in the book
say does that sound
familiar it's a human in the Chinese
room but it doesn't need to be we could
replace the human in the room with a
computer or the touring a touring
machine and it would we'd still get
exactly the same result the people
outside the Chinese room would conclude
that the touring machine inside the
room is intelligent it understands
Chinese but it clearly
doesn't what's the problem
here um it's not looking at like the
Nuance of returning responses to the
other person it's not looking at the
nuances what do you mean by Nuance here
like if the person is sending a message
through with a particular tone okay like
a tone that's like very sarcastic or
talking about an event that's recent
instead of from the past okay
then you would need to have like like
you would either need to have a book
that has
like 10 or 15 different responses for
any like singular question great point
and that would be like an immensely
large book absolutely we're talking
about a very large book now so maybe the
book right here doesn't quote unquote
understand sarcasm so let's write a
bigger book I'm not I don't know Chinese
I don't know how you write sarcasm into
a Chinese question presumably there is a
way will encode that in the book and now
the Chinese room understands sarcasm did
you have a question or comment I'm just
answering his question about okay so
basically for English Le I talk to a lot
of English native speaking and usually
they cannot understand sasm in our
language got it so do I have the right
to say that you're not intelligent
that's great great point right and also
I have something to say about this sure
um so is intelligence in this case the
ability to learn like recognizing
patterns matching Chinese character with
English because that's literally how I
learned English in the beginning and how
I do SAT exams I just like find some
like pattern in a question and then try
to Ste it through the paragraph that's
how I do the English test I mean it's
just beginning later I improve my
English and that's not how I do that
anymore or is it the case here the abil
the ability to speak the language okay
like we have different typ languages
true that a lot of things involve in
intelligence for example like reading
body languages and interacting with the
environment so language is not the only
thing that we can use to identify
intelligence great Point okay a lot of
good points in there let me highlight a
few of them you mentioned learning so
the touring test and sir's Chinese room
has says nothing about learning it just
assumes that learning has already
happened the book it already exists and
it's just execution at this point we
could argue that the room is missing
learning it doesn't take into account
learning you mentioned body language
somebody mentioned sarcasm there's lots
of other parts to understanding a
language that we as humans feel are
important I would assign you as optional
homework go back and think about the
Turing test in the Chinese room and see
if you can add those things to the
thought experiments I'm showing you the
original formulation of both of these
thought experiments that didn't contain
these subtleties I think you were next I
think in this case tones and sarcasm
doesn't like it's okay to make mistakes
because that happen all the time in real
life over text or letters or whatever
sure but I think it's just the format of
the medium that's causing a mistake and
might be more human to to make mistakes
yeah maybe we put uh we put some random
numbers in the book from time to time do
this from time to time do that make
mistakes intentionally maybe we add in
emojis if you see emojis that then do
something different all of these
subtleties that you're all pointing out
if surl were here he would probably
argue fine add them to the book yes this
book is going to become huge but we
don't care book can be as big as you
want for surl there was a book that was
big enough that would capture all of
these things that you're talking about
eventually I feel like that's like the
of exist just like oh yeah it'll just be
really big and it could exist but like
how big how big is Big infinitely large
like how much how much what if it took
infinite time for like or some
ridiculous amount of time for some like
I feel like that's the argument almost
breaks down because it could sort of Go
off into this like infin
okay y almost get true so there are
there are hundreds and hundreds of
rebuttal of the Chinese room and I love
that some of you are rediscovering them
so we're going to talk about just a few
of them and then we're going to move on
in the interest of time you've
identified another one which is okay
maybe maybe you could make a book that
would trick the people into thinking
that the person inside the room passes
the Chinese room but how big should that
book be I'm just going to add to that
you are all engaged in an intelligent
conversation with me at the moment and
from my perspective you're all passing
the
test how are you doing it what's going
on in here is it this or is it something
else if it is this if your skull inside
your skull is basically this this big
book with this little thing that looks
stuff up in it how big how big is it
thanks to Neuroscience we actually have
an answer to that for most uh adult
humans you have about 10 to the 11
neurons inside your head and you have
about 10 to the 14 synapses more or less
in your head no matter how you count
those are pretty pretty pretty big
numbers
still doesn't answer whether or not you
are a Chinese room again somebody asked
this at the beginning of today's lecture
it's up to you to decide I am not trying
to convince you one way or the other I'm
just trying to show you some of the
ground that's already been trodden by
those before you was there a point in
back great okay so let's end the Chinese
room discussion with that how are we
defining understanding Sur said this
thing does not understand Chinese full
stop that's an assertion he's not
proving that he just uses that as an
axiom or assumption for his thought
experiment this thing does not
understand according to surl and it
passes the Turing test therefore the
Turing test is flawed because it's too
easy there are things that do not
understand that can pass the Turing
test it's up to you you to decide
whether surl was
right this person understands English
they do not understand Chinese maybe the
room as a whole is understanding
Chinese seems a crazy statement to
make how can an inanimate object sorry
the room plus this person plus the book
plus all the actions that the person is
doing inside the room that whole system
understands does an individual neuron in
your head understand does an individual
synapse inside your head
understand most people would answer that
question with no or maybe it they do a
little bit do you as a whole do you as a
whole understand what I'm saying right
now I can see some of you nodding yes so
what's the
difference this thing doesn't understand
this thing doesn't understand the slot
in the door doesn't understand the door
doesn't understand the masonry that
makes up the room doesn't understand but
the system as a whole maybe understands
for surl the answer was no system
doesn't understand
either which is tricky for surl because
if the room as a whole doesn't
understand then how can this thing
understand sirl said I don't know but it
does we do we do understand this thing
doesn't we are special okay one last
point and then we'll move on um is there
a difference from like something being
intelligent versus like projection of
whoever made it intelligent is there a
difference between something being
intelligent and the thing itself not
being intelligent but it's just a
projection of the person's intelligence
who made
it depends on your definition of
intelligence which is historically
difficult no one has a good definition
of intelligence so what you asked is a
great question but your question is
predicated on the term intelligence
which is
undefined makes all of these discussions
difficult okay let's keep going uh let's
move forward the Chinese room was 1980
let's move to the mid
1980s um we're going to talk now about
Valentino brenberg brenberg was a a a
neurophysiologist meaning he studied the
physiology of brains not human brains
but usually uh fruit flies most of you
probably live in student housing or you
have recent memory of student housing uh
if you leave rotten fruit or any rotten
food out for a while after a while there
are these teeny teeny tiny flies all
over the rotten food those are fruit
flies super super small inside a fruit
fly is the fruit F's brain brenberg
studied those brains if there were uh a
piece if there was a rotten apple back
in the far corner of this room and I
opened up a jar with fruit flies in it
eventually they would fly over there and
in a few minutes they'd all be covering
the Apple how do the fruit flies find
fruit in the 60s and 70s brenberg
colleagues were writing papers arguing
that the fruit fly was performing
different differentiable calculus and
solving the equations of motion of uh
fluid dynamics to understand how to fly
through air and detect the uh odor of
the apple and swim through the air
Upstream to find the Apple meanwhile
brenberg is looking inside these teeny
teeny tiny brains saying wait a second
how can this teeny teeny tiny thing be
doing differentiable calculus this does
this seems
ridiculous brenberg said we're
overshooting we're coming up with
theories that are way more complicated
to explain fruit fly Behavior than we
need to so brenberg started to think
about what is the simplest explanation
for what's going on inside the brains of
fruit flies that would explain uh
chemotaxis I mentioned uh phototaxis a
few minutes ago moving to towards a
light source chemotaxis moving towards a
chemical Source or a piece of rotten
apple that is defusing uh an
odor he came up with some pretty simple
theories and he boiled these all down
into a book called Vehicles this is not
a scientific textbook it's written more
or less for the general public and it's
actually a series of 12 fairy tales the
first of those 12 fairy tales starts as
follows Once Upon a Time imagine that
there was a very simple vehicle that had
a body which is the little block that
you see here it had a single it has a
this vehicle has a single wheel on the
back and it's got a single temperature
sensor on the front sensor motor
controlling the wheel and one synapse
that connects the temperature sensor to
the motorized wheel so far so good we
dropped this teeny tiny single wheel
vehicle into a pool of
water and what will you see happen uh
you would see that this vehicle will
always move in a straight line because
it's only got one wheel it can't turn
it's going to slow down in cold water
and speed up in warm water why one
temperature sensor connected by one
synapse to one motorized wheel why does
it goes slow in the cold and speed up in
warm
because it's sensing in the front that
when it's warm it's like allowed to go
faster it's how it's programmed to do
okay I'm gonna pause you there it's
allowed to I love that anthropomorphic
language
right easier it's this is just a
physical system we got a temperature
sensor on the front so the temperature
sensor will just register a larger
floating point value when the water's
warmer that larger number flows along
the synapse the synapse is nothing more
than a tunnel it just takes that number
and sends it to the motor the motor gets
that big floating point value and Spins
the wheel quickly so that the machine
goes fast in the warm if it moves
through a warm pocket of water and moves
into a cold pocket of water suddenly the
numbers being reported by the
temperature sensors start to
drop which means lower smaller numbers
are going to the wheel which causes the
wheel to move slower so it slows down in
the cold nothing magical you can make
you can make this at a Lego you can make
a mechanical version of this very very
simple clearly this thing is not
thinking it's just a deterministic
mechanical
machine however Bren writes in his book
what would you think if you saw such a
thing swimming around in a pond and
assume that you didn't know what was
inside you didn't even know it's a
vehicle it's just a thing moving around
going fast in warm water and slowing
down in cold water you'd probably say
it's Restless it doesn't like warm water
it's also quite stupid since it doesn't
turn back to go to the nice cold spot
that it seemed to like before because it
slowed down in the
cold anyway you'd say it's probably
alive because you've never seen a
particle of dead matter move around in
quite that
way wow that's a lot of
anthropomorphization I think it's funny
that he says it's probably quite stupid
there but then kind of says but it is
intelligent you know where it's like
something can be what what we call like
intelligent but no nowhere near like a
level of arm intelligence where is you
know we think about like the large
language models as doing things that we
can't answer but we don't think of them
as super intelligent great great point
right okay so good comparison to chat PT
let's keep going in chapter two uh
brenberg says Once Upon a Time imagine
that there were actually two different
machines vehicle uh
2B which has the following properties
instead of temperature sensors let's
replace the temperature sensor with uh
photo sensors photo for light again so
on the front of vehicle
2B it's got two photo sensors one front
left and one front right it's now got
two wheels and two synapses one synapse
connects the front left sensor to the
back right
wheel the second synapse connects the
front right sensor to the back left
wheel these two synaps Es are crossed as
you can see so these are contra lateral
connections we starts to throw in some
neurophysiological terms Contra meaning
across across the center line of the
body of the robot in your brain you have
a lot of contralateral connections the
wires coming from your left eye connect
to the back right of your brain and vice
versa
okay if you were to chase this robot if
you took a flashlight and put and shine
that flashlight towards the front left
of the
robot what is it going to
do absolutely it's going to turn left
towards the light Sent Source because at
this moment in time there's more light
falling on the left sensor than on the
right sensor so there's a bigger number
leaving the left sensor than the right
sensor that bigger number travels to the
right wheel causing the right wheel to
spin faster than the left wheel
everybody see that okay which obviously
causes the robot to turn a little bit
towards the light source let's pause our
mental physics engine for a moment the
robot has now turned a little bit
towards the light what happens at the
next instant and time let's assume I'm I
haven't moved the flashlight I'm holding
the flashlight
constant the the other sensor starts to
pick up more light but the robot is also
turned towards the light so both sensors
are receiving more light but the right
sensor is receiving more light so what
does the robot
do it goes straight okay so now the
robot is heading straight towards the
light source let's pause our mental
physics engine again for a moment what
happens at the next instant in
time both equal so it just go
straight if it's facing if it's facing
the light both sensors are receiving the
same amount of light so they're both
sending numbers of the same magnitude
along their two synapses which cause
both Wheels to
spin so it'll continue to go straight
and what else starts to happen right
it's accelerating because the light uh
because there's more light more light
wheels turn faster gets closer we have a
positive feedback loop it speeds up and
if this flashlight is a naked light bulb
it'll smash into the light bulb and
destroy it this is the aggressor
brenberg writes in his book the vehicle
2B hates light with a passion and will
destroy any light source that it can get
its hands on on does vehicle 2B
hate is vehicle one
stupid is it alive is it
Restless let's keep going we'll do one
more brenberg vehicle this is vehicle uh
2A it's exactly the same as the
aggressor two light sources two wheels
but now we have ipsa lateral connections
same side left sensor attached to left
wheel right sensor attached to right me
wheel in this case I'm going to place
the flashlight to the front right of the
robot what does the robot do in this
case it's going to turn away from the
light it's going to move why
because
one
absolutely right so at this moment in
time there's more light falling on this
sensor which means this wheel is going
to turn faster than this wheel and it's
going to turn away from the light what
happens at the next instant in time
after it's turned away from the light a
little
bit assuming these are omnidirectional
sensors so the light sensor can still
see the flashlight that now is maybe a
little bit behind it it's turned left
and it's turned away from the light
source a little bit it's turned away
from the flashlight what happens at the
next instant in
time it'll keep slow it'll it'll turn
away but it'll start to slow down
because the S the light sensors are now
further away from the flashlight meaning
smaller number
are are emanating from the light sensors
along the synapses the wheels slow down
so I've got my flashlight I've shined it
on vehicle 2A vehicle 2A has turned away
from the light and slowed down now I
start chasing vehicle 2A with the light
source what's going to
happen it's going to speed away from me
and then slow down
until I come after it again this is the
coward it's afraid of light like nothing
else terrified of light does vehicle 2A
fear does vehicle uh vehicle 2B
hate does vehicle one like cold water is
it stupid is it Restless of course not
this is ridiculous why would a serious
neurophysiologist write such a book it's
obvious that the vehicles don't have any
of these
properties now we do we love we hate we
get Restless some of you are bored
looking at your watch we've got all of
these emotional States vehicles
obviously don't it's
obvious
comp responding to stimulus and doing
things are
like controls more
comps
arey it appears like we love hate and so
on the vehicle certainly appear like
they love and hate um there's an
experiment in my the course I study
psychology 101 about uh de construct
human emotion so a lot of psychologist
say that our kind of like label By Us by
the stimulus and not really what
happened inside us so basically they say
that when we Fe and when we happy some
of us have the same physical condition
but we label it differently because of
the stimulus so that's a experiment uh
there's still a lot of debates about it
whether it's accurate or not but a lot
of psychologists say that our emotion
also like language constructed and it's
not something that nature kind like Lael
great great point right so there's a lot
of emerging studies uh in uh psychology
also in Neuroscience cognitive science
in robotics that seem to militate
against our confidence I'm confident
that I love and hate I'm confident that
these things don't it's so
obvious science seems to be suggesting
not I see a lot of hands up which is
great because you're on the chopping
block here right if you think you're
better or different from a brenberg
vehicle prove it we don't have time in
this course to do that why did brenberg
write this book part of it was to ruffle
feathers for centuries if not Millennia
we have been sure we're the center of
the universe we love we hate the sun
revolves around us not the other way
around are we so sure about all these
things
I am not here to argue that you are
nothing better than a brenberg vehicle
as always it's up to you to decide for
yourself but there is a lot of evidence
out there that says it's increasingly
difficult to say how you are different
from some of these
things you certainly do have a lot more
wires inside you than a brenberg vehicle
is that it is that your only you the
generic you is that our only defense we
just have more wires if that's our
defense that's a pretty flimsy defense
okay I want to push on let's continue
into the 1980s while brenberg was
writing his book elsewhere people were
starting to replace the if then Els
programs like Eliza with new programs
that simulated small little bits of the
brain and wired them up in particular
ways and started to see that those kinds
of computer programs that simulated the
brain had some interesting
properties so here's the here's the
inspiration uh we know that brains take
as input sensation and brains send out
commands to our muscles those are neural
networks so let's similarly uh let's
simulate neurons represented by the
circles here and synapses by the arrows
we can do this in an artificial neural
network like chat GPT or other things
running inside a computer where we
Supply the input to the computer program
in the computer and we read out the
answer from the computer or we can drop
one of these computer programs that
simulates neurons and synapses into a
robot where the values arriving at the
sensors are sent into these neurons the
sensor neurons those values flow down to
the motor neurons and those motor
neurons send numbers to the motors that
cause the wheels to turn yeah okay so
that's an artificial neural network
dropped into a robot or an artificial
neural network in an AI
program okay starting in the 1980s um
these artificial neural networks were
starting to show the glimmers of
interesting intelligent Behavior until
someone came along and said these neural
networks can't do anything everything
there's a few things they can't do and
they uh this brought on an AI winter in
the 1990s there was huge funding going
to these neural networks in the 80s
someone sort of showed there's something
neural networks can't do suddenly all
the funding was removed and if any
scientist breathed the word artificial
neural network in the 1990s your funding
was yanked
you can go read about the various AI
Winters and AI Summers they look like
boom and
busts we are currently obviously in an
AI High summer you are not only allowed
in a research proposal to talk about AI
if you don't you're probably not going
to get
funding okay a lot of people like to
think about whether uh winter is on its
way it's a Game of Thrones meme right is
winter on its way back in the 19 early
1990s uh a then famous roboticist
pointed out why these Summers and
Winters were happening many researchers
got caught up in a web of EX increasing
exaggeration so they made promises to
DARPA which is the uh research wing of
the US military they made promises uh to
to DARPA that they would do X Y and Z
but those promises had been much too
optimistic and didn't actually work out
don't tell DARPA that
but DARPA remembers what you promised
the last time so when you go to ask for
money from DARPA again you can't promise
less you have to promise more if I wrote
a proposal right now and submit it to
DARPA DARPA still exists and I said I'm
gonna make a computer program that's
weaker than chat GPT what's the chance
that DARPA is going to give me money
zero right there's this treadmill that
builds up where you have to keep
promising more and more and more until
you as an individual scientist or the
community as a whole can no longer
deliver and DARPA gets fed up with all
this AI hype and Yanks all the funding
hopefully that doesn't happen who knows
so you are all taking a class in Ai and
Robotics in the middle of an AI High
summer we'll see what happens in the
months and years to
come okay this is not a course about
deep learning but uh we couldn't pass
through a history of AI without talking
about why we are currently in a high
summer I mentioned somebody proved in
the 1980s that there was a problem with
neural networks it took a while to solve
that problem that problem was solved in
the late 90s very early 2000s which
allowed researchers to make deep neural
networks input neurons uh here output
neurons here and lots of different
layers in between and they could then
train or teach these deep networks in a
particular away so that if you presented
a picture of a cat the face node the
node that rep recognizes human faces
would not light up but the node that
represents a cat would light up and this
neural network would tell you I see a
cat I don't see a human face if you
instead presented this neural network
with a picture of a human face this
neuron would light up this one would not
and this neuron would light up saying I
see a human face I do not see a cat it
took a lot to get this to work it
started to work spectacularly well
surprisingly well obscenely well in the
late 90s early 2000s and that
realization has gradually spread
throughout the AI community and now to
the general public and oh my gosh look
at all the things you can do with a deep
neural
network this is a non-embodied machine
it has no sensors and Motors this thing
canot not go out and get a picture of a
human face it sits inside a computer
waiting for people to supply images to
it okay as we all know these things work
fantastically well most of the time
here's one successfully recognizing that
it sees a granny smith apple and it
knows it's not looking at an iPod
exactly the same deep
Network now is
99.7% sure that it's looking at an
iPod okay we go back and retrain this
neural network on images like this and
tell it this is an apple not an iPod and
so now when you show it this pair of
images again it says Granny Smith and
continues to say Granny Smith when you
show this picture
we fixed this neural network right it's
fixed how will we know when it's
fixed we never as far as we know there
is no good way to know okay I am going
to argue you to death in this course
that we never can because this is a
non-embodied machine it can't reach out
into the world and push against the
world world and observe how the world
pushes back okay I want to finish this
lecture today so I'm going to skip over
this we're going to end here we're going
to argue that robotics is the answer
eventually embodied machines will be
able to not be fooled by things like
this here is a uh an overview of the
state-ofthe-art or the structure of AI
and Robotics at the moment as I've
already mentioned you can see car iian
dualism in the structure of these fields
itself we've got those on this side
those researchers that believe that
intelligent machines don't need a body
on this side of the line are researchers
that believe intelligent machines need a
body and I'm one of those researchers
you don't need to agree with me I'm just
going to make a case over the spring
that this is it we're going to spend all
our time in this course talking about a
particular branch of evolutionary
robotics
you can go Google these other terms and
learn about these other branches of
Robotics next time we're going to
actually talk about what this term
embodiment means uh you have a quiz due
tonight undergraduates you're working on
assignment two grad students you're
working on assignments three and four I
will see you all on Thursday have a good
day


--- Evolutionary Robotics course. Lecture 04. Embodied Cognition..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone welcome back
let's uh push on can everybody read that
all right it's like an like an ey test
this morning upper case b lower case b
all
good okay all right so we are going to
uh finish up this morning the first uh
uh module of this course our
introduction last time we did a uh a
whirlwind tour of the history of AI
obviously I left a lot of stuff out just
as you just to refresh your memory at
the end of lecture 2 last time you saw
the sort of overview of the all the
different fields that are attempting to
create intelligent machines and you can
relatively easily cleave all of these
different subdisciplines into two
different camps those working on AI that
believe we will eventually create
intelligent machines and that we don't
need a body to get there the other Camp
believe believes that the the root to
creating intelligent machines is going
to require a body somehow embodied AI
embodied intelligence robotics what the
heck does this term embodiment mean
we're going to spend this morning
talking about exactly that any questions
about the assignments quizzes
installation issues pyrro Sim we're all
good okay so here we go as you'll
remember from our discussion about
Turing in the Chinese room last time
very very difficult to Define exactly
what we mean by intelligence so what
we're going to do today to highlight
this idea of embodiment or the embodied
approach to creating intelligent
machines is we're going to look at a
whole bunch of building blocks of
intelligence if we can't Define what
intelligence is maybe we can identify a
whole bunch of the necessary components
that go into an intelligent machine
including us what are the things that
you would expect to see in an
intelligent machine and then how might
we go about uh
instantiating those in those building
blocks of intelligence in a non-embodied
man Manner and then the same intelligent
behavior in an embodied ma manner so
we're going to basically illustrate this
concept of embodiment by looking at
non-embodied approaches to creating
intelligent components and embodied
approaches yeah okay so let's go uh what
is an important thing for humans animals
plants robots drones xenobots if we if
we want to consider them intelligent one
of the things that you would expect to
see is that they're able to recognize
patterns in the world and respond to
them appropriately so let's start with a
very important building block of
intelligence that most people would
probably argue as important pattern
recognition this is one of the early
problems that computer scientists tried
to tackle um going all the way back to
the 1950s and the Dartmouth uh
conference how do we create machines
that see patterns out there uh in the
world okay we can sort of start to
concretize or make this more concrete by
asking the following question how do you
recognize objects in a scene so if we're
to stick a camera onto a robot or feed
photograph s into a computer how might
it start to identify there's a cat in
that image there's a this in that image
there's this particular person in this
image please convince me I'm not that
old who is this particular
person you still all know okay good all
right all right okay so um for you
hopefully the moment I put up this slide
I saw a few of you smile you not only
immediately identified that there was a
human being
in this picture but you identified a
pretty famous and familiar human being
you did it so fast you probably didn't
even realize you were doing it it feels
effortless right I don't see any of you
sweating it wasn't that difficult
hopefully for most of you right so back
in the 50s it seemed like an easy thing
to do this is going to be no problem
we'll either do it during the summer of
1956 or maybe into the fall of 1956
shouldn't take us that long to write a
computer program that if we give it an
image it can recognize whatever is in
that image or even a simpler task just
separate the object of Interest the main
thing that's in the image from
everything else this is known in
computer vision as the image
segmentation problem find the Marilyn
Monroe in the picture or the automobile
or the cat this is now a solved problem
but it's only been solved relatively
recently in retrospect it turned out to
be super super hard it was one of the
most difficult problems in computer
science and here you can see a computer
doing exactly that how does a computer
or an AI program do this it requires
millions and millions and millions and
millions of photographs that don't
include a cute kitty cat and millions
and millions and millions of images of
images that do contain a cute kitty cat
and gradually over time a deep neural
network like we talked about last time
can gradually start to recognize the
difference between these two types of
images those with and without the object
of Interest requires huge huge amounts
of data and computation as hopefully
most of us know that's the non-embodied
approach to solving this problem can we
do this in a embodied way so we're going
to we're going to talk about a a cog
here this is cog the
robot Cog is going to try and solve
exactly the same problem it's going to
solve first of all the image
segmentation problem as you can see Cog
has a couple of cameras here uh and it's
able to Cog is able to see its world can
it identify objects from background so
we're going to we're going to see how
solves the pattern recognition problem
uh uh the pattern recognition problem in
an embodied manner uh optional reading
for today you can go back and read the
original paper that reported these
results but I'm going to give you just
the summary of how this was actually
done the solution first of all in all
embodied approaches is that we're going
to deal with a machine that can push
against the world and observe how the
world pushes back sometimes
that push and observe the result is
going to be literal like in the case of
COG and as we move on in the course and
we look at more and more exotic machines
sometimes that pushing against the world
is a little more subtle or metaphorical
but we've got that feedback loop there
somehow action and sensing the reaction
or the repercussion of our
actions one of the reasons that
non-embodied uh AIS like chat GPT and
all the rest struggle with cause and
effect or causal reasoning the reason
they struggle with it is because they
can't cause effects or they can by
sending text to humans and seeing what
humans type back but it's sort of an
indirect Action Reaction one of the ad
the main advantage of having a body of
being embodied is I can push against my
world and immediately observe how the
world pushes back yeah okay all right
let's see exactly how uh Cog does this
so as you can see from this image Cog
has two cameras uh it's anthropomorphic
we heard that term last time also shaped
like a human being but missing some
parts um Cog only has one arm and one
hand the researchers in this case meta
and Fitzpatrick did something kind of it
seems kind of odd on the surface as Cog
was interacting with its world uh the
two cameras are receiving two live video
feeds they wrote some code uh that
filtered out from those video feeds a
lot of information first of all they
pulled all the color out of those two
video feeds and then they further
reduced every pixel in every frame of
those two video feeds to a binary value
so basically Cog is seeing in black and
white it's represented in the cartoon
here where a zero pixel is everything
the zero pixels are everything that's
grayed out here and a one is everything
that's not gray
out yeah the cartoonists here kind of
just drew in the detail so you could
sort of see you you would know what's in
CG's environment but the only thing Cog
is seeing at this moment in time is a
Big Blob of white or a Big Blob of zeros
and then this
blob of
ones so far so good okay seems like kind
of an odd thing to do they're kind of
they're hobbling Cog in a way they're
removing a lot of information that would
otherwise be available to Cog okay Cog
uh it can see very little it Cog also
knows very little you from your Vantage
Point can see that Cog has two eyes a
body an upper arm a lower arm a hand
there's some fruit in front of COG Cog
knows none of this the only thing Cog
really knows at the beginning is cog
knows that Cog can send a couple of
floating Point numbers three or four can
send them outwards it can generate three
or four floating Point numbers those
floating Point numbers are sent to cogs
shoulder elbow wrist and hand and those
numbers are received by the motors at
cogs shoulder uh elbow wrist and hand
and the motor notti uh the motor says
okay if I'm receiving a large number I'm
going to apply large torque we're going
to see this term over and over again
torque is rotational Force so a big
number means the motor a big number
means the motor is going to really start
to pull on the shoulder elbow or wrist a
small
number uh apply low torque and that
particular joint will start to rotate
slowly so far so good very very very
simple okay at the beginning of this
experiment Cog again knows very little
doesn't know what it's supposed to do it
just sends some random numbers out to
its Motors and its arm starts to move in
this particular example here um CG's arm
starts to move into its field of view
what does Cog see it Cog outputed these
three or four numbers what does it see
more or less
immediately like the outline of a
similar shape that it's looking it sees
an outline of something there's this big
black Lo blob that starts to come in
from its the left hand side of its field
of view everything was Zer and then it
sends three or four four numbers and
suddenly there's this big black blob
that appears in its field of view so Cog
has pushed against the world and the
world has pushed back at this instant in
time so far so good okay Cog is
recording all of this information so Cog
is going to start to learn using this
raw material of
Action Reaction we're not going to talk
about the learning algorithm in COG and
how actually learns we're focusing on
the embodied aspect of this experiment
how Cog is using its body to pull
information out of its
World okay so it sees this black blob
and remember the black blob are all the
ones and those ones are actually I'm
sorry I think I forgot this detail the
zeros in its field of view represent
pixels in which there has been no motion
during the last 10th of a second I'm
sorry I think I missed that detail so
there this computer code that's sitting
on top of the raw video feed coming back
from the cameras sets a pixel to zero if
there was no motion registered at that
pixel over the last tenth of a second
and it paints that pixel with the one if
there was a little bit of motion at that
pixel a tenth of a second ago yeah so at
the moment in my visual field most of my
visual field is quiet there's relatively
little motion I can see a few of your
heads bobbing a little bit there's a
little bit of motion the moment I do
this there is huge optic
flow a vast majority of the Machinery
inside my eye is registering
motion yeah okay so this is these are
pixels that are registering recent optic
flow and these are pixels that are
registering lack of recent optic flow
okay sorry back to the story so far Cog
has just sent some motor commands and
this big black blob appears in its left
field of view and then it stops sending
those three or four numbers what happens
at the next instant in
time the hand disappears from The View
that you said the hand disappears from
The View you know that Cog doesn't know
that we're going to try and use language
from COG point of view from CG's point
of view the big black blob in the left
side of its field of view disappears
everything turns
white okay Cog sort of records that
information is going to start learning
using it in a moment Cog randomly sends
another three or four numbers what
happens
now all the pixels are zero it sends
some random numbers
again something else appears in
something else
appears it's only got one
arm the arm is here but motionless
because it's stopped sending commands to
the motors now it starts sending
commands to the motors again what what
what does cog
experience blob reapps where it was
before it disappeared The Blob reappears
in the same shape in the same position
well that's interesting so Cog stops
sends sending commands everything goes
white again sends some more commands the
same sized and shaped blob appears in
the same position maybe moves a bit and
then Winks out of existence the moment
it's it stops sending those three or
four numbers what can Cog start to learn
using that little information it's
collected so
far that things remain in the same
position what like like I I object
permanence object permanence okay great
another important thing that early
humans take a lot of time to learn
there's a theory in child psychology why
why do children around the world love
peekaboo it's the most famous popular
game in the history of the human species
because peekaboo teaches object
permanence something that is uded
something important like mommy's face
will rapidly reappear in more or less
the same place in a short period of time
so the nickname for Cog became baby bot
for exactly these reasons Cog in the
first few minutes of operation starts to
make some stupendous discoveries like
object permanence there's this object
whatever this thing is it appears
Whenever I send numbers out into the
world and it disappears whenever I stop
sending numbers out into the world what
was the you might have said this earlier
um what was the benefit of having it
only like recognize moving objects
versus like is it just is that just like
an easier computer vision problem they
yeah so the question is why did they
remove most of the information from the
video feeds and only leave behind
whether or not there was motion there
they wanted to see what Cog can learn in
an embodied manner using just that
information a lot of what our our eyes
evolve to do is exactly that recognize
motion back in the day and arguably we
still are apex predators very important
to be able to recognize motion and lack
of motion where is their motion when was
their last motion and so on yeah how
much can you actually learn if that's
the only thing you can receive from the
outside world okay so Cog does some
learning it doesn't know it it doesn't
know anything about this blob it comes
up with some arbitrary term for this
this phenomenon not necessarily even
this object we're not really talking
about objects we're talking about
relationships between Cog and the world
when I send numbers The Blob appears
when I stop sending numbers The Blob
disappears that process Cog is going to
call
Self that seems to be I'll just pick an
arbitrary term self that's what self is
if you asked Cog what self is it would
say self self are is the collection of
blobs that appear when I act and disapp
appear when I don't act so far so good
okay so Cog bab bot continues uh moving
and stopping to move its arm and
suddenly through these random motions
something new
happens self this blob suddenly changes
shape it suddenly grows this big round
blob on the end of the self blob it's
hit the Apple what happens in the
instant of time after the next instant
of time after Cog stops sending commands
to the motors just after it's come into
contact with the
Apple little more y absolutely so cogs
mind is blown holy cow I've never seen
this before there is a new blob that
remains for a tenth of a second or a
half of a second after I stop sending
numbers to the world I've never seen
that before it keeps it doing its
experiments and its Hand by accident
comes back in contact with the Apple
again and suddenly the same thing
happens okay so Cog starts to realize
during its learning process that there
is stuff out there that's different from
self Cog thinks for a while and says I'm
going to call that the world there's
self or self and let's say other other
yeah this is another thing that young
humans and young uh mobile animals spend
a lot of time uh doing is distinguishing
between nonself and self I'm not having
good luck with pens this
morning okay how do you know where your
body uh ends and the world or the
nonself begins it's actually not an easy
thing to do luck Cog here kind of
stumbled into interactions that caused
that to happen I feel like we use a lot
of sensation for that like I I guess
watching myself H the table doesn't
actually like when you're numb you kind
and you kind of like don't realize that
you're touching like your own face or
something versus like kind of the
feeling of you at your fingertips
absolutely so if you ever had the dead
arm experience wake up in the middle of
the night and you've been sleeping on
your arm and all the nerves have gone
dead in your arm and you're you're half
asleep it's a little scary for a moment
you're not quite sure is this thing me
or is this something else right it again
feels effortless to us as adults when
we're fully awake but that illusion can
actually disappear sometimes it's not as
obvious as it seems as you pointed out
we have tons of more sensory apparati at
our disposal than Cog does it's very
limited but even in this very simplified
experiment Cog can start to embark on
this discovery process and it's
happening because of interactions with
the world it's not saying the world is
everything that's not shaped like this
it's not a geometric description it's a
description between these
processes send numbers stop sending
numbers and this is what happens and
this process send numbers don't send
numbers and something different happens
yeah so Cog is is starting to build up
an understanding of self and everything
else based on differences in actions and
reactions yeah okay so uh we'll just
call it maybe nonself so as Cog
continues to bump into the Apple
accidentally Cog can actually start to
learn more things about nonself you
actually kind of mentioned it what else
can Cog start start to
learn about this mysterious thing called
nonself has different shapes or form it
has different shapes so this thing that
has this particular blob shape remains
permanent for half a second or a second
after I collide with it but if I collide
with this thing down here this long
thing I bump into it it also appears for
a brief period after I stop moving but
it Winks out of uh existence much faster
because the banana doesn't roll right so
Cog starts to realize that nonself is
not some big undifferentiated Mass there
are different kinds of things out there
in nonself there are things that have
this kind of blob shape that have this
particular property they stay permanent
for a second more and things of this
shape which remain permanent after
ceasing action for a shorter period of
time so Cog thinks to itself and says
all right I'm going to invent A New
Concept called
shape and there are different kinds of
shapes I'll call things like this round
and things like this
non-round so now we're getting into
geometric words round non-round but from
CG's perspective the definition of a
round object is not this
it's for another second it's description
if Cog were able to tell you what what
the definition of is for round Cog would
tell you in the language of Dynamics I
do this then this happens and so on so
far so good okay we could spend the rest
of today talking about Cog we'll spend
just two more minutes what else can Cog
start to learn about if it C only has
this collection of fruit in front of it
and it's kind of randomly moving its arm
around and watching what happens what
else can Cog start to learn about
nonself one
objects ah discover that there are
multiple different kinds ofself they can
attct absolutely right it's not all
about me right so CG's ego is going to
start to take a blow that self is not
the only thing that can trigger that can
trigger action in the world self can
cause the Apple to start rolling but the
Apple might roll and bump into these
other small things that jiggle for a
little bit and then wink out of
existence right so there's cause and
effect out there in the world that maybe
I started the ball rolling literally but
it's not all about me there are other
things that can happen great point what
nonself uh different objects have
different kind of motion Absol
something absolutely right so the the
banana when pushed also displaces but
the shape doesn't change so let's call
that slide Cog says let's call that
sliding the ball keeps uh sort of
changes its shape as it's moving we'll
call that rolling so Cog starts to
invent action word starts to invent uh
verbs what else can Cog start to learn
can COG
okay uh I think it can but for this
experiment that's not so important but
you're right if it turn if Cog turns its
head what happens it sees everything
everything everything all the pixels
turn to White right so it could start to
learn about other things about the world
yep could it be like um Nuance between
how much like how much force it applies
like basic the torque absolutely right
so uh baby bot acts like babies and
starts smashing everything in sight and
learns that some things are squishable
and some things
aren't Cog starts to learn that once you
squish something it doesn't most usually
doesn't become UNS squished there are
non-reversible processes in the world
there's a gazillion things that Cog can
start to learn with just two eyes one
arm one hand and a couple of pieces of
fruit in front of it and the ability to
just see motion or lack of motion tons
of things Cog can start to learn as a
side effect of learning all these things
Cog has also solved the image
segmentation problem Cog can start to
learn how to see forground from
background and Cog doesn't need to
expend a lot of effort to do it in deep
learning there's a huge amount of
computation that goes into recognizing
the outline of Marilyn Monroe and we're
not going to go into the details of how
that happens for Cog it's
easy there it is right I my uh the optic
flow circuits in my eye pick that up
effortlessly I know exactly the shape of
that chair I just pushed it I know how
much it weighs I learned a heck of a lot
about the chair with very very little
computation and that only works because
you innately have a circuit in your
brain that does that kind of motion
detection absolutely it was given the
capability it needed for that to be
absolutely it was all built in from the
start right so you're right there is
still a lot of effort that goes into
this and me doing this but it was effort
done by my our ancestors and their
ancestors and their ancestors it's all
built in you're right there's no free
lunch but in terms of COG itself herself
it's himself whatever it is much less
effort for the individual
yeah but correct me if I'm
wrong wouldn't be able to recognize the
same set of fruits if it was just a
picture yeah so that's a really good
question um this work has mostly not yet
been done so I mentioned in this field
there's a lot of open questions you
could it's not too difficult to make a
robot that starts to get useful learning
information from physically interacting
with the world none of you are actually
pushing against the fruit you're just
looking at a picture and listening to me
how does all of that embodied experience
become a
scaffold become a scaffold for doing a
lot of this reasoning without literally
pushing against the object and observing
the world push push push in back in
embodied cognition there is an there's a
theory doesn't have that much evidence
yet that that's what we do as young
children we spend a lot of time
literally pushing against the world and
observing how the world pushes back and
that becomes the raw material that we
use to learn it becomes the training
wheels for us to gradually get better
and better at doing object recognition
without having to actually push against
Marilyn Monroe and see how she pushes
back hasn't really been tested or
validated yet lots of interesting work
that could be done in this area great
great Point yes I have a question so
babies when they learn to interact with
the world they can learn from other
people doing the same thing the thing
with robot is usually they have
different
shape and um different like people feel
it differently okay so the knowledge
cannot be from one to
yep what I'm thinking we caner knowled
to each other yeah robot great great
question so you're asking questions
originating from developmental
psychology which we will see many times
throughout this course the psychology of
how mostly humans develop right so this
is child psychology or infant
psychology infants and children are very
social they're looking around and trying
to learn from things in their
environment Cog at the moment is a
non-social uh learner there's no other
teacher in CG's environment it's
literally just interacting directly with
the world what human young humans do is
infinitely more complicated we're also
learning from others and for infants if
they're lucky they're surrounded by
things that look more or less like them
mommy daddy caregiver and so
on however it is a challenge for them
also to learn who or what to learn from
same challenge for machines Cog kind of
looks like us but kind of not if there
were various humans or other robots
around Cog that were moving and not
moving and reacting to Cog who or what
should Cog learn from it it's a
difficult problem difficult for humans
also difficult for machines good point
yes
also good question so what happens if we
put a different Apple in front of COG it
depends on how well it's learned given
the raw material we've talked about so
far we' have not talked about how Cog
learns so maybe yes maybe no maybe for
Cog that Apple which to us is familiar
it's just another Apple it might it
might be a completely new experience for
Cog it's a slightly different shape half
of it is rotten so it doesn't roll so
well who
know have been any experiments mixing
different kind
of yeah absolutely so we're looking at
one we're looking at One sensor modality
at the moment which is it's not even
Vision it's optic flow your question is
about uh what's known as multimodal
learning and you mentioned it as well
what happens if you watch your hand and
you see your hands stop moving and at
the moment you see your hands stop
moving you feel pressure on your
fingertips you're getting information
from two modalities Visual and haptic
information wow holy cow there's a
sudden change in both of those
modalities at exactly the same time that
is a very important uh piece of
knowledge that's a huge Topic in
robotics we're going to see several
robots that that do this they actually
combine different uh sensory information
from different modalities yes I have a
little question how do the how does it
store all the information that it learns
okay like if it store everything and how
can we have enough memory okay yeah
that's a really great question so you
have tons and tons of information
flowing in right now you're sitting in a
chair the haptic information coming from
your legs and your butt and your back
there's tons of it you're probably not
even aware of it is it being stored is
your spinal cord throwing away that
information is it is it actually being
stored somewhere you're just not
consciously aware of it again great
Point very difficult question to
answer in theory Cog should keep
everything because maybe something will
be useful for its learning down the road
but that's a lot of information to hold
on to
can all the information that's coming in
are there cases where you can say I'm
pretty sure I'm not going to need this
later and uh if it's visual information
your eye throws it away before it even
gets to your brain do the peripheral
parts of your body the things that are
far from your
brain do they do s do they do
pre-processing do they filter out
information before it gets to your brain
the answer is it's complicated the
answer is always it's complicated but
it's a it's a great point so again if we
want to make intelligent machines we got
to try and answer this question what
should they hold on to and what if
anything should they throw
away okay all right let's keep going
okay so that's pattern recognition we
can do it in non-embodied way thr throw
a gazillion photographs at a deep
learner and hope for the best or with
Cog it can do it with less information
but there's been some pre-processing
there's a little bit of smarts
beforehand like let's look at a
different building block of intelligence
as I mentioned it's hard to Define
intelligence but my favorite definition
if I even if I was forced to come up
with one is the ability to not let
yourself end up in a dead end in the
future I'm going to do things now to
make sure I don't have limited options
in the
future in order to do that there's the
word future in that statement that means
means you've got to be able to think
ahead somehow more uh uh more simply
known as planning we need to be able to
think ahead somehow planning was
something that the early AIP Pioneers
spent a lot of time working on and
thinking on and eventually they were
able to create an AI that was able to
plan sufficiently ahead in a game of
chess to beat the world champion in a
single game and then a short time later
beat the world chess champion in an
entire match anybody remember when this
happened roughly when this happened in
the 90s it was in the it was in the 990s
so this was the late
90s there was a huge uproar at the time
this is it superhuman AI is here we now
have machines that can beat humans at
chess and chess is the hardest thing
that humans do so everything else is
easy it's the end of the world the
machines are going to rise up there
aren't going to be jobs in 1998
999 machines are going to take over all
the jobs put us all out of work and so
on sound familiar okay all
right this uh so this was IBM's deep
blue deep blue is a non-embodied planner
it's a computer program running in it
was a computer program running inside a
main frame that could not push against
the world and observe how the world
pushes back someone typed uh the chess
positions into deep blue and deep blue
would spit back its move and so on
despite the fact that it's non-embodied
it did pretty well again required huge
amounts of
computation okay here's the embodied
approach to planning um many early
robots were able to plan this is
arguably one of the very first this is
shaky the robot developed in California
during the
1960s it was a Wonder of engineering if
you look
carefully uh you'll notice that most of
the brain of this robot is on board the
robot the actual computer is in the
robot it was carrying most of its smarts
with it a huge engineering feat in the
1960s okay okay so what would shaky do
the researchers would Place shaky at
some random position in the room and as
you can see they would put these big
heavy block uh obstacles at various
positions in the room and then they
would tell shaky get out of the room
this was one of the first escape room uh
experiments done with machines rather
than humans what would shaky do uh it
might be difficult to read this in the
back of the room it's got a laser range
finder here it's got a television camera
it's getting a whole bunch of visual
modality information it's getting a
whole bunch of visual information takes
all that information and uh crunches all
of those visual numbers down to create a
simulation of its environment this is
just some random physics engine picture
that I had lying around this isn't
actually from shaky but this was more or
less what shaky was doing it would make
a very simplified
virtual representation of its
environment then once it had that
environment and its virtual
representation of itself it would start
to plan an escape route through the
obstacles to the door question was it
was it building this model like was this
kind of like pre- de learning like oh
this is very pre- deep learning no
neural networks here at all so it was
actually just taking all the input and
like
doing the processing it was doing the
processing there was a huge complicated
computer program that somebody wrote and
gave to shaki so that shaky could take
all its visual information and construct
a virtual environment and then another
computer program that somebody wrote to
plan a route through the virtual
obstacles okay once it had actually come
up with a root that it was confident
would allow it to Escape the Room shaky
would wake up start
moving one inch and then
stop come to a halt scan its environment
construct a whole new description of its
environment do this whole loop
again for a few
hours another few
hours why was shaky the robot called
shaky the
robot given that description motion
yeah it would literally shake to a halt
and then move and then
move okay knock on wood heaven forbid if
fire broke out in this room is this what
you're going to
do our distant distant ancestors maybe
they didn't do exactly this but if they
did do this and there was a
fire right whatever it is that we're
doing it's not this this is not to pick
on shaky the robot it was definitely
Advance at the time if you if you were
to think about it before I showed you
shaky the robot if I said planning how
do you plan a lot of a lot of people
will often give a description more or
less like this I look at my environment
I build up a model of what the room
looks like I plan my Escape Route and
then I execute it remember last time we
talked about the touring machine it's
it's very familiar and comfortable for
us to think about information coming in
internal processing and then
action if you take that too literally it
can lead you in some directions that
don't really seem like what we
do
um why would it not just keep moving in
One Direction until it like had to turn
and theness okay why does it not keep
moving until it has to turn uh Shake is
a very big machine it's a very very
heavy machine it's a very expensive
machine Shaky's uh repres internal
representation this is a very uh
controversial term representation we'll
come back to it many times in this
course shaki's internal representation
of its environment is never perfect I
think the table is here but it's
actually here so I'm going to go around
it bang not such a good thing for shaky
to do the researchers wanted to make
sure that uh shaky never experienced a
false positive it never came up had a
wrong representation and something
terrible went wrong better to stay
still uh sense think plan act sense
think plan act sense think plan act
safer uh safe for shaky in the sense
that it doesn't hit anything but
eminently unsafe if there's something
that's happening in which you need to
react
quickly it seems like what we're doing
more is like just constantly sort of
adapting to whatever is like coming to
us instead of like making this plan the
whole way absolutely it feels now once
you start to think about shaky the
hackles on your neck go up right you're
like gosh that's not what I'm doing I'm
continuously adapting my internal
representation of the world and planning
an active
simultaneously right one of the nice
things about shaky is it sort of wakes
us up from this torper of thinking like
a turing machine sense think plan act
not such a good thing to do if you're an
embodied agent in the world with literal
skin in the game it matters right if
there's a fire it matters so whatever
we're doing it's probably not this and
we're going to come back shortly to an
example that's the complete opposite of
this regardless of whether this is a
good or not solution here's an embodied
approach to planning here's a
non-embodied approach to planning as
before with pattern recognition you can
see how it's not just about Shaky's body
it's about shaki's invi interaction with
the environment okay we're going to
pause for a moment and we're going to
take a few moments to talk about this
possible building block of intelligence
we could spend several months talking
talking about this topic we're going to
agree right now we're going to take 5
minutes to talk about this
topic Free Will okay deep breath here we
go we all have free will feels obvious I
choose to come to class or not I am free
to choose to come to class or not it's
blindingly
obvious libbit and his colleagues back
in n in the early 90s said wait a second
let's actually test this idea they came
up with this very famous and still very
controversial experiment here's the
cliff notes of the libbit
experiment they instrumented human
subjects with uh EEG which stands
for
Electro
electrograph which picks up electrical
activity um on the surface of the
brain they also wrapped a little uh
sense
around the human subjects index finger
uh which is an EMG uh sensor which
records muscle activity what does EMG
stand
musular myogram fancy word for muscle so
EEG EMG yeah so we've got human subjects
wearing a weird looking skull cap uh on
their heads and they've got a little uh
piece of tape wrapped around their
finger these human subjects were then
given the following instructions watch
this clock and you'll see there's a
moving second hand it was actually a a
moving light and at any time you are
free to
choose at the moment you choose that
particular time flex your finger so
watch the clock going going going I
choose to move my finger and I do I'm
watch I'm a human subject I'm watching
the clock d d d it's going around I
choose to move I choose to move I choose
to move I choose to move I choose to
move okay the human subjects were then
asked to report the exact time points at
which they made that decision to freely
move their finger so far so good okay so
what did they see um for they did this
with multiple different people for each
person they saw that at the time points
that those subjects reported that they
chose to move their finger there was a
repeated switch uh change in their EEG
patterns that particular EEG pattern was
unique for different human subjects we
all unique but there was a definite
change there was the same change in EEG
at every moment at which the subjects
chose to move their fingers which liit
and his colleagues interpreted as the
human subjects are not cheating they're
doing what we asked them to do there's
some some repeated change in their brain
signal at exactly those moments that
they reported they also saw that there
was a reliable change in
EMG 200 milliseconds later which looked
good that's more or less the time it
takes for a decision to go from your
brain to your index finger so it looked
like most subjects were obeying the
instructions of the experiment which is
choose and then act or from the
subject's point of view they act at the
moment they choose but that action takes
about a tenth of a second two two ten0
of a second to actually happen so far so
good everything looks perfectly
reasonable turns out that for each of
these subjects there was also a reliable
change in EEG patterns 310 of a second
before the subjects thought that they
had freely chosen chosen to move their
fingers okay now things start to look
problematic we don't have free
will dang
it you ask these subjects they'll say I
chose at six seconds past uh the minute
I chose but actually 5.7 seconds or
whatever it is 3 tens of a second before
that there was a reliable change in
brain activity what I'm telling you is
just what happened in the experiment
what you want to take away from that
experiment or what you hope to salvage
from the results of that experiment are
up to you I am not here to convince you
that you don't have free will you are
free to decide that on your own maybe
the point that of why we're talking
about this is to illustrate a warning
that you're going to hear me repeat over
and over in this class
thinking about thinking is misleading
introspection is dangerous if I asked
you how you plan before I had primed you
with this experiment most of you would
have said uh I look at my world I think
about how to R to get out of this room
as quickly as possible I plan my route
and then I execute it seems
obvious probably not how we do
it so again in all these experiments
uh in all of this work just remember
that thinking about thinking is
misleading okay all right I've kept to
my word five minutes about this if
you're interested in the libid
experiment it's fascinating I would
encourage you to read the libid
experiment first go to the source there
are replications of this experiment some
of them show that there are report
reporting to have shown that their
reliable brain
changes not just 310 of a second but
whole seconds 2 seconds 5 Seconds 10
seconds before you think you made the
decision there are other experiments
that have results where the authors
claim that it invalidates libet's
experiment it there's a huge literature
that's grown up around the libbit
experiment go have a look if you're
interested but it's all tangential for
this course I'll entertain one question
or comment I
was very very much very much so maybe
you freely made the decision but you
just you're not clear about when you
made the decision that's a way to
salvage Free Will from the liit
experiments which is disproved by other
experiments and around and around we go
great Point great Point okay remember
okay so back to embodied cognition we
just saw shaky which planned in a way or
acted in the world in a way that when we
see it being done by machines starts to
convince most of us that whatever we're
doing it's not that so in the 1980s uh
Rod Brooks came up with a completely
different way to control robots than
sense think plan
act sense think plan
act and then around and around we go
Brooks said that's terrible that's not
going to work so let's do something
opposite and this opposite became known
as subsumption
architecture imagine uh imagine that
we've got a simple wheeled vehicle like
the brenberg vehicles that we saw last
time and imagine that uh we've got uh
we've got the coward running inside that
machine when we talked about the coward
last time that was a robot with two
sensors two wheels uh and two
ipsilateral connections so it would turn
away from light imagine we replace the
light sensors with bump sensors which
means that now we have a brenberg
vehicle that's terrified of bumps if it
ever gets bumped on its front right side
it turns to the left immediately yeah
that's what's represented here obstacle
sensors avoid obstacle and send commands
to the motors which cause the robot to
turn away from objects it's terrified of
touching objects so far so good okay
what happens if it's not bumping it's
not touching any objects this vehicle
will just drive around and if it hits an
object then suddenly this part of the
robot's brain takes
over if it's not doing that it's driving
around but it also has two audio sensors
on its front and as long as it's not
touching any obstacles it's paying
attention to its audio sensors and if
there's loud noise over on its left
it'll turn to the right so there's a
second coward circuit inside the robot
and that uh noise that noise fearful
circuit is holding on to the motors it's
controlling the behavior of the robot
until it suddenly bumps into something
and then this circuit
subsumes or takes over control of the
motors there's a more urgent uh reflex
that overrides this less urgent circuit
and we can keep going if uh it's not
touching anything and everything is
relatively quiet then turn towards the
light and we can keep stacking these one
on top of
another what do you get if you were to
take just these three circuits and stack
them in this way put them inside a two-
wheeled robot put that robot in your
living room it's the middle of the day
there's nobody home so it's relatively
quiet there's light filtering in from
the window it's a little bit more light
on one side so the robot draws a gradual
Arc towards the light streaming in from
your window but then bumps the couch and
heads off in another Direction starts to
draw an arc gradually comes back to the
light from the window and keeps going
and going and going what do you
have kind of like a Roomba not only kind
of looks like a Roomba it's exactly the
Roomba so Rod Brooks was the director of
the AI Lab at MIT which I mentioned last
time is the mecca of AI he was at the
top of his game in the 1980s and came up
with this idea which as you start to run
this in your head you realize yeah
you've got a ve you got a machine that's
continuously moving like somebody
mentioned here it's not even building up
a representation of itself other than
there's more light on my left than my
right no physics engine no nothing a
very lightweight machine moving around
uh it might hit objects but it'll then
move away from them it doesn't get stuck
uh on objects wow amazing
why don't we spin off a company let's
call that company IR robot and let's
maybe make vacuum cleaners that's
exactly what Rod did he eventually
resigned his post as the D at the
director of the Cale at MIT which no one
had ever done seems like a crazy thing
to do to go make a vacuum cleaner
company all of his colleagues thought
were laughing at him at the time Who's
Laughing Now okay so again we have an
embodied approach to it's not really
planning but at least embodied Behavior
right this robot is using its body and
the distribution of sensors and its two
wheels in a very efficient elegant way
to actually do useful work like vacuum
your your carpets you don't need a lot
of heavyweight computation you don't
need a million photographs of your
living room if you think about
embodiment carefully
and you design the body and the simple
internal wiring in the right way you get
useful Behavior
right brenberg uh lived long enough to
see the Roomba I don't know if brenberg
felt validated I hope he
did okay all right so just to sort of
sum up we've looked at a few building
blocks of intelligence pattern
recognition planning acting well in the
world and we looked at at non-embodied
and embodied approaches to this so we're
going to uh come back to this term of
embodied cognition this term itself
actually comes from psychology um again
uh people have been studying humans for
a very long time and thinking about how
humans use their body to push against
pushes back and using that raw
information to learn to to survive and
flourish in the real world
roboticists have appropriated this term
to also think about if we're going to
create intelligent machines how might
they use their physical bodies to get
the information they need to survive and
thrive and do whatever we want them to
do in the real world yeah okay you can
say well wait a second even non-embodied
things like Chachi PT have a body they
exist in some server Farm or Farms
somewhere out there they have a physical
body you're desktop has a physical
body your desktop cannot push against
pushes back so embodied cognition
doesn't mean physical cognition it's not
just about physical materials it's about
how a machine or an organism uses and
exploits its physical
materials to survive and thrive in the
world yeah okay so EMB cognition is
really about the way in which you the
way you process information is affected
by the fact that you have a body what do
we mean by the way of processing it or
exploiting the body we do this all the
time and and the Roomba does the same
thing if you have a body that can move
you've got Motors somehow and you can
see the moment you move we've got our
little Lego robot over here that's
conceal see this big object out here the
moment it moves its distance to this
other object changes there's an
immediate repercussion of an action the
the speed of that reaction is useful
there's information in that as
well what are some other ways that we
exploit our physical
bodies when I see my hands stop moving
and I feel feel the pressure and those
two things happen simultaneously that
facilitates or helps me learn that those
two things are actually reporting the
same event they're reporting the fact
that my hand is collided with the board
I'm already I'm exploiting the fact that
I'm receiving multimodal information
Visual and tactile at the same time and
thank you I hear it as well yeah what
other aspects of your phys physical body
do you exploit to learn about the
world you can go anywhere you can go
anywhere okay so I can you opportunity
to like experience different things yeah
absolutely I can use my Motors to
actually create new kinds of Loops I can
go here and then now I'm involved in
another uh sensor motor
coordination that I couldn't do when I
was back here right there's an
opportunity for me to move and start to
generate some new interaction would it
be like you see something far away but
then you can't hear it immediately like
cling it's just like I don't know
determined distance based on absolutely
right things that are far away they're
hard to estimate how far away they are
if they're making noise that helps
absolutely we can like turn our heads
around and like build a I I know you
said don't use representation but we you
can build like a pretty good model of
the room that you're in kind just like
add a glance and then it still exists
yeah absolutely right so I can move my
head I can move my eyes and as I do I
see all of you move but some of you move
faster than others which helps me if I
am building a 3D representation I
immediately learn that you all are
closer to me than you all are I can I if
I close one eye I don't get depth so
it's a little hard to do but the minute
I start to act I get additional flow
information that helps me judge depth
absolutely I exploit self motion to
learn about relative distance what else
there's millions of ways you exploit
your body and its interaction with the
world to learn about the world to get
useful actionable
information like self-preservation
purposes like learning what can like
injure you absolutely right things imp
Mo other things move and they impinge on
me and I can press against things and
feel the rate at which the pressure
starts to increase edge of a table okay
edge of a knife different the rate of
pressure localized pressure on my palm
starts to go up really really fast I'm
going to treat that action reaction as a
yellow card things are about to get very
dangerous very soon um we could use just
kind of everything to determine like our
position in spaces um and that's like
not even I like I I feel like you can
hear if you're outside versus inside
okay yeah e Echo absolutely where am I I
I've I'm just in some situ where where
am I what's here is this a dangerous
situation a useful information uh
environment we can use tools as kind
extensions of our body okay yeah so
we're great point so tools we're talking
about exploiting the body
right you have a body with which to
learn about the world you've got these
things which can do things like
this great okay now something new is
happening I feel a new action reaction
Loop how does that help me I've got this
new information but so what we might we
might be able to like use tools to
explore or use tools to manipulate our
environment in various ways depending on
like the dynamic of the tool we're using
okay we talked about uh Blade Runner
last time right the movie 2001 with the
Apes at the beginning one of them picks
up a bone and starts doing this and
starts to do this with increasing force
and suddenly does this and hits another
bone and that bone
breaks wow okay for that ape it was not
able to break a bone itself but if I do
this suddenly now I can cause
repercussions in the world that weren't
possible with just this what a
discovery other examples of exploitation
feel like smell is underrated smell is
underrated dinner's cooking like in the
oven or gas leakers what probably our
arguably our oldest sensor modality
smell we're primarily visual creatures
these days but yeah absolutely how do
you exploit smell tricky hard to think
about yeah smell if food is rotten or
not something safe to eat or not so safe
okay now maybe action is involved a
little bit
maybe do what the fruit fly does right
you could act as a brenberg vehicle yeah
isn't there stuff with like smell that
activates memories ABS absolutely right
so there's some very subtle things that
are in there memory we're going to focus
we're focusing right now on exploiting
action and reaction in the Here and Now
absolutely we can link what's happening
the action reaction Loop that we're
causing right now with things in the
past but let's stay in the present for
the
moment think about us as bipeds you're
obviously sitting and you're at rest
right now but hopefully for a
considerable period of the day today
you're doing stuff like this what am I
exploiting right
now body has structure and balance that
is well suited to that form of motion
okay yeah my body is well suited to this
type of motion we're going to talk about
legged Locomotion later in this course
but how let's let's think about this for
a moment how is it well suited for doing
stuff like
this
system being able to sense basically
like your intergral horoscope absolutely
so the vestibular sensor your inner ear
another sensor modality
it detects acceleration so if I'm
walking and start to do this my inner
ear tells me and tells my body to do
this yep so keeps me
balanced we are one of the most
efficient land movers on the planet if
you're in relatively good shape you can
go 15 20 miles on half a Big Mac and if
you do the thermodynamics on that it's
incredible there's a theory that our
ancient ancestors when they were hunting
in packs they walked and just walked
their prey into exhaustion it's unproved
it's a theory but what is known is we
are incredibly good long distant
efficient movers we're not the fastest
land movers there are but we can go very
long distances with very little food how
how do we exploit our bodies to make
that happen well most of like by
Locomotion is less walking and more just
falling forward catching yourself
absolutely right so you've been doing
this for decades maybe you've never
actually paid attention to it when you
leave class today and you walk wherever
you're going I want you to actually pay
attention as best you can to all the
muscles in your legs your lower back
your
arms for those of you that have or have
taken a class in this what's what's
happening what's happen happening with
your musculature as you do
this it's your like every every step you
take you're actually adding very little
energy to the system versus a lot of it
is about how like you know how like when
you swing your arms when you walk it's
all about like continuing forward
momentum while like transferring it
absolutely okay so I'm going to walk
again here we
go not a good way to do things that's
not going to last
very long as you mentioned and you'll
feel this after class most of the time
the muscles in your legs are slack the
minute your stance leg the one behind
you leaves the ground becomes what's
called your swing leg and it's called
your swing leg for a reason the moment
your toes leave the ground all the
muscles in your leg go slack and your
leg acts like a pendulum it just swings
swings forward and your momentum will
eventually cause your heel to come into
contact with the ground and your swing
leg will become your stance leg again
the moment that happens you tense the
muscles in your leg and your momentum
carries you over your tensed leg and
each of your legs your individual leg
the muscles are slack for half the time
relax and swing tense and stand relax
and swing tense instead isn't there also
an argument that we like became upright
so that we could like take in a lot more
oxygen okay so why did we become bipeds
in the first place it's a fantastic
question there are very very many
hypotheses for why that happened and you
just mentioned one of them we'll come
back to this discussion when we talk
about bipedal locomotion for our
purposes today we're just illustrating
that if you have a body and you have a
little bit of smarts up here
you can come up with lots of different
ways to exploit your body's interaction
with the world that's embodied cognition
okay I want to make sure we finished
today's lecture we got five minutes left
so bear with me we just talked about
embodied cognition there is a related
idea called situated uh
cognition the definition is a little to
tological the way you process
information is affected by the fact that
you're phys physically situated in the
world for psychologists situatedness
more or less means that you're getting
information from the world in real time
you we are all situated here maybe
you're not actually moving right now
you're not exploiting the physical
forces of your body but you're receiving
sensory information in real time you are
situated in the
world uh a a passive deep learner that's
receiving text that was written by
someone long ago or receiving an image a
photograph that was snapped by somebody
in the in the past it's not situated
it's receiving information that was
generated or processed early earlier
okay so a common example of a machine
that a device that's uh situated but not
embodied are embedded devices so I can't
remember if this room has a smart sensor
or not but if if we all leave this room
and it's empty for a few minutes the
lights will shut off I know that's true
in the Davis Center so that that sensor
in the ceiling is situated it's
detecting motion or lack of motion and
when it detects lack of motion for long
enough it switches off the light but
that intelligent light sensor can't move
around in its environment it can't
exploit its physical Mass related to the
environment it's situated but not
embodied
everybody see the
difference that intelligence sensor is
still physical right it exists in the
world it's got a physical body but not
embodied in the embodied cognition sense
of the word
okay okay um from time to time I'll use
this term of a complete agent agent is
going to be like the term vehicles from
last time from Bren bird agent is a
catchall agent could be a plant a
bacteria uh an animal a human a drone a
robot it's sort of a a container term a
complete agent is an agent that is a
situated agent and an embodied agent you
are all situated and embodied agents you
are all complete agents the intelligent
light sensor is a situated agent but not
an embodied uh
agent uh okay we'll do this very quickly
so complete agents are subject to the
laws of physics how might they how might
complete agents uh exploit that fact we
just saw bipedal Walkers there's an
example of a complete agent that
exploits the fact that your leg is
subject to the law of gravity which
allows it to act as a pendulum gravity
often feels like something we're
fighting against you might not have
thought of this before but you're
actually exploiting it gravity is your
friend not your
enemy we generate sensory stimulation
when we move we've already seen that
example the moment you move in the world
you suddenly get a whole bunch of new
information about the world that is
difficult or impossible to get when
you're standing
still as you move about the world you
also leave a literal and figurative
imprint on the world that you can then
later exploit that imprint on the world
what's an example of us impacting the
world as we move about our daily lives
and then we exploit that fact later or
others exploit the fact that you've left
an imprint like you walk through like a
thing of snow and then you leave a path
other people try and walk right through
there have to walk through the snow
absolutely I always hope that this
lecture is on a snowy day not quite true
I can see some paths out there right
shortest path from building a to build
building B after every fresh snowfall
those paths reappear and your fellow
students are exploiting the fact that
you as a complete agent have left that
impact on the world sorry for rushing I
want to make sure that we finish this
today let's try and fill these four
boxes give me an example of a technology
that is both disembodied and not
situated it's like a computer a computer
a traditional desktop okay how about
situated non-embodied we just saw an
example what was it embedded device an
embedded device an intelligent light
sensor embodied and situated
agents us B uh Cog that we just saw how
about this one embodied but not
situated can you think of an organism or
a machine that is embodied but not
situated a remote control drone a remote
control drone maybe if we assume we
don't use the Drone sensory
information uh you're right though if
the the Drone might be taking pictures
but not using that sensory information
to drive its own action so are yes maybe
a a remote control drone kind of fits in
category RC car an RC car also remote
controlled which I don't think has many
sensors or any sensors on it yep it's
capable of action and interacting in the
world but not not not uh recording the
repercussions of its
actions a common one is the first
generation of industrial robots they
were programmed to weld the car door but
they weren't actually sensing the fact
that they were doing it or whether or
not that welding event was successful or
not okay sorry for the speed at the end
there um you have a quiz due tonight
undergrads you're working on assignment
two grads you're working on three or
four have a good rest of your week see
you
Tuesday


--- Evolutionary Robotics course. Lecture 05. Artificial Neural Networks..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everybody sorry about
the technical issues this morning off we
go I have a sick family member at home
so masking on can everyone still hear me
in the back okay yeah okay all right so
as promised Tuesday morning just a
little bit of a refresher of where we
are and where we're going with the
assignments uh undergraduates you're
working your way through uh empty
simulation objects which are known as
links in the pi bullet simulator that
we're using and you're moving on today
in assignment three to joints like your
elbow joint or your knee joint the
things that connect objects or links
together so far you've had a relatively
easy go of it because everything you've
been coding up in the assignments has a
visual counterpart so when you install
pyro Sim when you installed pybullet and
Pyro Sim at the beginning of the
assignments and you got the simulator
working you'd see a window opening in
assignment two when you were creating
links and you added a link if you mixed
up length and width and height you would
see it immediately in the block itself
so everything you were coding up had a
visual counterpart from joints onward
everything you're going to be adding to
your uh code base is invisible it's not
going to have a visual counterpart in
the virtual world the things that you're
adding like joints in assignment three
they are going to affect the physics in
your virtual world but they're going to
affect things indirectly because you
won't see for example the joints
themselves so the first thing I want to
advise you about in assignment three is
to train yourself in being able to
diagnose what goes wrong in your
simulator as you start to add these
invisible elements you're going to be
adding joints in assignment three in
assignment four you're going to be
adding sensors then Motors then neurons
then synapses none of which have a
visual component so how do you know
whether you've implemented The Joint the
sensor the motor the neuron or the
synapse correctly you're going to have
to build up an intuition for when those
things are having the effect you want on
the virtual world and when they're not
so I want to take three minutes now and
just talk about how to do this for
joints as I mentioned joints like my
elbow joint are going to connect
together neighboring
links in your uh physical simulation
there are a number of properties that
you need to set for each individual
joint the first one is the position of
the joint itself where in
three-dimensional SP space is that joint
it's kind of intuitive the 3D position I
of that joint should be exactly where
the two links come together that's where
you want to connect those pieces
together if you get that 3D position
correctly and you start dragging pairs
of connected links you should see each
link rotating relative to the other one
at exactly the point where they touch
make sense okay if you get the position
wrong you put the joint up here and
luckily I cannot demonstrate this for
you with my upper and lower arm if the
joint position is up here the two links
are going to rotate about this position
so if you add a link to if you add a
joint to your simulation and when you
start to simulate it in the first time
step of the simulation the objects or
the links seem to be correct but then
they start to move away away from one
another in weird non-physical ways
that's the indirect signal to you that
you've got something wrong in terms of
joint position make
sense that's of course also what the TA
and I are looking for when we're grading
your
assignments if you submit your links
your joints assignment and we see pairs
of links coming apart will deduct a
point because we know you've got the
position of the joint wrong so far so
good okay couple other points about
links that are are particularly
confusing so I want you to pay attention
to this as you're implementing
assignment 3 there are a number of
features uh or settings for a given
joint like position which we just talked
about there's another feature of a joint
which is going to be set for you by
pyrro Sim you're not going to have to do
it yet but I want to just mention it now
because this could be a little bit
confusing now and later on when you're
setting the position of a joint you
obviously have to supply three numbers
because we're working in three
dimensions you're you're supplying the
three-dimensional position of the joint
for now pyrro Sim whenever you create a
joint is also going to send three
additional numbers to the physics engine
which is known as the joints normal so
let's go back to the example of my upper
arm and lower arm those additional three
numbers the joints normal are going to
represent a vector in three-dimensional
space that Vector is going to dictate
the plane the two-dimensional plane
through which the pair of connected
links
rotates make sense so if I've set my
elbow joint to be here telling the
physics engine that I want this object
to rotate relative to this object about
this
point if I Define this particular joint
normal pointing towards you there is one
and only one two-dimensional plane that
is normal to this 3D Vector everybody
remember high school algebra yeah okay
so I'm telling the physics engine that I
want these two parts to rotate in this
way if I do exactly the same thing I
connect these two links together with a
joint I give the exact same position of
the joint but now I Define this joint
normal how is my upper arm going to
rotate relative to my lower
arm exactly right there is one and only
one two-dimensional plane that is normal
to this 3D vertical Vector the 2D
plane at the moment pyrosim is going to
to set the normal for you it's going to
set it to well I can't you'll see it
when it's set up uh later on in the
course you can change the joint normal
so you can alter how the two objects
rotate relative to one another question
kind of unrelated to to the Joint stuff
is pet just like pretty slow like I
notic even just building like the the
cubes like on what like I bought my
laptop like last year it took like a
considerable amount of time okay good
question so is piie bullet slow if
you're running it on a laptop from last
year it absolutely should not be what
might be slow is the graphics right you
see it building these towers and then
once you've built the towers and you
start to grab an object and throw it
around assuming you have a relatively
recent laptop that should go quickly if
it's not something's probably wrong come
and see the TA or myself what we're
going to do later in this course when
you start wrapping your evolutionary
algorithm around the physics engine and
it's going to try out hundreds or
thousands of millions of robots in your
virtual world you're going to be running
many many many many many simulations on
your laptop at that point we're going to
turn off the graphics Once you turn off
the graphics the physics will go should
go very
fast okay
question
I okay so good point for on some
platforms maybe it's the IDE like fider
that's actually slowing things down
again for the upper years here and
especially for the grad students if you
haven't had a chance to work directly at
the command line or The Terminal before
here's a great opportunity to learn how
to do things strip away all NE
unnecessary Machinery like idees it's my
recommendation any other questions tips
or
tricks if things are running slow for
now it doesn't matter but it will matter
once we start doing some optimization
yeah okay third and final thing I want
to say about joints just as a heads up
for you to spend some time thinking
about in P question yep um I was
wondering if it's important that the
joints are always like originating from
the central body or if they can
originate from anywhere because they're
just in
uh a like a swivel like well not a
swivel like an
axle
okay I think there's a couple questions
embedded in that question one thing to
point out is there are different kinds
of joints that you can Implement in
pybullet it supports different kinds of
joints for the moment you're only going
to be working with rotational joints
things that cause pairs of connected
links to rotate relative to one another
you can also create uh linear
joints in P bullet which acts like a
piston it allows pairs of connected
links to move away from one another and
towards one another different kinds of
joints we're only going to work with
rotational joints at the moment your
second question is about where do the
joints originate and that's a good
question so I'm going to try and answer
that right now so we just talked about
two important features of joints the
position of the joint the joints
normal last thing to pay attention to uh
especially in assignment three is
relative and absolute
coordinates so up till now when you're
dealing with uh links you're using
absolute coordinates somewhere in your
virtual world there is the position 0 0
0 the world origin and when you identify
when you supply a 3D set a set of 3D
coordinates for where a link should be
or where a joint point should be you're
dealing with absolute coordinates it's
at this position in the absolute in in
the
world as you start to connect together
multiple pairs uh of links with joints
some of those joints you're going to
start using relative coordinates to
Define them so continuing to use my body
as an example here I've got my uh upper
body here and my upper body is connected
to my upper arm with a shoulder
joint my upper arm is collected
connected to my lower arm with my uh
with at my elbow joint the first joint
you're going to Define you're going to
use absolute coordinates but as you
continue down the body of the robot
you're going to switch from using
absolute to relative coordinates you're
going to give the position of this joint
relative to the position of uh one of
the links that's relative POS relative
as in the position is relative to
something else you've already added to
your simulation it's a little confusing
I tried to make a little Google uh slide
show there to help explain it take take
some time to make sure you really digest
and understand absolute and relative
coordinates you'll know if you've got it
wrong in the
simulation because the objects will
start to separate from one another so
hopefully it's relatively easy to
identify when things are wrong work back
make sure you have this all clear in
head is the object that's defined in the
joint definition the one that like the
the child object that's connected to the
parent joint is that the only one that
has um relative absolute coordinates or
is it every single link after the joints
definition yeah it's a great question I
don't remember off the top of my head it
should all be explained in assignment
three it's all
there
okay okay why would a physics Engine add
this Twist of complication why not
Define the positions of every link and
every joint in absolute coordinates
seems much simpler why mix and match
absolute and relative coordinates
anybody have an idea um just because if
you're building more complex structures
and like like it could be very hard to
say like I'm trying to make even like a
hand that's bent like this it could be
really hard to figure out where the like
those points are in absolute space
whereas you know if you know the angle
and like the width of this joint it's
pretty easy to Define it relative to a
previous one absolutely if you start
you're not going to yet in this class
but if you start to build very complex
robots made up of many many parts it
gets a little bit easier to define the
positions of things relative to what you
said parent Parts parent meaning up
towards the center of the body of the
robot child meaning down towards the
tips of fingers and toes and legs and so
on another reason why is that pie bullet
tries to make it relatively easy for you
to build a complex multi-link object
like a
robot and then make exactly the same
thing but a different position in the
virtual world if everything if the uh if
the parent node the thing at the top is
defined in absolute coordinates and you
make a new one you define those
different absolute coordinates but then
all the other coordinates in that second
robot because they're all relative
positions stay the same yeah makes it
easier to make a complex thing and then
clone it throughout the simulator that's
why pyrosim is going to put you through
this torture session of learning when
and where to use relative and absolute
coordinates for those of you that are
going to make robot swarms later in this
course it's worth the time and effort
and
pain all good okay I think that's all
I've got to say about links and joints
for today graduate students you're
running ahead to neurons and synapses
week Motors and neurons and synapses I
think okay back to our lecture material
okay apologies for speeding through
embodied cognition last time hopefully
this concept is relatively clear we're
going to see lots of examples of robots
as we continue through this course that
exploit the fact that they are embodied
in the world to pull out of the world
the information they learn they need to
learn about their relationship with the
world and survive and thrive in that
world we will also see robots that
exploit their situated nature the fact
that they are continuously bring uh
pulling in sensory information in real
time we are now going to move on to the
second theme of this course which is the
nuts and bolts of evolutionary robotics
or the tools of the trade we just spent
a few minutes talking about some of the
intricacies of physical simulation we'll
come back to that uh probably next week
okay today however we're going to talk
we're going to start by talking about
the brain that are going to make up your
robots which are artificial neural
networks
okay a pretty Hot Topic at the moment a
lot of what we're going to see today
forms the engine room of chat PT and
stable diffusion and all the other fancy
AI models that are out there for some of
you this is going to be very uh remedial
a lot of you will have seen this before
but some of you are not going to have
seen some of this material before so
please bear with me today okay we're
going to start as is appropriate for
this course we're going to start with
robots which robots are these we've seen
these
already these are the brenberg vehicles
right so we've got two sensors on the
front of the robot in this case photo
sensors two motorized Wheels on the back
and as we saw last week we can connect
the two sensors to the two Motors in
different ways we can connect them
ipsilaterally same side sensor to same
side motor or
contralaterally this sensor to this
motor we could connect this sensor to
this motor and this sensor to this motor
there's different ways we could wire up
the sensors to the motors okay
let's a terrible thing to do in a
robotics class we're going to take the
body and throw the body away for a
moment and keep the the brain we talked
about cartisian dualism last time a few
weeks
ago bear with me this is a little bit
cartisian but it'll help us understand
neural networks so with a brenberg
vehicle fresh in your mind imagine this
non-embodied
brenberg vehicle the only thing we've
kept are the two sensors and the two
Motors back here we're going to start to
introduce some terminology
here we're going to assume that these
two circles in the top are actually
sensor
neurons so this is a simulation of a
neuron sensor neurons the only thing
they're going to do is collect numbers
from the sensors so we've got the
sensors themselves the sensors are
connected to sensor neurons and as we're
going to see throughout this morning's
lecture neurons hold a value inside side
themselves they're called neurons um
they're a very gross approximation of
how actual biological neurons work we're
going to strip away most of the details
about biological neurons and we're only
going to add back those biological
details as we need them for squeezing
useful Behavior out of our robots for
now the only thing neurons are are are
buckets they're collecting numbers from
the sensors we're going to assume that
neurons are connected together with
synapses so all the arrows you see are
going to be things that connect pairs of
neurons together here's a synapse
represented by an arrow each synapse has
a pre synaptic
neuron and a
post synaptic neuron as the name implies
if we're talking about any given synapse
the pre synaptic neuron is the one at
the base of the synapse the post
synaptic neuron is the neuron at the
head of the synapse we're going to
assume these synapses are very very
simple the only thing these synapses are
going to do is take the value from their
pre synaptic neuron and pass it on to
their post synaptic neuron pretty simple
so far biological synapses again are
horrendously complicated structures for
now we're going to focus on the basic
thing they do which is act as wires or
transmission wires they pass along
signals from pre to post synaptic
neurons so far so good nothing too crazy
here yet okay all right so we've got our
two sensor neurons up here we've got two
neuron neurons down here at the output
layer we're going to treat these two
sensors as motor
neurons like the sensor neurons the only
thing the motor neurons are going to do
is to take their value and send it to
motor the motor which is not drawn here
the motor is the thing that's going to
control the wheel the only thing that a
motor does is to interpret this number
as a
command if a motor is spinning a wheel
the motor might interpret this number as
a desired velocity how fast F should the
motor try and get the wheel to turn so
motor neurons send commands to Motors so
far so good okay from the robot's point
of view the sensors capture information
from out in the world pass those values
onto their sensor neurons these synapses
flow or propagate those values from
their pre to their post synaptic neurons
the values arriving at the motor neurons
are sent to the motors the motors apply
torque torque is rotational Force how
much to torque or twist the wheel and
the wheel
spins sense think act you'll hear this
over and over again when we talk about
robotics okay pretty simple so far let's
start to add in some neural complexity
to our uh our disembodied robot here
we're going to change the neural
architecture we mentioned this term a
few weeks ago neural architecture it
describes the number of neurons how
they're arranged which neurons are
connected by synapses so we're making a
change to the neural architecture of
this neural network by adding two
additional synapses and we're going to
add a little bit of complexity to how
our motor neurons behave from this
simple cartoon you should be able to
guess what is the added complexity we're
adding to our motor neurons what do they
do now that they weren't they didn't
have to do
before add that's it right so this
particular neuron has two arriving
synapses at every point in time this
motor neuron is collecting the values or
is collecting the values that are
incoming from all of its incoming
synapses we've added in one of the very
important features of biological neurons
biological neurons collect information
from other neurons that are sending
values to them along the incoming
synapsis the only thing these motor
neurons are doing is summing these
values if we were to take this
particular neural architecture and put
it back in the brenberg vehicle what
kind of behavior would this neural
network cause the vehicle to
exhibit drive straight why would it
always drive
straight absolutely we've got some
inbuilt symmetry here right the left
hand motor neuron is always doing
exactly the same thing as the right hand
motor neuron they're both doing exactly
the same thing which means they always
get exactly the same values which means
they're always applying the same amount
of torque to the wheels which means the
vehicle
always um also say would go
faster closer like the angle those
towards like the the light source ah
okay so it's always going to go straight
so you're answering my next question
anticipating my next question which is
tell me about the velocity of the robot
we know about its direction its
direction never changes it always goes
straight what about
velocity the velocity would decrease
because the light isn't headon if the
well we're assuming that this is from
this example
like um but since the numbers are not
the same on each side that means that
it's hitting it from an angle so that
means that at some point it would pass
that angle okay and what happens let's
let's do this example we've got the
flashlight front left of the robot we
know that the robot always grows
straight so it's going to obliquely
approach the light the light is going to
generally get closer to the body of the
robot and then pass by what happens um
as it gets closer the go
up absolutely so if the light is front
left of the robot and the robot moves
forward now the light is a little bit
closer there is still a difference in
the two input values the two values at
the sensor neurons but their sum is
greater there's just more light falling
on both sensors so the robot speeds up
go goes past the light and the light
starts to fade behind the robot what
does the robot do as the light starts to
fade into the background behind
it it slows down okay so the purpose of
our little back and forth here is just
to remind you that the choices we make
about the neural network inside the
robot changes to the neural architecture
like we just saw influences how the
robot behaves in its environment
that's the whole game we're going to
play in this course if we want the robot
to do something useful what is the right
neural network controller that will
cause the robot to do that so far so
good Okay so we've got neurons now that
are summing their
inputs let's assume this hypothetical
example uh over here we're going to now
fold in yet another biological detail
which is we're going to start to assign
floating Point numbers to the
synapses and these floating Point
numbers are known as weights why are
they called weights the larger the
number is sorry the greater the
magnitude of the number the more
negative or the more positive that
number is the greater the weight of
influence that synapse has on its post
synaptic
neuron this is again a biological detail
of synapses some synapses pass along the
signal from their pre to their post
synaptic neuron but they weaken the
signal as they pass it along they have a
decree they decrease the weight of
influence of their press synaptic neuron
on their post synaptic neuron this
biological detail is incorporated into
artificial neural networks by assigning
these numbers and then every time we're
calculating the value at a post synaptic
neuron
we take that neuron we look at all of
the incoming
synapses we take for each synapse we
take the value of its pre synaptic
neuron we multiply it by the weight of
that synapse add it to the value of this
post synaptic neuron go to the next
incoming synapse for this particular
neuron multiply that synapses pre
synaptic neurons value by that synapses
weight and add it to this growing sum at
the post synaptic neuron yeah so how did
we get 1.29 here 0.6 * 0.8 plus 0.9 *
0.9 so far so good okay this is the
magic formula the main thing that
underlies all chaty pts stable
diffusions everything is built on top of
this basic idea in chat GPT in stable
diffusion you have a gazillion of these
neurons wired up in horrendously
intricate intricate ways what do each of
those little neurons inside Chachi PT
do this times this plus this times this
that's it well that not not just it but
most of what these neurons do so far so
good okay all right so uh that's
synaptic weights
let's add in one additional detail known
as activation functions and this name
comes again from biological neurons
which we'll get to in a moment let's
back up a moment in this hypothetical
example we can see that the two motor
neurons receive these two values imagine
that the leftand motor over here says
excuse me I have a problem you're
telling me to rotate you're telling me
to apply rotational force or Torque to
the wheel at
1.29 whatever the units are for torque
doesn't matter for our purposes I'm a
relatively weak motor I can only apply
torque up to 1.0 nothing above you're
asking me to do the impossible I can't
torque the wheel that
strongly a lot of neurons what we're
going to try and do is Cap the raw sum
that we're calculating inside that
neuron we're going to try and cap it
within a reasonable range what do we
mean by a reasonable range in our case
where the neural networks are going to
control the motors that make up our
robot we're going to try and cap that
range to the values that those Motors
can apply not not too not above not
below so far so good so we're going to
again add a little bit of detail or
complication to how we simulate these
neurons after each neuron computes its
raw weighted sum we're going to pass
that raw sum which in this case is
1.29 for this neuron we're going to pass
it through an activation number which is
going to take those raw values whatever
those raw values are and ensure that it
squashes them within a reasonable
range in uh artificial neural networks
there are a lot of different kinds of
activation functions that are used the
simplest is the identity function which
doesn't do any squashing at all you just
take the raw value and supply and return
it as the output of that neuron that's
not going to work for our purposes
because our Motors can't do everything
we ask them to do we might use the step
function where if you think of the
horizontal axis here the X representing
the raw sum if that raw sum is greater
than zero X is greater than zero return
from that neuron a value of
1.0 if the raw sum arriving at that
neuron is less than zero X is less than
zero return a value of minus one for
example if we were to take this step
function and use this step function as
the activation function for these
neurons and then we took this neural
network and put it back inside the
brenberg vehicle how does this step
function affect the way the vehicle
moves uh that's part of the answer
y it would either be moving as fast as
it can right so the neurons are either
rece the the neurons are either spitting
out plus one which means rotate the
wheels as fast as possible forward or
the motor neurons are outputting a minus
one reverse as fast as possible if you
dropped this neural network with step
activation functions into a brenberg
vehicle you'd see if through this then
this then this then this then this it
would always either be racing forward or
racing backwards we've again made a
change to the neural network controller
of the robot and we can see there's a
change to the robot's
Behavior would it going backwards
require that the sensors have like a
negative light value okay great po
question in order for it to go backwards
meaning that the motor neurons are going
to have to receive or be able to receive
a negative
number don't the sensors have to
register negative
values before we answer that question
remember that in our cartoon example
here these two sensor neurons are
receiving values from two photo sensors
which are registering the amount of
light in the
environment can light sensors register
negative
values there's no such thing right so
the the sensor sensor neurons are only
ever going to receive positive values or
maybe zero if it's pitch black how do we
get negative numbers at the output layer
Nega negative weights you'll notice that
one of these four synaptic weights has
has a negative value associated with it
thank you for asking that question that
was one additional biological detail
that I was about to miss yeah what does
it mean for a synapse to have a negative
weight be inhibitory it's inhibitory so
synapses can be either
inhibitory or
excitatory so inhibitory neuron is an in
inhibitory
synapse is simulated by giving that
synapse a negative
weight you can see how an inhibitory
synapse works by looking at this
particular synapse here remember that
we're always going to multiply this
synapses pre synaptic neurons value by
its
weight if this value is very low meaning
this sensor is ready registering low
light values we've got a value near zero
being multiplied by a negative number
which means we are subtracting a small
amount from this growing sum everybody
see
that as the vehicle keeps moving towards
for example a light source this value is
going to start to increase in
magnitude what starts to happen in how
this synapse influences is its post
neuron this value is increasing in
magnitude the weight doesn't change it
stays minus
.3 what's
happening the output the output is going
to go down the higher magnitude
multiplied by this negative number means
we are subtracting more from this output
neuron the inhibitory synapse is
inhibiting its post synaptic neuron by a
greater amount
yeah gosh forbid this happens to any of
you over the next hour you start to
realize you might need to visit the
men's or ladies rooms after this lecture
finishes as this lecture continues that
need grows greater assuming you want to
stay and listen to the rest of the
lecture you're going your brain is going
to have to increasingly inhibit your
motivation to go visit the men's or
ladies room yeah this happens all the
time lots of interesting Neuroscience
even at this point in our discussion it
seems like uh Neuroscience is
discovering that most of the connections
in our brain are
inhibitory the pre the stronger the pre
synaptic neurons value is the more that
inhibitory synapse inhibits the firing
or the activity of its post synaptic
excitatory that's all the positive
weights the stronger the magnitude of
the pratic neuron the more it adds to
this growing sum rather than subtracts
from it so far so good okay lots of
different kinds of activation functions
we can choose the in the early days of
the deep learning Evolution there were
papers being published about new kinds
of activation functions were uh claiming
this is the best activation function you
put this in your early chat GPT and
it'll do way better you can imagine what
happened a few months later somebody
else published a paper saying no no no
no no this activation is the best one
okay this is not a class in artificial
neural networks we're not going to
discuss the pros and cons of different
activation functions the assignments
will instruct you to drop in a
particular kind of activation function
and off we go so far so good okay let's
push on okay what do neural networks do
in this class the neural network is
going to control the robot how does the
neural network control the robot by
acting as a function a neural network is
really just a mathematical object that
represents a function that
transforms
its inputs into a value or values
arriving at that Network or functions
output yeah okay so let's have a look
about at how neural networks actually
act as a function we're going to
simplify things greatly here we're going
to assume we have just two input neurons
I'm going to use input neurons
synonymously with sensor neurons in this
class when I say input neurons that's
kind of a hint that we're going to just
focus on non-embodied stuff for a little
bit we're going to ignore the body of
the robot when I say output neurons same
thing output neurons are synonymous with
motor neurons when I say output we're
assuming we're not really thinking about
the robot in which the neural network is
placed okay as you can see the
particular neural architecture for this
simple neural network it's got two input
neurons one output neuron two synapses
we're going to further simplify things
where we are going to apply values we're
going to plug values into the two input
neurons and we're going to see what
values we get at the
output we're going to use uh we're going
to use a step activation function at the
single output neuron if the raw sum that
arise that arrives down here is less
than some threshold we we're going to
set in a moment what that threshold is
if that raw weighted sum is below this
threshold we're going to set the output
neuron to zero if the raw weighted sum
arriving at that neuron is above that
threshold we're going to set the value
of that output neuron to one so the
input neurons and the output neurons are
only going to be able to encode binary
values we've got two binary input
neurons which means there's four
possible cases we can plug zero in here
and zero in here and see what we get at
the output we can plug zero in here one
in here we can see what we get at the
output and so on what I want you to do
now is to write down in these boxes or
on a on a sheet of
paper two synaptic weights I want you to
come up with weights for these two
synapses and I want you to come up with
a third number which is the threshold
for the output neuron so that if you
label these two synapses with your your
two chosen weights and you embed this
threshold in the output neurons
activation function I want you to do it
such that this neural network embodies
this particular Boolean function what is
this Boolean function and and yeah so
we're creating a neural network that
embodies a particular function the and
function what are those two weights and
what should that activation threshold
be
there is no one right answer there are
many triplets two weights and one
activation threshold that'll do the
trick five and five
okay
for okay can you tell us why you picked
those three
numbers it's just two equal numbers and
then some of those numbers to say okay
if I don't have both of these numbers I
won't be the sum or I'll be less than
the sum rather so that way you can say
if I have that sum then both are
absolutely great summary right so the
trick to the and function is having one
active unit is insufficient right it's
only when both input neurons are set to
one that you want the output neuron to
be one so if we take for Simplicity sake
0. five and we plug those two values in
here and we plug in 0 0 at the input
layer 0 * .5 is 0 plus 0 * .5 is 0 0 + 0
is 0 0 is below one the activ ation
function so uh zero the raw sum is below
one the activation thresold so the
output neuron will
output zero so far so good if we plug in
0 1 0 1 0 * .5 is 0 0 + 1 * .5 is 0.
five 0 + 0.5 is 0.5 0.5 our raw weighted
sum is still below the activation
function threshold of one so the output
neuron still outputs
zero it's only when we plug in 1 one 1
time5 plus 1 * .5 is
1 oh I've got a mistake here we've got
minus uh less less than or equal to we
now have the raw sum of one which is
less than than or equal to one which
means the output is being set to zero in
case not quite right we need to make one
slight change here to fix
things
like in the interest of time I won't go
back and do the original two cases let's
do this case again 1 * .5 + 1 * .5 is 1
which is greater than .95 thank you now
that the raw sum is the raw sum of one
is greater than 0.95 the output neuron
outputs a one these three set of values
assigned to this neural architecture
cause this neural network to embody the
function so far so
good
okay that's and
uh you'll see my solution here pretty
close to our
solution what about the or
function let's play the same
game what two synaptic weights plus an
activation function applied to this same
neural architecture will now cause this
neural network to embody the or
function and then be
tell me about your intuition how did you
come up with these
numbers get one
get absolutely so the values of the
synaptic weights before were 0. five
Your solution is to increase the two
weights of influence from .5 to one
which means now either of these cases if
we plug in 0 1 0 1 0 * 1 is 0 + 1 * 1 is
1 0 + 1 is one that one is already above
our threshold we now have a neural
network that embodies the or function
for some of you this might seem silly
and overly simplistic if you've never
done this before with pen and paper I
highly suggest you do so for those of
you lucky enough to go on and work in
the AI industry
and you build the next generation of
fantastically complex and capable
artificial neural networks it behooves
you to be able to in the absence of
everything else sit down and manually
simulate a neural network from the
ground up you know compared to tinkering
with the fantastically complex machine
but not really having a good intuition
for how that machine works at its most
basic level this is neural network
operating in its most basic way yeah
okay how about this one exclusive ore we
want to now again come up with two
synaptic weights plus an activation
threshold so that this neuron this
neural network will output a one only if
only one of its inputs is
on
you do one negative one for the
weights one negative one for the weights
and we need a threshold you use the same
threshold okay do these two synaptic
weights plus that activation threshold
does it do the
trick nope other ideas a threshold of
zero a threshold of
zero does that do it
in the interest of time I won't go
through all the four cases hopefully you
can do some of these in your head
now no I wouldn't do it because if you
were if you were adding both and you
would have um you have it being
like
if you were adding the negative one then
it wouldn't be giving like a positive
one value it's not going to work but
okay other
ideas could you just have weights of one
one and then have the threshold be
anything greater than one anything
greater than one or two or 1.5 sorry no
just one one of so like if it's one one
then the output is two which so
so
oh wait that doesn't work
either anyone figured out what the game
beneath the game is
here ah it's not going to do it there is
no set of three real values that will
exclusive or function okay let's pause
for a moment this realization was made
in the about around the mid 80s when
neural networks were first starting to
gain some traction there was a AI High
summer or at least an AI spring that was
in full bloom at that time most people
were convinced or a lot of people were
convinced holy cow these things called
artificial neural networks this is it
we're finally going to make intelligent
machines these really smart guys back in
1956 told us that it would just take one
summer they were wrong it took longer
than we expected but now mid 80s this is
it here we go look we can make a neural
network that embodies or we can make a
neural network that embodies and this is
it AGI is a breath away if we can do and
Andor we're almost
there somebody came along Marvin Minsky
who we actually talked about in the
history of AI came along and said wait a
second there are actually some
relatively simple functions that neural
networks cannot solve and that punctured
that ended up puncturing all of the
excitement in AI within the AI Community
more importantly within the funding
agencies that were giving money to drive
this research and that drove artificial
neural networks into a very deep winter
starting in the mid to late
1980s in the 90s if you mentioned
artificial neural networks in a Grant
application good luck to you some crazy
person came along in the early 2000s
didn't call them artificial neural
networks called them deep Learners they
rebranded what these things are called
and showed that you could actually could
create a now deep learner that solves
the exclusive or function somebody
mentioned adding one detail which is
maybe add a third case to the activation
function turns out there are different
ways you can add some complication to
make these deep learners embody
exclusive ore that wasn't the twist they
added what was the twist they added in
the early 2000s which triggered the
current High summer that we're in does
anybody
know add another
layer they made the networks
deeper if you think about each of these
rows of neurons and we're going to start
to see neural network arranged in rows
of
neurons you could add layers in between
this is commonly known as the input
layer this is commonly known as the
output layer and the layer or layers
sandwiched in between are known as the
hidden
layers as long as those hidden layers
also had certain kind of activation
function
and for our purposes we'll just we're
just going to sck with the step function
you can get a now deep learner to embody
exclusive
ore
how as you can see here I've added uh a
hidden layer we've got two hidden
neurons so-called hidden neurons because
they're hidden from direct influence by
the outside world these neurons don't
directly receive values from out here
whatever is Upstream of the input layer
and they also do not directly influence
whatever is outside here Downstream of
the output neurons all the hidden
neurons do is influence or modulate the
way that the layer before influences the
layer of neurons after so far so good
okay I've I've solved half the problem
for you I've added two hidden neurons
I've wired up the two input neurons to
the two hidden neurons with four
synapses and then we're going to take
our two hidden neurons wire them up with
synapses to the one output neuron and
now in order to get this thing to embody
exclusive ore we have to come up with
one 2 3 4 five six synaptic weights and
1 2 3 three threshold activation
thresholds for our two hidden neurons
and our one output
neuron this is a pretty difficult
problem to solve if you just attack it
head on I want you to pay attention to
the strong hint that I'm giving you the
two hidden neurons you're going to use
them to compute partial
results and then those two partial
results encoded in the two hidden
neurons I want you to come up with two
syn weights and an activation threshold
that combine those partial results in
just the right way to solve exclusive
or before you start trying to come up
with synaptic weights what do you think
the two sub result two uh partial
results should be what are the two
subfunctions that make sense to compute
and then combine them to solve exclusive
or is it and an or and and or are the
two subfunctions we want to create why
is Computing and and or first and then
combining them in some way why is that a
good way to solve exclusive
or exclusive or
is or and not and or and not and yeah if
we just look at the what we want the
exclusive or's outputs to be I'm going
to flick back and forth between
exclusive or and and here's and
here's exclusive or now I'm going to
flip back and forth between exclusive or
or in three out of the four cases we
want exclusive ore to act like or and
only in the fourth case do we want to
suppress or
inhibit the or
function okay so what do we need up here
if we want this thing to embody and and
this thing to embody
or0 five and 0 five and a threshold
of 95 which will give us which one
that'll give us and so if we apply that
to the left hand hidden neuron the left
hand hidden neuron will embody the N
function we want the right hand hidden
neuron to embody the or function so
it's
one
okay what do we label the last two
synapses with and what activation thre
threshold do we set so for this do we
want to inhibit and well keeping or
strong is that like
so yeah negative there
and a positive there why do we want to
inhibit the and
gate if if and is
[Music]
true we want it to not act like the or
gate going back and forth between
exclusive or and or in only the case
where one and one comes in one one will
light up the and hidden neuron that
neuron when it lights up it should
inhibit the output
neuron everybody see that apologies in
my cartoon example here I've got and on
the right hand side and or on the left
hand side it doesn't matter the
intuition here is we want the neural
network to compute and an or as long as
it's not one one let this thing flow
down to the output neuron this thing
should act like an orgate in three out
of the four cases in just that case
where one one happens that one one
should override this part and inhibit it
so it outputs a
zero the activation threshold of the
final neuron that just has to be any
positive number like
uh does it
just not any positive number or any like
value between zero and one any value
between zero and
one there's lots of different ways you
could do this and again I encourage you
if you got a free few free moments this
week sit down with pen and paper and
come up with different ways of doing
this yeah okay that's a lot of
explanation just to really drive home
this this fact that choice of neural
architecture the number of neurons and
synapses and how they're wired up plus
the labeling of that Network which
synapses we set to excitatory and
inhibitory and activation functions can
alter this
transformation for our purposes as we
leave this slide what we've done by
introducing neurons is allow for
nonlinear
Transformations for our purposes that
just means that there are certain simple
transformations that a shallow learner
cannot do there are more complex or
nonlinear Transformations for which you
need a deep learner you need something
with one or more than one hidden
layer
okay again this is not a class in
artificial neural network so I'm racing
through a lot of these details what
happens if the what happens if the
neural network makes a mistake we were
able just barely to to think up with our
Collective brains what all the weights
and activation thresholds should be
Beyond exclusive ore it gets near
impossible to actually write down the
correct weights and activation functions
for a neural network so why don't we
create a computer program that figures
out what those weights and activation
functions should be there were many
algorithms that were proposed to do this
the winning algorithm that came back
with a vengeance in the the early 2000s
was the back propagation of air
algorithm I just told you that the nuts
and bolts of neurons and synapses and
weights and activation thresholds is
sort of the bread and butter of the deep
learning Revolution it's really the
bread the butter is the other thing the
algorithm that is able to figure out
what all these labelings should be so
deep deep Learners plus the back
propagation of air algorithm is is what
made chat GPT and stable diffusion
possible okay very briefly how does back
propagation of erir work let's imagine
we have this particular neural network
that has two output neurons output one
and output two we have a big uh truth t
or not a big truth table we've got four
possible cases and for whatever reason
when we Supply 0 one here we want the
output to be 1 Z doesn't matter which
Boolean function this is let's just
assume this is what we want to happen
when this
happens let's start by just setting all
the weights to one we don't know what
they should be let's just all make them
one if we assign one and we feed in 0
one at the input layer we do not get the
desired Result One Zero we get one one
output one did the right thing output
one did the wrong thing there's error at
output two there is no error at output
one what do we do next the name of this
algorithm gives it away
hopefully we're going to propagate
backwards through the network we just
propagated from input to Output now
we're going to back propagate from
output up to input and we're going to
flow this air backwards and Trace the
origins of this err why did this neuron
make a mistake and we're not going to go
into how this is actually done it
requires a little bit of calculus we're
not going to do that this morning
suffice it to say the back propagation
algorithm is able to determine how to
change not the value of the neuron it's
going to go keep going backwards it's
going to propagate backward and it's
going to make changes in this case to
the two incoming synapses these synapses
these two synapses are the only thing
that's influencing the behavior of this
erroneous neuron so that's where you
should go back propagation travels
backwards along both links and makes a
change to
them so that now the next time you
propagate
forward it does the right thing that's
the back
propagation of air
algorithm arguably the greatest
invention ever human any human ever
invented if someone were to ask for my
opinion I would say this is ultimately
going to be more valuable than the wheel
you can form your own opinion okay all
right one last thing I want to point out
that will probably come up in your final
project is a problem with the back
propagation of air algorithm which is
overfitting just as a cartoon example of
how this works you can see we've now
made a more complicated truth table down
here it's still a binary table but we've
got more rows and columns now we're
going to assume that this is a clinical
neural network it's going to be used in
the emergency room right across the quad
over here as patients arrive at the
emergency room and complain this
particular patient one complains of
symptom one not symptom 2 yes they
complain of symptom k a minute later
another patient walks through the ER
doors this particular patient is not
suffering from symptom one or symptom 2
but is suffering from symptom K the ER
continues to record all of this
information and whatever happens to that
patient after their visit to the
hospital did they have a particular were
they eventually diagnosed with a
particular disease or
not we're going to assume that with
enough symptoms or tests that there is
an under Ling relationship between all
of these input values and the output we
care about does the patient actually
have the disease or not imagine we
create a neural network with this kind
of architecture where we have K input
neurons for all the K possible symptoms
that the ER uh is recording and we have
one output neuron which is the neural
Network's prediction about whether this
particular patient with these symptoms
is actually suffering from the disease
not we're also going to assume that we
don't know what this relationship is but
maybe it's complicated and nonlinear so
let's add in some hidden neurons down
here and apply the back propagation of
air
algorithm okay unbeknownst to us what
does this neural network do during this
back propagation of air where we feed in
these different patient symptoms
propagate forward propagate backwards
tune the weights feed in the next
patient propagate forward propagate air
back tune the weights tune tune tune
tune tune tune tune tune tune over and
over again with hundreds and hundreds of
patient data we see that this neural
network actually gets better at
reproducing what the doctors put a lot
of effort into actually figuring out
which is whether or not the patient was
suffering from that disease or not looks
awesome our neural network is working we
take it we give it to the nurses at er
we tell the nurses don't bother don't
bother the doctors just when somebody
comes through the ER door ask them
figure out what symptoms they're
suffering from plug that into the neural
network and if the neural network
predicts they're not suffering from this
disease discharge them there's no need
to test them for the disease this neural
network knows whether or not these
symptoms uh are indicative of the the
disease or not you can probably guess
from this story where things are going
okay patient n plus one walks through
the door and has a particular
combination of symptoms that this neural
network never
saw this neural network predicts that
patient n+1 is not suffering from this
infectious disease so the nurse kicks
them out of the ER room of er
unbeknownst to the neural network and
the nurse and patient this patient
actually is suffering from that disease
the neural network made a mistake
happens all the time the most common
explanation for why it's making this
mistake is that the neural network has
overfit let's assume we trained this
neural network on N patients and just by
coincidence we happened to have n hidden
neurons inside that neural network
there's is an easy way for this neural
network to learn and predict all of
these n
outcomes use hidden neuron one to
memorize or recognize patient one you
can set all the incoming synapses to the
first hidden neuron so that this hidden
neuron will only light up when it sees
patient one and the rest of the time it
will stay silent this second hidden
neuron will learn through the back
propagation algorithm to light up only
when it sees Patient 2 and so on it's
memorizing all of the patients that are
available during
training what do the weights of these
synapses flowing from the hidden neurons
to the output neuron
do how do you need to if all the hidden
neurons are memorizing the patient
symptoms what do these synaptic weights
need to do to allow this neural network
to cheat to predict correctly whether or
not that patient is suffering from the
disease they need to establish weights
that like the people who have the
disease will always be signified as
true and if the patient is not suffering
from the disease we set the weight
to there will always be like some weight
that will set it to be false so for for
for this particular patient one they
were suffering from the disease so set
this synaptic weight to one one time one
if we set the activation threshold low
this output neuron will light up with a
one if patient two we who was not
suffering from the disease we feed in
all of the symptoms of patient two only
the second neuron lights up all the
others stay silent we take that Lit Up
second hidden neuron on and multiply it
by a inhibitory weight we get a negative
value down here which is very likely to
be below the threshold and this output
neuron predicts no that patient is not
suffering from the
disease I tell you that surprise
surprise we actually have a huge exam on
Thursday you haven't done any of the
reading you madly do all the reading you
try and contact students who've taken
this class in previous years you get the
surprise exams from previous years you
don't have time to do all the reading
and watch all the lectures you memorize
previous exams and hope hope hope that I
recycle
exams we all Panic from time to time and
cheat by memorizing rather than learning
patterns and data same thing with
artificial neural
networks okay we got one minute left how
are we doing with time we're not going
to finish this
today one additional detail I want to
put uh point out uh we're going to add
one uh one final detail to our neural
network architecture we're going to
introduce what are known as recurrent
connections or recurrent synapses you
might have noticed that in all the
cartoon neural networks we've looked at
so far they're all pointing more or less
downward they're pointing from the input
layer towards the output layer in some
way we can also add recurrent
connections where now for example if
we're trying to compute the value at
this first motor neuron we can see that
there are three incoming synapses to
this particular motor neuron so we're
going to take this value times this
weight plus this value times this weight
plus this value times this weight to
compute this raw sum if we know what
this value should have been so that
there's error at this
particular uh there's error oh sorry
let's forget Air for a
moment we've computed the raw value at
this point we've taken this sensor value
times this synapse this sensor value
times this synapse we need to collect
the value from motor two but we haven't
computed the value of motor 2 yet we're
just on motor one we're going to take
the Val what the value of motor 2 from
the previous time step if we if we'd
already updated this neural network once
we have a value for motor 2 from the
previous time step so we're combining at
this particular
neuron sensation in the current time
step what it's currently sensing and a
memory of what motor 2 did a short
moment ago so the last thing I want to
leave you with today is if we add
recurrent synapses to our neural network
we add memory to a neural network netw
work which we're going to see is useful
for certain robots that need to combine
current sensation with a memory of
things that have happened in the past to
know exactly what to do in the current
moment undergrads you're working on
assignment three grads you're working on
five and six you have a quiz due tonight
I'll see you all on Thursday thank you


--- Evolutionary Robotics course. Lecture 06. Evolutionary algorithms..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone thank you for
uh adapting to the change in today's
schedule uh I'm still sick so we are
going to do this as a recorded lecture
today rather than uh live so just as a
reminder for uh where we are and where
we're going um we're working our way
through the tools of the trade for
evolutionary robotics what are the basic
tools you need to be able to evolve
virtual robots uh in a physics engine we
almost finished our discussion last time
about building brain for our robots
which are artificial neural networks
we'll finish that lecture uh shortly and
then we will move on to lecture five
evolutionary algorithms how do we
actually go about evolving the brains of
our robots in Virtual
Worlds just as a reminder uh undergrads
you're working on uh assignment three uh
where you're implementing joints that
connect links together and grad students
you're working on assignments five and
six uh I misspoke uh last time you're
implem ing uh you're implementing Motors
and then you're doing in assignment five
and then in assignment six you're doing
a little bit of refactoring of your code
to clean it up and modularize it uh in
preparation for the remaining
assignments okay I normally ask if
there's any questions but none of you
can respond so let's just push right on
uh just to remind you we were talking
about neural networks last time very
generally speaking neural networks are
made up of simulated neurons represented
as these circles and synapses
represented by these arrows which are
connections between
neurons we talked uh last time about
hidden neurons which added between input
neurons and output neurons can allow
more complicated Transformations from
the values arriving at the inputs to the
outputs and we ended last time by
looking at one of the problems that
neural networks can face which is known
as overfitting they can end up
memorizing patterns uh
and then they fail to be able to
generalize to new examples I showed you
this patient and emergency room example
last time this is important for robotics
as well you can imagine that if you
evolve an artificial neural network uh
for your robot that allows it to run
around in one environment after
Evolution if you take that evolved robot
with an evolved neural network and place
that robot in a new environment it fails
to behave properly because the neural
network because the robot has in a way
memorized the kinds of sensor motor
patterns that it experienced in the
environment during
Evolution this is just to remind us that
one of the still outstanding problems in
Ai and Robotics in general is what
happens when we train or evolve our
robots or AI in safe environments and
deploy them out in the world how can we
guarantee or at least reduce the
likelihood that they will misbehave in
new environments this is one of the
issues that we need to look out for okay
so uh we talked so we actually ended
last time talking about uh recurrent
connections or recurrent synapses all of
the synapses you've seen so far Point uh
away from the sensor or input layer
towards the motor or output layer we can
also have recurrent connections that
connect together hidden ner neurons
connect together hidden neurons or
connect together motor neurons and when
we're updating the values of the neurons
in a neural network that contains
recurrent connections we do so as
follows let's assume at this particular
point in time these two sensor uh
neurons have these two values we need to
update the value of or need to compute
the value of this motor neuron we take
this value times this value the weight
of this synapse we take this value and
multiply it by the weight of this
synapse we now need to get a value from
this neuron and multiply it by the
weight of the synapse but we haven't
updated or we haven't computed the value
of this neuron yet so what do we do we
reach backward in time to time step T
and we get the previous value of that
neuron so it's the current value of this
sensor times its synapse the current
value of this sensor times its synapse
plus the past value of this neuron times
its synaptic weight sum those three
values and that's the value of motor one
if you think about it what the this
motor neuron or what the robot so to
speak is doing at this point in time is
combining what it currently is
experiencing with what it remembers from
the past so recurrent connections add me
memory to a neural network this can be
very important when we're using a neural
network to control a robot because what
a robot should do in a in a given
situation may depend on what it's
experienced in its recent
past a robot with a neural network
controller that does not contain
recurrent connections or recurrent
synapses cannot remember anything that
happened in the past and is doomed to
always do exactly the same thing when it
experiences exactly the same sensory
input okay all right there's a problem
with recurrent connections though or
there's a challenge to it um let's
imagine this particular neural network
here's some synaptic weights here we've
got two recurrent connections one
connecting uh this output node this
output neuron to this output neuron and
a second recurrent connection that
connects this output neuron to this out
output neuron assume that we know what
we want our output neurons to do
whenever they receive a particular pair
of
inputs as we saw before when we talked
about the back propagation of error
algorithm we see what the actual values
are that arrive at the output neurons We
compare those outputed values to what
the values should have
been and we look to see whether there's
any error in this case output neuron one
did what it was supposed to do but
output neuron 2 did not do what it was
supposed to do so there is nonzero error
at this neuron the back propagation of
error algorithm tells us that we should
then take that nonzero error and start
propagating backwards along all of the
synapses that arrive at the erroneous
neuron let's start doing that if we do
we walk backwards uh we walk backwards
along this synapse we change its weight
we walk backwards along this synapse to
change its weight and we walk backwards
along this synapse to change its weight
the back propagation of error algorithm
says we don't stop until we get to the
input layer so let's keep going if we
went along this if we go along if we
back propagated along this synapse we're
done we've reached the input layer if we
back propagate along this synapse we
reach the input layer and we're done
when we back propagated along this
synapse we did not reach the input layer
so it might have been that this uh
synapse was contributing to the error of
this neuron but maybe this synapse was
actually correct and it was these neur
these
synapses sorry it was these synapses
that were contributing air here which
propagated along to here so we have to
keep going we have to keep back
propagating but if we do you're going to
back propagate along here along here
change this synapse and back propagate
along here which means we're back to
here and it's a mess We've Ended up
haven't we can't really localize where
the error originated at this neuron
we've had to go back along every single
synapse looking for errors and trying to
change every thing whenever we're trying
to do this Global change or make a
change to all the synaptic weights
there's a good chance that we actually
might be able to reduce the air here but
because we're making so many changes we
might actually break something that's
already working which is this neuron so
there's a good chance that we might
increase the air for another input
pattern or at a different neuron in
essence when we apply the back
propagation of air algorithm to a neural
network with recurrent connections it's
like using a sledgehammer on the neural
network we're making we we're forced to
make huge changes the reason we're
talking about this again is that there
are uh challenges with the back
propagation of aor algorithm that we're
going to sidestep in this in this course
by not using the back propagation of
error algorithm uh we are simply going
to evolve synaptic weights and that may
have a dilus effect on a robot's
Behavior or it might improve that
robot's Behavior slightly we're just
going to let Evolution figure out where
the error was and fix
it okay a little bit more terminology
just so you can connect what you're
learning in this course to what you
might learn about machine learning in
other classes what we the example we
just saw is known as supervised learning
in the sense that for every possible
pattern of inputs
that can arrive at the neural network we
know exactly what the output of every
neuron should be so we can supervise the
training or the reduction of air this is
the supervisory signal it tells us
exactly what we should have got and the
we can then localize errors at least at
the output layer we know whether where
the output layer made a mistake and we
can take that supervisory signal and
with the back propagation of eror
algorithm we can work backwards to try
and fix that error so supervised
learning is in many ways a simpler uh
task than what we're going to look at in
this class which is semi-supervised
learning we're mixing the term evolution
and learning uh Evolution and learning
in nature are very different things
unfortunately in Ai and machine learning
and Robotics sometimes these terms learn
learning and evolution are mixed up a
little
bit from now on we're going to just talk
about evolution in this class or
evolutionary algorithms or evolving
robots or evolving artificial neural
networks but you can uh you these
evolutionary algorithms are often seen
by the machine Learning Community as
semisupervised learning algorithms why
is that in the case of a robot for any
given pattern that falls on its sensors
we don't know what its Motors should do
that's what we want the evolutionary
algorithm to figure out for
us we simulate our robot in a physics
engine uh at time step uh zero it gets
this sensory pattern the motors do
something at the next time step for
example maybe the robot experienes this
sensor pattern the robot does this and
keeps going and keeps going at the end
of the simulation we get back just one
Global number which represents the
overall behavior of the robot it
represents the overall quality of the
neural network that's controlling that
robot um for a lot of the experiments
we're going to see in this course that
overall number represents the distance
the robot traveled we're going to evolve
the robot to move if we evolve the robot
to grasp an object this number might
represent the distance between the
robot's fingertips and the object
doesn't really matter what matters for
our purposes is that we don't get back a
detailed signal of many numbers which
allow us to uh localize exactly where
the problem is we get back a
semi-supervised signal we get a a global
picture of how well or how poorly the
neural network caused the robot to move
the task is then to obviously figure out
how to alter that neural network so the
next time we drop that altered neural
network into the robot this number
increases gets better we don't know
exactly where in the neural network to
make changes to make that happen so
we're in a semi-supervised learning
situation okay again that's just to
connect this back to some things you
might hear in other
classes okay that completes our lecture
on artificial neural networks obviously
you can't ask me any questions today but
when we meet again in person on Tuesday
if you have any questions about this
please raise them in class let's move on
now to our discussion of the second tool
of the trade for this class which is
evolutionary
algorithms obviously there are now
multiple courses uh at UVM that you can
take that are exactly about uh machine
learning and neural networks there is a
also a sister course to this class which
is called evolutionary computation which
goes into great depth about evolutionary
algorithms uh in this course we're going
to spend just one class this class
talking about them so apologies in
advance we're going
to apologies in advance we're going to
skim over a lot of the interesting
details about evolutionary
algorithms okay let's start at the
beginning um evolutionary algorithms
have been around for a long time um
arguably the very first computer program
that was written back in the 1950s was
something very much like and
evolutionary algorithm so they have a
very long and proud history in computer
science the basic idea um is as the name
implies evolutionary algorithms they
take inspiration from biology and they
take inspiration specifically from
darwinian uh Evolution so as a computer
scientist if you look at what happens in
nature you you can start to
recognize that darwinian Evolution looks
a lot like an
algorithm we start with a population uh
of organisms and those organisms look
and act differently that's the phenotype
of an organism we'll come back to
phenotype in a moment and some of the
reasons for why they look and act
differently can be traced back to their
genes so not only do these individuals
have phenotypic variation they look and
act differently um they also have
genetic uh variation their genes are
slightly different from one organism to
another inside a
species unfortunately uh how you look an
act influences whether or not you're
able to reproduce and be survived by
your Offspring those that do not uh
produce Offspring uh or die off early um
they die off early those that survive
produce uh copies of
themselves when they produce copies of
themselves there are slight changes that
occur in the in the genetics during that
uh copying and reproduction process so
we have the more fit organisms the one
that survived survive and reproduce less
fit organisms die and as we've all
learned uh as we've all learned this
leads over time to a population uh a
population of organisms that are more
and more fit to their
environment that's biological evolution
we can take this idea idea and distill
it down into a computer program so we're
going to replace our organisms in this
simple example with vectors of
numbers where these vectors of numbers
represent a solution to some problem we
haven't defined that problem yet but we
have instead of a population of
organisms we have a population of
candidate Solutions these are random
guesses at the beginning to what the the
these Solutions
are we then take each solution in turn
and apply it to the problem and we get
back a single number as we just talked
about uh a few slides back we get back a
single number which tells us how well or
how poorly that solution solves the
given
problem solutions that obtain a a lower
score than other Solutions in the
population are deleted
and the surviving
Solutions are a uh produce offsprings of
themselves we take this particular
solution and we make a copy of it we
take this solution we make a copy of it
when we're copying one solution to
create a new solution to fill the Gap
left by those that have died off every
once in a while we introduce a random
mutation we alter one or a few of the
values in the surviving Vector that's
being
copied sometimes in an evolutionary
algorithm or a genetic algorithm uh we
sometimes introduce not just mutation
but recombination as well we might
choose at random two of the surviving
Solutions and take genetic part of the
genetic material from one parent and
take part of the genetic material from a
second parent and glue those two pieces
together to make a new solution to the
problem that combines parts of two
different surviving Solutions sexual
recombination okay that's the basic idea
of an evolutionary
algorithm evolutionary robotics is when
the problem is we want a machine that
does something that puts away our dishes
or shovels our snow or cleans our floors
and a candidate solution to that problem
is a machine that actually does that we
can imagine if the problem is please
clean my floors you can imagine an
infinite number of robots that do a
better or worse job at cleaning your
floors and theoretically we could we
could use an evolutionary algorithm or a
genetic algorithm to search over the
space of all possible robots looking for
the robot that does the best job of
cleaning uh your floors so uh now we're
not looking at we're not looking at
birds or vectors we're looking at
robots here's uh here's a uh here's a
evolved robot this robot was evolved to
solve a particular problem which is to
move along uh to move along a horizontal
beam as you see here this robot has
evolved the ability to do so I am sure
in the space of all possible robots
there is a robot that moves faster and
more energy efficiently along this beam
but for our purposes uh this is one of
the better robots that we found uh this
is a screenshot from now a very old
experiment that I was involved in as we
talked about uh as we've talked about a
few times already we are doing this in
simulation we're evolving populations of
robots throw away the bad robots and
making randomly modified copies of the
better robots and repeating this process
and repeating this process over and over
again in this old experiment this was
the best we came up with and what's not
visualized in this uh flowchart here is
a final step where if we get a robot
that's sufficiently interesting or
potentially useful we go to the effort
of then taking that evolved robot from
simulation and building a physical copy
of it
uh in this particular experiment we we
actually went that extra mile and built
this robot and you'll notice I'm not
sure if I can play both of these at the
same time yep okay you'll notice that
there are some similarities and
differences between the ways they move
but pretty close pretty close um the
other reason why I wanted to show you
this particular pair of images is to
remind you of our discussion about
embodied cognition last week one of the
uh advantages of having a body as an
intelligent machine is that you can
evolve or learn to exploit the physical
interaction of your body with the
environment to do whatever it is that
you need to do this is one of the more
uh graphic examples of a robot that is
exploiting its interaction between uh
its body and its environment if if we
were in person I'd ask you what that is
most of you have probably figured out
what it is you'll notice that in both
the simulated and the physical robot
it's using uh these blocks at the bottom
of its body to actually throw its weight
forward it's actually using that uh
oscillating weight and that momentum to
be able to move faster and more energy
efficiently along this beam those big
blocks uh that black block that you can
see in the physical robot that's the
battery for the robot so we had to build
this robot out of uh uh parts that were
available in 2002 unfortunately
batteries were then pretty heavy they're
still pretty
heavy this didn't end up being we
thought this was going to be a
disadvantage for the robot it was going
to have to haul this heavy weight as it
moved along the beam Evolution figured
out how to sculpt the neural network
controller of this robot we haven't
talked about its neural network
controller but this neural network has
evolved or the synaptic weights uh
inside this neural network have evolved
such that the robot moves in a
particular way in response to
Sensation that causes it to throw uh the
bottom part of its weight forward and
facilitate or ease its ability to move
okay so in a nutshell evolutionary
robotics is simply combining a genetic
algorithm or an evolutionary algorithm
with a robot simulator and then building
a physical version of it okay all right
um in order to continue our discussion
about Evolution we're going to have to
uh perform a thought experiment um this
is one of the most famous and Powerful
thought experiments in all of science um
it was formulated by a biologist Su
Wright back in the 1930s and it's known
as the fitness landscape
so what I want you to do is call up in
your mind a hypothetical landscape let's
start with a very simple one let's start
with a two-dimensional landscape let's
imagine we have a horizontal axis here
and as we move left or right along this
horizontal axis um the the height of
that landscape obviously
changes I want you to imagine uh imagine
all the way back to brenberg vehicle one
and I'm sorry I don't have the ability
to annotate on my screen here so I'm
going to draw it with my uh with my
cursor V brenberg vehicle one had a
temperature sensor on its front and a
single wheel at the back and its
temperature sensor was connected to its
motorized wheel with a single synapse so
we have a One sensor neuron one motor
neuron one synapse neural network
controller for brenberg vehicle one that
that vehicle would slow down when it was
in cold water low temperature sensation
leads to low turning of the wheel and it
would move quickly through hot water uh
high temperature readings would lead to
Rapid turning of the motorized
wheel okay you can then imagine taking
the weight or considering what should be
the weight for that single synapse so
that the robot does something that you
want it to do maybe it's stops almost
completely in cold and goes really
really fast in hot water the question
becomes what should be the value of that
single synaptic weight that's what I
want you to imagine is the horizontal
axis here it says value of Gene one so I
want you to think of that single
synaptic weight as a single Gene we're
encoding all of the synaptic weights
into a vector in this case it's a vector
of length one we have just one number
that encodes a solution to our problem
our candidate solution to our problem
which is making brenberg vehicle one do
whatever it is we want it to
do imagine that we set the synaptic
weight to this particular value whatever
this value is and we then watch brenberg
vehicle one either in simulation or
reality and imagine that Bren that
brenberg vehicle one does exactly the
opposite of whatever we want it to do it
goes very fast uh in cold water and
slows down in hot
water if our evolutionary algorithm
assigns a value to that uh to that
particular genome or genotype which is
that particular setting of values just a
single value it's going to set a very
low Fitness value the robot did that the
robot with that particular neural
network did very
poorly if we increase increase the value
of that synaptic weight a little bit the
robot does a little bit better if we uh
if we increase it again it does a little
bit better and so on so you can think
now continuing the fitness landscape
thought experiment imagine that you're
taking steps backward and forward in
this Fitness
landscape and you're experiencing
different fitnesses so in essence what
we want an evolutionary Al to do is
explore this Fitness landscape and find
as best it can high points in this
Fitness landscape to find the one two
three different possible settings for
the single synaptic weight in brenberg
vehicle one that causes it to do what we
want it to do in fact there's one
particular setting which is the best
okay let's pause for a moment and
introduce use a little bit of
terminology we're going to uh talk about
genotype and phenotype quite a bit in
this class genotype is uh is basically
the vector or the the vector or the data
structure whatever it is that contains
uh that can that encodes a candidate
solution so in our cartoon example here
the genotype has one gene in it that one
gene encodes the single synaptic weight
for brenberg vehicle uh one the
phenotype is the form and
function of the robot that results from
the genotype so the genotype in our
example here the genotype is a single
value maybe the genotype is 0.3 that's
the value of the synaptic weight we take
that 0.3 we label the single synapse in
vehicle one and then we let Vehicle One
start moving around in its
environment as it moves around in its
environment and we observe how it moves
that trajectory of its movement is the
phenotype it's the behavior of the
robot
okay okay um finally Fitness Fitness is
a measurement that we make on the
phenotype so Fitness is never computed
from the genotype Fitness is computed
from the phenotype we watch how vehicle
one moves and we assign in this simple
example a single number which is how
well vehicle one did at whatever we
wanted it to
do okay so armed with that uh
terminology oh sorry and here's a
summary of these uh a summary of these
for our purposes genotype is the storage
of the genetic information and the
phenotype is the system produced by that
information generally speaking
for this for the purposes of this course
the phenotype is the form and function
or the form and the be the shape and the
behavior of the
robot that results from that
genotype okay armed with that
terminology let's come back to the
fitness landscape for a moment if the
genotype has n genes the fitness
landscape is always going to exist in n
+ one Dimensions because the height of
the Fitness landscape as the name
implies is always Fitness yeah okay
let's imagine now uh brenberg vehicle 2
remember brenberg vehicle 2 has two
photo sensors front left and front right
and two motorized wheels back left and
back right and we have two synapses
either contralaterally connecting the
sensors to the motors or
ipsilaterally connecting the sensors to
the motors doesn't matter matter we have
two uh synapses which means if we're
going to evolve
behavior for vehicle 2 uh every time we
need to come up with two numbers the
weights of those two synapses so now uh
assuming we uh we going to evolve
vehicle 2 to exhibit some Behavior like
perhaps circle around a light source we
don't know what the two weights for
those two synapses should be so so that
the robot circles around a light source
we can imagine a fitness landscape where
we now have two horizontal dimensions
and every horizontal point in that
Fitness landscape obviously has a
two-dimensional coordinate we can take
that two-dimensional coordinate look at
those two numbers take those two numbers
apply them as synaptic weights to the
two synapses that's the genotype that
pair of numbers we then let go of the
robot we let the robot start moving
around in a simulated or physical
environment armed uh labeled with those
two synaptic weights measure how well it
does at for example circling around a
light source and assign a single number
for how well it does it's circling
around the light source and that single
number is the third coordinate it's the
value we assign to that genotype and we
get a
three-dimensional Fitness landscape in
this cartoon example you can see here uh
this particular pair of synaptic weight
values produces a robot that circles
around the light source very well this
particular pair of synaptic weights
causes the robot to do a terrible job at
circling around the light maybe it turns
around and runs away from the light
there's a whole bunch of other uh pairs
of synaptic weights that cause the robot
to do a so so job of circling around the
light okay take a moment to absorb uh
the fitness landscape metaphor we're
going to use it to explore a series of
evolutionary algorithms okay we're going
to start we're going to look now at a
series of evolutionary algorithms that
start very simple and get more and more
sophisticated they increasingly start to
resemble actual bi olical
Evolution let's start with arguably the
simplest evolutionary algorithm it's so
simple that you probably wouldn't even
consider this an evolutionary algorithm
at all bear with me I'll explain why uh
in a
moment uh this very very simple
evolutionary algorithm or maybe just a
search algorithm is called the hill
climber and here's why in the hill
climber we start the we're going to
start the hill clim Climer by creating a
random population of genotypes here's
one genotype remember it's a string of
numbers um it could be the vector could
be of length two if we're evolving pairs
of weights for vehicle two this Vector
could be of length one if we're evolving
a single synaptic weight for brenberg
vehicle one okay in the hill climber the
population size is always one meaning in
essence there is no population in the
hill climber at any given time there is
only one candidate solution to the given
problem okay let's create that single
Vector let's create that single Vector
uh with and and let's fill it with
random numbers you'll see over here
we've got our fitness landscape picture
again um I'm just drawing it in two
dimensions in this in this cartoon
example we have just one gene so let's
imagine we have just one vector we have
a population size of one for the hill
climber and the length of that Vector is
just one we have just one floating point
value so let's imagine we're trying to
find a single synaptic weight for
vehicle one we create that single
synaptic weight at random drop that into
vehicle one let vehicle one start to do
its thing this is known as the parent uh
ution represented by P here let's assume
that we randomly created a synaptic
weight that was pretty high in magnitude
it's pretty far to the right here and it
causes the braon uh vehicle one to do a
pretty poor job at whatever it is we
wanted vehicle one to do it doesn't
obtain a pretty uh it doesn't obtain a
very high height on the fitness
landscape okay what do we do at this
point um you can see that we want to go
in this direction we want to push up
here but from the point of view of the
hill climber it does not see the fitness
landscape the only thing that the hill
climber sees is the height of this
single
point I want you to imagine that uh you
want to climb Mount Mansfield but
unfortunately you choose to climb Mount
Mansfield on an incredibly foggy day you
know enough to drive to uh one of the
parking lots next to Mount Mansfield
Feld you then turn off your phone no
cheating no GPS how do you get to the
top of Mount
Mansfield first of all I don't recommend
actually trying
this it's not really clear you start in
the parking lot at a pretty low altitude
what do you do well um one thing you can
do is take a random step in a given
Direction and see whether you increase
or decrease in height that's exactly
what the hill climber does as promised
it's a a very simple algorithm but not
the smartest algorithm there is what
does that mean that means we take our
parent solution which is a vector of
length one remember in this simple
example the hill climber makes a copy of
that single length one vector and when
it makes a copy of that Vector it makes
a random alteration to the values in
that Vector there's only one value in
that Vector so it's this value that gets
Chang Changed by a slight amount in my
cartoon example here that random
mutation increases that single Gene
value or that single synaptic weight
value by a small amount which means uh
from the point of view of the hill
climber it's moved one step to the
right along this horizontal axis we take
that new synaptic weight drop it back
into vehicle one and again Watch How
vehicle one does in this cartoon T
example
here uh the child solution actually does
worse than the parents solution vehicle
one does an even worse job at whatever
we wanted it to do compared to vehicle
one when it was labeled with the
synaptic weight from the
parent let's go back to the parking lot
next to Mount Mansfield it's a foggy day
you walk out of the parking lot and you
go downhill a little bit you're probably
headed in the wrong direction what do
you do you you would probably do exactly
what the hill climber does which is
delete the
child the hill climber throws the child
away goes back to the parent makes
another copy of the parent and again
randomly mutates the parent and maybe
now this second child actually has a
lower synaptic weight than the parent we
take that lower synaptic weight run it
on vehicle one and we now realize that
vehicle one actually does a better job
at whatever we wanted it to do than
vehicle one did when it was labeled with
the parent synaptic weight in essence
the hill climber has uh figuratively
taken taken a step in the right
direction we now have a parent with
lower Fitness than the child what do you
think the hill climber does at this
point it throws away the parent keeps
the child the child becomes the new
parent so there'd be a p sitting here
and we repeat the process the parent
produces a child we evaluate the child
if the child's Fitness is lower than the
parent we throw away the
child if the child's Fitness is higher
than the parent we throw away the parent
that's it the hill climber repeats this
over and over again let's go back to the
example of you on the uh in the
foothills of Mount Mansfield you you
always retrace your step if you go
downhill but as long as you take a step
that increases your own altitude you
stay where you
are doesn't take you probably won't take
you long to realize that that's not
going to help you get you're you're
going to be very unlikely to get to the
top of Mount Mansfield you can see that
on our fitness landscape here parents
and children keep uh reproducing over
and over again to the hill climber and
the hill climber will probably gradually
climb
this hill but when it gets up here and
there's a p sitting up here p is going
to start producing children
nearby through mutation that are all
worse than P so all of those children
are going to keep getting thrown away
and P will probably continue producing
children forever and never escape this
local Hill that it's got gotten caught
on this is an important uh issue in
evolutionary algorithms in general
um what this peak is know what this
local Hill is known as is a local
Optimum meaning in a local space local
meaning in the horizontal Direction so
for synaptic weights of about this value
this is the optimal solution here's
another local Optimum within this range
of synaptic weights this is the best
synaptic weight this is the local
Optimum
if theoretically we were able to visit
every possible setting for this single
synaptic weight we would realize that
there is a global Optimum this is the
best setting for that single synaptic
weight that's possible what happens with
uh weak evolutionary algorithms like the
hill climber is that they tend to become
trapped on local
Optima so the hill climber simple to
implement is a relatively weak search
algorithm doesn't do a very good job at
search so can we complicate the hill
climber a little bit so that it is less
likely to get trapped on local
Optima what's the simplest thing we
could
do we could uh what's the simplest thing
we could do instead of you going to
Mount Mansfield on a foggy day and
hoping to find a slope that takes you
all the way to Mount Mansfield call a
bunch of your friends have them go to a
bunch of different parking lots that
surround Mount Mansfield everybody
starts taking local steps and continue
moving if they're moving uphill but
retrace their steps if they end up going
downhill and keep texting one another as
you do
this and hope that one of you manages to
to land on a slope that takes them all
the way to the top of Mount
Mansfield that's the parallel hill
climber as the name implies it's very
much like the hill climber it just runs
a bunch of hill climbers in parallel so
now when we initialize the population we
initialize the population with more than
one genome or one
genotype we've got a bunch of them which
are going to be represented as parent
one parent two and so on for each of
those parent Solutions we're going to
set the internal uh value to a random
value which means uh those initial
random parents are going to materialize
at different points along the horizontal
axis P1 lands here P2 lands here and
then both P1 and P2 run one step of the
hill climber P1 produces one child P2
produces a child and if uh if the child
is worse than the parent if a par parent
one's child is worse than it that child
is killed off and parent one is allowed
to produce another uh Offspring in this
case parent 2 produced a child that has
higher Fitness than its parent so the
parent is killed off C2 becomes the new
P2 and we then repeat one step of the
hill climber over here and another one
over here yeah so we're increasing the
odds
that someone is going to land on the
lower slopes of what turns out to be the
global
Optimum I've picked the positions of P1
and P2 on purpose here to illustrate
that this slightly more powerful
evolutionary algorithm the parallel hill
climber still can get stuck on local
Optima p uh P1 over here is going to
eventually and its offspring are
probably eventually going to climb but
then get stuck on this loal Optimum P2
and its descendants is probably going to
end up getting stuck
on uh this local Optimum so better but
not perfect can we do better let's add
in an additional detail from biological
evolution which is sexual recombination
for now we've just been considering
mutation when we take a parent and
produce a copy of that parent we
introduce a slight change a random
change to one of the values in the
child's genotype in the genetic
algorithm which is one of the oldest and
probably the most popular kind of
evolutionary algorithm we're going to
introduce sexual
recombination another note about
terminology the genetic algorithm is
such a famous algorithm that often the
name of the field as a whole which is
evolution uary algorithms is referred to
as genetic
algorithms as you've already seen and as
I'm going to try and drive home in the
rest of this lecture evolutionary
algorithms is a field of study and
within that field of study there are
dozens if not hundreds of different
kinds of evolutionary algorithms one of
which is the genetic
algorithm okay how does the genetic
algorithm work it starts out very much
like the par hill climber we start by
creating several uh random genotypes
several candidate solutions to our
problem we're going to stick with our
cartoon example of vehicle one with one
synaptic weight so again we have two
random solutions that end up at these
horizontal positions in the fitness
landscape as we just saw in the previous
example we evaluate each we evaluate P1
on vehicle one
we evaluate P2 on vehicle uh one we see
how well they do um now we take these
two
individuals and when they produce
children they do not produce a child
alone we randomly choose two uh
Solutions in the population in this
population we only have P1 and P2 so we
choose P1 and P2 we then choose a random
point along the genotype of parent
one and parent 2 and we cut the genome
uh the genotype of parent one at that
horizontal position and we cut parent
two at exactly the same horizontal
position in my cartoon example here
we've chosen this cut
Point uh after the second Gene my
apologies I'm kind of mixing metaphors
here we're dealing with a fitness
landscape over here that just has has a
s a genotype of L length one over here
in order to illustrate recombination we
have genomes that contain more than one
gene my apologies okay so we cut at
these two positions and we take all of
the genetic material uh to the left of
this cut point from parent one which is
shown in red and we copy that into child
one we then take all of the genetic
material that's to the right of the cut
point from parent 2 and copy that into
child two so we're taking some of the
genetic material from parent one we're
taking the leftand genetic material from
parent one and the rightand genetic
material from parent two copying those
two pieces and gluing them together to
make a new child in the genetic
algorithm after we've performed this
recombination event we also walk along
on this new child genome and from time
to time slightly randomly change some of
these numbers so we add mutation on top
so the genetic algorithm contains
mutation and sexual
recombination continuing my example down
here these parents might actually end up
producing a second child in which now we
take the right hand material from parent
one and we take the leftand material
from parent two and glue those together
to make a second child so that now we
have two children that are genetically
dissimilar from one another represented
by the Numbers here but still resemble
their parents in some way they they are
genetically related to their parents
what does this end up doing well as you
can see here this particular child has
more numeric differences from this
parent and from this
parent than if we just do mutation this
child is more numerically similar
similar to its parent than this child is
to its parent the fact that let's call
this C1 C1 is more genetically
dissimilar from parent one and parent
two means that child one has moved
further horizont Al in the fitness
landscape everybody see that okay so
that's a good thing we're introducing
more difference into the child compared
to the parent which means it might be
possible if the parent is trapped on the
slopes of a local Optimum for the child
to escape from that local Optimum in my
cartoon example here uh Child 2 was not
so lucky Child 2 is still pretty far
from both its parents
horizontally compared to here where we
can see that child two is not that
horizontally distant from its parent and
same thing with child one it's further
but unfortunately C2 is still trapped in
the same on the same local Optimum as at
least this
parent see one over here in our cartoon
example has been lucky it's inherited
some genc material from P1 and P2 that
has allowed it to escape from both local
Optima that its two parents are
respectively trapped on and it invades a
whole new space a whole new way of
Behaving and unbeknownst to C1 remember
this whole thing is bathed in fog the
genetic algorithm can only see the
heights of the points that it's tried so
far suddenly C1 is higher than anyone
has been before and as C1 continues to
produce Offspring in this cartoon
example one of its descendants is likely
to reach the global
Optima okay so what has happened in the
case of C1 C1 has gotten lucky that
through a series of random events we
randomly choose which pair of parents to
pair up to produce an offspring we've
randomly chosen where along the genot
types of these two parents to
cut those through those random events
we've ended up bringing together good
parts of parent one and parent two
parent one and parent two are low have a
low height meaning poor Fitness so
there's some something wrong with both
parents they're not so good at something
but whatever it is that they were bad
out that got spliced out and wasn't
brought into C1 so C1 is inheriting the
best of both parents and avoided
inheriting the worst of both parents
that is in a nutshell why sexual
recombination evolved in nature and why
it's useful for evolving robots and all
sorts of other things in machine
learning in Ai and
Robotics so the genetic algorithm it's
not perfect and it's a little more
complicated than the parallel hill
climber but it tends to a better job at
escaping local Optima um at this point
uh students usually have a number of
questions the most popular question is
how can you guarantee that the genetic
algorithm or any evolutionary algorithm
will eventually find the global Optimum
if any of you are thinking of that
question good for you it's an important
question and the answer is nobody knows
evolutionary algorithms are relatively
simple algorith orms in the space of all
machine learning algorithms but they all
share a limitation at the moment which
is we cannot guarantee that even if we
run the genetic algorithm or any other
evolutionary algorithm for a very very
long time that it will find the global
Optimum often what an evolutionary
algorithm will do will find is to find a
very very very good solution we don't
know whether it's the optimal solution I
mentioned this way back at the beginning
uh of this course biological evolution
is not an
Optimizer as many of you know the human
body is not perfect the human brain is
not perfect but it's good enough for
most of us to survive to childbearing
age uh and and protect our children
until they reach childbearing age every
organism on Earth is good enough um to
survive and some times reproduce
biological evolution is not an Optimizer
it's a
satisficer same thing goes for for
evolutionary algorithms they are not
optimizers they are
satisficers
okay okay uh let's keep going um we're
going to look at uh we're going to look
at uh the evolutionary the evolution
strategy now um this is an interesting
algorithm we're not going to use it in
this class but I think it's worth
mentioning in this case in the evolution
strategy it looks very much like uh the
genetic algorithm so I've removed a lot
of the details that they share in common
the one thing that's different about the
evolution uh strategy is the data
structure that encodes the genotype so
the genotypes in an evolution uh
strategy H uh are actually matrices
they're two uh they've got two rows in
them sorry yeah they've got two rows in
them and N columns representing the N
genes whereas in a genetic algorithm we
have just a 1 byn Vector Evolution
strategy 2 byn Matrix okay why is that
the case let's go back uh let's go back
for a moment to the fitness landscape
let's imagine uh that an evolutionary
algorithm is running and The
evolutionary algorithm has found this
particular
genotype which produced is a phenotype
that obtains this particular Fitness
it's doing
okay let's imagine that this particular
parent solution is now going to start
producing children where it either
combines its genetic material with
another parent to produce that child or
it simply produces a copy of itself and
some mutations are introduced however
the children are produced the children
more or less fall this horizontal
distance away away from the
parent um we're introducing this idea of
Step size here so the more we change the
copied genetic material of the parent
the further away horizontally the child
will fall from the parent we can
actually boil that down to a number
known as the step size which is exactly
what an evolution strategy does we'll
come back to that in a moment just think
of point one is meaning that a child any
child produced by this parent can be at
most
0.1 uh 0.1 to the right of this parent
or 0.1 to the left of this parent if you
think about the distribution of all of
those possible children you can see that
50% of them are going to be worse than
the parent and 50% are going to be
better than the parent so what that
means is it won't take long for this
parent if it's producing offspring
spring to eventually produce one that
does better than
itself let's imagine this particular
let's imagine this particular Fitness
landscape now which you can see has many
more local Optima in it than this one
does and you can see that the slopes are
steeper this is a more rough Fitness
landscape and it's much tougher to
search as you can imagine any one step
might cause you to fall off any of these
local Optima so let's
imagine let's imagine we have this
particular solution here which after a
lot of evolutionary search is actually
doing pretty well it's actually on
unbeknownst to The evolutionary
algorithm it's found a point that's on
the slope of the global Optimum Remember
The evolutionary algorithm doesn't know
this this whole mountain range is
wreathed in fog okay let's again imagine
uh let's again imagine that this
particular parent is producing children
that are at most
0.1 uh 0.1 to the right of it in terms
of Gene value and at most 0.1 to the
left of this point in gene values so
going back to vehicle one this means
that the uh synaptic weight of a child
can be at most 0.1 greater than the
synaptic weight of the
parent and a child can have a synaptic
weight that is at most 0.1 less than the
synaptic weight of this parent at in
this particular Fitness landscape a step
size of
0.1 is going to ensure that this parent
is very unlikely to ever produce a child
that's better than itself any children
that fall in this horizontal range are
are going to be worse than this
parent any children that fall within
this horizontal range are going to be
worse than the parent and it's only
within this very narrow range that
children are going to be better than
this parent this means that even we uh
even though we can't see these Peaks the
step size at this point in time should
be less than 0.1 this parent should be
producing children that are more
genetically similar to it than in this
example how do we break this Catch 22
the evolution strategy does this by
again encoding Gene values in its genome
but in the same genome every Gene value
has a corresponding step size this is
known in evolution strategies as the
strategy parameters what this means is
that if this parent represented by this
genotype here produces an
offspring we copy all the values of this
parent Vector into a child vector and as
we copy each number we're going to
mutate those numbers but we're going to
mutate them uh by a magnitude dictated
by the step size associated with the
value or with that g with that Gene so
if we copy 0.3 we might modify the value
0.3 by anywhere between 0 2 and 04 0.1
less than3 or 0.1 more
than3 when we modifi as we're copying
the parent Gene values into the child
Gene values when we hit uh this
particular Gene this one might be M this
one is going to be mutated More Than
This Gene
was this particular Gene is going to be
mutated less than these other genes so
we're allow o the evolution strategy to
set the step sizes how much we mutate
any given Gene by the last twist and the
the most the beautiful part of the
evolution
strategy is that the step sizes
themselves are
mutated so imagine multiple parents
lying somewhere in this region parents
that encode smaller step sizes are going
to produce children that are closer to
it in the fitness landscape than other
parents nearby if that have higher step
sizes those parents are going to produce
children that fall further away from it
the parent that just by chance is
producing more similar children its
descendants will start climbing this
peak better than the parent that's
producing children that are further from
it
and we're going to end up with more
genotypes in the population with smaller
step
sizes so what the evolution strategy
does is actually evolve over
evolutionary time how far or how closely
children fall to the parent and
evolution Tunes those magnitudes of
jumps by where those particular points
lie in the fitness
landscape an evolution an evolution
strategy when it's running if it's
running on a fitness landscape that's
relatively smooth those step sizes will
evolve to be bigger so that things are
jumping around more uh an evolution
strategy that's running on uh Fitness
Landscapes that are rougher like this
one here will start to evolve step sizes
that are smaller we'll see less and less
differences between children and
parents okay we've got 10 minutes left
which is great that should be just
enough to talk about the final
evolutionary algorithm I want to talk
about today that final evolutionary
algorithm is not called symbolic
regression it's called genetic
programming but before we talk about
genetic programming I want to talk about
uh the problem that genetic programming
is really good at solving the best way
to understand genetic programming is to
watch it solve a problem and that
problem is symbolic regression so let's
talk about the problem first and then
we'll talk about genetic programming
which is a solution to that
problem imagine we make a bunch of
observations we have a whole bunch of X
values which is our uh independent
variable we know what those values are
and for each value of x we then observe
the value of y which is our dependent
variable and if we plot all of that data
we can immediately see that there seems
to be some sort of pattern or
relationship between X and
Y you'll notice that the values of Y
tend to dip around a value value of x an
x value of three and they tend to
increase on either side of that value
hopefully uh that will dimly somewhere
in your dim recollection this will uh
remind you of uh High School uh High
school
algebra and you might remember what the
solution to this problem is but but bear
with me let's imagine instead of you
trying to write down a function for uh X
trying to write down uh y as a function
of X we task uh an evolutionary
algorithm with coming up with this
problem The evolutionary algorithm in
this case the uh candidate solutions to
the problem are equations here's one
candidate equation which is yal X if we
draw y = x and then we ask how well does
this equation capture the relationship
between X and Y we can see it does a
pretty poor job of capturing that
relationship if we look at how far the
observations are from the actual yal X
line we can see there's a lot of error
here
so in this
particular evolutionary algorithm that
we're going to see in a moment we're
going we're it's going to try not to
maximize Fitness but it's going to try
and minimize error this can be a little
confusing we're going to see this again
uh as we continue through this course
some of the robots we're going to evolve
are trying to minimize airor which could
be the distance of their hand from an
object or they're trying to maximize
Fitness they're trying to move as far as
they can from their starting point for
this example we're going to try and
evolve populations of
equations and better equations have
lower
air returning to our fitness landscape
for a moment when we're minimizing air
we replace Fitness on the vertical axis
with eror and now we're going to try and
search for points that move into the
deepest valley so when we're minimizing
error here's one local Optima here's one
local Optimum here's the global Optimum
other than that everything stays exactly
the same maximize Fitness or minimize
error okay all right so uh we find that
this particular equation gets high air
so it's probably deleted from the
population and replaced with something
else Let's uh hopefully you were able to
work this out in your head it's okay if
you couldn't uh here's a second equation
um and let's imagine this evolutionary
algorithm actually discovered this
equation this particular equation gets
low air or high Fitness if you want to
think about it that way and you can see
that visually the observations now are
closer on average to the uh to this
equation than this one is yeah
okay so what is the problem and what are
the candidate Solutions so the problem
that we're trying to solve in this case
is we would like to write down a
mathematical equation that describe or
the problem is we'd like to find the
relationship between X and Y a candidate
Sol any a candidate solution to that
problem is an equation here's one
candidate solution here's a second
candidate solution so in this case our
genotypes are equations remember
remember a candidate solution in is
encoded in a genotype so a candidate
solution is an equation and phenotype or
the behavior
produced The behavior produced by that
equation is this line how far is the
line described by this equation from
points okay just to try and ground this
so relatively abstract discussion um
here's a real world problem if you ever
spend any time in Burlington in the
summer sometimes parts of Lake Champlain
are closed to swimming because of toxic
algal blooms it turns out it's really
really hard to predict where and when a
bloom will form in the lake that being
said the Rubenstein school here at UVM
has spent many years collecting data
from the lake um they take measurements
at different points in the lake at
different times of the year sorry in
different
years and at any point uh in the lake at
a given time they measure different
features of the water how much nitrogen
is in the water how much phosphorus is
in the water at that time what's the
temperature of the water how easy is it
to look through the water how
transparent is the water uh how much
rainfall has there been uh in the last
day and so on these are all our
independent variables X1 X2 X3 X4 X5
and we want to see whether we can find a
relationship that or an equation built
from all of these parts that predict t
the actual amount of toxic algae found
in the water at that time so what you're
looking at here is just a single x value
and a single y value here we've got one
2 3 4 five X's so we have X1 X2 X3 X4
and X5 I can't draw that we would have
five quote unquote horizontal dimensions
and then the sixth vertical
Dimension uh the sixth vertical
Dimension is the
eror sorry the sixth vertical direct the
sixth vertical Dimension is T toxic Al
Al Alo blooms yeah okay so what is this
equation nobody knows
um but some researchers here at UVM have
actually applied genetic programming to
try and find out here we go as I
mentioned uh in genetic programming that
are that's trying to solve symbolic
regression genomes here's one genotypes
here's gen genotype one genotype 2 or
parent one and parent two they are not
encoded as vectors of numbers they're
encoded as in a tree data structure some
of you taking this course have not taken
a data structures course so this may be
a little
confusing what I'll invite you to do is
notice that this tree is made up of
mathematical operators like over here
multiplication plus and each uh Leaf in
the tree all of these nodes that do not
have any nodes below them are made up of
uh state of State variables like X or
floating Point numbers 0.8 1.4 so as
always when we're starting an
evolutionary algorithm we usually create
a population of random candidate
Solutions so how did we create P1 and
how did we create P2 let's start with P1
we start by uh we want to create this
genotype at random so we make a bag and
in that bag we throw in all the possible
uh mathematical operations that we think
might be a part of this equation and we
also throw into this bag all of the uh
variables so this just says X and Y but
if we're doing this problem we throw in
n p WB and R and T we throw them in here
and we throw in some constants as well
we'll see why in a moment we shake up
the bag so we got a whole bunch of
operators and operand we reach into that
bag we pull something out of that bag at
random and in this case we M we pulled
out the multiplication operator that
becomes the root of our
tree the multiplication operator
requires two arguments so we create two
outgoing edges from this tree we need to
multiply two things together we don't
know what those things are yet so let's
go to the first branch of the tree put
the multiplication operator back in the
bag shake the bag up again reach into
the bag and this T time we pull out plus
plus also
requires plus also requires two
operators throw plus back in the bag
Shake It Up reach in to the bag again in
this case we pull out Point uh
808 does not require any arguments so
we've created a leaf to the tree we go
back up to the plus we need two
arguments we've already created one we
need a second argument so we shake up
the bag we reach in again in this case
we pulled out at random X and we've
completed this part of the tree we have
to go back up to the root of the tree
multiplication we filled in this leftand
Branch we still need to fill in we need
still need to randomly set the second
argument for this multiplication so we
shake up our full bag again reach in and
pull out at this case a random value
which is 1.4 and we have now created an
equation we have now created an equation
at random and we have our first genotype
I will invite you to while this is fresh
in your mind and this lecture is about
to end do this uh go through this
operation with this bag to create P2
reach into the bag pull out Division and
see if you can con conru this we will
finish this lecture uh on Tuesday when
I'm pretty sure I'll be back to see you
all in person uh just as a reminder you
have a quiz due tonight undergraduates
you're working on quiz number three uh
you're working on assignment number
three graduate students you're working
on assignments five and six have a good
rest of your week and I'll see you all
on Tuesday thank you byebye


--- Evolutionary Robotics course. Lecture 07. Physical simulation..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone let's Dive
Right Back In we are making our way
through the 10 assignments that will set
you up for your final project just to
orient the undergrads and graduates as
to where you are and where you're
going as we're setting up our
evolutionary algor our evolutionary
robotics experimental platform you're
working your way through at the moment
putting together all the bits and pieces
that make up your simul ated robot
running around in its virtual
environment the robot itself is made up
of physical objects called links uh you
just finished the assignment on joints
which are the invisible objects in the
physics engine that connect pairs of
links together that was assignment three
uh a few of you pointed out a few things
that were a little bit confusing about
joints I'll come back in a moment to
just refresh and reinforce some of those
Concepts undergraduates in assignment
four uh which you're going to be working
on this week you're going to be leaving
the physics engine behind in the sense
that you're going to now start to add on
some additional bits and pieces that are
simulated inside the physics engine that
the physics engine itself doesn't really
deal with so everything above this line
just sort of comes default with the
physics engine in order to simulate a
robot in a physics engine you're going
to have to simulate some addition things
inside that physics engine such as the
sensors Which pull information in for
the robot from its virtual environment
in assignment four you're going to be
working with two python packages numpy
and matplot lib who's familiar with both
of those pretty much everybody okay if
you're not or it's been a little while
since you've used numpy or numerical uh
numerical methods for python spend some
time time refamiliarizing yourself with
numpy this week matplot lib uh it's been
around for a long time it's not ideal
but it is sort of the gold standard in
most science and engineering projects
for visualizing data you're going to be
using matplot lib in assignment 4 to
visualize the incoming sensory
information to your robot so again if
you haven't used matplot lib before or
it's been a while re familiarize
yourself with mat plot lib we're going
to be making very heavy use of numpy and
matplot lib as we continue on with the
assignments this is a good time to ref
familiarize yourself with those okay
sensors uh Motors to follow graduate
students you're moving on to uh neurons
and
synapses uh when you finish assignment 8
you are going to close the sense think
act cycle which we've talked about a few
times already we will mention it many
more times
in this course information comes in to
your robot neurons and synapses as we
saw when we talked about uh artificial
neural networks last week transform
values arriving at in our case the
sensor neuron layer the first layer of
the neural network your sensors your
neurons and synapses are going to
transform that sensory information and
possibly combine it with memory that
your robot already has and those
transformed incoming values are going to
be sent to the motors Motors apply Force
which in our case is going to be torque
or rotational
Force the values arriving at the motor
neurons are going to apply rotational
Force to the joints and the joints are
going to try and rotate links relative
to one another so for grad students when
you're finishing a assignment 8 you're
closing this Loop that connects all of
these pieces together in the physics
engine which we're going to talk about
we're going to spend quite a bit of time
talking about physics engines today time
passes in discreete chunks as you've
already seen in assignment one and two
at each time step of the simulation
values arrive at the robot's sensors
those values travel through the robot's
neural network those values arrive at
the motors the motors apply forces at
the joints to the
links which cause the links to change
their positions and accelerations at the
next time step and your robot starts to
make small movements from one time step
to the next make sense that's my best
attempt to try and summarize all these
bits and pieces of things we've talked
about so far in this course course all
good okay I want to come back to joints
for a moment um there was a little bit
that was confusing in there the first
and most confusing thing about joints
and links in pybullet the physics engine
that we're using is the juggling of
absolute and relative coordinates if
you're still confused about absolute and
relative coordinates come and see the TA
and myself and we can walk you through
that the other confusing element about
joints is joint normals and we talked
about this last time if we've got this
link and this link attached by this
joint at the moment the code base you're
using sets The Joint normal for you by
default to a particular direction The
Joint normal is a vector and for every
Vector in three-dimensional space there
is one and only two-dimensional plane
that is normal to that 3D Vector yeah so
if you set up all your links and joints
correctly what you should see is that
the links in your simulation rotate
through the vertical plane relative to
one another right so you've got this
three uh this three link robot main body
front leg back leg you should see these
three objects rotating relative to one
another through the vertical plane that
cuts through your
robot okay some of you may see something
different which is instead of this
happening and I can't demonstrate this
with my upper and lower arm let me do it
with my hand and my lower arm you might
see this happening meaning that the
objects seem to be rotating about the
long Axis or the the plane that cuts
through these robots that's not what
we're looking for if you see that what
that means is that when you set up your
robot like this you actually set it up
like this there are two horizontal axes
in pi bullet X and Y you're supposed to
be building along x and z if you build
it along Y and Z so you've got your
robot like this remember that the joint
normals are set automatically by pie
bullet so if you build objects like this
The Joint normal is still set by default
by in pi bullet like this and you're
going to see things rotating about this
joint normal so if you see objects
twisting about one another or rolling
around about one another go back and
swap the two
horizontal
coordinates make sense okay if you are
seeing that and my explanation still
didn't make sense to you come and see
the TA and myself and we'll sort
everything
out any other questions about the
assignment so far links joints sensors
Motors all good okay all right so back
to lecture uh just to remind you we're
working our way through this second
theme of the course the tools of the
trade what are all the bits and pieces
that go into a basic evolutionary
robotics experiment we saw last week how
neurons and synapses transform incoming
sensory information for a robot into
action we almost finished lecture five
last time we'll finish it uh shortly
which is how do we wrap a search process
in our case an evolutionary algorithm
around a robot controlled by a neural
network such that that evolutionary
algorithm is tinkering with the internal
bits of the neural controller of the
robot such that the evolutionary
algorithm finds a particular setting of
synaptic weights that causes our robot
to do whatever we want it to do we'll
finish that in a moment and then we'll
push on to lecture six physical
simulation you've already already been
doing a little bit of work with physics
engin a lot of what's going on is
actually hidden from you we're going to
look under the hood of the physics
engine today to see what's going on okay
so back to evolutionary algorithms very
quickly to remind you when we look out
at biological evolution if we squint an
approximate by huge orders of magnitude
you can view what's going on out there
in nature as an algorithm we have a
population of diverse things that
diversity causes some of them to not
survive long enough to produce
Offspring other aspects of diversity
allow some members of the population to
survive and produce randomly modified
copies of themselves that very very
short and crude description of
biological evolution also describes more
or less pretty much every evolutionary
algorithm that's out there and there are
hundreds of if not thousands of
different kinds of evolutionary
algorithms reported in the literature
last time we did a very quick crash
course of visiting some of the most
famous of them in order to understand
the pros and cons of those different
evolutionary algorithms that we looked
at we introduced this uh intuition pump
or this thought experiment which helps
us think about what these evolutionary
algorithms are doing which is the
fitness landscape we introduced a very
important distinction last time between
genotype and phenotype genotype is some
sort of information storage and
phenotype is a read out of that
information and an instantiation of that
information it becomes the thing the
form and function of the organism or in
this course the form and function of the
robot yeah okay we looked at this
progression of evolutionary algorithms
by looking at uh by starting with the
arguably the simplest one the hill
climber you can cat up a hill climber in
about five or six lines of python code
and you're going to do exactly that in
assignment
nine drawback of Simplicity is it's a
weak search method weak in what sense
what's wrong with the hill
climber it'll local it gets stuck on
local Optima right so we looked at the
parallel hill climber in order not to
get stuck on Hills why don't we airdrop
a whole bunch of different points at
random horizontal positions in the
fitness landscape and they all act as
hill climbers it helps but it doesn't
guarantee that we're going to find the
global Optimum actually no evolutionary
algorithm guarantees that we're going to
find the global Optimum we just try and
do a better increase that probability as
best we can we looked at the genetic
algorithm which is arguably the most
famous evolutionary algorithm out there
so famous in fact that often the field
of evolutionary algorithms is referred
to as genetic algorithms so if you hear
these two terms sometimes they're
confused it's important for us to
remember genetic algorithms are just one
type of evolutionary algorithm what does
the genetic algorithm have over parallel
hill climbers it introduces sex we now
can genetically recombine genetic
material from two parents that also
reduces the probability that we're going
to get stuck on a local Optimum during
search we looked at the evolution
strategy last time which accelerates or
decelerates horizontal jumps so as
evolution is searching we can act The
evolutionary process can figure out how
quickly or how slowly to move in
different parts of the fitness landscape
if you are climbing mountains in heavy
fog if you are in a particular part of
the mountain range that looks like this
you want to take small steps
horizontally or you're going to find
yourself in TR trouble if you find
yourself on very gradual slopes you can
speed up and take bigger steps that's
the intuition underlying the evolution
strategy we ended last time with genetic
programming genetic programming is yet a
different type of evolutionary
algorithms but we started by talking
about the problem that made genetic
programming famous the problem that
genetic programming was originally
invented to solve that problem is
symbolic regression we have a bunch of
observations and we want to search over
the space of all possible
equations that best describe the
relationship in that data
set uh we motivated this by looking at
an actual real world problem that is
near and dear to the hearts of anyone
that lives in chitan county or
thereabouts
okay we ended with this slide I
apologize we went a little quickly last
time through this we just talked about
the genotype to phenotype distinction
the genotype is some data structure that
stores information about the phenotype
in our case the robot in the case of
genetic programming the phenotype is
going to be the behavior of the
equation the genotype is going to be
encoded not in a vector of numbers which
is what we usually see in an
evolutionary algorithm in genetic
programming what makes genetic
programming unique is the genotype is
stored as a tree data structure there
are some non-computer scientists in this
class some of you have might might not
have come across tree data structures
before so we've got a cartoon example of
how this works we're going to start by
building up a population of random
candidate solution to our problem like
we usually do in an evolutionary
algorithm each individual in that
population or here are two different
individuals in that population we're
going to build them at random by
reaching into a bag that contains all of
the operations that we think should be
in the equation but we don't really know
how and all of the state variables
nitrogen phosphorus turbidity in the
Water of Lake Champlain whatever the
actual independent variables are the
things that we can measure we want to
throw them into the bag as well and some
random floating Point numbers that are
going to be sort of the raw material
that genetic programming uses to build
and then evolve these equations we ended
last time by randomly building parent
one the first individual in the
population by repeatedly re reaching
into this bag and grabbing at random
operations or operands and as we saw
last time we build up this particular
tree which represents what
equation so
0. 0.8 plus X
yes times 1.4 so this tree is encoding
an equation and the way to read this
equation is to start at the top or the
root of the tree and start walking down
the left hand side of that tree until we
get to the end 0.8 and then retracing
our steps 0.8 plus X keep walking up
times 1.4 here's a second random
equation in the population which again
was constructed at random by repeatedly
reaching into the bag of operations and
operands in this case we randomly
grabbed a division
division requires two uh two arguments
so we kept reaching in the bag and we
made this equation which
is mentally walk or Traverse through
this tree and you should be able to
construct this equation in your
head absolutely so to write this out for
us this tree is encoding this equation
this tree is encoding
this equation here
yeah okay all right
so once we have these equations we can
plug in our values for x and y in this
case which is going to give us
back a curve and we can see how closely
that curve matches our operation uh our
actual observations which are shown by
the scatter plot and I went I went
through this cartoon last time we can
see that this particular equation does a
particularly poor job at matching the
observations so it would be assigned to
low Fitness and would probably be
deleted from the population this
particular equation over here actually
does a relatively good job of explaining
or matching all the scatter points it's
got low error or high Fitness it's
likely to survive in the population and
produce randomly modified copies of
itself equation child equations that
look similar to
itself question um why would you want to
do this over like just normal like
machine learning like where you're you
know using networ to find Nar function
is it about like predictability or like
prediction
versability of the actual equation you
get back out that's exactly the reason
why so the question was why not just use
a neural network to learn the
relationship between in this example
here X and Y and the dependent variable
Z the reason why is of course a neural
network can do a fantastic job of doing
that if you want insight into actually
why algae is blooming at particular
points in the lake hard to get a neural
network to tell you why not impossible
this is pro arguably the most active
area of machine learning research is get
relationship ship and be able to explain
it back to us poor human beings genetic
programming was invented back in the
1990s for exactly this reason is that
assuming you know how to read equations
the equation should in theory give you
insight into the problem if you remember
your high school algebra well enough you
should be able to look at this equation
not the graph and know which value of x
will minimize why you know what kind of
conditions in the lake for example are
most likely to lead to an algal bloom
that's important actionable information
yeah this is not a class on machine
learning or interpretable machine
learning it's a great Point that's why
it was
invented okay so uh in genetic
programming uh we introduce mutation so
let's assume that these these two
individuals in the population did a
relatively good job at matching our
observations better than other random
equations in the population those other
equations are killed off these two
survive and we're going to allow these
equations to produce child
equations we want to produce randomly
modified copies of them so we could take
one or the other let's take P1 for
example and start copying that tree into
a new tree and as we go every once in a
while when we're copying one particular
node like this node for example we're
going to introduce a mutation we snip
out this node and now we have a dangling
Arrow what do you think we do at this
point we're going to try and put some
new random equation material where 1.4
used to
be how do we simulate mutation do you
think in genetic programming given what
I've told you about GP so
far um are you going to put in a new
node with like a new constant value I
guess you're not going to put on like a
whole new Branch it's a great point so
we could say well there was a constant
value here before 1.4 so let's just
tweak that value 1.5 1.21 could do that
which is probably a good idea it's
making a slight change to the
genotype to the genetic encoding of the
equation or we could just throw 1.4
again and reach in start reaching into
the bag and make a whole new tree your
observation that you probably don't want
to do that is a good observation why
might you not want to do
that um if you are to like if you are to
add like large l number of like a three
or more Branch nodes a whole new
operation then that could like greatly
decrease the um evolutionary like value
especially because like it would be hard
to figure out whether just removing that
constant or if one of those two
variables um caused it to like really
decrease in um like evolutionary value
absolutely great point so if we were to
make a large change to the genotype at
this point we're making we're adding
quite a bit of new material or changing
things quite a bit remember that P1 is a
Survivor it survived in the population
compared to the other ones that didn't
do as good a job at explaining all our
observations so if you have a partly
working machine you probably don't want
to go in with a sledgehammer and start
making big changes to that partly
working machine because you're most
likely to break it right it would be
better to go in with tweezers and make a
very small change this rule about the
magnitude of mutation how much you
change a child relative to its parent is
inversely
proportional to the likelihood you're
going to make a beneficial
change said even simp more simply the
bigger the change the more likely it's
going to break things yeah okay great
point we're not going to go into that
too much this is not a class on
evolutionary algorithms but good
observation so we can introduce
mutations when we're copying uh
equations by every once in a while when
we're visiting a node tweak it a little
bit or delete it added some new genetic
material and hope for the best in
genetic programming we can also simulate
sexual recombination in addition to
mutation let's see how that
works uh I've set this up for you
already by introducing these two parent
equations which we're assuming have
survived uh up to this point in the uh
in the population and these two parents
were going to take genetic material from
these two parents and recombine them to
create two child equations down
here you can see that we've randomly
chosen
this point in parent one and we've
chosen this point at random in parent 2
we take those two sub trees and we pull
them off of their
parents we copy all the black material
into C1 and C2 so C1 is inheriting this
genetic material from its first parent
and this child is inheriting this
genetic material from its parent we're
going to take these two detached pieces
of genetic material these two pieces of
genome and swap them this piece from
parent one gets placed here on child two
this piece of genetic material from
parent 2 is placed here on child one you
don't need to madly copy down all of
this you should be able from this
description to do it at your Leisure
what I want you to see here and I
apologize that it's at the bottom of the
screen here let me pop out for a
minute what you should be able to see
down here if I can get rid of my I'll
ignore my speaker notes here you can see
down here that the equation for C1 looks
similar to but is not identical to
parent one and the child equation C2
looks similar to but is not identical to
parent
one question um if this like drastically
decreases the accuracy of the functions
would you
um like go back to the previous version
of both of the functions and then tune
it even less okay that's a great
question so let's continue this
hypothetical example we have these two
parents that survive up to this point in
The evolutionary algorithm at this in
this new generation they've just spawned
two new children C1 and C2 so in this
population at this new generation there
are four individuals P1 P2 C1 C2 and
some other equations we've made some
pretty big changes to C1 and C2 and as
you just mentioned and as we just
discussed that means the likelihood that
C1 and C2 are going to do as good a job
as P1 and P2 at explaining the data or
even do a better job that probability is
pretty low C1 and C2 are probably going
to be assigned very low Fitness values
because they're probably going to suffer
High error what do you think genetic the
genetic programming algorithm is going
to do at that point at the Next
Generation that's it right right we're
back to P1 and P2 they keep generating
C1 and C2 as you pointed out P1 and P2
might have to stick around for quite a
while until they eventually produce
children that are as good if not better
than themselves there is there are
hundreds of papers that have been
published about how to ensure that this
big genetic change is constrained so
that it has less of an impact on C1 and
C2 it's very similar
actually in spirit to our discussion
about Evolution strategies where
evolutionary Evolution strategies were
designed to make sure that individuals
move horizontally a small distance
relative to their
parent remember that in a fitness
landscape horizontal distance represents
the genetic distance you are away from
another individual it's a non-trivial
thing to constrain genetic programming
to do that it's a great question if
people are interested email me and I'll
I'll email you back some papers and you
can dig into that
literature okay we're going to push on
so we can talk about physics engines
today uh here's a fun example of genetic
programming up till now we've been
talking about genetic programming
evolving equations one of the nice
things about encoding genotypes as trees
rather than vectors as the is these
trees can grow bigger
smaller have different shapes you can
encode more or less genetic information
and that genetic information that's
encoded in the tree doesn't necessarily
have to be an equation here's an example
of genetic programming that is not
encoding uh it's not encoding in
equations what I'm showing you is the
phenotype the thing that's produced by
each genotype in this evolving
population of genotypes in this
particular application of genetic
programming as you can see the phenotype
are little
pictures what do you think the genotypes
are how is genetic programming encoding
these
pictures in a
tree there's some Clues embedded in the
way that genetic programming is going to
evolve images
here
any ideas n maybe it's subdividing
triangles subdividing triangles that's
one
idea let's have a video Let's watch it
in
action okay I don't think we need the
fancy music here we go you're watching
uh if you can read this you can see
Generations elapsing up here so we're
watching One run of genetic programming
and at every frame in this video you're
seeing the best tree in the population
at that
time you're seeing actually the
phenotype produced by the best tree in
the population at that time how do you
think these trees are encoding this
phenotype or these
phenotypes
um possibly for like the reward function
it could go
like pixel by pixel or it could like um
Define certain sub regions and
see um how close it is to this original
image um and then can I just pause you
for one moment so what you just
described is great it's the fitness
function remember we always compute fit
on the phenotype so we have a phenotype
on the right hand side of this image we
take that phenotype and we overlay it on
the actual image of the monol Lisa and
we look at the differences in colors
between Pairs of lined up pixels and the
sum of those differences is the fitness
the closer the match the higher the
fitness of that phenotype sorry you were
saying um and does it also like
maybe have like each generation make
like a hundred random triangles at these
different um these different like X and
Y
positions maybe like vectorizing them
and like it sees which of those has the
greatest Fitness and it takes that one
and just adds triangles every single
generation close remember there's
nothing here except mutation and
recombination so we've just got
300 trees in the population each tree
produces its own
image other ideas where the
triang I'm trying to decide
where parent child structure
is it's hard it's it's a little hard to
see from this I would invite you to go
and watch the video on your own screen
what it's actually doing this tree is
encoding in a whole bunch of sub trees
polygons not quite triangles but close
enough so a sub tree has a whole bunch
of nodes inside of it those nodes uh in
that subtree correspond to each point in
the polygon and that each individual
node encodes two numbers the
two-dimensional coordinate of that node
of the polygon so if we have a tree
that's made up of 13 subtrees
that genotype is encoding 13
polygons as you can probably guess from
this uh
video each of those subtes also contains
a little bit of additional information
aside from just the positions of the
nodes which is color color and Alpha
value Alpha value what's Alpha value for
those that don't know Alpha values like
transparency the amount of transparency
absolutely right so you can see that an
individual tree with uh a whole bunch of
different sub trees can put a whole
bunch of different polygons on top of
one another it can color them
differently increase or decrease the
transparency add or remove nodes to a
polygon and relatively quickly come up
with a pretty good approximation of the
Mona
Lisa why would you do such a
thing the answer is obvious no because
it's
fun okay one other observation from this
is in a relatively short period of time
you get a pretty good approximation of
the Mona Lisa if you take that tree
which encodes all those polygons that
approximates the monolisa and you apply
a compression algorithm to it you take
that same compression algorithm and
apply it to this what do you think
happens the tree value is probably going
to be smaller or the tree space smaller
the tree is actually more compressible
it's not the most efficient way to do it
but you this is a way to actually come
up with a compressible description of
the Mona Lisa okay for our purposes it's
just meant to be a visual A visual
representation of how genetic
programming is working okay that
concludes our discussion about
evolutionary algorithms any questions
before we push on all right shifting
mental gears here we go we're going to
talk about physics engines the things
that you're going to use to simulate uh
each individual robot that your
evolutionary algorithm dreams of let's
go back to the 1980s when computer
Graphics was just getting off the ground
how was computer Graphics done in those
days if you wanted to make a 2d or 3D
representation uh of a physical scene
you would do it as follows
as the computer Graphics programmer you
would manually uh figure out and then
Define in your code the position of all
of the objects that make up your
three-dimensional scene the orientation
of those objects how are they orientated
in three-dimensional space the shape and
so on then you'd click render and your
computer would more or less take a
snapshot of that 3D screen save it that
3D scene save it to a file you would
then go back in change the position and
orientation of the objects that make up
the scene click render again it would
save out a file and if you wanted to
simulate for example a single
sphere uh accelerating towards the
ground it took a fair bit of work to do
as you can imagine it didn't take very
long for computer Graphics researchers
to get pretty Fed Up of this approach
and try and dream up something easier
which is instead of manually defining
all of the
traits all of the features of every
object in your scene let the computer do
it for you the moment that was done
physics engines were born so let's
contrast a very simple physical
simulator to a computer Graphics program
in a physics engine as you've already
done you have to start at the beginning
you have to do some work up front you
still have to Define the initial
position of objects that make up the
scene you have to define the orientation
of those objects you have to define the
shape and then you have to do some
additional work that you didn't actually
have to do in computer Graphics which is
also Define the physical properties of
these objects the mass of the object the
friction of the object what happens if
of if the surface if the surface of this
object comes into contact with the
surface of another object going to do a
fair bit of work up
front you have to Define how these
objects are attached together and so on
that's what you're doing in assignments
one two and
three once you've done all that work you
can then recoup all that effort by
instead of having to click render and
redefine all those values for the next
time step of the simulation the
simulation will now take over and update
the positions update the positions and
orientations of all of the objects for
you how a physics engine does that is
actually fantastically complicated but
at heart there is one important equation
that takes care of most of this which is
hopefully something that's familiar to
most of you
FAL
ma a is acceleration um and in our case
we're going to be working in a
three-dimensional virtual environment so
acceleration is going to be a
three-dimensional Vector again remember
your high school uh physics class
perhaps where acceleration represents
the speed the rate of change of speed in
the horizontal Direction the y direction
and the Z Z Direction yeah that's linear
acceleration there is also the rate of
change in the speed of the change of the
orientation of the object this is
usually known as a yaah pitch and roll
let's see if I can do this right so I'm
an airplane this is roll pitch is my
nose goes up my nose goes down which
leaves ya which is I rotate about the
axis sticking out out from under me uh
from above me yeah so that's rotational
acceleration so we need three numbers to
tell us how the X Y and Z uh velocity of
the object is changing we need an
additional three numbers which is how
the I won't act it out how the yaw pitch
and roll velocities are also changing so
in a physics engine at every time step
that physics engine is Computing all of
the forces that are acting on every
object and we'll come back to forces in
a moment and the physics engine knows
the masses of the objects you've defined
those masses for it the physics engine
can rearrange this equation into AAL F /
by m so the physics engine takes all the
forces and the masses of the objects and
work works out these six numbers what
are what is the change in the positions
of the position of the object and what
is the change in its
orientation this is a physics engine in
a nutshell if I've lost you at this
point let me know so far so good okay
all right so that's acceleration for our
purposes you can think of this as six
numbers uh masses are scalers for the
moment we're just assigning a number
this object weighs 3 kilograms this one
measures U uh has is 30 kilograms and so
on force is also made up of six numbers
here's my object we mentioned torque
already torque is rotational Force so at
every time Step at every time step the
physics engine visits each object that
makes up your scene and looks to see
which forces are acting on that object
in this simple example here there is one
and only one force acting on the object
which is I can see some of you mouting
it it's gravity right so gravity is
pulling on this object and altering its
linear acceleration it's pulling it down
the Z coordinate of linear acceleration
is going to be NE negative at each time
step due to gravity pulling it down yeah
so what does that do as we go from one
time step to the next at time step T the
object we that we started at we place
the object at this position at time step
t + 1 the physics engine has run FAL Ma
and figured out that the linear
acceleration downwards is
positive the physics engine takes that
acceleration
and applies it to the the old position
of the object to come up with the new
position of the object which is downward
by a little bit Yeah okay at the next
time step it does the same thing and the
same thing and the the position of this
object changes changes changes until it
hits the ground and it stops moving why
why does the object stop moving from the
physics engine's point of
view suddenly there's
absolutely so the physics engine is
going to detect that two objects have
come into contact with one another at
time step t plus n and now the physics
engine is going to add two forces to
that object one force pulling the object
down which is gravity and then the
physics engine again you don't see any
of this is going to add an additional
Force pushing up against the object with
equal magnitude
you plug those two opposing forces in to
this equation what do you get back as
a they cancel out and this thing
suddenly decelerates and comes to a stop
resting on the ground yeah most of
everything that's going on in a physics
engine is Computing f equals ma over and
over and over again so far so good
okay uh what we're going to do now in
the next few slides is actually look at
some pseudo code you don't need to
remember any of this pseudo code um some
of you that are paying attention see
that there are semicolons here which is
a reminder to some of you that you're
now not looking at python code you're
looking at C code when I started this
course we were working with the open
Dynamics engine physics engine rather
than Pi bullet uh open the open Dynamics
engine is written in C I am not going to
torture any of you by having to write
physics engine code in C be thankful
you're taking this class in
2024 but I put it up here as a reminder
of one of the main Concepts in this
course which is tools come and go but
basic concepts remain yeah so lots of
different physics engines they're all
doing more or less the same thing so
let's have a look at the preliminary so
in od and in pi bullet as we mentioned
you need to do some work up front in od
there were a couple of lines uh of code
that would set up the virtual world um
that would set the gravitational force
in this world you can set it to minus
9.8 if you want to simulate things that
are happening on this planet you can set
it to different values if you're
prototyping a Rover for NASA that's
going to send your probe to planetary
bodies that have a different
gravitational force you can also set
uh different parameters that have to do
with friction for all the objects in the
world uh and so on we're not going to
talk about uh these other preliminaries
first this just a reminder we can tune
the physics of the physics engine up
front if we want
okay we then have to create a whole
bunch of links that are the physical
objects in our physics engine in od they
were not called links they're called uh
bodies we need to do a few things for
each body or link that we add to our
physics engine you've already done this
like for example setting the position
initial position of the object in od the
second coordinate was the height
coordinate in pi bullet the third
coordinate is the vertical coordinate
right I still confuse myself about this
one okay all right so as we can see here
in this cartoon example we're starting
by setting an object six meters above
the ground you'll notice when we set the
position there are no units associated
with uh these uh quantities units is
kind of hidden from you by the physics
engine so again in this course we're not
going to worry about whether this is
this object is initially placed 6 meters
above the ground 6 feet above the ground
six microns above the ground doesn't
really matter for our
purposes okay in od you also you could
set the mass of the object which is
usually just one number in od you could
distribute that mass across the length
width and height of the object so you
could actually make interesting Mass
distributions inside an object maybe you
want to simulate an object in which
inside that object there's one heavy
component on inside one part of the
object it's a detail it's not important
uh for us okay some other parameters
that we're not going to worry about so
we're setting position and mass of the
object we can also set the or the 3D
initial 3D orientation of objects uh in
uh in your scene this is a little
complicated so uh in pybullet and
pyrosim I've hidden this detail from you
when you create a cube uh in uh pyro Sim
it's placed with a particular
orientation you cannot at the outset set
the orientation to be something
different in your uh simulation if you
find you want to do that or you have to
do that when you get to your final
project here's a link to tips and tricks
which are at the end of all of the
learning modules in our subreddit so
there's additional things you can do I
want to just talk through how you how
you do this in general
just to again give you a sense of what's
going on under the hood of a physics
engine let's imagine we have a
rectangular solid like you see here and
we want to try and set its orientation
in space there are a lot of different
ways to do this some of these are more
complicated than others some of you may
have heard of querian before we're not
going to go into too much detail about
them here um but I'm going to give you
an intuition for how this works
if we have a rectangular solid we can
take three of those numbers to Divi
Define a a vector in three-dimensional
space we can tell the physics engine to
take that rectangular solid find its
longest length so if it's got different
length width and height find the longest
one which is the long axis of the
rectangular solid and place it so that
that long axis is lying along that 3D
Vector so far so
good the fourth Vector as you can
probably guess from the fact that we're
using Theta Theta is a rotational
directive it tells us then how to take
that object and rotate it about its long
axis which is lying along this three
dimensional
axis so far so good with those four
numbers you can Define any
three-dimensional orientation for our
object why is that important remember
that in uh f equals ma what your physics
engine is doing is summing up all of the
forces and torqus that are acting on
your object we've got three numbers for
force which is how much uh how much that
force is pushing or pulling
on the linear acceleration of the object
torque is a rotational Force which is
trying to alter the rotational
acceleration of your object so at every
point in time the physics engine is
updating not just the position of your
object but also its orientation in
three-dimensional space if for some
reason you need to set the orientation
yourself at the beginning you would
normally do it with
quance so far so
good okay we saw an example of
gravitational force which is an example
of a linear force acting on objects in
your physics engine what kinds of torqus
are acting on your links what are the
what are the what are the rotational
forces that cause the orientation of
your links to change from one time step
to the next in your physics
absolutely a motor attached to a joint a
motor attached to a joint is applying
rotational force is applying torque to
try and alter the three dimensional
orientation of the pairs of objects that
are attached by The Joint so if there
are links if there are links that are
connected by a joint that link may be
acted on by a linear Force for like
gravity that's trying to pull it down
and torqus the physics engine is summing
up all of those linear and rotational
forces to compute the new linear
acceleration and rotational acceleration
acting on each object the physics engine
finishes that time step by using the
linear and rotational acceleration to
compute the new position and the new
orientation of each object question
I was just going to say that the weight
of the connected link is
also the weight of the connected link
absolutely can be uh actually can be a
torque absolutely in this physics engine
we're assuming that links are massless
they're invisible they have no Mass the
only thing that have masses are links
sensors and motors and joints in the
physics engine you're using pi bullet
have no Mass if you want to approximate
if you want to make a more physically
realistic robot you could put a link
sitting right here and connect this link
to this link and then connect this link
to this link to better simulate a
motorized joint in a
robot okay any questions about that so
far okay we need four numbers if we want
to specify the three-dimensional
orientation of an object in a physics
engine if we've got a cylinder
we only need three numbers
why yep yes rot doesn't matter the
rotation doesn't matter right so if you
look at my pen obviously three of the
numbers matter I need to set the yaw
pitch and roll of this object but once I
set it this fourth number in a querian
Theta if I apply different thetas
assuming there's no actual complex
pattern on the surface of the cylinder
it doesn't
matter how many numbers do I need to
specify the orientation of a sphere in a
physics
engine in the red hoodie in the back
there orientation the the orientation I
want to set the orientation of the
sphere zero zero I don't need any it
doesn't matter for a sphere I set the
three-dimensional position and we're
done right it doesn't actually matter
assuming again the surface is uniform it
doesn't matter how we rotate it in space
now a physics engine absolutely will
apply torqus and uh rotational linear
forces to a sphere and cause it to
rotate as it's moving through 3D space
in a physics engine it's not really
going to have much of an impact on the
physics how would that be effective if
you started adding joints to your links
it get very complicated very quickly
right on a specific part of it right and
so then the orientation would matter yes
absolutely so let's go back to my arm as
an example we've got this link attached
to this link by a rotational joint and
let's say I set this is the initial
position and orientation and this is the
initial position and orientation of
these two links I set them before I
start the simulation running once the
SIM imation starts
running torqus and forces start to act
and the positions and
orientations of these two objects start
to change I'm applying rotational Force
to these two objects and I'm also
counteracting the linear force of
gravity that's pulling them down if you
look at my lower arm you can see that
the linear acceleration and rotational
acceler ceration of this object is
changing in complicated ways it's very
very very very difficult to work these
all out by hand that's why physics
engines were invented you don't need to
okay so each link still has four values
for orientation you just only need like
three to set for a absolutely great
point every object regardless of its
shape has three numbers specifying its
position in space it's got four numbers
specifying its orientation in space it
also has three numbers representing how
quickly or how slowly it's moving
through space and it has another three
numbers specifying how quickly and how
slowly it's rotating through space all
of those numbers change at every or can
change at every instant in time in a
physics engine and all of those numbers
are hidden from you
unless you need those numbers which
we're going to see in a moment there are
cases in which you do so far so good
okay let's keep
going okay uh we've actually already
talked about this so hopefully this is
going to be a little bit uh familiar and
a reinforcement for you again we're
looking at C code from a different
physics engine so you can ignore a lot
of the actual details here what I want
you to pay attention to is the fact that
we're now creating a joint
which connects together two different
objects in this case we are attaching a
particular type of a joint called a
hinge joint which are the kinds of
joints we're going to be using in this
class they affect how objects rotate
relative to one another we talked about
setting the position of the joint in od
the position of a joint is called its
anchor and the three-dimensional
position of a joint also starts to move
once the physics engine starts running
you have to set the position of that
joint at the beginning of the simulation
and then the physics engine does
everything from there yeah it is an
invisible massless extensionless object
meaning it has no orientation just
position in
space you then also have to set the axis
otherwise known as The Joint normal
which we already talked about uh in this
class we just talked about how this is
set manually and hidden from you most of
the time this makes your life easier
unless you do something differently
which then causes your robot to act
mysteriously if you want to unlock joint
normals and play around with them you
can jump ahead to learning module n in
the subreddit and give it a try this was
my best attempt to try and draw in
three-dimensional space two objects with
a vertical joint normal which causes
these two objects to rotate about x and
z yeah just as a reminder if I have
these two objects and I Define this
joint normal there is one 2D plane that
is normal to this 3D Vector I apologize
for repeating this several times but
it's worthwhile getting the straight in
your head before your robot gets more
complicated with lots more links and
joints and relative and absolute
coordinates okay all right the one
aspect of a physics engine one of the
big parts of a physics engine that we
have not talked about until now is uh
detecting and resolving collisions so
collisions in a physics engine there are
two parts that the physics engine needs
to deal with detecting collisions have a
pair of objects come into contact with
another and resolving collisions what
should the physics engine do when it's
detected a collision okay so how does
this uh work let's actually just ignore
the the code for a moment let's assume
we make a physics engine where we've got
a whole bunch of bouncing balls none of
them are connected together with joints
so we've got in the case of Pi bullet
you would have nine links and zero
joints yeah okay they all start bouncing
around and hitting the ground and maybe
a few of few of these spheres might come
close together and actually come into
contact with one another how does the
physics engine detect this and how does
it deal with this if these nine links
happen to be spheres it's super simple
how does the physics engine know when
two spheres have come into contact with
another
close absolutely so we've got it's going
to the physics engine is going to look
at pairs of spheres and as you said the
physics engine knows the XYZ for this
sphere and the XYZ for this sphere how
does it know whether they those spheres
have collided or
not
ruses
maximum absolutely right so we have
these two spheres we know the radi of
these two spheres because the user
specified the user specified uh the the
size of those object the size of that
object at the beginning of the
simulation so we sum those two rate so
if we've got this position and this
position and we sum those two rate if
that sum if the I'm sorry I take that
back if we take we take the distance
between the centers of the two objects
and if that distance between these two
centers is less than the sum of the two
radii these objects have collided and
are possibly interpenetrating one
another already it's a big no no in a
physics engine physics engine doesn't
like that very much much so far so good
okay so in order to do that in the this
case of nine uh nine spheres how many
potential collisions does the physics
engine need to look
for it knows the positions and radi of
all nine of these spheres at this
particular point in the physical
simulation
two two to the 9 that's one
guess would it
be eight or n factorial eight or nine
factorial any other guesses how do we
how do we get to these equations well
let's put ourselves in the shoes of the
engine deep breath pick one of the nine
and compare the position of this against
each of the other eight spheres and
detect whether or not the sphere is in
contact with any of these eight okay so
that's eight collisions we've just
considered let's go to the second of the
nine
spheres how many Collision potential
collisions do we need to detect in this
case or consider seven right one of them
we've already done if object I is in
contact with object J by definition
object J is already is also in contact
with object a so you mentioned factorial
right we need to consider eight then
seven then six then five then four then
three then two then one potential
collisions which is how
many okay we've got n objects and we
need to consider its potential collision
with every other one of the N minus one
objects but because of the
Symmetry we can get away with doing half
as many if we've got nine spheres in our
simulation how many collisions are we
talking
about
3 36 okay at every time step in this
particular simulation the physics engine
needs to consider 36 possible
collisions rewind your mental tape to
when you were creating these towers I
forget how many links were involved in
that does anybody
remember
50 there were 25 Towers each Tower was
made up
of 25 towers and how many
sorry so there were 250 links in that
physical simulation at every time step
when that simulation was running on your
laptop how many collisions was Pi bullet
considering can see the eyes rolling
back into your head for some of you
right it's it's a big
number yeah
how many of you started to hear the fan
going on on your laptop when you
simulated those 25 uh Towers this this
is why so again some of these details
are not that important for us but it's
good to really know what's going on
under the hood when you run a physics
engine the vast majority of work that
that physics engine is doing is
detecting potential collisions it's
super complicated to do if we've got
spheres as we just said it's relatively
easy the algorithm is running a
relatively the physics engine is running
a relatively simple algorithm to detect
for each of those potential collisions
whether a collision is happening or not
what about two cubes if we replace these
nine spheres with nine cubes we still
have to detect or the physics engine
still needs to look for this many
potential pairwise
collisions how is the physics engine
determining whether two cubes are in
contact with one another or
not it can I mean it can just do the
same thing as this here just with a
slightly more complicated calculation to
find the outer bound yes it is a it is a
more complicate it can't just take the
distance between the centers of those
two cubes it's more complicated and you
got to run that more complicated
algorithm this many
times now your fan is really running on
your laptop yeah th this is where this
is why physics engines took a long time
to get right and why they're so
computationally uh they they computation
they computation Hogs yeah okay so one
additional detail which again is hidden
from you um in physics engines is
something known as Collision spaces and
I kind of breezed over this uh when we
introduce the preliminaries here so
we're going to talk about Collision
space
for a
moment let's in this case we've placed
all of our nine links in one and only
one Collision space what that does we're
telling the physics engine that at every
point in time please look at all of
these potential collisions and resolve
them don't let these fears
interpenetrate one
another let's imagine a slightly more a
slightly different simulation we still
have nine links and zero joints but we
know for some reason that these objects
tend to be close to one another and
these links tend to be close to one
another and they're usually not very
close to one another maybe we're going
to simulate two robot
swarms what we can do is Define two
different Collision spaces and put these
links which tend to be close to one
another in this space and put these
objects in this second space I'm going
to stop explaining Collision spaces for
a moment and see if you can guess the
rest of the intuition behind Collision
spaces why are we doing this you can
reduce the number of collision
calculations if you're explicitly saying
do not calculate collision between this
of objects and other of objects
absolutely right so in the case where we
have just one Collision where we have
just one Collision space we had nine
objects * 8 / 2 which is 36 potential
collisions if we place these objects in
these two different spaces how many
collisions do it does the physics engine
now need to deal
with can we do better than
that
the physics engine can actually use
these Collision spaces to to get away
with actually most of the time doing
much less than 16 collisions
how can just be like if the distance is
too
great if the distance of what any
uh possi possibly there are other things
you can do that say when they're really
far apart I'm going to do a preliminary
calculation I'll only do a more
complicated one when they're closer so I
don't know the exact details of I know
they most use ISE based Collision y so
they'll
basically dynamically create Collision
groups based on what is with proximity
of what else and dnamic arange theary
according to that absolutely so this
tree based Collision detection that you
mentioned this is a simpler version of
it in state-of-the-art video games they
use Dynamic trees we're going to use a
static one we've created you can think
of this as a tree where we've got our
world as the root and then we've got two
sub trees which are these two
spaces at any given point in time in
this physics engine the in the in the
virtual world the physics engine is
going to look to see whether these two
cubes come into contact with one another
these two
spaces if these two spaces if these two
cubes that are wrapped around these two
groups do not come into contact with one
another what can the physics engine get
away
with 16 I'm sorry I misspoke so this
doesn't let it do less than 16 it lets
it do less than 36 so it's just at this
particular point in time it's done one
Collision detection between these two
cubes yeah assuming they these two cubes
don't Collide it's got to do each of the
pairwise collisions inside here 4 * 3 /
two and it's got to do pairwise
detection of all of the collisions in
this box for each of the five there's it
collide with any of the other four C
other four spheres in space two divided
by two that's how many collisions it
needs to
compute at the next time step imagine
these spheres and their respective
Collision spaces have moved a little bit
and now at this new time step when the
physics engine looks to see whether
space one and space two are in collision
with one another and finds that they are
collision with one another what does the
physics engine have to do
now merge the two spes
effectively it's got to merge the two
spaces and
unfortunately it's got to do all of them
yeah so there is a fantastically
complicated literature and you mention
this most in the computer graphics and
computer games communities about how to
reduce the computational burden of colle
of collision detection the most
computationally painful step that the
physics engine needs to perform during
each time
step so far so good okay we've got two
minutes left so let's finish uh let's
finish with um Collision
resolution what happens when during any
given time step the physics engine finds
that two objects actually are in
collision with one another in most
physics engines they introduce a little
bit of event based programming and again
not everyone in this class has come
across this concept
before most of the time when you write a
computer program the computer goes to
the first line of your code executes
that line goes to the next one next one
next one next one enters a loop and
marches through each line of your code
one after the other in event-based
programming sometimes as the computer is
leisurely moving from one step to the
next there's an event that happens from
somewhere outside the execution of your
code and that causes your computer to
leave whatever line in your code it's
currently executing and immediately jump
to some other part of your code to
handle that event events that are very
important in a physics engine are these
kind of events so at during a individual
time step in a physical simulation if a
pair of objects are detected to be in
collision with one another this part of
your coat the physics engines code uh
takes over and it says what do you want
me to do boss what do I do these objects
are in collision with one another you
usually have to write that code again in
this class I've written that code for
you it's going to be taken care of
automatically the first thing this code
asks is are the two bodies or in our
case the two
links that have been detected in
collision with one
another are they are they are they are
connected together by a
joint if they are what do you think the
physics engine
does it doesn't care it leaves this
piece of code that is resolving the
Collision it ignores the Collision right
that Collision is supposed to be
happening it's actually a good thing you
so there's usually a bunch of if
statements inside this part of your code
that resolves collisions that say if
it's this type of collision ignore it if
it's this type of collision ignore it so
on and so on we're out of time so we
will continue our discussion of
collision resolution uh next time you
have a quiz due tonight undergrads
you're working on uh ensors grad
students you're working on neurons and
synapses see you on Thursday


--- Evolutionary Robotics course. Lecture 08. The first years of the field..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone let's dive uh
right in you're working on various
assignments any questions about the
assignments everything flowing
relatively
smoothly okay all right so we are going
to finish up uh this morning we are
going to finish up lecture six on
physical simulation which will finish up
our second theme on tools of the trade
um any talk about one of the quiz
answers let's talk about one of the quiz
answers go for it yes for the for the
collisions one why was there a plus one
in the answer if we were ignoring the
ground why was there a plus one there's
one additional Collision that needs to
be detected in addition to the 3 * 2 / 2
and the 4 * 3 / two between the two
groups between the two groups that's why
Collision groups exist most of the time
assuming this group is relatively far
from this group there only needs to be
one Collision detection which is between
the pair of bounding boxes around the
collisions which is the Collision group
as long as these two boxes don't Collide
none of these collisions need to be
computed that's why it was a bit of a
trick question on Tuesday my apologies
okay just to make sure you're paying
attention another question I should ask
can um talk about the dimensionality
question
from sure yeah the dimensionality
question so there was a question on the
quiz from last week about Fitness
Landscapes remember that the fitness
landscape is a way to sort of visualize
as best you can how an evolutionary
process occurs it was originally
formulated back in the 30s to actually
think about biological evolving
populations we can use it when we're
talking about evolutionary robotics or
evolutionary algorithms the idea in a
fitness landscape is usually it exists
in a high dimensional space so it gets a
little difficult to actually visualize
it when we're talking about large
dimensions but imagine a space in uh in
high Dimensions where every quote
unquote horizontal dimension in three
dimensions there's two horizontal
dimensions and one vertical Dimension
each horizontal Dimension corresponds to
one element in your genotype if we're
talking about DNA that's individual
nucleotides if we're talking about
vectors of numbers that encode synaptic
weights for robot's neural controller
we're talking about each element in that
Vector if you're running an evolutionary
algorithm with a genotype encoded as a
vector and that Vector has length n
there are n horizontal dimensions in the
fitness landscape so far so good yeah
was
a
like
different mot synops
and all them count
ases all of the all of the parts of the
phenotype for the brenberg vehicle count
that are encoded in the genotype so if
we're fixing the sensors and motors and
then we're connecting up this sensor to
that motor with the synapse that synapse
has a weight associated with it and
that's what we're encoding in the
genotype for the moment so if we have
two sensors
and four Motors and we're wiring up
every sensor to every motor we've got 2
* 4 total synapses eight total synapses
which is eight synaptic weights imagine
we take those eight numbers and embed
them in a vector that's our genotype
we're encoding eight numbers for those
eight synapses the corresponding Fitness
landscape has eight horizontal
Dimensions right if we go to any point
in that eight dimensional space that
point is is represented by eight
coordinates in space that point in that
horizontal space represents one and only
one genotype the particular settings or
values for those eight synapses we take
those eight synapses we run it on the
brenberg vehicle we see how well the
brenberg vehicle does at whatever it is
we want it to do and that number that
comes back from the Fitness function how
well the robot did with those set of
eight synaptic weights is the ninth
Dimension it's the height of that
point so in a two sensor four motor
brenberg vehicle we would have a fitness
landscape that exists in nine
Dimensions make sense um any you could
really quickly difference between
genotype and phenotype difference
between genotype and phenotype genotype
is a catchall term for where the
information is encoded in us that's uh
that's your DNA in the the case of the
brenberg vehicle we just talked about
the genotype is the vector we talked
about genetic programming a particular
type of evolutionary algorithm last time
the genotypes in genetic programming are
encoded as trees yeah the phenotype is
when you take those numbers or that data
that's stored in the genotype and you
translate it into something and you make
that thing go and then you measure how
well that thing does at whatever you
want it to do that thing is the
phenotype phenotype normally refers to
Form and Function your particular form
and your function whatever it is that
you do in most every evolutionary
algorithm we're going to see you're
applying the fitness function to the
phenotype the robot how well it does and
actually we're going to talk about two
of the first evolutionary robotics
experiments today and you're going to
see some different
phenotypes all good any other clarifying
questions thanks for ask asking them I
want to make sure we're all on the same
page as we move
forward okay all right so back to tools
of the trade and physical uh simulation
uh we ended last time by talking about
collisions yeah uh actually you're right
we talked about collisions we ended last
time by talking about Collision
detection just what happens when a
collision event happens in most physical
uh simulators there's some event-based
programming means meaning that your prog
your computer's attention jumps to a
particular point of code whenever a
collision
occurs now we're going to talk about
Collision resolution which is how does
the computer how does the physics engine
resolve a collision once a collision has
happened what does it do okay first
thing it does is check to see whether
pairs of objects that have hit one
another are supposed to be in contact
with one another or not if they're
connected by a joint ignore that
Collision event if they are not attached
with a joint the physical simulation is
going to have to try and resolve that
Collision the way in which different
physics engines resolve collisions is
different we're really getting down into
the engine room of physics engines now
so I'm going to just sort of give you
the basic intuition for how this works
and again you can ignore the code but
for those of you that are really
interested in physics you can dig into
the code a little bit to see how this
works let's imagine we've got these two
cubes like uh the cubes in your Tower
from assignment one or
two the physics engine has detected that
these two cubes have come into contact
with one another the intuition is very
much like uh what we talked about last
week when a sphere is falling and comes
into contact with the ground the physics
engine detects that collision between an
object in the
ground and applies an additional force
acting on the objects and those forces
are going to try and push the objects
apart make sense yeah okay how does it
do that turns out that it's actually
tricky to get that right to make the two
objects hitting one another and then
bouncing off one another trying to
simulate that accurately is actually
very difficult and requires a lot of
computational effort and as you Rec from
last class we just talked about the fact
that at a given time step in a physics
engine your physics engine might have to
be resolving a lot of contacts so it's
in the physics engine's uh best interest
to try and simulate this collision and
rebound uh as accurately but also as
quickly as possible so um in in pet when
we have links connected by joints do
they one thing I notic is sometimes
they'll like fold into each other yes is
areion just never accounted for great
point so all physics engines are
accurate none of them are perfect and
you can already see one obvious
approximation we're making in the
programming assignment so far which you
have these two cubes attached by a
rotational joint which means that the
physics engine is ignoring collisions
between these cubes because by
definition they're always colliding at
every time step the problem with that uh
ignoring those collisions is depending
on how they rotate they can literally
rotate into one another which is very
physically
inaccurate if you want what you can do
with that when you uh at the beginning
of your final project you can add in
some details to clean that up and fix
that and we'll come back to that at some
point okay all right so what does it
what do most physics engines do they
detect a collision and they know more or
less where the Collision has occurred so
in this case the physic physics engine
knows it's around here why am I saying
around here in order for the physics
engine to detect exactly where a
collision is occurring between Pairs of
objects is computationally intensive so
the physics engine most physics Eng
engines cheat at this point they know
more or less where the Collision has
occurred and they sprinkle a whole bunch
of uh points into that region
and at each of these points for one time
step and one time step only the physics
engine creates a
joint remember that when we talked about
joints uh last week we talked about the
fact that joints restrict the relative
motion of pairs of objects my elbow
joint restricts this particular body
part for moving that way while this body
part stays here different kinds of
joints
restrict the relative motions between
Pairs of objects in particular
ways contact joints you'll notice
there's some mentions of contact joints
here some mentions of contact joints
back here contact joints are different
from hinge joints so joints there's a
whole bunch of different kinds of joints
hinge joints are rotational joints ball
and socket joints uh uh piston joints
that cause two pairs of cylind
or rectangular solids to move relative
to one another but not rotate relative
to one another lots of different kinds
of joints this particular kind of joint
the contact joint is temporary at each
point the physics engine is temporarily
kind of welding these objects together
or is going to apply forces that cause
them to accelerate this object is going
to accelerate away from this point and
this object is going to
uh accelerate away from this point these
pairs of objects are also temporarily
connected by this contact joint as well
so this cube is going to accelerate away
from this point this cube is going to
accelerate away from this point yeah
okay in most physics engines if you want
to get down under the hood you can set
the number of contact joints that are
spread by the physics engine into this
estimated region of interpenetration
where these objects are either touching
or already starting to collide the more
points you allow the physics engine to
sprinkle the more accurately it's going
to uh resolve collisions between objects
and figure out how they should rebound
away from one another but it's going to
cost you it's
computationally uh it's it's
computationally
intensive okay couple other details
about Collision resolution there's some
other uh there's some other parameters
that are being set here called mu and
bounce you can set for these contact uh
joints which are restricting relative
motion of the points they're applying
forces that cause these objects to
decelerate and rapidly accelerate away
from one another you can set the exact
way that these forces are applied to
simulate different kinds of
collisions imagine two rubber balls
coming into contact with one another now
imagine two steel ball bearings coming
into contact with one another two two
pairs of objects imagine they have
exactly the same shape size and
mass given their material properties one
pair are rubber balls the other are
steel ball bearings the way in which
they're going to rebound from one
another is very different and you can
get down into the engine room of a
physics engine and play around with that
as always all of these nitty-gritty
details are hidden from
you okay Collision detection and
resolution is a tricky business there's
some things that can go wrong what do
you think can go wrong given what we've
talked about given the details of
collision detection resolution we've
talked about so far what could go wrong
I mean I kind of just think about
doesn't a sphere only really ever make
contact at one point do do do pairs of
approaching spheres only ever Collide at
one point great
question in reality in this physical
Universe yes in a physics
engine I see Nate shaking his head no
why
not because you have to get so
everything is divided into discreete
slices and so you know the chances that
you capture the exact moment where the
two spars are just kissing it's un likee
absolutely a little too late sure
remember that regardless of the physics
engine you're using in a physics engine
time moves forward in discrete moments
and that discreete uh updating of time
has huge repercussions for everything
that happens in a physics engine
including collisions we've got two
objects that are moving towards one
another but the positions of those of
those two pieces are teleporting
actually a short distance during each
time step when you run the jpeg or you
run the simulation uh you don't see it
right it looks like Smooth motion but
like old time uh movies there's actually
discrete frames it's your eye that's
tricking you into thinking that there's
continuous Motion in the physics engine
there isn't which means as Nate
mentioned you can have objects that are
at time step T just separated but at
time step t+ one they are now
overlapping by some amount and the
physics engine is not always exactly
sure what that amount is again with two
spheres it will sprinkle a whole bunch
of contact points into that space I saw
there was a question I just want to
uh cycle back for a moment to contact
joints one detail that I mentioned
contact joint uh contact joints are the
one and only type of joints which are
temporary the physics engine creates
them during one time step the physics
engine using f equals ma uses those
contact joints to apply additional
forces that push the objects away at the
next time step during which all of these
contact points are deleted again yeah
tempor joints question
I simulation does that that accumulate
over simulation absolutely it means that
errors accumulate over a physical
simulation because we're updating time
in a discreete manner right you you're
trying to simulate steel ball bearings
which in the real world absolutely do
not ever interpenetrate right they
absolutely only come into contact with
one another at a single dimensionless
point and it's at just that point that
forces act to push them apart it's hard
to get that just right in a simulation
which means two objects that you're
trying to simulate in a physics engine
that have ve that are very very rigid
that the the way in which they move
apart again after a collision is not
going to be accurate which means errors
can start to accumulate absolutely how
do we rain back in that error
accumulation do you think in a physics
engine you you modify the amount of like
physical time that passes for each
absolutely so we mentioned a while back
that there are a number of time scales
that we need to juggle when we're
running a physical simulation one of
those time scales is simulation time the
amount of time that elapses in the
virtual world between one time step and
the next and in most physics engines you
can set that time step if you set it to
0.1 that means 0.1 seconds of time
elapses from one time step to the next
if you make that number very small
0.001 you still have a discret simulator
but it's discreet like this rather than
discreet like this so why not just set
the time step really really really
really really
low
expensive it's computationally expensive
so everything that goes Mo most things
that go on in robotics that involve
physical simulation and modern video
games they're trying to strike a very
careful balance between physical realism
so that errors don't
accumulate and ensuring that the
simulation doesn't take longer than the
lifetime of the universe to run hard
actually in practice to get these things
right okay so errors accumulate based on
the discreet nature of time in a physics
engine how else can errors come in there
ultimately because of this discret
nature but what are the other things
that can go wrong when you're simulating
two objects that are moving quickly
towards one another for
example I me if we're moving quickly and
the simulation
time each other that's exact L the
question answer that I was going for
let's imagine you're going to simulate
two bullets that have been shot at one
another you set the time step pretty low
because you've got very high velocity
moving objects but they're still doing
this you can get into a situation in a
physics engine where the two bullets do
this then this then this then this then
this there was no Collision detection
and resolution the objects never
approached one another or they never got
close enough for Collision resolution so
you often need to think carefully about
not just not just the physical world but
what's going on in that physical world
are some things moving a lot faster than
others what if you've got slower moving
objects but they're really really really
really
small same issue right even if they're
moving like this but they're teeny tiny
there's a good chance that they could
miss one another and you've got some
significant errors that are going to
start to accumulate in your physics
engine
okay none of this is probably going to
be relevant for your actual projects but
just to give you a sense for some of the
challenges in simulating robots and
their environments
accurately okay mate you've already seen
some examples where one object ends up
embedded NE and kind of flings itself
off yep like practically speaking is
that ever really a problem or is that
close enough to realistic Behavior
usually that
yeah it's a huge problem so if you've
got parts of the robot that are
interpenetrating and uh forces are being
applied for the physics engine to pull
them apart and they're flying off none
of that has a counterpart in reality if
you don't notice that that's happening
and you try and take your evolved robot
and instantiate it as a physical robot
you're not going to cross the reality
gap which we're going to spend a fair
bit of time in this course talking about
in about a month's time how do you
ensure that what evolution did in
simulation transfers to reality very
hard to get this right still a very
active area of
Investigation okay let's push on okay I
think we've said enough about that um
okay all right next thing we're going to
do uh we have our list our usual list up
here of all of the bits and pieces we
want to build into our uh build into our
robot links the parts that make up the
robot joints that connect links together
uh sensors and
Motors sensors Motors neurons and
synapses as I mentioned before
everything above this line is the
responsibility of the physics engine and
we've just finished talking about most
of those pieces in the physics engine
after today's quiz you can safely forget
all of these nitty-gritty details what
you're going to be doing uh in the
sensors assignment and forward is adding
additional stuff on top of what comes
out of the box with the physics engine
to allow it to simulate a robot a
physical simulator is not a robot
simulator at least not out of the box
you got to add additional things so how
do we add sensors every sensor that you
might add to your robot in this course
you're going to do so by exploiting
stuff that the physics engine is already
calculating
let's start with one of the simplest uh
sensors that are found in most robots
these are touch sensors or bump sensors
so I've got a sensor in this part of my
body that this touch sensor is not
firing now it's firing now it's firing
now it's not firing now it's firing and
so on so if I want to simulate a touch
sensor I could start adding additional
code on top of the physics engine to
look to see whether this object collides
with any other object it would be an
extremely stupid thing to do because the
physics engine is already doing this for
us it's already detecting when pairs of
objects touch one another so if you dive
into some of the pyrro SIM code which is
this additional code I've given you that
sits on top of pybullet pybullet is the
outof the- box physics engine we're
using in this course py bullet is some
additional code that I wrote that's
hiding some of these details from you
one of the things that pyrosim is hiding
uh from you is simulating sensors
pyrosim is dipping in to the contact
points that the physics engine has
already strewn within the volume of
pairs of objects that are in Collision
during this time
step and we're then pyrosim is writing
some additional code uh that is looping
through each of these contact points and
looking to see if any of these contact
points are
associated with the desired link if you
say there's a touch sensor in this link
but not a touch sensor in this link this
piece of code runs during every time
step of your
simulation this piece of code is looking
at contact points and if it finds a
contact Point that's inside a link
that's supposed to be simulating a touch
sensor it sets something to one so it's
simulating that sensor for you so we're
exploit pyro Sim is exploiting stuff the
physics engine is already doing to
simulate in this case a touch
sensor question so does that mean that
the touch sensor only lights up for like
one frame or is it just like it will
just like keep finding the new contact
point if things haven't bounced apart
yeah good point so the only thing pyro
Sim will do for you is detect that the
touch sensor has turned on there's a
there's a collision that's occurred and
it's returning that value to you what
you do with that is up to you you might
want to you might want to simulate a
touch sensor that fires and then
immediately turns back off
again a lot of the a lot of the tactile
uh sensation in your skin actually walks
works like this right there is press
pressure on your back and your Underside
right now but you're usually not aware
of it you're usually aware of it for the
first tenth of a second in the moment
you sit in the chair and then it kind of
goes away again right so maybe you want
to simulate a touch sensor that works in
that way or you want to simulate a touch
sensor that stays on as long as the
object is in contact with some other
object it's up to you right pyrosim is
just trying to provide additional
information for you and what you do with
it is up to you was there another
question here nope okay all
right okay so uh I'm going to just pause
for a moment and I want to put all of
this stuff together so you can see how
this works again this is old C code from
the physics engine we used to use in
this course but it should look more
relatively familiar to you now we have
uh we have this inner loop here called
simulation Loop this simulation Loop is
running a number of sub routines and in
your case these number these sub
routines are sitting inside this for
Loop that you created all the way back
in uh assignment one so you got a for
Loop somewhere that's looping uh a
thousand times each time it executes an
instance of that loop it's simulating
one instance of time in over a thousand
time steps in your simulation yeah so
what actually is going on during each
time
step in open uh OD you would actually
see this again in pi bullet this is
hidden from you the first thing the
physics engine does is look to see if
anything is uh colliding with one
another and sprinkling these uh
temporary contact joints between Pairs
of colliding
objects every physics will then step the
world and step the world is shorthand
for go to each object look at all of the
linear and rotational forces acting on
that object update that object's linear
and rotational acceleration and use
those linear and rotational
accelerations to update the position and
orientation of that object then go to
the next object do the same thing and do
that for each object in the simulation
which steps the world what's 0.05 here
do you
think discreet time step the discrete
time step so in this particular
simulation the coder is telling the
physics engine step the
physics by 0.05 seconds all right okay
next thing OD does now that the world
has been stepped is throw away any
temporary contact joints if any were
made and assuming the graphics window is
turned on draw the current state of the
world for the Observer and then rinse
and repeat one thing you can do if you
haven't done this already is you can
start to run your physical simulator in
headless mode headless mode is uh is
slang for turn off all the graphics
again remember that there are multiple
uh there are multiple kinds of time
unrolling in a physical simulation there
is simulation time time 0 time 0.05
seconds time1 seconds and so on when you
render the world that's going to slow
things down because your your your
computer has to actually draw the
graphics so you might actually watch the
frames the visual frames one after the
other depending on the speed of your
computer those frames may be appearing
on your screen faster than
0.05 or if you have a very complex
simulator with thousands of links and
Joints each frame may actually be drawn
in more than
0.005 seconds yeah that's Graphics time
and again you're sitting there and
watching that then we've got wall clock
time as well three different kinds of
time that are unrolling during a
simulation okay all good
okay all right so let's keep going we're
going to we're going to put together uh
a cartoon example where we're going to
put all of these things sensors Motors
neurons and synapses on top of a virtual
robot for those that have already got to
the synapses assignment my apologies
this is going to be a little remedial
for those that haven't got there yet
this is a bit of a preview for where
you're going let's assume a very simple
physical simulation that's only in two
dimension
we have a two-legged robot here with a
front leg and back leg and a main body
and there is some object that is out
here uh in its
environment this little black dot and
white dot are meant to represent two
touch sensors so we've got one touch
sensor in this object and one touch
sensor in this object and as we just saw
we're going to simulate these touch
sensors by piggybacking on top top of
the Collision detection and resolution
that the physics engine is already doing
so far so good we're just setting the
stage for a moment okay okay what if
we've got our touch sensors here let's
add in just to practice let's add in one
additional uh sensor which is a light
sensor or a photo sensor remember
vehicle uh brenberg vehicle 2A and 2B
the coward and the aggressor that we're
detecting light levels let's say you
want to simulate a photo sensor in your
simulation and we're going to assume
that this external object is actually a
light source it's emitting light and
we're going to place this photo sensor
in this particular object up here object
one you can see my code to do this at
every time step I'm going to add in an
additional sub routine that's going to
simulate or update the value of this
photo sensor at that time step you know
in order to do that I want to get the
three-dimensional position of this
object object one get the position of
object one I'm going to get the position
of this particular object out here which
in my numbering scheme is object four so
get the position of object 4 and I'm
going to now compute the light level of
this photo sensor as a function of the
position these two
positions not surprisingly I'm going to
take the ukian distance between
them and then take one over that ukian
distance the smaller the ukian distance
between the light source and the photos
sensor the more strong more light is
falling on the light sensor the bigger
the ukian distance between the photo
sensor and the light source the lower
the light level arriving at the photos
sensor that should all make perfect
sense yes
so we're I again I'm piggybacking on top
of what the physics engine can already
do for me which is tell me what the
current position of this object is and
the current position of this object
is there's an additional detail here I'm
raising the ukian distance to the second
power anybody know why go back to your
high school physics the distance
increases the line
R the light intensity falls off as one
over r s so if I'm looking at this
overhead light and I move twice as far
away from it as I just was the amount of
light falling on my retina drops uh four
times if I move four times away as I was
before from the light source the amount
of light falling on my retina is
116th this is the inverse Square law
it's just physics so I happen to know
that and I'm putting that into my robot
simulator this is just you don't need to
remember the inverse Square law the
reason I'm mentioning this is this is
something that uh roboticists and people
working on physical simulation do all
the time we try and put in additional
details of the physical world so that
ultimately if we evolve this robot to
perform Behavior as a function of the
light falling on the photos sensor and
we take that evolved light sensitive
Behavior take it off the simulated robot
and put it on a physical robot that
operates in the real world where the
inverse uh where the inverse Square law
applies we've got a better chance that
that behavior is going to transfer what
about line of sight or occlusion what
about line of sight or occlusion right
there's nothing in here that simulates
that so if this robot moving around ever
comes if an object ever comes between
the robot and its light
source that evolved behavior is not
going to transfer from simulation to
reality so let's go back in and
elaborate the code that we use to
simulate the amount of light falling on
a light source at every time
step what happens if there's a shadow
that falls on the photo sensor what
happens if there's dust in the air
if we're prototyping a Rover for NASA
there are certain planetary bodies where
there's going to be significant dust in
the air that's going to definitely
affect photos sensors oh my goodness
that is not an easy thing to simulate in
a physics Engine things get increasingly
difficult to simulate very very
quickly one over ukian distance trivial
one line of code inverse Square law of
light trivial one line of code
simulating occlusion not so trivial 10
to 100 to a thousand lines of code
simulating dust and how it influences
photo sensors somewhere to half a
million to a million lines of code
things get really tricky really quickly
um at some point you just like start
looking to use like kind of a mature a
more mature like physics simulation that
like has light already in it absolutely
NASA is in con constant contact with all
the major games companies on the planet
for exactly this reason trust me you do
not want to try and simulate how a Dusty
atmosphere uh influences a photo sensor
but the good people at ID software have
spent millions of person hours and coder
hours simulating how to make sure that
for a virtual camera inside a modern
video game that when there is dust in
the environment it looks realistic and
it turns out that that gets you 99% % of
the way to simulating that it's actually
realistic not 100% but gets you very
close other questions so far so good
Okay so we've got our simple two-legged
robot we've got a light sensor in the
body and touch sensors in the
feet let's add in some Motors now and
again you don't need to memorize or
remember this code here this is C code
from the old physics engine OD but just
to try and drive home this point
remember that a motor uh for our
purposes Motors are always going to be
attached Motors are always going to be
attached to a joint and the motor is
going to send a value to that joint
joint it's the torque the rotational
force that should be applied and forces
act on links so the joint is going to
take that number that torque and send it
to the pair of links that that joint
connects and then the physics engine
takes over from there it updates the
positions and orientations of the links
given that additional force that the
motor is applying to the to the links
through the
joints let's imagine at this particular
point in time at a particular time step
in the physics engine the robot's front
leg is off the ground its back leg is on
the ground we've got a motorized joint
at the shoulder here
and whenever at time Step Zero when a
simulation starts the angle of a hinge
joint is always zero this is a little
confusing and again this is kind of a an
annoying part of physics engines
intuitively it looks like we've got this
body part and this body part that are
attached by a link here you would kind
of think that this angle is maybe
90° doesn't matter what it looks like to
you the moment you create a joint that
attaches pairs of objects together the
current angle of that rotational joint
is
zero if I had created this robot by
placing this front leg out pointing out
into the front of the body out here and
again connected that front leg to the
main body with a
joint the angle of that joint at time
Step Zero of the simulation is zero it's
confusing I know okay we're going to
assume that fact going forward we're
going to assume that as the joint starts
to apply torque rotational Force to the
pairs of objects that it connects
together that the angle of that joint
changes we're going to we're going to uh
assume a particular way of describing
this where extension meaning objects
that rotate out and away from the body
those are going to be uh posit positive
values and flexion meaning rotations of
the joint that cause the cause objects
to move inward towards the body those
are going to be negative numbers so
positive numbers for extension and
negative numbers for flexion it's an
arbitrary convention we're just going to
use it for describing all the different
kinds of robots and physics engines
we're going to see in this class so far
so good okay so at time Step Zero Theta
is zero we're going to tell this
motorized joint that we want this
motorized joint to rotate uh this object
and this object so that this object rot
extends away from the body extension
flexion in towards the body we're going
to tell the physics engine we want to
extend this body part away from the main
Body by
60° it's an arbitrary number for the
moment I just kind of picked this out of
thin air remember a motor has a single
value it's sends that to a motorized
joint in this case a desired angle that
joint takes that desired angle and turns
it into a torque rotational Force that's
applied to the uh the links connected by
that joint okay here that is here's that
in code I am I am coding this up I am
telling this motorized joint I want you
to rotate your pair of links to
60° the the code that follows before
it's got It's got to take this desired
angle and turn it into a torque so it
asks the physics engine what is the
current angle of the joint and it takes
the difference between the desired angle
that I want and the actual angle that
the joint currently has in this C to an
example we're assuming Theta is at zero
we just started the simulation so actual
angle is zero the desired angle is 60 60
minus 0 is 60 the difference between
what I want and what currently exists in
the simulator is
60 in uh OD the code that we're looking
at I would send that difference into uh
into the motorized joint and the physics
engine kind of takes it from there it
figure figures out an appropriate torque
to apply we're going to stop here and
not go deeper into the code so far so
good okay you can imag you can probably
imagine what that torque is there's a
pretty big difference between zero and
60 so it's the physics engine at this
point in time is going to apply
significant rotational Force to try and
get this thing
going okay so it applies some some
torque and at the next time step that
torque remember torque is a force f
equals ma the physics engine uses that
force and the other forces to accelerate
this partic all the all the objects but
we're focusing on this particular object
so this object has now accelerated and
changed its position and orientation
remember physics engines update position
and orientation so now the object is
here and the current angle of this joint
is 20 it was zero and now it's
20 I still want this joint to rotate
this object to 60 degrees extend this
object out 60 degrees away from this
object so far so good okay so if we run
this piece of code a second time during
this new time step the what I want is
still 60 the actual angle is now 20 the
difference is less it's
40 what do you think that does to the
torque reduces it the the torque is less
difference is less so torque is less so
at the next time step time step three
there's a bit of an an error here this
this object should now be ex uh moving
but moving less we're applying less
torque to rotate it to
60° yeah so if this angle was Zero then
it was 20 at this one it's probably like
38 or 39 right it's still accelerating
and rotating outward from the body but
it's slowing down because the motorized
joint is applying less rotational Force
less
torque walk me through what happens over
the next 10 100,000 time steps if this
piece of code stays constant
what happens to the front leg of the
robot asically approaches it asically
approaches right it starts move the leg
starts to kick out in front of the robot
very quickly and very forcefully and
then it starts to slow down and slow
down and slow down until it gets to 60
degrees at that point this difference is
zero the actual angle I want is 60 the
uh sorry the desired angle that I want
is 60 the actual angle is 60 the
difference is zero apply no
torque what happens is this leg is
hanging out in front of the robot at 60
degrees let's test our intuition about
physics engines just wobbles back and
forth it wobbles back and forth why does
it wobble back and forth at one step
it's zero so it'll drop a little bit why
does it drop a little bit because since
it's zero zero torque is being applied
so
gravity remember that there are also
other forces acting on this body like
you just just mentioned gravity is
always pulling it down so it starts to
droop or uh Flex inward again which
increases this difference which causes
the motorized joint to apply rotational
Force to kick it back up again and the
front leg will probably wobble back and
forth yeah so far so good all right
that's uh
Motors
okay we've got sensors we've got Motors
in there now let's connect up the
sensors to the motors with some uh
neurons and synapses so we've got two
touch sensors in this case we're going
to now ignore the photo sensor for a
moment we've got a touch sensor in the
back leg a touch sensor in the front leg
and we're going to just focus on this
one motorized joint at the shoulder
there is another motorized joint back
here at the hip we'll forget that for a
moment we've got two sensors so inside
we're going to build the brain for our
robot we're going to assume it has two
sensor neurons and remember that sensor
neurons just collect values from the
sensors at this point in time the two
sensor neurons are set to one one
because the two touch sensors are
firing we've got one and only uh one one
and only one motor neuron M1 here we've
got one one and we're to continue the
example we just saw we're going to
assume that at time Step Zero the value
that arrives at this motorized this
motor neuron is
60 to keep things really simple we're
going to ignore activation functions
remember that activation functions sit
at neurons and they squash values back
towards some desired range we're going
just ignore activation functions for our
purposes
today what are the synaptic weights here
we've got got two synapses that connect
the two sensor neurons to the one
motorized
neuron 3030 30 30 and 30 let's say Mak
sense right 1 * 30 plus 1 * 30 gives us
60 yeah so assuming we have a three
neuron neural controller for our robot
three neurons and two synapses and the
two weights are 3030 let's imagine we've
got a genotype uh length two we've got a
a vector that contains two numbers the
two synaptic weights and the current
values of that genotype are
3030 that particular pair of synaptic
weights for this robot at time Step
Zero cause the motor to receive a value
of 60 so we're now replacing this
hardcoded code that I put in here
imagine we delete this code and we're
replacing it with a neural network now
the motor neuron
is talking to the motor not my couple
lines of code here so far so good as we
just saw what happens that causes torque
to be applied at the shoulder which
causes the front leg to rotate off the
ground which at the next time step shuts
this touch sensor
off right so in robotics we talk about
sense think act here's
sense 1 + 30 + 1 * 30 = 60 that's the
think sense think and then the ACT is
the uh is the torque that's applied to
the motor which causes a change in the
configuration of the robot so at the
next time step this action has caused
this sensory repercussion the robot has
pushed against its environment and
observed how the world pushes back this
is a situ uated and embodied
agent yeah
okay now the touch sensor values have
changed at this time step the synaptic
weights have not changed we're assuming
that the synaptic weights during these
thousand time steps of the simulation
the synaptic weights stay constant they
don't change the values inside the
neurons are changing from time step to
time step but not the synaptic weights
there's no learning here the strength of
connections between neurons is not
changing over the Thousand EP lifetime
of the robot this is an important
distinction between evolution and
learning when we talk about learning in
this course and usually in robotics in
general learning implies that the
synaptic weights themselves are changing
from one time step to the next in the
simulation of the robot not happening
here no learning we're just assuming
there's some evolutionary process in the
background that has set these two
synaptic weights to
30 turns out that these two synaptic
weights are not actually 3030 they're
something different if these two
synaptic weights don't change and when
these two neurons are one the value
arriving here is 60 when the value of
these two neurons is one Z the value
arriving here is us 990 a number I made
up what are the two synaptic weights
actually absolutely so we know here it's
got to be 1 * x + 0 = - 90 so X has to
be minus 90 so this synaptic weight is
actually minus 90 which means this
synaptic weight has to be 150 1 * -90 is
-90 plus 1 *
150 is 60 kind of arbitrary numbers for
the moment question the
back yes okay learning we have this
robot that's running around in its
physics engine for let's say 1,000 time
steps as you we're just visualizing two
different time steps here time Step Zero
and time step
one and we can see even in this simple
example that the values at the neurons
are changing from one time step to
another we're assuming for this
simplified uh example that the two
numbers sitting on the two synaptic
weights uh minus 90 and
150 we're assuming those two synaptic
weights are the same at the next time
step minus 90 and
150 the synaptic weights are not
changing the strength of connection
between Pairs of ner neurons is not
changing over the 75 minutes that you're
sitting here and having to listen to me
strengths of connections between Pairs
of neurons in your brain are changing
you are learning hooray that's learning
changes in the strength of connection
between Pairs of
neurons over the lifetime of an organism
or in our case a
robot okay all right so uh we've got
minus 90 What's Happening Now what
happens as we keep unrolling this
hypothetical simulation
forward yes so made it like out yes so
it's extended 20 degrees out and then
it's the next so
itus 20 is absolutely so at this
particular time step
the uh current angle of this leg of of
this joint is plus 20 because of what
happened during the previous time step
it's extended out 20 the motorized joint
is saying I want a desired angle I want
a desired angle of minus 90 the
difference between these is 110 or minus
110 we're taking the desired angle and
subtract off the current or actual angle
what happens at the next time step do
you
think it'll like make
contact but with with the ground and so
it'll go back to the first one we've got
we've got a value of minus 110 the diff
a difference of minus 110 being sent to
the motorized joint it's going to apply
a heck of a lot of torque that's a big
difference in flexion minus
always means rotate in towards the body
a positive difference always means
rotate outward away from the body so
there's a lot of rotational Force that's
going to be applied that's going to
crank or Torque that front leg back in
towards the body which means either at
the next time step or at least very soon
this foot is going to come back into
contact with the ground which as you
said means now we're back back to this
situation the moment that front leg
comes into contact with the ground
suddenly the two sensor neurons are
registering one one again and because
we're not changing the synaptic weight
that means that the motorized joint is
going to ask for plus 60 again which
means now torque is going to start to be
applied in the opposite direction is
there any potential it to like kind of
keep swinging through there's also
momentum in a physics engine which we've
kind of ignored for now you're you're
right if there's enough uh torque that
causes the front leg to accelerate
inward towards the body to flex inward
towards the body it might actually hit
the ground and keep going we're glossing
over that detail for the moment so the
leg the front leg started in contact
with the ground rotated out away from
the body suddenly started to rotate back
in again and came into contact with the
ground what happens over the next 10 20
50 100 time steps tell me about the
robot moves it moves
how at some frequency there's an
oscillation in the movement of the robot
when you walk there's an illation most
of the time if you're not in a hurry
it's at about one Hertz yeah where's the
clock in here that's timing this
motion
there uh there is no clock in the
physics engine right it's not actually
timing this
oscillation generated by the phys engine
that creates it's the movement that
creates this oscillation not just the
movement it's everything it's it's the
accelerations and decelerations the
momentum the weight of the leg the uh
the particular neurons and the synapses
the particular weights of the synapses
are all set we've got this sort
complicated system now lots of different
moving pieces that collectively result
in
this if you if I were to hide all of
this in the spirit of Valentino brenberg
from you I didn't tell you anything
that's going on and you just watched the
robot and I asked you how it was doing
what it was doing and you hadn't taken
this course you might give me an answer
like well somewhere inside the robot
there's probably something like a
metronome that's like Counting off and
every time the metronome strikes the
muscles Twitch in the robot and it does
this most of us would tend to attribute
some explicit timer inside the robot but
when we crack this robot
up there's no one home there is no timer
inside remember our discussion about
brenberg vehicles I have emotions inside
I love I hate brenberg doesn't it's just
wires I have free will ins side I have
prospection inside I can close my eyes
and imagine what's going to happen an
hour from now I have retrospection
inside I can close my eyes and remember
what happened on my last birthday it's
all in there I can feel it it's obvious
I have it machines
don't
maybe okay back to physics ents okay all
right that concludes our discussion of
physics engines and tools of the trade
any questions about any of that before
we spend 15 minutes on the very first
years of evolution and robots with that
diagram when the leg swings out with the
robot not just like kind of topple over
there's also that absolutely right so
there's momentum the leg has weight when
it swings out it might actually topple
forward this is obviously a cartoon
example yes lots of other things going
on you probably have a code base set up
at the moment where with about half an
hour of effort you could probably knock
something like this up and try it out
can you set the synaptic weights so that
you get your robot to do this can you
set your synaptic weights so you get it
to do this faster can you set the
synaptic weights to cause it to do this
slower give it a
try is it like more computationally
heavy for a robot to learn than to be
set by evolutionary algorithm that's a
great question so is it more
computationally intensive to get the
robot to learn in uh in addition to or
in opposition to what we're currently
doing which is evolving the weights
setting the weights and letting the
robot do its thing the jury is still out
I'm an evolutionary roboticist I'll tell
you I would guess that in the final
analysis evolution is helpful it's
probably both right we evolve and learn
ultimately when when we create useful
and intelligent and safe machines it'll
probably be some combination of evolving
the structure and the neural controller
of the robot and also allowing the robot
to to learn allowing the robot to change
its synaptic weights as it moves around
in its environment yeah good
question okay all right so onward to uh
our history of the field of evolutionary
robotics the field of Robotics as a
whole just as a reminder has been around
since the end of the second world war
there are many many different schools of
thought thought and uh ways of
approaching Robotics and camps we're
talking about evolutionary robotics uh
in this course evolutionary robotics has
been around
since uh about the early 90s no that's
not what I
want uh so about about 30 years so we're
going to go back and look at two of the
very first evolutionary robotics
experiments uh the first one was
conducted at the epfl uh in Switzerland
by uh uh by an Italian researcher so for
our purposes I'm going to refer to this
as the Italian approach an Italian doing
a scientific experiment in Switzerland a
little confusing we'll just call this
the Italian approach okay how did this
work um this is n uh this is the Kea
robot that they used in this experiment
the experiment was actually carried out
a few years few years earlier there were
some prototypes of this Kea robot that
existed
in the early
9s physics engines did not exist at this
time which means that how are these
experiments going to be carried
out they're going to evolve this
robot in the real world absolutely okay
the Kea robot's about the size of a of a
hockey puck um the nice thing about the
Kea and there are versions of it that
still exist today is it's kind of uh
stackable it's plug and play so you
there's the the sort of drive train
underneath these two motorized uh Wheels
one left and one uh right and you can
stack things on top in this little
grainy picture here they placed a little
gripper on the top and this gripper can
rotate down and close around a sugar
cube and then lift that sugar cube up
over its head sound familiar okay all
right uh nice thing about this hockey H
keer robot is you could perform
experiments with it on a table and it
wouldn't kill anyone if it falls over
you're going to be
okay
okay here are some of two arguably two
of the most uh widely deployed
autonomous robots on the planet at the
moment what's this
one it's the Roomba this is the the one
that that's actually a brush I can't
remember what it's called but yes the
Roomba anyone recognize this
one it's a warehouse bot um used by a
particular
company anybody bought anything from
Amazon the last few days if you've
received a package from Amazon it was
probably moved about it originally that
item that you bought was sitting in one
of these vertical shelves one of these
little orange robots drove underneath
and lifted up the vertical stack and
brought it over probably to a human
worker who then pulled out the item and
put it in your box the Kea not a lot of
people have heard of it it is the great
great grandparent of a lot of the
autonomous robots that are currently
moving about on the planet
okay uh here's a different extension uh
we just saw the gripper uh they're going
to we're going to actually look at it
the first evolutionary robotics
experiment where they put a linear
Vision module on top of the robot not
quite a camera uh it's kind of a very
crudee camera sits on top of the robot
and at every point in time here in the
real world it that little camera returns
30 uh sorry 64 numbers which is the
amount of light falling on these 64
photo receptors so not that different
from a brenberg vehicle and it covers
about
36° uh of coverage in front of the road
robot okay how did they set everything
up no physics engine so they're going to
have to uh apply synaptic weights to the
physical robot let the physical robot
run around on the top of the table for a
few seconds compute the fitness of that
robot go on to the next set of synaptic
weights in the population next set of
synaptic weights next next next it's
going to take a lot of time and a lot of
effort so what they did uh in this case
was to tether the robot to a desktop uh
computer and the computer is going to
run the evolutionary algorithm it's
going to at the beginning generate a
random set of numbers which are the
random weights for the
synapses they're going to the computer
is going to send those synaptic weights
to the
robot I'm sorry I misspoke it doesn't
say here the brain The evolutionary
algorithm is running on the desktop the
brain of the robot is also running on
the
desktop the desktop is going to take
that set of random synaptic weights and
apply it to the synapses of a neural
network that's being simulated on the
desktop they're going to propagate the
sensor value they're going to get the
sensor values back from the robot
through this tether they're going to
plug those sensor values into the neural
network propagate those sensor neuron
values through to the motor neuron
values get those motor neuron values
back turn them into torqus send those
torqus back along the tether to the Keo
robot and those torqus are going to be
applied to the two
wheels so far so good okay all right so
what are the sensors um there's a little
there was a little laser uh up in the uh
Corner uh above the table table and that
laser would Shine Down onto the Kea and
that would allow the Kea or the system
to take that light the laser information
and compute the XY position of the kepra
on the tabletop and Alpha The Heading of
the robot so there are three sensor
values coming in in this hypothetical
experiment x y and Alpha and then the
neural network would say given the
current X Y and Alpha motorized Wheels
move like
this so far so good okay given that
setup what kinds of behaviors could you
evolve for this little hockey puck type
robot maybe like basic navigation a 2d
maze or
something a 2d maze like this one yes
well done okay all right so this is the
arguably the very first evolutionary
robotics experiment ever conducted they
built this simple 2D it's not even a
maze racetrack on the top of a
table remember I told you that there are
these 36 numbers coming into this uh
linear Vision system they put a little
bit of code in place to take those 36
numbers and boil them down into one two
three four five six seven eight
proximity sensors so as this little Kea
is moving around and starts to approach
one of the walls of the racetrack a
light will actually
drop and it uses that drop in light to
approximate proximity how close it is to
a source to to the wall Okay so we've
got actually eight different
sensors and two motorized uh wheels so
the neural network control rer they've
actually drawn it right on top of the
robot might be difficult to see from the
back but we sh we've got our eight uh
sensors these gray boxes and we've got
eight uh sensor neurons the white
circles we've got two Motors here the
white boxes and two Mo uh two motor
neurons which are the two big circles in
center eight sens
two Motors every sensor is connected to
every motor neuron how many total
synapses do we
have 16 each of the eight sensors is
attached to each of the two Motors so
imagine a genome which is a vector of
length 16 we need to come up with 16
weights for these 16 synapses which is
what they allowed The evolutionary
algorithm uh to do we're going to assume
that the value that's sent from the
motor neuron to the motorized wheel can
be positive or negative a positive
number is the motor neuron uh trying to
apply torque to the wheel to cause the
wheel to move forward a torque of zero
is causing the wheel to not spin and a
torque of minus5 is causing the wheel to
rotate backwards quickly yeah so the
according to the synaptic weights the
wheels are going to start spinning
forward backwards at various
velocities okay we're going to assume
that the eight proximity sensors are the
values arriving at the sensor neurons
have a Val a floating point value
between zero and one proximity sensor is
going to register a value near zero if
it really can't see anything there is an
obstacle 5 cm or further away clear
sailing as the robot moves around and
starts to approach uh a an object closer
and closer that proximity sensor that's
nearby is going to start firing with a
larger and larger value if that
proximity sensor comes into contact with
the wall of the racetrack that proximity
sensor is going to fire with a maximum
value maximum proximity
one okay if you it might again may be
difficult to see in the back of the room
you might notice that the synapses here
have little uh arrows associated with
them and the sensor neurons that are
attached to the ipsilateral same side
motor neuron have a particular kind of
Arrow associated with them and synapses
that are that connect from a sensor
neuron to a motor neuron
contralaterally like this one have a
different Arrow these two different
Arrow types are representing that some
of these synapses have been set manually
by the researchers to be either
excitatory or
inhibitory so in this experiment the
researchers are coming in and they're
saying listen I have a little bit of an
intuition for what these synaptic
weights should be ipsilateral
connections they should have positive
values whatever those weights are going
to be they should be positive and
contralateral synapses those values
should be negative what the actual
values should be that's going to be up
to the evolutionary algorithm what is
the intuition that the researchers are
drawing on
here you want to move away from sources
of contact you want to move away from
sources of contact so why do excitatory
contralateral excitatory connections
make sense like theel on the
sideward sound familiar where have we
seen this before
brenberg Vehicles was written in 1980 if
I get now five or six right so six or
seven years before this experiment was
done these researchers did their
homework they knew that generally
speaking that's what you want but what
those actual values should be who knows
okay we got one minute left in class so
let's think about how we're going to
select for this Behavior we're going to
evolve vectors of length
16 we need to come up with a fitness
function where as after a few seconds of
the physical robot moving about in this
racetrack we want a function that
returns zero if the robot does the worst
possible job and a one if the robot does
the best possible thing lower values are
going to correspond to worse Behavior
values closer to one represent better
values in this particular experiment the
researchers built their Fitness function
from these 10
variables they're assuming that they're
going to get back from the robot the
speed of the left and right wheel at a
given point in time and the values of
the eight proximity sensors we have 30
seconds left give me a general intuition
how do you combine these 10 variables
you want to fast as possible and then be
those to the brightest so the farest
away from the walls okay you want the
wheel to spin as fast as possible and
you want the proximity sensors to be as
low as possible
great
Fair perverse
instantiation I know that isn't quite
what you meant work on it see if you can
write something down with pen and paper
uh we'll see you on Tuesday you have a
quiz due tonight you're working on some
set of assignments have a good rest of
your week


--- Evolutionary Robotics course. Lecture 09. The first years of the field, contd..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
[Music]
okay good morning everyone let's Dive
Right In uh just to get reoriented as to
where we are and where we are going uh
undergraduates you are going to be
tackling assignment five uh this week if
you haven't already which is uh Motors
couple notes about uh
Motors we ended last time talking about
the little Kea robot that was running
around on the top of a table that robot
has wheels your robot has quote unquote
legs motor neurons send commands to
Motors and Motors interpret the numbers
coming from the motor neurons in
different
ways in these programming assignments
the number coming from the motor neuron
to the motor the motor is interpreting
that as a desired angle
Theta that's the angle that the motor
neuron wants the joint to get to when we
jump jump back to talking about the Kea
this morning that Kea has motor neurons
inside it as well those motor neurons
are also sending commands to the motors
but those Motors are attached to
Wheels those Motors are going to
interpret the values they get from the
motor neurons as desired uh angular
velocities Theta per second yeah so
motor neurons all they do is send
numbers to Motors the neurons don't
really care what those numbers mean as
we continue on in this course and we
look at lots of different legged robots
and wheel robots and wagged robots which
are combinations of legs and wheels the
number that's being sent from the motor
neuron to the motor is being interpreted
differently just wanted to point that
out now for the undergraduates that are
tackling the motors uh
assignment okay any questions about A1
through A5 so far so good
okay graduate students you have reached
the end or at least the end of the
beginning you are going to be tackling
assignment nine and assignment 10 this
week which again if you haven't got
there
yet in assignment nine you're going to
be implementing three different
evolutionary algorithms and they're
arguably so simple they're not really
even evolutionary algorithms yet the
first of the three that you're going to
be
implementing is random search dropping
points at random places on the fitness
landscape once you've implemented that
you're going to go and implement the
hill climber the hill climber drops a
random single point somewhere in a
fitness landscape that parent produces a
child if the child lands at some place
in the fitness landscape that's higher
than the parent meaning the child has a
higher Fitness than the parent parent is
deleted the child becomes the new parent
and the hill climber as the name implies
starts to climb its local Hill as we saw
when we talked about evolutionary
algorithms a short while back the hill
climber can get stuck
at local local Maxima or local minimum
depending on whether we're trying to get
to the bottom of Hills or the top of
Hills so the third and final this is
starting to look like an evolutionary
algorithm that you're to implement is
the parallel hill climber drop a whole
bunch of parents at random places on the
fitness landscape and then execute the
hill climber algorithm in parallel at
all those points the parallel hill
climber is starting to look like an
evolutionary algorithm because at least
we're dealing with a population of
potential solutions to our problem
that's assignment
nine assignment 10 uh you're going to be
throwing away this minimal
thre link two joint robot that you've
been working with so far and instead
switch to a nine link eight joint robot
that's got a main body four upper legs
and low and four lower legs for pretty
much anything you're going to be
creating in the P bullet physics engine
whenever you have n links in this case
nine links you always have eight joints
n minus one joints right joints connect
pairs of links uh together okay as you
build the quadrip in assignment 10 I
highly recommend you draw it with pen
and paper or annotate on a tablet
however you do it I would suggest you
draw it out first get all the
coordinates the positions of all the
links and Joints straight in your head
you're going to be juggling a lot of
different absolute and relative
coordinates so if you're still shaking
on that concept go back and review when
and where to use absolute and relative
coordinates and I suggest do not add all
nine links and Joints at once it's a
little confusing add one link one joint
at a time make sure everything's working
as you expect it to add another link a
joint and on and on you go and at the
end of assignment 10 you will have a
relatively complicated robot with a
relatively complicated neural network
controller in it and a parallel hill
climber that's wrapped around the whole
thing that's going to search for neural
controllers for your quadruped to get it
to run along the virtual ground as
quickly as possible the end of the
beginning so far so good okay next week
for uh next week for The Graduate
students you're going to be going all
the way back to the beginning and doing
everything again but in a differentiable
simulator and I will say a few words
about differentiable simulation uh in
class uh Tuesday morning when we assign
the first of the 10 differentiable
assignments to the grad students but I'm
just going to speak very briefly about
differentiable simulation and we will
come back and talk about differentiable
simulation and differentiable robots at
the end of the
course okay little bit of orientation
any questions about any of that okay I
have not dropped a link to the first of
the 10 differentiable uh assignments yet
because I haven't written it yet I am
madly trying to run ahead of all of you
so it'll be ready by next Tuesday
morning okay all right uh if there's no
questions about that uh back to our
lecture material we're working our way
through not tools of the trade we're
working our way through uh this this
third segment of the course looking at
the admittedly brief history of
evolutionary robotics this particular
branch of Robotics only started in the
early 90s so we don't have to go back
back very far we were partway through
our discussion of actually the first two
experiments that were reported in the
literature back in the mid90s we'll
start we'll go back and start talking
about those in a moment we will finish
that discussion uh today and then we'll
start in on lecture eight where we're
going to take a little bit of a
digression and talk about a particular
kind of neural network that's that's the
nnn in CNN's CNS were invented in the
mid90s and they were used for some
minimal cognition experiments which
we'll probably talk about later this
week or into next week okay that's where
we are where we're going okay so back to
the mid90s and the uh early days the
very early days of evolutionary robotics
this was arguably the first reported
evolutionary robotics experiment where
as we saw last last time it involves
this little hockey puck side
Kea robot with two wheels just to remind
you it's got six proximity sensors on
the front two proximity sensors in the
back two motorized Wheels I just erased
it the motor the two motor neurons here
are sending desired angular velocities
to the wheels which can cause the wheels
to rotate backwards stay still or rotate
uh forward the six proximity sensors
they the proximity sensors will report
very low values if they see nothing in
front of them or something far off and
the each proximity sensor starts to fire
more strongly as that proximity sensor
approaches some object that that
proximity sensor is facing okay we ended
last time I ended last time by
challenging you to think up a fitness
function Fitness function we're going to
use five for our fitness function here
we're going to going to try and write
down a function here of these 10
variables some combination of these 10
variables and we want to write down a
function so that the Val whatever the
values of these 10 variables are the
function evaluates to zero or near zero
if the robot is doing the worst possible
thing and this Fitness function when fed
these 10 numbers should evaluate to a
number very close to one if this robot
is doing close to or very well at
whatever we want the robot to do which
in this case is to drive around and
around this track as quickly as
possible let's go what did you come up
with
um I'm assuming that one through six is
the first six sensors that are on the
front of the robot are on the back we
can assume that proximity sensors 1
through six are on the front and seven
and eight are on the back so you'd have
um
BL and
then have it
be have
multiplied by VR to make sure that
they're both going at like a sort of
equal distance for you to get one
and then VL should
be it should be like
having one two and three um subtracted
by four five and six to get like what
the true value of VL should be then have
the opposite for
VR or when you say one two three you're
talking about the proximity sensors now
yes okay let's hold off on the proximity
sensors for a moment this is a good
start let's incrementally build up this
Fitness function I want you to run this
in your head we don't have a Kea here so
we can't try it out so if we drop a
neural network controller into our Kea
here we drop in weights for all of these
synapses and the resulting wheels don't
rotate at all for example so VL and VR
are near zero the robot is staying still
and fi uh fi is is evaluating to a value
near zero so a pretty good start right
the wheels don't turn the robot isn't
moving it's not doing what we want and
the fitness function correctly says yes
this set of synaptic weights is not
causing the robot to do what we want
let's ass assuming VL and VR are both
spinning forward very quickly and the
robot takes off and starts driving in a
straight line it's a good start this is
going to evaluate to some value
maybe not one but at least above zero
it's doing the right thing what about
the left wheel spinning back and the
right wheel spinning forward and the
robot is turning
counterclockwise a negative value so not
quite what we wanted here but at least
we're in the right ballpark right higher
values more positive values are get G
are rewarding controllers that cause the
robot to move forward very quickly or or
both wheels turning backwards very
quickly nice idea to multiply these
together because if they're both
negative and the robot is
reversing there's nothing here that says
the robot can't drive backwards through
the maze that's okay that would also
give us a high value of five so pretty
good could you maybe divide it by V time
VR plus the summation of the proximity
sensors say that again you wanted to
divide it by something dividing it by V
VR so that way it's like always um so it
can't be above zero and then in the wait
so you want to put VL VR on the
denominator keep that as numerator but
divide it by the sum of that term plus
the summation of the proximity sensors
yeah then you're trying to um like
minimize the number of sensors that are
on at any given point so you're try not
to run into stuff okay so let's iterate
over all eight proximity sensors and
then just adding the V VR term that way
if you have none that it's not with
infinity okay all right
so J is going to iterate over 1 through
eight so this is the value of the jth
proximity sensor I was not a good choice
for proximity sensor but there you go
all right apologies for my notation here
so we're going to sum up all of these
and then you want to also add the
product again did you say that way if
like it wasn't if all those terms were
zero you're not dividing by
zero fair enough okay can you run this
Fitness function in your head we drop
some random set of synaptic weights onto
the Kea and let's imagine that the Kea
takes off in a straight line VL and VR
are both positive both wheels are
rotating forward so the robot starts to
move let's say this is forward hard to
tell from this grainy 1990s photo which
direction it's actually pointing in but
let's assume this is the front of the
robot and it starts driving forward as
it starts to drive forward what's
happening to the six proximity sensors
on the front of the robot maybe not all
eight but for the majority of the eight
proximity sensors what's
happening as it starts to move
forward the values are changing there
the values of these of the six on the
front changing changing
how we're getting closer to a wall
they're going to have higher vales
they're going to start to increase so
the value down here on the denominator
is starting to increase which which is
pulling the whole value of fi downward
which is good that's the intuition that
we
want go ahead like if you spin in a
circle in the Middle with no walls just
be one so if this spins if this spins in
a circle we've got one of the wheels
with a negative angular velocity and the
other wheel with a positive angular
velocity so they're canceling out right
well and then you put it over itself so
we've got zero on the numerator we've
got zero down here and it's spinning in
place so I don't know what the proximity
sensors are doing it's starting kind of
near this wall so maybe they're kind of
intermediate values kind of hard to
say I was saying what if it's near zero
you still have like the same number on
the top and bottom if the if the
proximity sensors are firing near zero
you're saying like if the proximity
sensors are near zero and then
blvr are
like not they're not moving the robot
around like moving enough that they're
not zero okay so you just have then it
would just be
one be like the best okay possibly maybe
instead of adding vvr in the body we
just add one because that would be the
maximum value of that that way it
wouldn't cancel out its signs
and okay maybe a little bit better if
you're not able to follow what kind of
behavior this is selecting for to run
this in your head that's okay the main
message I want I want you to take away
from our little discussion here this
morning is that it's not easy to
actually write down a fitness function
and give it to the evolutionary
algorithm this is arguably one of the
simplest evolutionary robotics
experiments we're going to see in this
course as we keep going things are going
to get more complicated we're going to
have robots with more Motors more
sensors we're going to want them to
exhibit more complex Behavior which
means there's more possibility of
perverse instantiation there's more ways
for this thing to do the wrong thing
right we started our discussion of the
Kea about thinking about this which
meant one perfectly valid solution is
this right so we got to multiply them to
guard against that particular kind of
perverse instantiation It's
Tricky okay here's what the here's what
the investigators of this experiment
came up with and we're going to walk our
way through this first thing to notice
about the fitness function is it's the
product of three terms one two three and
we're going to talk about these three
terms in turn let's start with the first
one uppercase V this first term is
actually a sum of the absolute
values of the velocities of the wheels
and remember that the wheels can take on
the the wheels can rotate at any
velocity in the range of
-.5 theta per second up to plus5 Theta
per second so by summing the absolute
values of these we gu we can guarantee
that this particular term ranges between
0 and
one as you all have already identified
if we had just I can't cover up this
term but if we had just plugged in v and
not these other
terms our robot is still vulnerable to
perverse
instantiation right this spinning in
place where one wheel is rotating at
minus5 and the other wheel is rotating
at at plus5 that would still max out
this particular term I don't know but
I'm guessing the researchers probably
did this and ran it on the robot and saw
as Evolution proceeded that the robot
evolved to spin in place faster and
faster that's my guess so they probably
went back to the maybe literally the
Whiteboard and multiplied it by one
minus the square root of Delta V so
here's what does Delta V do it takes the
difference between the magnitude of the
two
velocities we're going to see a lot of
double and triple negatives in Fitness
function so we've got to lean into this
here we go so what minimizes what what
values of VL and VR minimize Delta
v0.5 for both
um what values of VL and VR will
minimize Delta V here just Delta
V that's close together anything that's
close together right the the more
similar VL and VR are to each other the
smaller Delta V the smaller the Delta
between VL and
VR if we go back to this term forget the
square root for a moment they're taking
1 minus Delta
V what maximizes
V what maximizes one minus Delta V when
V and V when VL and VR are the same
again apologies lots of double negatives
here right so a neural a set of synaptic
weights some set of synaptic weights
dropped into the robot and the robot
starts be uh performing a set of
synaptic weights can maximize 1 minus
Delta V by getting both both Wheels to
turn uh as similarly as possible and
that same set of synaptic weights can
maximize
V if they're spinning backwards together
really fast or forward together really
fast so far so good um for just like
capital V is
zero pointing towards one talking about
like the limit or like the range of that
yeah yes I'm sorry again this is
probably not great notation this is me
just showing you what the range of this
particular term is yeah they they were
trying in this case to come up with a
fitness function that ranges between
zero and one it's maybe not strictly
necessary but just in this first
experiment they were trying to cross all
their te's and Dot all their eyes okay
all right what about why are they taking
the square root of Delta V this is kind
of a detail but may worth pointing
out giving you a very strong hint
here why didn't why didn't they just
create a second term that was one minus
Delta V why one minus the square root of
Delta
V trying to find like the diagonal
distance then you need to find the
square root of the two
variables and if
you're if you're moving on like a
two-dimensional plane then you need to
be Computing it in relation to like the
pyan distance uh not not quite so let's
have a look at the square root of Delta
V so let's put Delta V
along the horizontal axis let's imagine
that we're going to start the
evolutionary process we're going to
start dropping sets of random synaptic
weights into the robot most set of
random synaptic weights that you drop
into this robot are going to probably
cause it to fidget and move a little bit
but definitely not race around the track
so there's probably going to be small
differences in Delta V the wheels are
turning a little bit they're a little
bit different let's imagine we're
running the hill climber on the set of
synaptic weights so we have one set of
synaptic weights we drop it into the Kea
the Kea kind of Jiggles in place and
whatever else it does there's a
relatively small difference in the
angular velocity of the two
wheels the hill climber takes that
single Vector of synaptic weights makes
a copy of those synaptic weights to make
the child genotype
and when it copies the parent to create
the child it makes a slight change to
one or a couple of the synaptic weights
so now the child is all those child
synaptic weights we drop them into the
Kea and we evaluate the Kea second time
and it also kind of spasms and jiggles
around a little bit but maybe there's a
little bit uh a little bit more of a
difference between the speeds of the two
wheels so we've moved by chance from the
parent to the child to have a slightly
larger Delta V tell me about the square
root of Delta
V what happens as we start to move to
the
right and we have robots that are
exhibiting a greater difference between
the angular velocity of the left wheel
and the right
wheel
what does the square root function look
like so a child that exhibits slightly
more Delta V than the parent is going to
have a much larger value of the square
V and we're taking 1 minus This this
term is a punishment term one minus the
bigger this is is the smaller the closer
to zero this overall second term is so
the square root they added the square in
the square root in to exert greater
punishment on Delta V if Delta V starts
to creep up in children compared to
their parents everybody see that okay so
we're going to see a lot of Fitness
functions throughout this course and
that's why we're spending quite a bit of
time talking about this first one this
one has three terms in it these various
terms are rewarding or punishing for
certain aspects of the behavior this
term is rewarding for Speed turn the
wheels don't sit still this term is
punishing for turning right keep the
speed of the wheels as similar as
possible they added this extra square
root to extra punish for
turning it doesn't say in the paper if
you go back and read it but my guess is
when they started dropping sets of
synaptic weights onto this kepra and
watching One Behavior after another most
of those behaviors the robot was
probably doing a lot of this so they
went back I'm guessing and added square
root to root out get rid of that
behavior as quickly as possible they're
exerting more or stricter punishment for
doing more of a bad thing everybody see
that okay given that tell me about the
third term what is the third term is it
rewarding or punishing it's punishment
term for getting too close to walls it's
punishing for getting too close to walls
the the clue that it's a punishment is
it's one minus something so it's
probably trying to this term is probably
trying to minimize this something this
I it is punishing less yeah they did not
apply a square root to this okay
terrible termin uh notation here we've
got one minus I so let's go and have a
look at
I we won't actually write out the
equation for this but at every time step
that the that the Kea is running around
on the tabletop in this maze they look
at all eight of the proximity sensor
values and remember that the proximity
sensors can report a floating Point
number anywhere between zero and one so
they're looking at all of them and
they're looking for the highest number
among those eight proximity values at
that time step they hold on to that
maximum value the robot moves again a
little bit and they're recording all
these sensor values they look at the new
set of eight proximity values and if
there's a new value within that set of
eight that's even higher than the the
maximum recorded value so far they throw
away that value and hold on to that one
so among all eight proximity values over
the lifetime of this robot's Behavior
they're looking for the maximum value of
any proximity sensor why why did they do
that
why not just take the average because
the maximum value would be the one it's
closest to and so it's makes sense to
pay so you don't bump into the wall
closest to absolutely right so the robot
might actually stay still for quite a
while and then right towards the end of
the evaluation period it suddenly takes
over and hits the wall right if we took
the average of all the proximity sensors
over those let's say 10 seconds that we
evaluated the Kea the average value of
the proximity sensors would actually
maybe be pretty good right this robot is
only as good as its worst proximity
value what's the closest it ever gets to
a wall or potentially hits the wall so
generally speaking we're trying to
minimize the values of the proximity
sensors stay away from the
walls and go really fast and make sure
your wheels turn at as similar values as
possible multiply all those three
together and I'll show you the
experiments on the next slide but as you
can imagine with all of this leadup they
ran this experiment they kept dropping
sets of synaptic weights over and over
and over again into this little hockey
puck and eventually they started to get
sets of synaptic weights that yielded uh
motor motor and values which when
combined into fee started to produce
values of f fi closer and closer and
closer to
one what Behavior do you think was doing
that what was the robot actually
doing or getting better at doing as F
started to approach one over
evolutionary
time driving around pretty fast without
driving around pretty
fast in the Maze this is the mid90s
pre-youtube era so I'm afraid no Fancy
videos we'll see lots of fancy videos
later I promise here was their attempt
to show you what the best set of
synaptic weights did they ran their
evolutionary algorithm for almost three
days and at the end of those three days
they had a particular genotype that when
supplied to the robot produced this
Behavior what do looking at each one of
these little cross stitches is the
center of that short line segment is
representing where the robot is and the
angle of that little line segment is
indicating the direction that the robot
was pointing
in everybody see that and each one of
these little uh ticks is representing
changes in the position of the robot and
the position of its heading how did the
robot
do
did the robot do the best is this the
best it could have possibly
done maybe probably not you can sort of
see from some of the little wig Wiggles
and kinks in the trajectory that even
though we don't know what the optimal
solution is we can be pretty sure it's
not the best biological evolution and
evolutionary algorithms are satisficers
not optimizers we're never guaranteed to
get the best behavior we hope that for
most
applications really good or pretty good
is good
enough
questions okay all right so let's we
haven't really talked about the
evolutionary algorithm itself they uh
they didn't run a parallel hill climber
but it was something like a parallel
hill climber they had a population of
vectors they took each vector and
dropped those random synaptic weights
onto the Kea uh robot evaluated the Kea
for about 10 or 20 seconds somebody
reached in grabbed the Kea put it back
to the starting position in the Maze
somebody else on some desktop hit enter
which downloaded the next vector or set
of synaptic weights onto the Kea it ran
around for 20 seconds reset the Kea
download the next one the first
generation which contained a whole bunch
of sets of random synaptic weights took
40 minutes to
run after they had evaluated each
genotype each set of random synaptic
weights they applied fi to each of those
vectors and vectors that suffered a low
value of fi were deleted and those
vectors that enjoyed a high value of fi
produced randomly modified copies of
themselves and those new vectors were
again downloaded on the KRA and over and
over again for another 99 Generations
question yeah it's not specified here I
don't actually remember you'd have to go
back and look at the paper let let's say
a 100 I'm not quite sure right so 100
random vectors that means you got to
evaluate the physical Kea 100 times so
10 20 seconds of evaluation 100 times
plus half a minute or a minute to reset
the Kea press enter download blah blah
blah with mid 90s technology and all of
that added up to about 40 minutes of
real time in the real world no physics
engine here real time yeah okay they sat
there and did this for 66 hours not all
at once they took a break but it took
them a total of a little less than three
days to do one trial of an evolutionary
algorithm and they got this at the end
of three days of effort know
okay again I apologize for the quality
of these images what you should be able
to see and you might not be able to see
this from the back of the room is on the
horizontal axis here we have
evolutionary time here's generation zero
here and here's generation 100 over here
and on the vertical axis it says Fitness
but they're plotting five and remember
that fi in theory can range between zero
and one and if you squint very carefully
you'll see the top of the vertical axis
here
is.3 this lower curve here this is
averaging the value of fi for all the
individuals in the population at that
generation so among all the ra the
random neural network brains for the
robot in generation zero they cause the
robot to fidget and not move very much
or maybe bump into the wall and all of
them suffer to Value ofy very very close
to zero not surprising these are random
behaviors this upper curve reports the
best individual in the population at
that point in evolutionary time so among
all these sets of synaptic random
synaptic weights there was one vector
one set of random synaptic weights that
caused the robot to actually achieve a
value of five of about
.005 not great but better than the
average as evolutionary time proceded
that particular parent started to
produce children and children of those
children and so on and the
average behavior of all the sets of
synaptic weights in the population
started to rise over evolutionary time
and the best in the population also
started to get better until they reached
this particular set of synaptic weights
up here which achieved a
5.22 23 which produced this
Behavior a lot of effort for not a lot
of gain but this is the mid 90s and this
was one of the first
demonstrations of automated design of an
automated machine if you remember back
all the way to the beginning of the
course that's the long-term goal of
Robotics we want to create a machine
that is not remote controlled it's
deciding what to do based on its sensory
information and we don't want to
manually program an autonomous machine
because it's super hard so although this
is very humble and very simple and took
a long time to do this was a partly
automatic someone was still reaching in
and moving the Kea and hitting enter on
the desktop but getting there automated
design of an automated and an autonomous
machine so far so good okay all right
what do you see down here again I
apologize we've got the same horizontal
axis down here this is evolutionary time
over here the solid black line here the
solid black line is reporting the VA
value of uppercase V for the best
individual in the population uppercase V
is the total the angular velocity of the
wheels so we can see that the dotted
line Sorry the solid line started near
zero which means that even for the best
individual in the population the wheels
were turning just a tiny little bit very
very low angular velocity over
evolutionary time The evolutionary
algorithm started to discover discover
sets of synaptic weights that caused the
wheels to to turn
faster the uh dotted line represented
here this is reporting 1 minus the
square root of Delta V what's happening
to 1 minus Delta V square root of Delta
V over evolutionary time it's starting
to go down right remember this is a
punishment a punishment term we want to
punish this we're taking one minus this
which means we actually want one minus
the square root of Delta V to go up over
time but it's not it's bouncing around
quite a bit and then maybe it sort of
evens out at intermediate values what's
going
on the robot needs to turn to go around
the dra so there needs to be differences
if it's going to move around through
this track it by necessity has to
approach some of the walls s it can't
help it right the robot can't have its
cake and eat it too it's got to balance
uh displacement it's got to move and not
move in place and it's got to stay away
from the walls if you look at the solid
line and the dotted line This is
evolution trying to strike a balance
between what are called antagonistic
terms these two terms generally making
one term better through Evolution causes
the other one to be worse and vice versa
it's trying to strike a balance
yeah uh our ancestors as they were
evolving to walk around on our hind legs
we were trying to strike a balance
between staying upright not falling down
being able to move relatively quickly
with relatively little food in our
bellies and not lose a lot of children
to child
birth standing upright caused a lot of
evolutionary changes to the to the hip
structure of
hominids Evolution had to strike a very
very careful balance between figuring
out how to alter homonid physiology so
that we could walk upright in an energy
efficient manner not suffer unduly High
rates of child birth everything that
happens in evolution is always a
tradeoff between antagonistic pressures
yeah that is part of the reason why
biological evolution an evolu an
evolutionary algorithm is a satisficer
not an Optimizer you can't have your
cake and eat it too in the real
world okay dash line this one's a little
bit harder to uh interpret oh I'm sorry
I misspoke right we were talking about
the dotted line This is not staying away
from the walls this is
turning I I apologize I misspoke this
overall term here is punishing Delta big
V's but if you're going to move through
this maze you have to turn and when you
turn you experience an increased Delta V
one wheel has to turn faster than the
other I'm sorry I misspoke so it's still
striking a balance between the solid
line which is go fast and the dotted
line which is don't
turn then there is also the dash line
which is also trying to keep the robot
away from the walls and it can't do a
perfect job of that yeah it's a bit of a
juggling act here okay apologize I
misspoke okay this was their attempt to
try and draw to better show you how
evolution is moving through the fitness
landscape and striking a balance between
these three competing terms I'm not a
big fan of this plot so we're just going
to push on in the interest of time
okay so what they wanted to know was how
well did they actually do they put a lot
of Blood Sweat and Tears into actually
evolving this Behavior how good is
it they don't know they don't know what
the optimal is but the researchers sat
down and used a lot of brain power and
actually did try and write down weights
for all of these synapses that would
cause the robot to move through the maze
what did they do they created a brenberg
vehicle what kind of brenberg vehicle
would you want to put into this keera to
cause it to race around the maze but
stay away from the walls it would be a
coward with the wall coward with the w
walls yes so when the proximity sensors
on the front left were firing strongly
meaning the front left of the robot was
closed to a wall that should inhibit the
contralateral wheel so something is
approaching from the front left that
should cause the right wheel to slow
down relative to the left
wheel the left wheel is now spinning
faster than the right wheel the robot
should turn to its right away from that
obstacle on its front left and hopefully
if it points up and into the tunnel
uh into into the track there's less
stimulation of the six proximity sensors
on the front and it goes forward that
was the best they could come up with and
it does okay at driving around and
around the track but this particular the
brenberg vehicle has a
problem as it's racing around the track
if it ever starts to head directly into
one of the corners specifically this
corner it actually the robot slows down
and grinds to a halt you can see there's
a whole bunch of these cross- hatches
sitting on top of one another the robot
is facing into the corner and doing this
why it's getting inhibited on both sides
it's getting inhibited on both sides
right it's facing into the corner
there's slightly more proximity on the
left turn to the right now there's
slightly more proximity on the right
turn to the
left what they found is when they took
their evolved individual and pointed it
directly into a
corner it didn't have this problem it
would turn to its left and do a 180 and
start heading up the track their evolved
individual was better than a brenberg
vehicle it got stuck less often that's a
strong hint to what's going on among the
set of evolved weights
most of the time Evolution comes up with
a set of synaptic weights for our robot
and our robot does something and it's
very hard to have any insight into what
exactly those sets of synaptic weights
are in this simple example we actually
can gain a little of insight from the
nature of the behavior into what the
synaptic weights probably
are what's the hint here what can you I
haven't shown you the actual set of a
synaptic weights
know yep it doesn't do this jittering in
corner
know
counterwise at all times it's always
going to
PR that's true so that's a description
of behavior we're trying to go from
Behavior which in this case is just make
a 180 in when you're pointing directly
into a corner to the sets of synaptic
weights
so the weights have just evolved like
asymmetrically the weights have evolved
to be asymmetric whatever the sets of
synaptic weights are on one side of the
robot it's different from the sets of
synaptic weights on the other side of
the robot the the the the synapses here
have probably evolved a little bit of
asymmetry on
purpose if you're perfectly symmetric
like a brenberg vehicle that's not
necessarily A good thing an interesting
observation if you look around in nature
including the 2030 or so so hominids
that are in this room right now we
mostly look bilaterally symmetric the
left of you looks like the right side of
you for most purposes being bilaterally
symmetric is a good thing but there are
certain subtle situations where a little
bit of asymmetry is actually a good
thing and there are cases of that in
nature and here we see artificial
evolution rediscovering that fact that a
little bit of asymmetry is often is
sometimes a good thing do they try the
robot in like a
different great question if they did
they didn't report it in this paper it
probably did horribly and they were
probably exhausted after all of this and
figured they'd done their due diligence
write it up and submit it for
publication that I would agree who knows
they don't say okay any other questions
about this first evolutionary robotics
experiment before we move
on okay this experiment was conducted in
Switzerland in about
9394 at the same time on the other side
of the English Channel at the University
of Sussex in the UK this particular
experiment was being conducted so in the
history of the field it's usually these
two experiments which are pointed to as
the first ones which one came first as a
matter of of argument okay this robot it
looks very very different from the one
we just saw here we go this is has
become known since as the Gantry robot
for a very good reason it's a Gantry
these Sussex researchers took a table
and a saw and sawed out the actual table
to just leave uh the frame of the table
and then they set this large wheel
trolley on top of the of the table this
is known as the X trolley the wheel this
x trolley can move back and forth left
and right along the top of the
table on top of this x trolley they
placed a smaller y trolley that can that
with a wheel trolley that can move up
and down along the spine of the X
trolley so far so
good okay they then dangled again they
had a tether to a desktop no Wi-Fi in
the mid90s everything's going to run on
the desktop computer here they have a
tether and cable and that cable descends
and drops through the center of the
little y trolley and drops down below
the table and at the end of this tether
is a camera pointing straight down
towards the
ground this is a very crazily designed
robot so far so good
okay the camera is in here you can't
actually see the camera it's pointing
downwards it's not actually pointing at
the ground it's pointing at a little
circular Dental mirror this little ra
circular mirror this circular mirror is
attached to a little motor underneath
and this motor is spinning this Dental
mirror this design design is getting
Crazier by the minute so far so
good tell me about this little vertical
setup here it might sound a little bit
familiar we have something that's
pointing in a vertical Direction and
there's something that's spinning
allowing the robot to look actually
horizontally around itself under the
table aisc it's an inverted Periscope
right like on a submarine you send
something up and you look around this is
just the opposite something is pointing
downward under the table and looking
around at things placed on the floor
under the
table what was the point of this crazy
machine I did my Master's Degree at the
University of Sussex in 99 and at this
point the gantter robot had been
mothball that was 6 years old at this
point but it was still there and of
course all the students wanted to go
over and look at this machine which
should have ended up in a museum I don't
know what actually happened to the
Gantry robot why would serious Engineers
ever make such a crazy
machine as you can guess they're going
to start to drop sets of synaptic
weights onto this robot to control the
Gantry robot and the spinning motor to
cause it to do some desired behavior in
and among objects placed underneath the
table why did they set things up like
this any idea
Emily what's that drone of a drone okay
maybe this is long before drones ever
existed yep satellite like
GPS okay maybe they're trying to
prototype some bigger more serious
technology turns out that wasn't the
reason there was a actual Here and Now
practical reason for for setting things
up in this way seems
odd what's
that oh yeah yeah maybe this would again
approximate some sort of Rover moving
around is it so that you can just move
in X and Y without getting closer
getting closer to the answer something
in a factory a fixed area yeah okay so
don't think about actual applications
maybe this particular way of setting
things up no they they're about to run
an evolution algorithm on this
robot and they're try they set
everything up in a particular way to
make this easier in the back corner
find could be so we're proposing like
what kind of behavior they actually
evolved doesn't matter what the behavior
is why set things up in this way well
it's like it's as you said like Sol is
highly specific have like three
variables to actually play with uh three
variables right so there's the motor
controlling the the X trolley a motor
controlling the Y trolley and a motor
controlling the spinning Dental mirror
okay I'm really fishing here let's see
if I can get
it now we're getting a lot closer right
if you think about it with these two
trolleys moving around the cable
actually never rotates getting very
close to the right answer now they've
made their lives simpler they don't have
to go in and disentangle this cable the
Italian res Searchers back in
Switzerland they had to go in and
untangle the wire over and over and over
again they didn't have to reset
everything up there it
is drop a set of synaptic weights onto
the Gantry robot the X trolley the Y
trolley starts moving the dental mirror
starts moving they collect all the data
from this moving robot on the desktop
they have some Fitness function that
computes the value of that set of
synaptic weights they're done after
about 20 or 30 seconds of evaluating
that neural network controller they hit
one button on the desktop and everything
moves back and resets itself without
them having to touch the Gantry
robot the Sussex researchers were smart
they started to realize what they were
getting themselves into if they were
going to try and evolve behaviors for
this robot that's why they designed it
in this crazy
way okay
all right so we just uh we just talked
about the three motors something that
moves the X trolley back and forth a
second motor that drives the Y trolley
back and forth on the X uh uh the X
trolley the Y trolley on top of the X
trolley and a third motor in here that
spins the dental
mirror let's talk about the sensors now
we've got three motors in this
particular Gantry robot there are seven
sensors let's go through them you'll
notice there's one additional item
they've placed on the bottom of their
inverted pendulum which is just a little
plastic disc nothing fancy going on here
but as this inverted pendulum is moving
under inverted Periscope is moving
underneath the desk if that per inverted
Periscope ever bumps anything this
plastic disc will hit that object under
the table first and it will deflect
it'll rotate this whole thing and
there's a little sensor sitting in here
which is detecting the angle of
deflection of this plastic
disc I won't go into the details but
they basically take the result from that
sensor and they uh and they turn it into
four different binary sensor values was
the robot bumped from the front right
yes or no was the robot bumped from the
back right yes or no same so we got four
different sensors each of those sensors
at any given point in time when the
Gantry robot is moving those four sens
each of those four sensors is either
going to report zero or one so far so
good okay all right this is the tricky
part the fifth and sixth and seventh
sensor pay attention here we go
I mentioned that there are three motors
in the Gantry
robot in the in the evolutionary process
we're about to see the neural network
controller of the Gantry robot only is
able to control the first two Motors the
neural network controller is only going
to drive the two trolleys they're going
to set the third motor to a constant
angular velocity that motor is just
going to keep spinning
constantly doesn't matter what the
trolleys are doing which causes the
dental mirror to rotate around and
around at a constant velocity and the
camera is continuously recording
frames video frames of what is hitting
the dental mirror so far so good so
imagine you're in a submarine looking
through a periscope upwards and you keep
doing this imagine it's probably easier
to just take everything that is seen in
that 360 View and squash it into one
frame that's showing you a complete 360
Dee view so far so good that's what the
Gantry robot did every tenth of a second
the camera spun the dental mirror
through One 360 degree rotation every
tenth of a second and all and the
desktop computer actually stitched this
all together into one 360 degree
view so far so good okay this is mid90s
technology so they're getting a a huge
amount of pixel data every tenth of a
second it's too much information to feed
into a neural network controller at that
time so they added one additional detail
which is inside the set of vectors
inside the vector that encoded the
synaptic weight there were an additional
nine numbers that were tacked on to
every set of synaptic weights so we're
talking about the genotype now a
genotype for the Gantry robot
encoded uh weights of all the synapses
that connected the seven sensors to the
two Motors the motors that control the
two Gantry robots and nine additional
numbers what are those nine additional
numbers in code I want you to take those
nine numbers and break them into three
sets of three in your
mind each triplet of numbers specifies a
2d coordinate in this video frame so a
particular point in the frame and the
third number in the triplet indicates a
radius
so if we take those nine numbers and
turn them into a phenotype the phenotype
is three differently sized circles that
are dropped at three different positions
into the video
frame so far so good there's a lot of
seemingly odd details in the in this
experiment but trust me there's a
there's a reason for
this at the moment when you're looking
at me or you're looking at the slide or
you're looking down at the desk it feels
like you're getting a more or less maybe
not
360° but you're getting a pretty good
panoramic view of everything at the
front of this room right that's how it
feels at the
moment thinking about thinking is
misleading that is absolutely not what
you're actually getting at the back of
your eye you have a very small region on
which light is being focused so it might
not feel like it but most of the time
actually all of the time what you're
getting is this you're getting a very
focused small bit of your visual field
that's known as your fobia the focused
part of your eye that's what they're
simulated here simulating here but in
this case the researchers are allowing
Evolution to drop three fobia these
three circles all of the pixels in the
video frame that are outside side of
these three fobia that data is thrown
away so far so
good okay so we have these three circles
and for each circle at every every tenth
of a second for each new video frame the
there's some code that takes the value
of all of the pixels inside one of these
fobia and takes the average brightness
of the pixels in inside that phobia so
they're also throwing away color they're
throwing away detail shape lines
cross-hatching all the other detail that
might have been captured by these pixels
and
reducing uh everything that's inside
that single phobia to a single number
what's the average brightness of the
pixels inside that fobia so far so good
okay so for a given Snapshot from the
camera they're going to get back three
numbers from these three fobia the
average brightness inside of these three
fobia those are sensors six sorry five
six and
seven so it can like basically look
around with in its visual field it can
decide like what to look at H it can
decide actually it's the genotype that
decides the genotype contains a bunch of
synaptic weights and numbers so the
genotype is encoding where the phobia
are where your eyes actually are it's
not where your eyes are going to focus
in us we have one phobia which is at the
back of your eye who decided to place
our phobia at that particular place in
our eyes an evolutionary process for our
ancestors and luckily still for us it
makes sense to focus on the back of your
eye which means focusing on on exactly
what your eye is pointed at not
something up here right same idea here
they're going to evolve uh fosi focusing
points inside their visual field and the
Gantry robot is going to Evol is going
to uh ignore everything
else so this is a little confusing let's
try and put some of this stuff
together we've got these two trolleys
moving back and forth along the table
which means the inverted Periscope under
the table is moving about in
two-dimensional space but the Periscope
is not rotating so luckily the cable
doesn't get snarled the camera is
spinning the dental mirror it's taking a
picture throwing all of that spinning
and all that material away and at every
point in time it's just getting three
numbers what's the average brightness of
the pixels there there and and there at
every tenth of a
second a different genotype a different
brain for the robot with these sets of
synaptic whites might encode a different
placement and size of the three fobia so
Evolution can evolve the ability to look
at or focus on different parts of the
robot's visual
field again some of these details still
seem strange why they did
this we'll see why in a moment so far so
good Okay so we've got seven sensors
we've got two Motors how many total
synaptic weights does the genotype need
to
encode as always they're going to wire
up every sensor neuron to every motor
neuron how many
synapses 14 right so each of the seven
sensors has two outgoing synapses seven
time 2 is 14 in every genotype we've got
14 synaptic weights plus an additional
nine numbers that incode the fobia 14 +
9 is 23 in the genotype it's a vector of
23
numbers
okay all right here we go here's the
evolutionary algorithm they started uh
with a particular way of evolving these
set of 23 numbers they evolved the Gant
robot to do something simple and then
once it evolved the ability to do
something simple they changed the
fitness function to select for or evolve
for a more complicated more difficult
Behavior once the Gantry robot evolved
to do this more complicated task they
replaced that Fitness function with a
yet more difficult Fitness function
sound familiar
we've seen this before where did we see
this before scaffolding this is
scaffolding I showed you an example of
this right back at the beginning of the
course with the robot that was lifting
that Blue Block onto its back when it
evolved the ability to do that we made a
change which made things more difficult
in that experiment we changed the
environment in this experiment we're
going to change the fitness function
okay this first Fitness function what
they're going to do is they're going to
take those 23 weights download it onto
the Gantry robot and they're going to
want to see that the Gantry robot drives
towards the back wall from some random
initial position under the
table they're going to then send a
command that sends the gantu robot to
some other random position under the
table and they're going to evaluate that
same set of 23 numbers that same
genotype again so they're going to
assess the fitness of one genotype
multiple times and they're going to take
the average of the behavior of the
Gantry robot for that set of 14 synaptic
weights plus the nine numbers that
encode the three fobia and in this first
case they want to see that for random
positions the robot always drives
towards the back
wall they made this task a little bit
easier for the Gantry robot they placed
a big black
rectangle uh underneath the back to uh
um struts of the table so it's got
something to sort of look at and evolve
the ability to go towards go towards the
big black rectangle underneath the
table so far so good
okay it didn't take them long to evolve
a set of 23 numbers that when downloaded
onto the Gantry robot no matter where
the Gantry robot started it would always
drive the inverted Periscope to the back
wall not that difficult then once they
got that they continued evolving this
population of length 23 vectors but now
they changed the fitness function so
that every time they set the initial
position of the Gantry robot they placed
a black rectangle either a black
rectangle either at the back left of the
table or at the back right of the table
and the robot had to drive to the
rectangle not that difficult a little
bit more
difficult finally once the Gantry robot
evolved a set of 23 numbers that when th
when those 23 numbers were downloaded
onto the Gantry robot it would always
drive towards the back rectangle no
matter where it was placed uh underneath
the back part of the
table so far so good okay once they got
that they replaced that Fitness function
with another Fitness
function that uh the fitness function
that's selected for the following
Behavior the Gantry robot was set again
to some random position underneath the
table and they would place a a black
Square back left and a triangle back
right and the robot should drive away
from the rectangle and go to the
triangle then they'd reset the Gantry
robot to some random position and they'd
swap the positions of the rectangle and
the triangle now the triangle was placed
back left and the rectangle was placed
back right the robot should do the same
thing avoid the rectangle and drive to
triangle doesn't sound that difficult I
would normally go through the fitness
functions I'm not going to do that in
the interest of time because I want to
finish this lecture today have a have a
go at trying to come up with these three
Fitness functions this is optional
homework I want to end with this slide
today like we saw with the little Kea
robot racing around inside the maze
here's a
visualization of the best set of 23
numbers that the evolutionary algorithm
produced again after two or three days
of running on the Gantry robot so during
those three days The evolutionary
algorithm tried out hundreds or
thousands of genotypes on the Gantry
robot and it did the Gantry robot did
whatever those 23 numbers caused it to
do over and over and over again until
eventually they got a set of 23 numbers
or a genotype that caused the robot to
produce this phenotype this Behavior
okay how do we parse this figure we're
looking down from above through the
table in this case the rectangle has
been placed in the back left part of the
table the triangle has been placed at
the back
right they commanded the Gantry robot to
move to this random position in the
horizontal plane of the table the Gantry
robot starts to move like this describes
a 180 hits the front edge of the table
and starts to then move in this
direction and eventually ends up up
right in front of the triangle so far so
good same set of 23 numbers they kept
those 23 numbers they commanded the
Gantry robot to now move to this set of
initial to this initial position and in
this case the Gantry robot drove more or
less directly to the triangle they reset
the Gantry robot to a third random
initial position it did this they
commanded the Gantry robot to move to a
fourth and final initial position and
the Gantry robot moved with this crazy
cork screw behavior until eventually
straightening out and heading directly
to the
triangle it's not shown here but if they
swapped the shapes underneath the table
and evaluated the Gantry robot again
with that set of 23 numbers it would do
something like this but it would drive
directly to the back left part of the
table and stop directly in front of the
triangle so far so good okay we got
three minutes left perfect here we go so
it looks like when we're looking at the
behavior of this Gantry robot then it
can now distinguish between triangles
and rectangles again it's not going to
win any Nobel Prize for this not the
most difficult task to perform but
presumably this robot can distinguish
between triangles and rectangles yeah
how how does it distinguish between
triangles and rectangles deep breath
let's go and plunge into the brain of
this gantter robot and see if we can
figure out how it's doing
it it turns out that the genotype that
produces this Behavior actually doesn't
use the third phobia it actually makes
the radius of that phobia Zero The
evolutionary algorithm is kind of
showing off it says I don't even need
three phobia I just need this one and
this
one it also says I don't need the bump
sensors because there's nothing for me
to bump into there's nothing underneath
the table so what happens is although
there are seven po there are seven
sensor neurons only two of the seven
sensor neurons have synapses that
connect from those sensor neurons
eventually on
to uh eventually on to the two Motors
there's actually three outputs here
we'll just ignore this detail for now so
the EV the this particular genome is O
only using two of the seven sensors to
drive the behavior of the Gantry robot
so far so
good
okay where is the recognized triangle
neural component in here where is the
recognize rectangle neural component
oent in
here I see some of you shaking your
heads good I I know I repeat myself
thinking about thinking is misleading
this robot can clearly distinguish
between triangles and rectangles it has
no recognized triangle component and
recognize rectangle
component as uh you you might see that
there are synapses that are pointing
from the left to the right that are
sending sensory information down to the
motors but there are also some self and
recurrent connections what do recurrent
connections do in a neural
network build memory they provide memory
this Gantry robot can remember things
okay let's have a look at these two
phobia as the robot is moving around and
describing a curved trajectory these two
phobia come and they hit the left side
side of the black rectangle as they hit
it the top left fobia goes dark and then
as the robot is driving in this curved
trajectory a short time later this
phobia goes
dark everybody see that so if I'm
looking just through these two fobia and
I there's a black rectangle on the wall
back there this one goes dark and now
this one goes dark or better yet this
one goes dark then this one goes dark
that's what the Gantry robot is
seeing as it continues moving these
fobia sweep over this triangle as well
this one this phobia goes
dark then this phobia goes dark how does
the robot distinguish between triangles
and rectangles there's a difference in
like how
long there's a difference in the timing
between fobia one going dark and phobia
2 going dark we're going to end today
with arguably my favorite slide in the
entire course this is embodied cognition
this thing can distinguish between
objects and its environment and the way
in which it distinguishes is a function
of how it moves what it sees what it
thinks what it remembers it's combining
space time movement sensation action in
a particular way that allows it to
recognize distinguish between objects
with a tiny tiny tiny brain there are 10
12 synapses here easy peasy a computer
Graphics algorithm or a deep neural
network can also distinguish between
triangles and rectangles with way more
synapses and more mental effort embodied
cognition wins you have a quiz due
tonight undergraduates you're working On
Assignment five grads you're working on
9 and 10 see you Thursday
morning


--- Evolutionary Robotics course. Lecture 10： Continuous Time Recurrent Neural Networks (CTRNNs).en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everybody thanks for
breathing the cold this morning um let's
dive right back in just a reminder about
uh assignments undergrads you're working
on adding Motors to your robot in
assignment five grad students you're
completing the ninth and then the final
assignment uh in the original round of
assignments and then as promised next
Tuesday Morning graduate students who
will start in on the first of the
different enable robotics design uh
assignments and I will talk briefly
about what those are on Tuesday question
are your office hours be on
Monday what's on what's happening on
Monday I can never keep
track president stay uh yes I believe I
will be available I may not be here it
may be remote but I'll make a note yes
to office hours uh on Monday my
apologies to US
presidents okay
any other
questions all good okay so uh just to
reorient you as to where we are in the
lecture material we finished lecture
seven last time hopefully for you on a
high note where we looked at this
particular evolved neural network that
is able to distinguish between triangles
and rectangles with no triangle detector
no rectangle detector detectable in
inside the neural network the way in
which it's able to exhibit this
particular building block of
intelligence which is being able to
distinguish certain things from others
is a function of the way this thing
moves its interaction with the
environment its ability to remember past
sensation timing space you name it it
all brings it together in order to solve
the problem we cannot
localize this particular building block
of intelligence which is categorization
to anywhere inside the brain or the body
of the robot this slide if you forget
what embodied cognition is all about
bookmark this slide and come back to it
as we go okay any questions about any of
that from last time okay so that
finished uh our introduction of the
first two assignments uh the first two
assignments the first two experiments
that kicked off the field of
evolutionary robotics in the '90s
uh we're now going to dive into lectures
eight and nine where we're going to look
at a series of minimal cognition
experiments these also took place at the
beginning uh of the
field and the idea behind the minimal
cognition experiments was to strip away
as much of the complexity of the robot's
body its brain and its environment as
possible so that we'd have a minimal
environment minimal robot minimal robot
brain and in sec sequence investigate or
evolve into that robot various building
blocks of
intelligence you might remember from
lecture two in our history of AI decades
were spent and are still being spent
trying to Define what intelligence is is
chat GPT intelligent or not I don't know
it depends on your definition of
intelligence so as you'll see in the
minimal cognition experiments a
different tack is taken in the attempt
to try and create intelligent machines
it which is to identify certain features
of intelligent Behavior or certain
features of behavior that you would
expect to see in an intelligent machine
regardless of whether that's a
biological machine or a technological
machine what do you think some of those
building blocks of intelligence might
be we just mention mentioned one of them
for the Gantry robot which is
categorization tell triangles from
rectangles friend from fo food from
poison um potential mate from aggressor
so on and so forth if you want to
survive in this world you need to be
able to distinguish between A and B
that's a building block of intelligence
some equivalent ability to act in the
world to push on the world okay so to
act on the world and observe how it
pushes back so that would include all
the brenberg vehicles yeah that's
probably a building block of
intelligence would be a little bit more
specific
you're all intelligent machines you can
categorize what else sorry commun
communication great we're not going to
see that in the minimal cognition
experiments but we are going to see it
when we get to uh Collective robotics
but absolutely being able to communicate
with your peers other potential building
intelligence able react to your envir
being able to react to your environment
see what's coming in and decide what to
do
planning planning being able to think
ahead a really important Hallmark of
intelligence is not getting trapped in a
corner in the future to keep your
options open right a building block of
intelligence that that's the idea we're
going to see we may or may not get to
lecture nine today in the minimal
cognition experiments we're going to see
the evolution of very very simple robots
that are able to exhibit more and more
of these building blocks of int Ence at
which point you want to point to that
evolved robot and say now it's
intelligent now it's thinking now it
understands now it has free will now it
has Consciousness that's up to you we're
going to approach approach this in a
very operational way the robot should be
able to behave in this way and that way
and that way and that way and so on yeah
okay before we get there however in the
minimal cognition experiments all of the
robots in the minimal cognition
experiments use a particular kind of
neural Neal network controller which is
known as a ctrnn so we're going to spend
some time this morning looking at this
particular type of neural network and as
you'll see when we talk about CTI and NS
CTI and NS make it easier for The
evolutionary algorithm to evolve
intelligent building blocks for the
robots the neural networks that we've
been talking about so far are very very
very simple they go back to our brenberg
vehicles we have circles representing uh
biological neurons and our arrows are
representing biological synapses we
figure out how to wire up the sensor
neurons to the motor neurons we might
throw some hidden neurons in the middle
once we wired everything up we need one
number for each
synapse which is the weight of influence
that that press synaptic neuron has on
that post synaptic neuron and then we
also need an activation function for our
uh are hidden and motor neurons because
the raw sum arriving at that neuron may
be outside some bound and our activation
function is going to squash that value
back to some range and then possibly
pass that value on as you can imagine
this is a gross simplification of how
actual biological neurons and synapses
work so within Robotics and Ai and
computational Neuroscience there is a a
very large community
Community that's interested in creating
a more accurate model of biological
neural networks and then investigating
whether and how that additional
biological detail makes it easier for us
to make intelligent machines we're going
to do a little bit of that in lectures
eight and nine we're going to look at
CER and NS which include some additional
biological details into these neural
networks and then we're going to see in
in lecture 9 how that makes it easier
for The evolutionary algorithm to evolve
intelligent behavior for robots
controlled by cnns sound good okay
that's our preview for what we're doing
in the next two lectures all right here
we
go uh cnns stands for continuous time
recurrent neural networks and we're
going to tackle each noun and adjective
in this name as we go in order to do so
we're going to need to do a little bit
of calculus deep breath this is the only
place in the course for the
undergraduates where you're going to
have to do a little bit of calculus for
The Graduate students that are going to
be tackling the differentiable robot
design you're going to see calculus uh
again we're not going to do too much
calculus so just to remember what
calculus actually is turns out for a lot
of branches of science and engineering
and for robotics we often want to be
able to describe how how a particular
variable changes as a function of
another variable here's arguably the
simplest experiment example of this
we've got one variable here x and we've
got one variable y here and as you can
see from this line here as X changes I
changes in exactly the same way right
this is Y equals X in calculus what we
often want to do is describe at a
particular point for this variable we
want to be able to explain how Y is
changing at exactly that point so what
is the delta in y as the Delta of X
becomes smaller and smaller and smaller
and hopefully this is reminding you of
your first year Calculus class where it
gets exceedingly difficult until it
becomes infinitely difficult when Delta
X becomes zero so way back in the day uh
some folks invented this idea of
calculus which is a way to describe
instantaneous change of one variable y
as a function of X and that's what's
written down here and my apologies I've
switched from variables X and Y to x and
t this is a little bit confusing so I
should really update this slide on the
horizontal axis here we're going to
assume that the variable we're
interested in is T for time we're going
to see in continuous time recurrent
neural networks how the values of
neurons change as a function of
time so we've got T on the horizontal
axis here and X on the horizontal axis
here and DX overt tells us that we're
going to write down on the right hand
side of this equal sign how X changes
where X is going to be in a moment X is
going to be the value of the neuron how
does the value of the neuron change as a
function of time in my super cartoony
example here DX over TT equals
1 this is a differentiable sorry a
differential equation we're going to see
a bunch of differential equations this
morning what you're doing at the moment
in your neural networks if you've gotten
that that far is actually to use
difference equations we write the value
of a neuron at a new time Step at time t
+ one as a function of the old value of
the neuron plus some other
stuff we can try and write down how this
function changes as a function of sorry
how this variable changes as a function
of this variable we can try and write it
down as a difference equation where
we've got discrete time steps which is
what we usually have in a physics engine
or we can write down how this variable
changes as a function of this one in a
continuous manner using a different
differential
equation okay the rate of change of X
what this equation says is the rate of
change in X is equal to the rate of
change of
T familiar to everybody so far so good
all right okay okay so the con CER and
NS The Continuous time is because we're
going to write down and describe the
behavior of these neurons not in
discreet time we're going to write down
down the behavior of these neurons as
differential equations so we're going to
describe and simulate the behavior of
these neurons in continuous time that's
the CT and C CTR rnns what about the
recurrent part this should be familiar
we've already talked about recurrence in
neural
networks that
connect they are yes so we have we're
going to have in curn ends as we'll see
in a moment recurrent synapses that can
connect from the output back to the
input or from the output back to the
hidden they're kind of flowing instead
of flowing from Sensation to Motors and
actions they flow backwards which
creates a loop and allows the robot to
hold on and reme or allows the neural
network to hold on and remember
stuff okay okay so in a in a CNN we are
going to write down a set of ordinary
differential equations where we if we
have a set of K ordinary differential
equations those represent the behaviors
of the K neurons inside the
ctrnn if we have a ctrn with 28 neurons
we're going to write down a set of 28
ordinary differential equations so
things are already getting more
complicated compared to the traditional
neural networks you're familiar
with okay you see a big red box here I I
highly encourage you to write down these
equations as we go as you all know if
you just sit and stare at equations they
don't soak in so I invite you to write
along with me as we build out one of
these differential equations uh as
you'll see I've spaced out where to add
the terms because we're going to add
detail to this differential equation as
we go so leave space as you annotate
this okay so let's start with the left
hand side of the equal sign we've got y
sub I prime so the prime is just going
to remind this is shorthand for dy over
DT so we're going to describe and I'm
sorry I keep switching back and forth
between variable
names typically Y is used in all the
papers that describe
cnns y sub I is going to represent the
value of the I neuron in the
ctrnn we're I'm not going to have you
write down 28 differential equations
it's a waste of time so we're just going
to write down y sub I to REM to remind
us that this particular differential
equation that we're going to build up is
the differentiable uh the differential
equation describing the behavior of the
ith neuron in the
ctrnn okay all right let's start by
placing minus y subi to the right of
this differential differential
equation why would we add this
particular term does anybody have any
Neuroscience experiment this particular
term is
representing a particular behavior of
biological
neurons anybody see yet what it
is Nate simulate
spiking uh good question question so you
mentioned spiking so for those that are
not familiar with the behavior of
neurons they tend to emit a spike or a
pulse of electricity and then they go
quiet again and it's often the the uh
the distance or the bunching up of these
spikes that is representing the
information that one neuron is sending
to another CNS are not simulating that
particular detail of neurons there are
other neural Network models that do
represent spiking this is not one of
them is it like a w or uh not
quite
Emily okay like damping ah damping we're
getting close okay let's actually try
and draw a geometric representation of
what this differenti differentiable this
differential equation is doing as you
may remember when you're going to
simulate or integrate a differential
equation you need to give it an initial
value so let's imagine we have a single
neuron in our CNN and so we've got the
value of this neuron at the beginning of
us simulating this neuron we need to set
it to some value we can imagine that
this single neuron is sitting inside of
a brenberg vehicle and it's connected to
a sensor and that sensor is supplying a
value of plus one let's say just
hypothetically so the neuron is
receiving a value of one and then this
differential equation is going to
describe how the value of this neuron
changes assuming it doesn't receive any
more input this is just a hypothetical
situation if the current value
of the neuron is Plus 1 at t equal 0
what happens as time starts to move
forward what happens as dy over DT D
starts to increase if our differential
equation is saying the rate of change of
Y with respect to T is decreasing as a
function of the current value of y what
starts happening approaches zero it
approaches zero so if we move some
arbitrary distance forward and remember
our differential equation is operating
in continuous time so we can just pick
some arbitrary point in time as T
increases the rate of change of Y
decreases as a function of this so we
can take this value of plus one and plug
it in here and say the rate of change at
this moment is minus one so the value
starts to decrease let's imagine that
this particular point in time the new
value of the neuron
is8 tell me about the new value of the
neuron as we continue to move forward in
time now it's like decreasing something
less it's decreasing at a lower rate
right y Prime equals
minus8 the rate of decrease was one now
the rate of decrease is minus 8 so now
it's maybe
7 7 and as Nate says if we keep going
the neuron will start to approach a
value of zero we plug in a value of one
we excite the neuron with a value of one
and then we stop exciting the neuron and
what does the neuron do it relaxes back
to zero what feature of neurons are we
simulating by adding this term to our
equation
is it inhibition it's not quite
inhibition so we don't have any we don't
have neurons connected together yet in
our hypothetical CN we have one neuron
no synapses so nothing's inhibiting
anything else we just have this single
neuron let's try another example let's
take the exact same cin n one neuron
which is being simulated by this
differential equation and now we assume
that at a particular point in time it
receives a value of minus one some
sensor that this neuron is connected to
sends a signal of minus one and then the
sensor shuts off the neuron doesn't get
any more external stimulation what does
this what does the neurons start to do
now as we run forward in time from this
event again absolutely so so it's minus1
the rate of change uh the rate of change
of Y is equal to
minus minus1 the current value of y so
the rate of change at this moment in
time is plus
one so in a short time later we've got a
value of
minus8 at this moment in time we plug
that value of y sub I in and we get the
rate of change of Y is equal to minus
minus8 so the rate of change of Y at
this moment in time is Plus 8 it's
increasing by a slightly lesser amount
and this neuron starts to approach zero
what about this initial value or this
initial value or this this this this
this this what happens in all of these
cases they all go towards
zero this is rep uh Emily yes
uh resting membrane potential the the
first adjective is right the resting one
of the things that neurons are above all
else is
lazy given the fact that nothing else is
going on they will slowly relax back to
resting potential or using as little
oxygen as possible your brain is about
2% of your total mass but it uses up 20
20% of all the oxygen you breathe and
everything you eat brains are massive
energy Hogs it makes very good sense for
neurons when they're quote unquote not
needed for anything to relax back to a
low energy State that's what this
particular term in the differential
equation is
doing as we continue to go through and
add material add bi add mathematical
detail to how these neurons are behaving
we're adding in additional biological
details of how actual biological neurons
work so far so good so everyone can see
the correspondence between this equation
and our simulation of how this neuron
behaves okay all right let's add in an
additional
detail a neuron that will just relax to
zero uh if it's not stimulated never
useful for
anything we're going to add in an
additional term here which is a time
constant so this is to subi the subi is
there to remind us that we actually have
K ordinary differential equations for
each of the K neurons in the CTI andn so
each neuron has its own time constant
it's called a constant because it means
that throughout the simulation of the
ctrnn this value is not changing we're
going to set it y changes as we simulate
a neuron but the time constant does not
is that like a parameter you set before
it's a parameter not you set as you
might Guess The evolutionary algorithm
is going to start setting these
parameters so as we build up this
ordinary differential equation there's
going to be a mixture of variables which
are the things that are simulated and
change over time and a set of parameters
which The evolutionary algorithm is
going to try and set it's going to try
and find good settings for these
parameters to get the robot that's
equipped with that CNN to do whatever it
is we want the robot to do like we've
seen before so far so good okay you may
or may not have seen this before um this
is putting obviously a parameter on the
left hand side of a differential
equation usually we put everything on
the right hand side um we could do that
by dividing both sides of the O the
differential equation by T sub I and now
we've got a right minus y subi divided
by too not only are these neurons lazy
but the people that created cnns are
lazy and didn't want to bother writing
out everything as a fraction so they
just put it on the left hand side so
everything fits nicely on one line this
is just kind of a notation thing yeah if
you feel uncomfortable about looking at
this with stuff on the left hand side
you can mentally divide both sides by
tal
subi okay let's imagine let's keep
things simple let's assume that our time
constants are going to be positive
values we can set them to anything
.001 we can set them to 10 to the 8
anything any floating point value that's
a positive
number what does a neuron with a low
time constant do let's assume that the
time constant is set to something very
very close to zero
.001 how does that neuron behave comp
compared to this
neuron
it
longer more quickly approaches zero okay
one of those two statements is correct
we still have minus y sub I so this
thing is still lazy if it's not being
stimulated it whatever its value is
it'll gradually Decay back to zero to
rest with the low time constant does it
approach that asmode quick
or
slowly
thinker correct so let's go through this
we're setting talsa by let's set it
equal
to
0.01 all right just so you fix a number
in your
head multiply both sides of the ordinary
differential equation by
001 and we've got y Prime = - y /
001 so suddenly EV everything that we
compute on the right hand side tends to
be a very very big number which means
the rate of
change is Big right so if we go back to
our example of setting a value of y to
one and then not stimulating that neuron
anymore we've got on the right hand side
minus 1 divided
001 and we've got a huge negative number
right the slope at this point is now
very precipitous it's dropping so boom
down goes the value of the neuron to
0.02 now we want to keep simulating the
behavior of this neuron As Time
increases so we plug in on the right
hand side minus. 2 /
.001
boom what's
happened absolutely so we've overshot by
let's say minus
0.1 we've overshot now what
happens it goes up if we plug in uh
minus minus1 on the right hand side we
have plus 0.1 divided plus
0.01 we've got a precipitous increase
what does this particular neuron
do absolutely it's still asically
approaching zero it's still trying to
get to rest but it's continuously
overshooting and oscillating this is
known as the Woody
Allen neuron it's neurotic any little
stimulation and it goes absolutely
bananas it's depressed it's super
related it's all over the place it's
very very
sensitive you you can do this hopefully
now in your head you can simulate this
same Woody Allen neuron Now with an
initial value of minus 01 what does it
do same thing it's all over the place
okay let's imagine a different uh neuron
where everything's exactly the same
we're going to set its initial value to
plus one now we're going to set a very
high time
constant 10 to the 8 let's
say what is this neuron do if its
initial value is plus one
approaches very very slowly it
approaches very
slowly we plug in plus one on the right
hand side so we have minus + 1
-.1 / 10 8 is
-001 a slope like
this if we start with a value of minus1
what is the neuron with a very high time
constant
du same thing
right very very slowly approaching
rest everybody remember Eeyore from
Winnie the Poo very chill individual
very happy to just not do anything you
can prod Eeyore with immense strength
and it'll take quite a bit to get Eeyore
moving and even when Eeyore starts
moving he doesn't move very quickly yeah
very very resistant to external
perturbation yeah okay let's keep going
oh I forgot to mention we've added this
time constant this is also true of
different uh neurons in your brain
certain neur neurons are very sensitive
and they will start emitting spikes with
the the least provation they're very
very sensitive and they will react to
the the smallest provocation there are
other eore neurons in various parts of
your brain and spinal cord that take
quite a bit of external electrical
stimulation in order to start emitting
spikes so again as we go we're adding
biological detail here so far so good
okay let's keep going this part
hopefully looks somewhat familiar to you
we are now adding to the right hand side
of our ordinary differential equation a
summation
term as we compute the value of the ith
neuron at any point in time we are
visiting plus uh uppercase n uh other
neurons in the CNN and pulling out their
values and multiplying their values by
the weight that connects that neuron the
jth neuron to I the neurons value that
we're currently
Computing okay so again we have a whole
bunch of Odes ordinary differential
equations in our set here that are
simulating all these other neurons so as
we move forward we're going to assume
now in our hypothetical ctrnn that we
don't have just one neuron we have
uppercase n neurons and we have
uppercase n differential equations we're
just looking at one of them so far so
good okay here's where the recurrent
part of cnns comes in you'll notice that
as we iterate from one to uppercase n
we're not skipping over any values in
the uppercase n neurons which means as
we're Computing the summation at some
point as J is increasing from one to
uppercase n J hits I it's the neuron is
taking its own value and multiplying its
own value by the weight that connects it
to itself there's a particular type of
recurrent connection which is a self
connection Okay so we've been drawing
we've been drawing uh neural networks so
far in a layered Manner and this is
typically how neural networks are drawn
in our case for robotics we have a a
sensor a set of sensor neurons then we
have a bunch of hidden neurons and then
we have a bunch of motor neurons um as
you'll see if you look at any of the
Publications about CN ns cnns are not
drawn in that way the neurons are
arranged in a
circle and every neuron is connected by
a synapse to every other
neuron including
itself okay so in my cartoon example
here we've got uppercase n equals 6
neurons how many synapses do we
have we've got six neurons we've got six
differential equations we've got six
time constants one time constant for
each if this is one 2 3 four five six
neurons we've got T sub one t sub 2
maybe this is a Woody Allen neuron maybe
this is an eore neuron maybe this one
has some intermediate time constant
which means it's not too sensitive not
too uh not too
fmatic how many synapses do we
have 36 36 right so they're all
contained in let's say a matrix a 6x6
Matrix so so far if we were to deploy
this neural network into a robot The
evolutionary algorithm needs a genotype
that contains 36 numbers the 36 weights
plus the six towel constants The
evolutionary algorithm can tune the
reactivity of the neurons and how the
neurons influence one another so far so
good we'll keep things simple and assume
that time constants are positive numbers
and weights can be negative
or positive numbers negative weights as
you'll remember create inhibitory
connections and positive synaptic
weights create excitatory connections so
far so good okay here's something that
again hopefully is familiar we're adding
our activation function which squashes
the value of a neuron to some range in C
tier and NS the activation function
that's usually used is hyperbolic
tangent which will take any values and
squash them to a value between minus one
and one for our purposes it doesn't
really matter what this particular
activation function is what is of
interest to us is you'll notice that the
activation function is placed in an odd
place in the
equation it's kind of inside this
summation term anybody have any
intuition for why they're putting it
there when ites from neurons
ising that is true yeah that is a true
detail of biological neural
networks that that doesn't dictate why
they're putting the activation function
in
here so I guess the alternative to that
be to apply it whenever you're
calculating the value of the neuron
which means all the intermediate values
are going to be in that fix range yeah
so by not doing that you're allowing the
neuron values to stay in a broad range
you only normalize them when you're
combining them that's it exactly so by
putting it by putting the activation
function in here inside the neuron
itself if we were to look inside the
value of that neuron can range greatly
but the moment we read sorry let's add a
connection going from this neuron to
this neuron the moment we read out the
value of the JF neuron the minute we
read out that value because we're going
to take the value of that neuron and
multiply it by the weight for it to
influence the eyth neuron the moment we
read out that value at that moment of
readout bang that's when we apply the
activation function so that the value
that's coming out of here is always
guaranteed to be a value between minus1
and + one all these other pieces that
simulate the behavior of the neuron
might cause that neuron to take on very
high magnitude negative numbers or very
high magnitude positive numbers no
problem fine whatever the neuron does
behind closed doors that's fine when we
need it to influence something Beyond
its own borders then we squash it that's
why the activation function is put in
here so far so
good
okay in the ctrnn we have yet another uh
parameter associated with each neuron
which is G the gain of the neuron if we
have six neurons and six differential
equations we have six G's the gain for
each neuron you can see that the gain is
placed right inside this activation
function right next to the raw internal
value of the
neuron what is the gain parameter doing
the very name of this parameter kind of
is a very strong
hint just a straight multiplier it's a
straight multiplier that's what this
equation is telling us but what is that
multiplication
representing
conne uh you said a strengthened
connection between the neuron it's not
actually the gain is not being applied
to W which is the connection between
Pairs of neurons the gain is being
applied directly to the neurons
value what is this representing like how
well the neuron consense how well the
neuron consense it's not in the incoming
value of the neuron we have the value
the raw internal value of the neuron and
then we're multiplying it by G and again
we're going to add all these G's to the
genotype of an evolutionary algorithm
that's going to be evolving the behavior
of these neurons is it the strength of
the signal strength of the signal it's
literally the gain imagine a neuron that
has a g of zero what is that due to the
neuron is it a constant or do it's uh
it's not a constant it's a parameter so
but it stays constant throughout the
simulation of the neuron just like the
time constant as well sorry this yeah
this's a little bit of confusion about
terminology it stays constant during the
simulation of the neural network but
over evolutionary time Evolution might
change G's and
tals great question what's the
difference between
gain and synaptic weight
here the gain is like quiet neurons
verus loud neurons and the wave is how
much each neur listening to the other a
absolutely so let's go through this
let's imagine let's go back to assuming
we're looking at a particular neuron in
the CNN and this neuron has a gain of
zero it's also connected to all the
other neurons
if this neuron has a gain of zero what
does that
meaning it you're you're just it's gone
it's as if it's not there a gain of zero
is literally silencing that neuron it
doesn't matter how strong the weights of
connection are this is the difference
this neuron might be wired up to this
other one with a very strong weight of
influence but this neuron can just it's
muffled it can never speak anytime
anyone asks for a value of y subj if
we're Computing the value of the ith
neuron and we're Computing the right
hand side of this differential equation
and we get to the jth neuron we're
multiplying it by zero it's as if it's
not there yeah so as someone was just
saying gain is like the volume if
evolution over evolutionary time is
altering the G's of the neurons it's
changing the volume of these neurons it
can turn down the volume or the gain of
some of these neurons to zero and in
essence remove them from influencing
anything else it can also increase gain
and make that neuron very loud even with
very
small uh even with very small influences
if this neuron is very loud it's going
to tend to increase its influence on
everybody
else now Evolution could set all of the
outgoing could set all of the outgoing
synapses of a particular neuron to zero
and that would be another way to shut up
the
neuron but Evolution's got to come up
with mutations that bring all of these
to zero the gains are basically like uh
giving the evolutionary algorithm a
shortcut if for whatever reason it's
useful for evolution to turn off or
silence or alternatively to turn up the
volume or the overall influence of
particular neurons it's easier for
evolution to do it because it just needs
to change one number the gain for that
neuron as opposed to changing uppercase
n numbers the weights of all of the
uppercase n outgoing synapses from that
neuron so far so
good okay almost almost done
Theta subj we're going to throw in
another six numbers we're going to throw
in a Theta for each neuron in the
equation what is bias do what does high
bias do what does low bias
do could beely is it
basically it absolutely is so different
value bias represents the fact that
biological neurons have different
resting potential so when we started
draw way back drawing the behavior of Y
we were seeing the value of the neuron
always dropping back to a resting value
of zero that's not true in practice
different bio different neurons in your
brain and your spinal cord if they're
not being influenced by things from
outside they will drop back to a certain
rate of emitting spikes or basically a a
rate of activity which is actually not
so restful for the neuron it's got to
burn oxygen in order to do that for
whatever reason that seems to be a
useful thing in biological machines it
makes sense for different neurons if
they're not being stimulated to start to
rest at different positive values or
different negative
values for whatever reason my
understanding and reading of the neuro
uh biology literature is still not quite
known why that's the case but it is so
they threw it
in okay let's just take a breath to
review everything we've seen here we've
got variables in this equation which are
all the Y's these are all our variables
we have a fixed function the activation
function and then we've got a whole
bunch of parameters TOS W's G's and
fetas if we have a CNN with six neurons
and they six ordinary differential
equations what is the length of a
genotype that encodes values for all of
these
parameters little bit of arithmetic this
morning we're checking our intuition
that we understand how all these pieces
fit
together how many towels do we
have six we got six tows how many W's do
have 36 right we've got six neurons and
every neuron is connected to every other
neuron including itself so this neuron
has six outgoing weights uh out six
outgoing synapses another six outgoing
synapses another six 6 12 18
24 uh 30 36 total synapses so 6 + 36 42
an auspicious
number how many G's do we have six six
so we got a total of 48 parameters
plus plus six biases I lost count now
what are we at 54 so a six neuron ctrnn
has 54 total uh parameters that need to
go into the genotype if we take a random
set of 54 floating Point values and
assign that to the CNN those neurons are
going to start those six neurons are
going to start changing values in a
particular
way if we take a different set of 54
floating Point values and download that
onto our six neurons CNN those neurons
are going to start changing in a
different way
yeah The evolutionary algorithm is
downloading one set of 54 values after
the other onto the CNN as we're going to
see in a few moments that CNN is
controlling a robot the robot does
something Evolution deletes the set of
54 parameters that cause the robot to do
poorly at whatever we want the robot to
do and The evolutionary algorithm makes
randomly modified copies of the length
54 Vector that caused the robot to do a
little bit better at whatever we wanted
to do and rinse and repeat that part is
familiar we've seen that before so far
so good okay last piece horrible
notation this time it's not my fault
this is uh uppercase eye sub lowercase i
for the mathematicians in the room my
apologies on behalf of the authors of
cets okay this additional term tacked on
to the end is meant to represent the
input that's coming into the ctrnn from
outside when we started our discussion
of CNS this morning I said imagine that
a neuron is set to some particular value
at a given point in time we're going to
drop these cnns into robots and connect
the robot sensors to some of the neurons
in the ctrnn so we've got our six we've
got our six neuron C tier andn here
let's assume that four of them are
connected to four sensors sorry this is
getting a little
messy we're going to connect we're going
to assume we're going to drop our six
neuron ctrnn into a robot that has four
sensors and I'll just draw them as
squares to distinguish them from neurons
we've got four
sensors we could imagine that these are
touch sensors so they're binary sensors
that are either sending minus1 or + one
into the ordinary differential equation
for that neuron so if we have six
neurons like this we have six ordinary
differential equations two of those six
ordinary differential equations are
missing this term they just don't have
it the other four uh differential
equations each have this term and they
are receiving or that neuron is
receiving the value of the neur that
neuron the value of that sensor at that
time step is tacked onto the end of the
differential equation and obviously
influences not the value of the neuron
it influences how the value of the
neuron changes we're dealing with
continuous time neural
networks what happens if for the I
neuron its particular sensor at a
particular point in time fires the value
of plus one how does that influence the
behavior of neuron I at that
moment any
ideas we've got we've just added plus
one to the right hand side of this
differential equation how is that sensor
value influencing the behavior of the ey
of
neuron does it make the rate go more
positive more more positive great right
it doesn't necessarily make it go
positive because the rate of change of
this neuron is also being influenced at
that moment in time by a whole bunch of
other things who knows what else is
going on maybe all the rest of this
stuff is setting the rate of change of
this neuron to be negative so it's the
neuron is poised to decrease in value
moving forward in time maybe this value
that's arriving is making its drop
slightly less it's making its rate of
change more positive not necessarily
positive but more
positive this neuron let's say it's
receiving an incoming sensory value of
minus one we're tacking at that point in
time a minus one onto the right hand
side of this differential equation it's
making the rate of change of this neuron
at that moment in time more negative not
necessarily negative but more negative
this will be the initial condition term
it's uh not necessarily the initial
conditions because we can take our six
neuron CNN drop it into a four
sensor uh robot and then at every point
in time that we simulate that robot and
we s integrate or compute the value of
these Odes of these differential
equations the values of the neuron the
values of the synapses are sorry the
values of the
sensors are influencing these four
neurons at every time step so it's not
necessarily initial conditions it's a
forcing term the the sensors out here
are continuously influencing the rate of
change of the
neurons sensors only influence
change correct the in in our cartoon
example down here the first and the
sixth neuron do not have any sensor
attached to them so the first and sixth
differential equation do not have this
term associated with them their behavior
is only influenced by all the other
neurons and then their own internal
parameters too G
Theta make sense okay again this term is
influencing a biological detail of neur
biological neurons which is the vast
majority of the neurons in you are
influenced only by other neurons there
is a vanishingly small fraction of
neurons in your body that are being
influenced by the outside world the
neurons right close to the back of your
eye are being more or less influenced by
incoming photons there's a little bit of
intermediate steps that are going on but
basically the firing rate of those
neurons very close to the back of your
eye are being influenced by the rate of
the rate of incoming photons same thing
with the neurons that are inside the
Clea inside the part of your inner ear
they're being influenced more or less by
the pressure waves that are coming from
my voice and so on
yeah okay all good okay how we doing for
time we got 20 minutes left okay so
that's a lot of theory what we're going
to do in the next 20 minutes is look at
an application of cnns we're going to
look at an application of CNN's not to
the minimal cognition experiments we're
going to look uh we're going to apply
them to a more complicated robot to see
why
ctrnn are more useful for evolving
intelligent Behavior than the simpler
less biologically realistic neural
networks that we've seen so far okay and
that'll finish off lecture eight this is
a bit of a complicated experiment so if
you don't get all the details that's
okay this is sort of mostly meant for
the grad students for the undergrads
follow along as best you can okay here
we go we're going to deal with this cute
little robot
here this Little Robot here as you can
see is going is uh as you can probably
guess is equipped with by with a CNN
there's a whole bunch of these
continuous time recurrent neurons inside
and this robot is being trained to try
and grasp and manipulate this small
block that's placed in front of
it here you can see the human teacher
helping this robot as this robot is
moving sensor information is is coming
from its hands and from it the camera in
its head those those sensor neurons
those sensor
values are flowing into the CNN that's
controlling this
robot and then some of the neurons
inside the ctrnn are sending values out
to the motors the one thing that we
haven't discussed yet about these cinns
we see how they receive values from
outside but how do they send values to
the outside we haven't really talked
about that but you can assume that
another subset of the neurons whatever
the value of that neuron is it just gets
sent
to a
motor remember that whenever we read out
a value from inside a neuron we squash
it with the activation function so we're
sending values that range between minus1
and + one we're sending that to the
motors of the
robot
okay we'll talk about this little figure
in the upper left in a
moment
okay I'm G to play this short clip again
you'll notice that the robot has evolved
the ability to lift this block up and
down a few times and then it's evolved
the ability to move this block left and
right a few times not a very
sophisticated set of behaviors but even
in this admittedly simple demonstration
this robot is showing a particular
Hallmark of intelligent Behavior which
is the ability to stitch together a
couple of simple motor behaviors in
sequence these are known as motor
Primitives you are all intelligent
machines when you learn a new Behavior
like learning to walk learning to run
learning to kick a ball learning to play
the piano learning to play the violin as
you learn more and more physical actions
you don't learn them from scratch that's
not a really good way to do things you
learn all the things that you can do in
a hierarchical manner you build up very
simple motor Primitives for walking this
is one motor primitive this is another
one once you learn them then you start
to put them together and you
get a bigger Behavior then you can start
to stitch those together walk then run
walk then jump over the hurdle then run
a bit jump over the hurdle run jump run
jump run jump we can keep stacking more
and more complex behaviors in a
hierarchical manner when you learn to
play a musical instrument of course you
don't learn an entire piece of music all
at once and then learn an ENT other
entire piece of music at once you learn
chords however that works depending on
the instrument you you learn different
chords then you learn how to stack them
together into phrases then you learn how
to stack phrases together it's a often
unsung building block of intelligence
it's so familiar and so obvious we don't
even realize that we're doing it if you
want to be intelligent here in the real
world and be able to flexibly do lots of
different complicated things like Walk
and Run and play the piano and play the
violin better to learn them and put them
together in a hierarchical manner okay
okay that makes sense how the heck do we
get a robot to do the same thing how do
we get it to learn to do different
things like lift a block up and down
three times and then shift a block left
and right three times without that robot
learning all of those behaviors from
scratch every
time why would it be bad for the robot
to just learn them from scratch every
time just a lot slower
three different movements that could be
repeated absolutely right so it's going
to take it a long time to do it let's
assume this robot has all the time in
the world time is not an issue compute
is not an issue this human teacher has
infinite patience even then there's a
disadvantage for the robot to learning
all of these simple behaviors from
scratch every time there's absolutely no
flexibility there's no flexibility right
hey robot but I want you to go like this
now right or go like this now or I want
you to do three times left and right
then up and down three times then
forward and back three times and repeat
that whole sequence 17 times it's got to
learn that whole thing from scratch
again not a good way to do that so in
this experiment what the investigators
tackled was how do we evolve all the
parameters for a ctrnn that controls
this robot so that it's able to learn
different motor Primitives one here's
another one and then after training be
able to stitch them together in new
combinations and
permutations okay here we go here's how
they did this okay here's the simplest
possible way to do this what you're
seeing in panel a down here hopefully
you can see this from the back is maybe
we create a CNN with one fully connected
subset of neurons we're going to to wire
up all of these neurons and these
neurons are going to be responsible for
up and down we're going to stitch
together these neurons we're going to
wire up all these neurons with synapses
but cut all of the synapses that connect
this group of neurons to this group of
neurons and make this neural module
responsible for uh this is responsible
for left and right this is responsible
for up and down wire up all of these cut
all of these connections and train or
evolve this CNN so that these neurons
control forward and back you might
remember back towards the beginning of
the semester we talked about the
subsumption architecture which is like
basically a set of stacked brenberg
vehicles and the brenberg vehicle that
keeps the robot from smashing itself to
Pieces is in charge most of the time if
the robot is not in danger of Smashing
itself to Pieces then it's free to turn
towards the dirtier part of the carpet
and turn away from the cleaner part of
the carpet where did we see this what is
this thing
called it's a it's a Roomba inside the
Roomba is the subsumption architecture
the Roomba is basically running a stack
it h it houses a stack of brenberg
vehicles and vehicle one two or three
can take control of the motors depending
on what the sensors are saying that's
one way to do things and works pretty
well if you're a Roomba and the only
particular motor primitive you ever need
to do
is
this and this it's okay but if there are
three or 10 or 100 or a thousand
different motor Primitives you need to
do and you need to stack and make more
brenberg Vehicles doesn't scale very
well yeah is there one part of your
brain that's responsible for you playing
the violin and another for playing
soccer and another for playing soccer on
a rainy day and another one for playing
soccer on a sunny day another one for
playing on AstroTurf another one for
playing on natural grass not a very
scalable way to do things
so in this paper the investigators
create a CNN and I've just copied and
pasted the uh uh the differential
equation describing the behavior of an
individual neuron in a ctrnn over here
and they arranged things in the
following way they W they allowed all
the neurons to wire up to everybody else
but the
investigators um clamped the time
constants Evolution was play was was
free to Tinker with the weights the
gains and the fetas but the
investigators are going to set the time
constants themselves based on their own
intuition this is always difficult to do
but possible in this case what's the
intuition the intuition is visualized
down here we're going to set the time
constant for some of the neurons to be
Woody Allen neurons we're going to set
the time constants to be close to zero
so that these neurons can react and
change values very
quickly these fast neurons are going to
be connected to the motors
they set some they took some other
neurons in the ctrnn and set those to
have high time constants or high
magnitude time time constants to make a
set of eore neurons these neurons
respond very
slowly what's the intuition here why did
they do
this
absolutely so you can think of these
slow neurons as like the conductors of
an orchestra as you can see with this
slowly changing purple value this is
meant to represent the slowly changing
uh act activity of a slow neuron it's
like a conductor when the value of that
neuron is at intermediate value that
value of the slope neuron is influencing
all the other neurons through synapses
including the fast neurons and evolution
is going to try and tune all of those
synapses and gains and thetas so that
that intermediate value of the slow
neurons pushes the fast neurons into
pattern if the slow neurons slowly shift
to some other pattern that P that causes
a different influence on all the other
neurons including the fast neurons so
that they shift from doing this to doing
this make sense okay what particular uh
values of w and G and Theta will cause
all this to
happen who knows this is where we pass
things off to the evolutionary algorithm
we're not going to talk about the
fitness function I'll just give you sort
of a high level overview of how this
works
the fitness function is going to just
select the the fitness function is going
to try and tune all the Ws and G's and
thetas so that when these neurons
receive an outside value of one this
value is actually coming from the human
investigator the human investigator
plugs a a value of one into one of the
slow neurons from that neurons point of
view this just looks like a sensor value
right it suddenly just receives a value
of one which influences the behavior of
that slow neuron and when that slow
neuron gets a value of one the fast
neurons should cause the robot to do
this that's one part of the fitness
function if that neuron receives a value
two whatever it does it should cause the
fast ones to do this and same thing for
forward and back so far so good so in
theory if the evolutionary algorithm
Tunes all of the G's and W's and thetas
correctly the human investigator should
be able to play the Robot like an
instrument when the investigator presses
one the robot does this when the robot
presses two it does this and when the
investigator presses one again it goes
back to doing this and then the
investigator can take one step back and
send a series of values here one one one
1 2 1 1 3 3 1 2 two at a slow sequence
and that's in in essence the
investigator saying shake the block up
and down three times then push it
Forward back and forth three times and
so on we want to see how well the robot
does at being flexible somebody
mentioned flexibility send a new unseen
combination of requests for motor
Primitives and the robot should be able
to to do it so far so good good okay we
got four minutes left we should be able
to finish this
out I'm not going to talk about this
figure I invite the grad students to go
read the actual paper that are
interested in the details the only thing
I want you to take away from this
complicated picture here is that it's
basically a whole spaghetti mess we have
a whole bunch of neurons I think there
were uh I can't remember how many there
are there's a large number of neurons in
the ctrnn they're setting some of the
time constants to five which are the
fast neurons they're setting some of
them to slow I don't know how they got
the values of five and 70 but the
investigators are sending in the goal
they're telling the robot what it should
be doing at a high level shake the block
up and down three times back here in the
slow neurons so the conductor is
basically receiving a piece of music and
then the conductor is pushing the fast
neurons into different distinct
patterns
okay last figure we're going to look at
today this is what you're looking at
we're looking inside the brain of an
evolved ctrnn that's controlling the
robot so Evolution has tuned all the W's
and G's and thetas so that when the
investigator presses one when the
investigator presses three and so on
okay let's have a look at let's read
these off each individual panel here
each panel on the horizontal axis
corresponds to a few seconds of time in
the robot's experience we're not looking
at evolutionary time here we're looking
at a few
seconds in this particular panel here on
the vertical axis we're looking at
proprioception proprioception is a
particular uh type of Sensation that
records where your body is in space or
basically the angles of all of your
joints so is one two three four
different lines here I think these
correspond to the two elbows and the
four and the two shoulders of the robot
so we can see that the angles of the
robot's joints are oscillating three
times when it received the command to
shake the block up and down three times
doesn't necessarily mean that it's
actually going up and down three times
it's just doing something the robot is
repeating some motor primitive three
times when the robot receives a
different command shake the block left
and right there's a different pattern a
different oscillation three times this
is a visual sensation which we haven't
talked about this is the teaching signal
so this is the uh the teacher actually
holding the robot and shaking it in the
appropriate way and this is the robot
with its Motors trying to follow along
so each of these individual panels This
is the Rob this is the teacher saying
this is what you should feel this is the
teacher saying this is what you should
see and this is the robot saying this is
what I actually feel and this is the
robot saying this is what I actually see
myself
doing we've got one minute left okay
down here on the horizontal axis we
still have about five seconds of the
robot's experience each row in this
panel down here corresponds to one of
the neurons in the CTI andn within each
row a black pixel represents that that
uh neuron is firing with a big positive
value a value near plus one and a white
or gray pixel indicates that that neuron
is firing with a value that's near minus
one what's going on among all the fast
neurons
you can see that oscillation so if you
look in this part of the panel you can
see that the fast Woody Allen neurons
are oscillating three times and then
when they when the robot receives a
different teaching
signal the robots the the fast neurons
also start to oscillate back and forth
three times at some other different
pattern down here the these are the slow
neurons and if you look at the first
part of this lowermost panel you'll
notice that there is no little to no
oscillation the slow neurons over here
the conductors are holding constant some
particular set of activities and that's
pushing these fast neurons into an
oscillation back and forth three times
which you'll have to trust me
corresponds to the robot actually doing
what it was told to
do the neurons then re the slow neurons
then receive a different teaching signal
which pushes them into a different set
of patterns and there's a little bit of
an oscillation in the slow neurons but
essentially they start pushing the fast
neurons into a different fast
oscillation which again you'll have to
trust me corresponds to left and right
back and
forth okay we're out of time um if
there's any questions about this we'll
we'll feel those questions on Tuesday
you have a quiz due tonight undergrads
you're working on A5 grads you're
reaching the Finish Line with a n and 10
see you Tuesday
morning


--- Evolutionary Robotics course. Lecture 11： Minimal cognition..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning
everyone congratulations to those taking
the course for graduate credit you've
reached the end of the first 10
assignments hopefully you have an
experimental platform now on which you
can evolve neural controllers for
virtual robots inside of virtual
environments take a deep breath pat
yourself on the back and around we go
again so for The Graduate students uh
there is now waiting for you the first
of the five differentiable assignments
uh I've been working on these there are
not going to be 10 there will be five of
them in the first one you're going to be
tackling objects like you tackled links
in the first
assignment next week you're going to
tackle Springs so we're going to attach
objects together with springs this is a
little bit different from attaching
links together with rotational joints
we're going to connect together uh Mass
points so very very small bits of
material attach them together uh with
springs the week after that you're going
to be adding Motors to the Springs so I
want you to imagine two small bits of
material attached with a spring and
inside the spring is a piston that can
pull the spr the pairs of connected
objects towards one another or the
Piston can extend uh extensive force and
push those pairs of connector
objects
apart after that uh as usual after that
will be spring recess and then after
that the fourth assignment you will be
adding sensors to a whole bunch of
objects that are connected together with
motorized Springs that will make this uh
robot start to move and as always
towards the end you're going to be
connecting Those sensors to those
motorized Springs to get your robot to
move
what you should have at the end of this
fifth differentiable uh assignment is a
robot that's made up of a bunch of
objects connected together with
motorized Springs that are pulling and
pushing pairs of connected objects
together we have actually seen a robot
in this in this class that already looks
quite a bit like that where and when did
we see that robot anybody remember is
that the T SEC the 10 security robot so
NASA is actually prototyping this is a
potential way to develop uh Rovers for
the years to come that's what you're
going to be developing in these
differentiable assignments what do we
mean by differentiable assignments well
if we go back to our brenberg vehicles
for a moment where we've got a small
vehicle that's running around with
driving around with two wheels on the
back and two sensors on the front and we
have the two sensors connected to the
two Motors
this is as we've seen sort of the
simplest robot you can
imagine in this course what we're
looking at is ways to wrap this whole
thing in an evolutionary algorithm where
the evolutionary algorithm in this case
is trying to find two numbers for these
two synaptic weights that cause this
brenberg vehicle to do whatever it is
that we want this vehicle to do in an
evolutionary robotics experiment it's a
semisupervised learning problem
semi-supervised meaning that we take two
sets of synaptic weights drop them onto
our robot's neural controller watch how
the robot does it running around and we
get back a single number which is how
well the robot did how do we determine
how to change these two synaptic weights
to make this number bigger to make the
robot do more
phototaxis randomly the short answer is
we don't know so we make random changes
part of what's going on in the current
AI Revolution is figuring out how to
actually take this number and propagate
it backwards from the sensors into the
motors and
identify it was this one that was wrong
not this one we can actually in some
cases localize where the problem was or
where the issue was that was causing the
inefficiency and then we can also
identify not just where the problem is
but automatically identify how to
improve that number whatever this
synaptic weight is should we make it a
little bigger or a little smaller again
usually we don't know so we do it at
random when we design robots in a
differentiable manner we can actually
apply some of this machine learning uh
Machinery to actually identify where the
problem is and fix it automatically and
remove the randomness from the way in
which we automatically design autonomous
machines make sense okay all right so
for the grad students that's what you're
going to be doing in D1 through D5 for
the undergraduates if you're running
ahead and if you reach the end of
assignment 10 uh early before the end of
the course you're welcome to try and
tackle the differentiable assignments if
you want um this is New Territory for
this course so if you do tackle the
differentiable assignments and you get
stuck please come see me during my
office hours rather than the teaching
assistant and I will try and help you as
best I can any questions about any of
that okay all right undergraduates uh I
lost where we were here here we are uh
you are going to be tackling uh
assignment six this week uh in
assignment six you're kind of pausing
for a moment and you're going to be
doing a bunch of refactoring uh your
code base through assignments one
through five is getting larger and
larger and larger and I don't know about
you you but at this point you've
probably forgotten where variable XYZ is
and where function ABC is so you're
going to refactor the code modularize it
clean it up a little bit so as you
continue on through assignments 7 8 n
and 10 you'll have a more modular code
base and it'll be easier for you to
remember where everything is make
improvements rapidly debug anything when
it goes wrong and so
on okay all good okay all right back to
our lecture material so last time we
just finished uh lecture eight where we
looked at a particular kind of neural
network controller the cnns CNN stands
for thank you continuous time so we're
dealing with neurons that are changing
their their values continuously over
time cnns have much more biological
detail built into them than the standard
neural networks we've been looking at so
far they're more complicated but that
complication buys us some things it
allows us it allows us or it allows uh
The evolutionary algorithm makes it
easier for The evolutionary algorithm to
evolve behaviors for robots that are
being controlled by a CNN we ended last
lecture by looking at this small
humanoid robot that was shaking blocks
up and down and then left and right and
then forward and backwards that robot
evolved the ability to exhibit a
particular building block of
intelligence which is the ability to
stack hierarchically together motor
Primitives yeah it was able to do that
by having a cinn brain in which some of
the neurons are quick and orchestrate
sensor motor
coordination and then other neurons are
slow and act like the conductor of a
symphony and slow changes in those slow
neurons
push the activity of the fast neurons
into different motor Primitives fast
push the fast neurons into different
motor Primitives like this like this and
like this so some of that biological
detail made it easier for The
evolutionary algorithm to evolve
hierarchical arrangement of motor
Primitives okay so today we're going to
push on to lecture N9 where we're going
to look at the original minimal
cognition experiments as you'll see in a
moment the robots in these minimal
cognition experiments they look very
much like brenberg Vehicles they're very
very simple they're being all all of
them are going to be controlled by CTI
andn so they don't necessarily have
minimal
brains the goal in the minimal cognition
experiments is to try and evolve more
and more and more and more of these
building blocks of intelligence if we
can't Define what intelligence is why
don't we sort of agree on the things
that are necessary for intelligent
Behavior here in the real world and see
how many of them we can evolve into
machines which ones are more difficult
than others how do we combine them
together in a machine that is able to
exhibit more and more and more of these
building blocks and maybe that's a more
systematic way to approach the creation
of increasingly intelligent increasingly
complex increasingly useful and
increasingly safe
machines very different from the
dominant Paradigm at the moment which is
make Chachi PT release it to the world
and hope everybody finds a good use for
it and that nothing bad goes wrong you
obviously know where my uh sympathies
lie I'll leave it up to you to form your
own opinions okay minimal cognition here
we go uh I hope you enjoy today's
lecture it's you can think of it as like
the robot Olympics we're going to look
at a whole bunch of different events
where the robots are going to be tasked
with exhibiting uh some of the uh we're
going to look at four different building
blocks today four different competent
icies of intelligent behavior let's
start with the first of the four which
is perceiving
affordances we've seen another uh a
number of Concepts from psychology make
their way into robotics so far
affordances is another big one anybody
come across this concept in a site class
before sort of giving you the punchline
here already when we look about in the
world around us and I was to ask you for
example to describe what a chair is
you'd probably give me a geometric
description of a chair it's got these
vertical things underneath that are made
of sufficiently strong material to hold
up this flat piece and there's usually a
flatb and you go and try and describe it
back in the 1970s when people were
starting in on uh trying to get AI to
recognize objects and what they're for
that's what they did uh PR programmers
spent decades trying to describe to a
computer what a chair is by giving it a
geometric description a geometric
understanding of chairs it doesn't take
long to realize that a geometric
approach to understanding objects runs a
muuk because this particular thing here
not strictly not strictly a chair but it
clearly belongs to this other
group breaks a lot of those geometric
assumptions of what a chair is I
deliberately picked these five images
because they clear hopefully to you they
all immediately have something in common
but I challenge you to find a geometric
commonality among these five
objects it feels as if we understand
objects in the world based on their
geometric properties but thinking about
thinking is
misleading a concept that came out of uh
psychology in the 1970s and the 1980s
was an idea that when humans look at
objects we might think we're classifying
our understanding objects based on their
geometric properties but we're actually
understanding objects based on the
affordances they project to us we can
imagine objects out in the world
shouting at us about the ways in which
we can interact with those objects so an
affordance that's shared by all of these
objects for adult human beings is that
they are cable you could rest your
weight on them in a relatively
comfortable manner that description is
about you or about you and the
interaction with the object and what
kind of interactions that object affords
to you that's the idea of
affordances what do these objects have
in
common what about these objects
objects what do they have in common
we're playing the affordance game
now all contain
energy they all contain energy that's
exploitable by by us it's always an it's
it's about us the Observer is a part of
understanding the world around it what
we are doing as active entities in the
world that want to survive and thrive in
the world we're selfish we're looking at
everything thinking about how we can use
it how we can inter how we can interact
with it how we can consume it how it can
make our lives a little bit easier and
so on that's the idea of affordances so
maybe when we're making computer we're
trying to make smart computers and smart
robots and smart machines we should be
trying to teach these machines to look
at the world around them and not run
computer Graphics or try and recognize
particular geometries like does this
thing have three or four vertical struts
and a horizontal platform on top they
should be looking for affordances trying
to learn or evolve the ability to
recognize how they can interact with
objects out there in the world make
sense okay optional homework as you
continue on with your day today and you
look at the Myriad objects that you look
at watch yourself watch those objects
and you'll notice that on the surface it
feels like you're recognizing Things
based on geometric properties but you're
really thinking about
affordances writable listenable erasable
and so on okay all right so now let's
have a look at trying to get a minimal
machine to perceive affordances here's
the first of the four minimal cognition
experiments as promised we have a very
very minimal robot here we've got a
square so this is a minimal physical
simulator as well this our little robot
here exists in a two-dimensional World
these two little horizontal axes here
represent two Rockets So in our brenberg
vehicle we had two spinning wheels I
want you to now imagine a square with
two opposing rockets and those Rockets
can exert more or less thrust if both
Rockets exert exactly the same thrust
the robot goes nowhere if neither of the
Rockets uh emit thrust the robot also
doesn't go anywhere if one emits more
thrust than the other it moves to the
left and vice versa it moves to the
right so we've got a little Space
Invaders type robot moving along the
bottom of the screen left and right at
different velocities and accelerations
and decelerations and from above we're
going to drop a pair of
objects everybody still know what Space
Invaders are okay all right all right
here we go we're going to evaluate every
ctrnn we're going to drop ctrnn into
this minimal robot one after the other
we're going to evaluate each individual
cerin n's ability to produce behavior on
average for the robot so the first
little bit of math here in the upper
right we're going to compute P or the
performance of the robot this is
synonymous with Fitness the authors of
this paper just use P instead of f for
our purposes it doesn't matter and
they're going to sum a whole bunch of P
subis which is the performance of a
given CNN on the robot the eyth time
we're going to take the average of how
well that CN causes the robot to do it
whatever want it to do a numb trials
time so far so good okay in each of
these numb trials trials we're going to
drop a pair of objects from above that
pair of objects are going to fall at a
constant rate and the robot can sense
these uh this object pair so the gray
emanating lines here uh represent 1 2 3
4 five six seven proximity sensors on
the front of the robot so this should
look pretty familiar this robot has
seven proximity sensors two motorized
rocket thrusters and a CNN inside you'll
notice that at this instant in time this
pair of falling objects is triggering
the second uh fourth and fifth proximity
sensor Those sensors are firing a little
bit more strongly and the first third
sixth and seventh proximity sensor are
returning a value of zero make
sense okay what is the robot supposed to
do
um as this pair of objects is falling
the robot has to figure out whether the
pair of objects is
passable the robot is trying to
recognize a particular affordance
projected by this object pair which is
whether the robot if it gets between the
pair of falling objects the pair of
objects will fall on either side of the
robot and not hit the robot is the
object pair passable or not is this Gap
wide enough for the robot to pass
through or not that's the affordance
we're going to try and evolve this robot
to
recognize okay so how do we compute P
subi how well the robot does given a
particular ctrnn on the ith trial we're
going to consider two different cases
we're going to consider the case where
the opening between the object pair is
too narrow for the object to pass
through so let's imagine actually you
can see it in this cartoon here this Gap
is narrower than the width of the robot
so in this case we're going to set P
subi to a maximum value of 100 if the
robot does not hit this object pair this
object pair is going to fall towards the
ground and the robot should be nowhere
near this object pair when it gets to
the ground if it does that during the
ifth trial 100 points otherwise if it
hits uh either of the pair of objects
we're going to assign p subi t 2 * d sub
i d
subi uh diabi is the final horizontal
separation between the horizontal
position of the robot and the horizontal
position of the object pair when it gets
to the
ground horizontal distance between the
robot and the object pair when it hits
there's a typo in the paper they take
the absolute value of the distance
distance is always a positive number
little typo there okay so what is this
particular term
doing for the
robot what's the worst possible thing
the robot can do in this
case the object pair is falling the uh
the Gap is too narrow for the robot to
get between the object pair what's the
worst possible thing the robot can do
try tole get right underneath the object
pair whack the pair of objects hits the
agent and we take we compute du subi
which is the horizontal distance between
the robot and the center of the object
pair in this hypothetical case DBI is
zero Pabi is set to zero maximum penalty
the robot did the worst possible thing
so what is this particular term in the
fitness function doing it's rewarding
for
Runway if the Gap is too narrow
everybody get the game so far okay you
can probably guess even without parsing
the math here what this term is going to
do in the other case in one of the ith
trials if the aperture the gap between
the object pair is wide enough for the
object for the agent to pass through it
should get 100 points the maximum score
if the robot is standing directly
underneath the object pair and the
object pair passes right past the agent
and it's inside the Gap maximum possible
points if the robot runs away when the
Gap is wide enough for it to pass
through minimum points no
points if the robot collides with one or
both of the objects as that object pair
reaches the ground we're going to set
pabai to this thing what is this thing
rewarding or penalizing
for well the absolute worst thing is if
it runs Beyond block so then it's
rewarding forting
closer the successfully going yes so the
worst thing you can do is be beyond the
blocks that's zero if you're pretty far
away from the center of the object pair
and you get hit that's bad and you're
gonna have a pretty big a pretty big D
subi so we've got a pretty big term on
the minus uh the minus side here so
we're trying to uh minimize du subi if
the robot's not quite sure what to do
and it's jittering back and forth
underneath this object pair and it hits
one or both of the objects we're going
to set T sub I to 80 minus this distance
we're trying to make this distance less
and less and less so we're trying to
make everything on the right hand side
of this minim of this minus sign less
and less and less if the robot's hitting
the block until eventually a robot
evolves in which du subi is small enough
that boom it's not hitting any it's not
hitting either of the objects in the
pair it's staying right underneath and
letting both objects pass on on either
side so in this second case when the
aperture is
passable what is this conditional doing
what is it selecting
for when the aperture is too narrow this
selects for Runway when the aperture is
wide enough this term is selecting for
going through going through stay in the
center right be right in the
center imagine we take one CNN we drop
it into the robot numb trials times and
sometimes the object pair has a passable
Gap sometimes the object pair has a has
a non-p passible gap we're applying
these two different Fitness terms we see
how well it does at running away when
the Gap is impassible and we see how
well it's doing at get right underneath
when the object with passible sum all
those up and take the average of all of
those terms and P should be high when
the robot runs away when it should run
away and P should be high when it gets
right underneath the pair when the Gap
is passable make sense
okay let's see how it
does I apologize in the back of the room
I'll try and talk you through this axis
what we're looking at in this bottom
left panel is
the most fit CNN after the evolutionary
algorithm has run so the investigators
have evolved a population of cnns in the
first generation with random cnns p is
probably pretty close to zero the robot
doesn't know what to do and over
evolutionary time in this population of
evolving ctrnn some of the cnns start to
achieve higher and higher average
performance until at the end end of
several hundred Generations they have
one ctrnn that gets a P value very close
to 100 they take that one evolve ctrnn
go back to the robot and drop it into
that robot thousands of times under lots
of different conditions and they want to
see how robust is that evolved ctrnn how
well really does it allow the robot to
do at what we want it to do in this case
on the horizontal axis here this is
showing us that the investigators
dropped that curnin back into the robot
thousands of times with varying
aperture good to know my software is up
to date thank
you okay dropping that uh curn in back
into the robot thousands of times with
aperture widths that are wider and wider
and wider than the robots width and
apertures that are narrower narrower and
narrower and
narrower and in all of those different
cases they measured the robot's final
horizontal separation where was the
robot horizontally relative to the
object
pair when the object pair hit the ground
how does this ctrnn this single evolve
CN how well does it do in
general
well well yes it's doing well is it
doing
perfectly not quite right evolution is a
satisficer not an Optimizer how is it
deviating from optimal
behavior
um I'm guessing from looking at this
that the robot is around like 40 units
wide uh
it it doesn't actually show us that so
the 40 up here this says that the robot
was 40 horizontal units away from the
object pair when the object pair hit the
ground again this is a unitless
simulation so it's not really that
doesn't really tell us much you just
have to trust me that 40 just means it's
really far away from the object pair
well um we can we can tell on the plot
that it's not perfect because like it
doesn't immediately drop down to zero
when it begins like going in between
both of the pairs assuming that's like
what it means when the final horizontal
separation is around like one or like
1.5 uh actually zero here relative
aperture width of zero this represents a
case where the width of the aperture
between the pair of objects is exactly
the same width as the
robot okay make sense go ahead so like
when when it Dr down it doesn't drop
down to like immediately zero it is just
never able to reach like the point where
it's perfectly between the blocks
absolutely so there's something
interesting going on here right in the
case where the width is just about pass
yeah I can't like quite tell if it can
fit or not so it's
like I should just go away because it it
might not be able to fit good good point
right do the same kind of thing too it's
like yes yes if it's like life or death
like that you might you might be like a
it's better to run away it's better to
run away right we're using very brenberg
es language here which is fine
right right when the aperture is a
little bit wider than the robot in
theory the robot can pass between the
object pair these big black vertical
bars these represent uh error bars or
confidence intervals what this means is
that this evolves C andn saw lots of
different falling object pairs in which
the aperture was wide enough and some of
the time it ran away and some of the
times it took a deep breath and actually
went for it and tried to get between the
object pair but it's being kind of
conservative right optimal behavior is
this black dot should be right down here
if the aperture is passible the robot is
supposed to go for it but it's not it's
being a little bit careful and as you
said we tend to do that as well so on
average maybe the best thing is to air
on the side of caution if you're not
quite sure run away kind of interesting
right it's a nonoptimal behavior humans
and every other species on the planet we
are also not optimal but the bias that
we typically have kind of makes sense
the ways in which we're non optimal
sometimes are kind of a good thing right
kind of interesting to see that
reflected here in an intelligent machine
as well
Emily absolutely great point right so we
could go back if we saw this and said
yeah we want this robot to be a little
bit braver we might be able to go back
and alter the fitness function to ex
exert a greater reward for going for it
regardless of how passable the aperture
is or maybe we would punish with greater
force cowardice right running away when
you shouldn't be running away
interesting another piece of optional
homework for you see if you can sit down
and try and rewrite these Fitness
functions that at least in theory would
would sort of clean up this conservatism
here
everybody see that question yeah how can
we be sure that the behavior we're
seeing around zero is due to you know
sort of this potential
cowardliness instead of just like
inaccuracies in the sensors causing it
to sometimes accurately you know yes
will say that it can fit whereas
sometimes it thinks it can fit and it
can't just because of the data it's
given that's a great that's a great
point and you're right so what we're
looking at is we're looking at a lot of
data in this plot but but all that data
is coming from one evolved ctrnn and
that one evolved ctrnn might have
idiosyn idiosyncrasies in it we could
take this evolutionary run and instead
of taking the ctrn with the best fitness
we take the CN that had the second best
fitness maybe it's the brother or sister
of this CNN or a cousin or a second
cousin it's not quite the same does it
if we did the same thing to that CN
would we get the same picture
maybe we'd get a different picture maybe
that one would be a little more Brave
and maybe it would be fool hearty maybe
it would try and run the Gap when the
Gap is too narrow maybe there's an issue
with the sensors maybe when that Gap is
just right at the edge of being passible
the robot can't
tell my understanding of this simulation
is the robot actually can tell the the
the sensors itself it's only ever
getting seven numbers at any one time
but remember that this robot is moving
back and forth horizontally at the
bottom of the screen it's like cat
whiskers it's able to sweep its seven
proximity sensors across the unders
sides of the objects it can this thing
can actually sense very well and pick up
very subtle details and we'll see
another example of that in a moment so
it's a good observation but I doubt it's
because of some limitation in the sensor
motor Behavior good good point other
questions or comments before we push on
yes it's funny to me that like as that
WID gets larger it starts to like seems
like maybe
ites it's it's showing off right the Gap
is really wide it gets underneath and it
kind of want to move or something yeah
exactly exactly and again I apologize it
would have been great to see some of the
videos of these not quite clear exactly
how this robot is is moving we're
inferring Its Behavior by looking at
this data
okay okay let's actually dive in again
we don't have an actual video of this
Behavior but let's actually investigate
a little bit more about how uh about how
these curn ends are evolving I love this
particular paper and I love this
particular lecture because of these sort
of different building blocks they look
at but these investigators really did
their due diligence as you as we're
going to see they really analyzed in
great depth how good or how poorly these
cinns evolved how well do they do in
general this was 23 years ago this was
in my opinion good work this is
something that we as a society are now
struggling with we have intelligent
machines and we're kind of deploying
them out into the real world and
sometimes they generalize well and
sometimes they don't how do we really
know when we've got something that does
well on paper and also will generalize
well to many many many different
situations in the real world including
edge cases cases where it's going to be
difficult for the machine to know
whether to Zig or zag in this experiment
literally okay here we go again we're
going to look at one we're going to look
at uh one good evolved ctrnn up here
let's have a look at this uh let's have
a look at this uh upper left panel for a
moment what they're going to do in this
case is they're going to take an object
pair in which the uh an object pair in
which the Gap is not passable the robot
can't get between the Gap and they're
going to drop that uh they're going to
drop that object pair above and to the
left of the robot then they're going to
drop that same object pair above and a
little again above and to the left of
the robot but a little bit towards its
Center they're going to drop that object
pair from here then here then here then
here here then here then here then here
then here so each one of each one of
these black trajectories represents one
trial everybody see that so far
okay the horizont sorry the vertical
axis here is representing the vertical
position of the object pair so as we
descend this panel from the top to the
left and watch one of these trajectories
we can see that pair of objects
falling
the horizontal axis is representing the
horizontal position of the
robot sorry the horizontal position of
the robot relative to the object pair so
let's start with this trajectory in the
upper left so at this point the object
pair was
dropped 40 units to the robots left what
did the robot do in that
case follow this
leftmost black trajectory from the upper
upper left part of this panel how did
the robot
move if we follow this trajectory it's
more or less vertical kind of vertical
for a while what is that telling us
about the robot it's like just waiting
it's waiting the relative the horizontal
distance between the robot and the
object pair is remaining at minus 40 the
robots moving a little bit but not too
much and then it starts to move
horizontal position starts to decrease
towards zero what is the robot doing to
the center it's going towards the center
at least the robot is moving to the left
the object pair Contin always falls
perfectly vertically I'm sorry I forgot
to mention that detail before object
pair always falls perfectly vertically
the robot is starting to move to its
left and what
happens after that
point it keeps going the robot keeps
going it's a little hard to see in this
plot this trajectory continues down here
and this trajectory ends down here in
the bottom right what does that tell us
about the state of the robot and the
object pair when the object pair gets to
the ground it's not it's not under it
it's where on the other side it's on the
other side the object pair started upper
left the robot started to move
underneath it and just kept going and
the object pair fell 40 units to the
robots
right okay that's for one trial now tell
me about all of these trials what is the
CN causing the robot to do in all of
these trials in which the Gap is not non
passible
impassible it's causing it to move 40t
away from like that Central position 40
feet away 40 meters away whatever it is
sometimes to the object pairs left and
sometimes to the object pairs right it's
always doing the right thing right
always running away everybody see
that okay same evolved CNN we're going
to expose it to a whole bunch of other
situations here we're going to drop the
object pair from different horizontal
positions at the top of the screen but
in this case the Gap is just passable
just wide enough for the robot to thread
its way between what does the robot do
in this
case goes through the Gap goes through
the Gap in every
case it's interesting that it's like
going back and forth through the middle
ones you'll notice that if we drop the
object pair towards the more or less
above the robot it kind of goes a little
bit to the left and then a little bit to
the right and then back and then stops
and shows off right for the last third
of the simulation it just stands there
and waits for either object to fall on
either side of it does that mean like
the of it is helping it to judge the
Gap so this is what the robot did can we
work backwards from its behavior in both
situations to what it's
thinking is it sweeping back and forth
so again it's using its proximity
sensors like cat Whisper whiskers to uh
to brush against the undersides of the
objects to better understand whether the
Gap is pass or
not I guess that at least for the closer
ones momentum just might have a play
might just try to move too fast and it's
trying to recorrect itself it could I
don't remember whether the physics
engine contains momentum it might that
that might be part of the reason it
might just not be able
to who knows maybe this sweeping back
and forth under the object pair is
useful maybe
not what else are you wondering about
about what's going going on inside the
CN given these
behaviors
sure
yep yes it's it's not clear from this
caption is it a huge passible gap or a
hugely impassible Gap it's not clear
from this picture or from the
caption
it's interesting that it doesn't just
like
immediately go somewhere like it does
take some time and it like does this
oscillating or whatever and then it like
decides maybe you would expect it to
like just sense and judge and go where
it needs to go but it doesn't do
absolutely right again there are lots
there's evidence here of
nonoptimality it seems to be taking its
time again that's due to the fitness
function the fitness function uh
contains du subi remember which is the
horizontal distance between the robot
and the object pair when the object pair
hits the ground there is nothing in the
fitness function that says figure it out
quickly just do the right thing when you
need to that's it so not surprisingly
the robot seems to be taking its time
you could have some term or something in
there that like punished it for using
more energy or something like that
absolutely you could
yep what else else can you infer about
the behavior of this robot it's minimal
it's very simple but even in the simple
case there's a lot of Rich dynamics that
are going on here lots of aspects of its
evolved behavior that suggests things
that might be going on inside the ctrnn
which is interesting that it seems to
behave the same exact way it's to the
left or right ah yes so I'm wondering
yeah like I feel like I remember you
saying usually the waves like AR sycal
when we evolve
but great observation if you look at
both panels each panel is bilaterally
symmetric the left side of the panel
looks like the right side of the panel
which means that the robot seems to be
exhibiting exactly the same way of
moving and ultimately what it
does in whether the objects are top left
or top right which suggests the synapses
inside the CN have evolved to be
bilaterally symmetric and I can tell you
that the researchers did not put that in
in this case so this is probably the
evolution of bilaterally symmetric
Behavior good observation um for the one
you can see there are like certain
trajectories that get further away
faster which is interesting it looks
like it's maybe like the ones that are
closer to the middle versus like all the
other ones thether out ones take a
little bit longer absolutely that is IND
something about how it's like sensing
the Gap could be but it's interesting
that there's like pretty much all the
ones in the middle seems to like hit
this one trajectory and the one on
theide absolutely so it looks like in
some cases it's taking the robot longer
to decide what to do when does the robot
know when does it decide the Gap is too
narrow I'm going to run away or when
does the robot decide the Gap is wide
enough I'm going to go for it
when it looks like it right if we look
at both panels above UH 60 those two
pair of trajectories look almost
identical right so the robot seems to be
doing exactly the same thing when the
block when the pair object pair is above
that height regardless of whether the
Gap is passible or impassible looks like
the robot doesn't know until 60 and then
it looks like at a height of 60 the
robot decides and either runs away or
gets right underneath the object it's
obvious the robot is making the decision
at a height of
60 I see some of you smiling you should
know by now in this course whenever I
say it's obvious that it's not the robot
is acting as if it decided at that
point never know right you remember the
liit experiments human subjects said I
know I decided at this particular to
time point to Twitch my finger they
thought that they were wrong right hard
to know actually when this robot decides
or how it decides but it does decide
there's something that's triggering run
away or stay where you are or at least
get under the pair all good okay let's
keep going these these uh investigators
really were uh interested in detail
let's talk about the lower left panel
now you'll notice that it's a whole
bunch of differently colored pixels
white gray and black pixels each
individual pixel in this panel
represents a single drop of an object
pair pixels that are uh pixels in the
upper half of this panel represent
object uh pair drops in which the Gap
was
passable pixels in the lower half of
this panel represent drops of the object
pair in which the Gap was not
passable uh pixels to the left of this
panel represent object pairs that were
dropped up and to the left of the robot
and pixels to the right hand side in
this panel represent pair drops uh drops
that were pairs that were dropped up and
to the right of the robot so far so good
okay for each of those conditions the
investigators colored that pixel white
if the robot did the right thing black
if the robot did the wrong thing and
gray if it kind of did okay maybe it was
jittering around maybe it bumped one or
both of the objects
tell me about again this single evolved
ctrnn what is it causing the robot to do
in thousands of different situations now
it has trouble like on the sides
horizontal position are
to okay you're talking about these big
gray blobs up here you're right so these
are far to the left and far to the right
which represent cases where the objects
were dropped far to the left or far to
the right of the robot and all these
gray blobs are in the upper half which
means go the that the aperture was
passable it could go through but it was
bumping the blocks in this case it
wasn't quite sure what to
do if you drop the object pair
directly above the robot it does really
poorly when it does really poorly when
the aperture is passable it runs away
away down here when the Gap is narrow it
also runs away which in that case is the
right thing to
do why do you think it does so terribly
right when the object pairs Dro directly
overhead seems kind of
odd if you look at the graphs above it
needs some sort of motion to
protect or like to make
decision it needs to go maybe so it
looks like the robot needs to move back
and forth to determine whether the Gap
is passable or not but the object pairs
dropped from directly ahead it's still
free to move back and forth and figure
it out it doesn't seem to be able to
figure it out in a lot of these cases
what
gives um when an object's like directly
above you like it's the hardest to
perceive like distance between both the
objects maybe in that case the robot
should just move left and right figure
it out right don't don't have the object
pair be directly above you the robot's
free to move back and
forth the network developed complely
symetrically
could could be could be may maybe
there's something about the Symmetry
that that helps it in general but there
are specific cases in which it kind of
you know it's fighting with itself
possibly another hint is if you look at
this picture you'll notice that they
never actually dropped the object pair
from directly overhead now this was an
experim experiment they performed after
Evolution but my guess is and they don't
explicitly say it in the paper is that
during Evolution they also never dropped
an object pair directly above the robot
it just never saw that
situation again it's not clear might be
a little bit of all of these
explanations this is a Hallmark
unfortunately of every intelligent
machine on the planet at the moment
right robot chat GPT stable diffusion in
general they work pretty well most of
the pixels in this plot are white great
unfortunately there are regions or there
are situations in which not only does
the machine kind of misbehave it does
absolutely the wrong thing and in this
minimal experiment we can actually sweep
over all possible conditions or almost
all possible conditions and see where
those blind spots are in the machine
unfortunately here in the real world
harder to do no one has an answer about
how to deal with this problem or make it
better plenty of people in the community
will tell you that they
do no one's figured it out yet hopefully
some of you will help with this very
needed uh solution okay should we push
on okay that's uh competency number one
perceiving affordances we just saw an
evolved robot that's able to tell you or
show you that it knows whether a gap is
passable or not let's look at the second
of of the second of four building blocks
of intelligence that we're going to look
at in the minimal cognition experiments
this one is discriminating between self
and non-self we've actually already seen
a robot in this course that learned to
do this what was that robot anybody
remember you forget his name her name
what what did baby bot right the two
cameras all it could see was whether
things move or not when it sends
commands to its
Motors very important thing for machines
and Tiny humans to figure out as well
figure out where you end and everything
else begins okay so characteristically
the
investigators uh investigated the
ability to evolve self- non-self
discrimination in a minimal robot this
robot is welded at the bottom center of
the screen it has no Rockets it can't
move left and right but it has an
arm pointing up in front of it and it
can send commands to rotate this arm
backwards and forwards above its head
and it's got a little tiny hand which
self Eudes its Vision so again this
robot has seven uh outgoing
it's got seven outgoing proximity
sensors and you'll notice that uh two of
them are being blocked by its hand it's
actually seeing its own hand everybody
see that at the same time that this
robot is seeing its own hand it is also
seeing a single object that's falling
from above and the dashed Arrow here is
telling us that this object can fall at
different angles towards the bottom of
the screen
it can fall at different
velocities from the robot's point of
view all it knows is that its second
third and seventh proximity sensor are
chirping and the other four proximity
sensors are at
zero how does the robot know which of
these is
self and which of these is
nonself seems easy right the one the
object that's really far away that
that's probably nonself and the thing
that's really close is probably
self easy now but as this object
continues to fall and touches this
imaginary Arc here now it's seeing self
and it's seeing nonself which is equally
close to it how does it know which is
which not so not so easy yeah okay how
did the investigators evolve
self non-self discrimination they're
going to rerun the experiment they just
did before they made a few changes to
the robot and a little bit to its task
environment the underlying evolutionary
algorithm stays exactly the same they're
going to evolve populations of CNS but
they're also going to change the fitness
function the fitness function is still
going to compute P for each CNN in the
population its average ability over a
bunch of object drops for each for the
eyth object drop they're going to
compute the performance of the c n
during that ith object drop and they're
going to compute it using this equation
again there's a typo in the paper where
it says Max it should be Min you'll see
that on the right hand side of this
equal sign there is only one variable
Theta subi and Theta subi is the angular
error error at the end of the ith trial
the end the trial ends when this object
touches this imaginary
Arc and at that point they look at the
angle of the object relative to the
robot so if this black sphere hits here
this would be an angle of whatever that
is minus pi over 8
radians and the angle of the arm in this
case it looks like it's minus pi over 16
radians more or less L Theta is going to
take the air between those two
angles what is this Fitness term doing
what is it trying to evolve CER and NS
do catch the ball right Theta you can if
you ignore all the other Machinery in
this term Theta is on the right hand
side of the minus sign so they're trying
to uh they're trying to Min if this
thing if this error is a positive always
a positive value which it is because
it's inside absolute
bars they're trying to make this error
minimal which is the robot should catch
the object its little hand should be
exactly where the object is when the
object hits this imaginary
Arc so far so good okay all right evolve
evolve evolve evolve and at the end of
evolution they pluck out the CN that has
the highest P value the most fit CNN and
then they drop that CNN back into this
little robot over and over and over
again under a whole bunch of different
conditions let's look at these
conditions on the horizontal axis here
they're reporting final object error so
this is the angle at which the object
hits this imaginary Arc minus values uh
left uh the left hand part of this pan
panel represents objects that hit above
and to the left of the robot and the
right hand side of this panel
corresponds to objects that fall and hit
the right hand side of the
robot the vertical axis represents the
angle of the arm when those situations
occur tell me about the behavior of this
robot when it's armed with this
ctrnn how does it do
Rob okay so when the object falls and
hits right above the robot the air bars
are a little bit taller here
representing there's a little bit more
variation in its Behavior sometimes when
that object hits directly ahead
sometimes the arm is a little bit to the
left
and sometimes when that object hits
directly overhead the arm is a little
bit to the right so it's a little unsure
but generally speaking how does the
robot
do it's good right it's not optimal
again what would optimal Behavior here
look like no error no error you see this
dashed Gray Line underneath that's what
it should be doing right the angle of
its arm should always be exactly the
angle at which the object hits the
imaginary Arc
good not
perfect okay here we go this is arguably
the most difficult panel to parse so
deep breath uh we'll take it a little
bit at a time same thing we're looking
at the behavior produced by one CN when
we drop that one CNN sequentially into
robot some cases uh uh the let's see
let's start with um let's start with the
colors here so
dark uh dark trajectories here
correspond to cases in which let me make
sure I get this
right oh yeah yeah okay trajectories are
shaded according to the initial angular
position of the object so black
trajectories over here which you can't
see because they're underneath this
light trajectory dark trajectories over
here correspond to the object being
dropped
above and to the
left lightly colored trajectories
correspond to objects being dropped
above and to the right of the
robot the uh the actual position of the
trajectory corresponds to the angle of
the robot's arm so all of the
trajectories that start up here to the
left this is the investigators taking
the robot arm and cranking it to the
left just before the simulation begins
and then when the simulation begins they
let the ctrnn control the arm all the
trajectories that start bunched up here
in the upper right those are cases in
which the investigators cranked the
robot's arm to plus pi over8 radians and
then when the simulation starts they let
the robot the CNN control the
arm light gray trajectories that start
to the left to the left meaning the
robot's arm was cranked to the left but
light trajectories mean the robot's arm
is to the left and the object drops from
upper
right get
it black trajectories to the left here
the trajectories to the left object is
cranked to the left the trajectories are
black the object starts falling from
can you parse the rest of this figure
what's
happening the
horizontal uh the horizontal position of
the trajectory at any point in time
represents the angle of the arm during
simulation what's
happening sweeping absolutely whatever
else is going on in every case Cas it's
doing a lot of this what else can you
tell me about what this robot does under
these
conditions what does it do at the end
when the object gets to the robot what's
happening there's four different initial
conditions arm crank to the left drop
the object from left upper left up or
upper right crank the arm to the right
drop the object from upper left or upper
right four different initial conditions
what happens in all these
cases absolutely at the end down
here all of these
trajectories are at an angle of zero the
object the robot is holding its hand
directly overhead we know that this
particular evolve ctrnn more or less
does the right thing under most
conditions so where do you think the
object is hitting regardless of whether
it's dropped from upper left or upper
right middle of the AR the middle of the
Ark right it's catching in every case
the ctrnn is enabling the robot to catch
the object more or less there's a little
bit of uncertainty here but it's mostly
doing the right
thing how how is it catching the
object it's like
tracking it as it's coming down and
sweeping across it and then as it comes
down it looks
likees absolutely yeah you can see like
when it's on the other side it goes all
the way over and then it tracks it down
and you're talking about these
trajectories they start over here
exactly so let's let's follow one up
here to the right meaning the object was
dropped upper right and the arm goes
like this and then if we follow this
trajectory over over here the object the
arm is going all the way over to the
left and we're following a dark
trajectory sorry I misspoke I misspoke
sorry if we follow a dark trajectory
from upper right uh if it's a dark
trajectory that means the object was
dropped from upper left but the arm was
cranked all the way to the right the
object starts to fall the arm over
overshoots and then as this object is
falling from upper left the robot is
showing off right it's sweeping its arm
back and forth it's basically pointing
to where it's going to capture the
object it's pulling a Babe Ruth here
right saying I know over
here it's like it seems like it figures
out pretty quickly where the other thing
is you can see that it sweeps over to
the under the it seems to know pretty
quickly where the object is sense it's
a
it knows like okay at this point yeah
kind of know where my arm is like good
point does it know that does it know
that its hand is smaller than the
falling object we know it because we're
looking at this
jpeg it only gets seven numbers at any
instant in time it's only ever got one
number does it know
is it easy for this robot because it
knows its hand is small and the falling
object is
Big learned that maybe maybe it's
learned that remember the Gantry robot
which was able to distinguish between
triangles and rectangles it learned to
or it evolved the ability to distinguish
between those two shapes through
movement probably the same thing is
going on here it looks like this is a
relatively easy task for the robot to to
solve so far so good
okay okay let's keep going we've got 5
minutes left so we should be able to
tackle the third of the fourth
competencies this one is short-term
memory if you an organism or a machine
cannot remember anything from your past
there's only so many things you can do
you're you're pretty fragile right
definitely an important building block
of intelligence is memory so how do we
evolve a robot to remember stuff we've
already seen some robots like the Gantry
robot that does evolve the ability to
remember stuff let's have look at
another example okay we're back to our
Space Invaders robot now it's got two
rocket thrusters underneath it's moving
back and forth along the bottom of the
screen it's got seven proximity sensors
like before but now they're being drawn
with dashed lines which is a visual
representation of an additional detail
they built into this experiment which is
that the robot is able to see but the
moment that the robot starts
moving the proximity all seven proximity
sensors turn off it goes blind so this
robot cannot move and sense at the same
time it's being forced to sense and then
to quote unquote choose to act and the
moment it chooses to act no more sensory
information they're going to drop uh
single objects from the top of the
screen and those single objects are
going to fall at different angles
towards the bottom of the screen and
they might fall at faster uh or slower
velocities you can probably guess what
the robot is supposed to do in these
cases what's the robot supposed to do in
this particular
event get hit by the ball go catch the
ball catch the ball yeah so you're the
robot you're standing motionless you're
watching stuff the object fall from
above you make a decision you go blind
and you start moving to make sure you're
there when you catch it this is a very
simple Fitness function we've got du
subi on the right hand side of the minus
sign which is telling us
what are they reward is evolution
rewarding for d or penalizing for
DUI peniz penalizing we want to min
minimize DUI DUI is the horizontal
object when it hits the bottom of the
screen pretty simple right minimize that
distance catch the
object okay here we go evolve evolve
evolve evolve at the end of The
evolutionary algorithm pluck out of the
population of evolved cnns the one that
has highest Fitness and drop that c trnn
repeatedly back into the robot under a
whole bunch of different conditions what
are those different conditions they're
going to drop the object so that it hits
the ground at different horizontal
positions in these cases over here the
object uh is going to hit bottom left
part of the screen over here the object
is going to hit the bottom right side of
the screen and for all of those cases
the vertical axis is telling us where
the robot was when that happened the
robot was either at the left part of the
screen at the bottom center of the
screen or at the uh lower right part of
the screen how does the robot
do well but not perfect again right and
for some reason it seems to be having a
particularly hard time with objects that
are hitting uh the midpoint of the
bottom of the screen why who knows
okay I think we'll end with this plot
today same evolve ctrnn we're going to
put it back in the robot a whole bunch
of
times we're going to start dropping uh
we're going to start dropping the
objects and again the horizontal axis
here uh the horizontal axis here is now
going to represent where was the robot
when the object hit the ground bottom
center bottom left or bottom right
the vertical a sorry I misspoke
horizontal axis is representing the
difference between the robot and the
object's position when the object hits
the ground minus 40 means the object hit
40 units to the left of the robot plus
40 means the object hit 40 units to the
right of the robot in most of the cases
here you can see the robot did more or
less the right thing it was directly
under underneath the object when the
object hit the
ground vertical axis here represents the
height of the
robot and the horizontal difference
between the the robot's position and the
object's position you'll notice that for
a while all almost all of these
trajectories are perfectly vertical what
is that mean what does that tell us
about the robot's Behavior Ming the
robot is not moving the object the
object is placed 20° above placed 20
units to the left of the robot at the
top of the screen that object starts
falling and that horizontal difference
doesn't change then it does start
changing when the trajectory deviates
from vertical what what's
happening it's like acting upon its
prediction of where the their object is
eventually going to fall it's acting on
its prediction right it starts moving
which means it's blind at that point how
does it
move continu continuously there's no
shaking left and right anymore it's
constant movement at a constant velocity
until catches the object
why because
it because
is like it's not trying to change for
like what the what like the later
positions of the other like object is so
the robot just decides like it's going
to go to this place and it starts
heading there and there's no there's no
other information to make it like swing
back and forth and scan the air it
doesn't need to sweep back and forth
because it's it's blind it can't see
anything right it's cat whis wh scers
have been cut which suggests that in
these other experiments it was actually
probably useful to be doing this
right so if it's moving a con blind the
whole
timeing it's blind the whole time it's
moving all of these times in which these
trajectories are non-vertical the robot
is moving and it's
blind it has short-term memory it has
short-term memory it knows the moment it
starts moving it moves starts moving at
a constant velocity and it knows that it
that velocity is going to get it right
to the object right when the object gets
there so does that mean that like one of
it neurons or some of them evolve to
have like those
longer like we were looking at how those
researchers had some neurons that have
like longer oh longer term Behavior
versus like shorter Behavior the the
time constant con maybe maybe the CER
has tuned the speed of response of some
of the neurons to produce this slow
stroll at a constant rate to get there
maybe
maybe there's a couple of other details
uh in this plot about the behavior of
this robot we'll save that for next time
you have a quiz due tonight grads you're
working you're starting work on D1
undergrads you're working on A6 see you
all on
Thursday


--- Evolutionary Robotics course. Lecture 12： Active categorical perception..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone Let's uh Dive
Right In uh those taking the course for
graduate course uh for graduate credits
you are now working your way through the
differentiable assignments so far so
good okay assignment six for the
undergrads doing a little bit of
refactoring some spring cleaning before
we push on all good okay all right then
so back to our brief survey of the
history of evolutionary robo
we uh Are we almost finished lecture 9
last time looking at four of the initial
minimal cognition experiments trying to
evolve some of the building blocks of
intelligence into an autonomous machine
we got through three of the four
experiments last time we'll finish the
fourth and final one and then push on to
the last experiment in the minimal
cognition series which is yet another
building block of intelligence active
categorical uh perception
okay so uh again the idea behind minimal
cognition make a very very simple robot
is simple as you can simple physics
simple environment simple body handful
of Motors handful of sensors and let's
set up some environments and some
Fitness functions that select for some
of the building blocks of intelligence
like perceiving affordances then we
looked at uh discriminating between self
and non-self and we ended Last Time by
looking at this example of a robot that
can evolve short-term memory it can move
left and right along the bottom of the
screen it's got seven proximity sensors
but the twist in this experiment is the
moment the motors receive nonzero values
and the robot starts to move lights out
for the robot can't see anymore all
seven of the proximity sensors report
zero for the rest of the simulation and
we ended last time we ended last time
with this figure here as usual in the
midle M cognition experiments we're
playing back the best CNN that we got
back from The evolutionary algorithm the
most fit CNN drop it back into the robot
a whole bunch of times under different
environmental conditions and let's see
how well that evolved CNN allows the
robot to uh uh to generalize to
situations it did not see during
evolution in this case here uh they were
dropping uh an object that falls
straight down from the top of the screen
starting at different horizontal
positions at the top of the screen what
is the robot doing in this
case how well is the robot doing in this
case pretty well
yeah there's a few hints here about what
the robot is actually doing when armed
with this
ctrnn how is it solving this
problem to do like the Lin being
like
am so the robot definitely knows exactly
how much time it's going to take for the
object to hit the ground and how to move
to get there
yeah any other ideas it just seems like
like the closer is like uh like where
like the less units end the later it
starts to move so it's like it's trying
to time it perfectly so it'll hit it
like right last moment almost absolutely
yeah it's kind of showing off again
right it could get there faster but it's
sort of taking its
time you'll notice it does a
particularly poor job with the edge
cases the the two drops from the upper
left and the two drops from the upper
right and those trajectories are drawn
in Gray to show that at the end the
robot wasn't exactly where the object
hit it's having up a bit of a difficult
time with these cases why do you think
that
is is it's ravity like an acceleration
in this case versus like a linear speed
and so like for for cases where it's
close it's not really being affected by
the acceleration versus the far one uh I
you got the you got the tail end of it
here so um this is a very simple simple
physics engine there is no acceleration
the objects are just falling straight
down but you're right there's something
about the edge
cases that's a little bit harder for the
robot just be like motor speed just
there it could be motor speed um again
hiding a lot of details from you this
robot can move a lot faster than you see
here it's choosing to move at this so
it's not limited by its speed yep is it
not allowed to hit the walls there's no
walls there's a black box here but it
could move indefinitely to the left and
the
right any other ideas why is it having a
hard time with these edge cases is it
out of bounds the
sensors remember that these proximity
sensors before they turn off they're
pointed up in a cone so again like like
a cat's whiskers as the objects are
falling straight down the object is
stroking the tips of these proximity
sensors the values are f are firing at
nonzero values for a short period of
time but
then the object
passes uh underneath the cone of
perception here and of course the robot
could try and move to see the object
again but it can't right it goes blind
so in these four cases the robot is only
seeing the object for a very short
period of time it's got less information
and clearly it's kind of making a an
approximate guess about where the object
is eventually going to hit and it's not
perfect right from this point would
giving it the ability to like rotate its
field division would that like just
totally complicate it and make what
currently exist not work probably so if
we suddenly gave this evolve ctrn a a
different sensor motor apparatus so
suddenly the ctrn is getting values from
sensors that move or stay on when it's
expecting them to turn off probably not
going to do uh very well and again this
is the the elephant in the room for all
of AI and Robotics research if something
different happens in the real world from
what happened during training or
Evolution who knows what's going to
happen but usually something not great
is going to
happen okay I think the interest of time
we're a little bit behind I'm going to
skip over this um this kind of is more
or less what we've seen before the the
robot does okay but not
perfect okay let's have a look at one
last example here um so this is again uh
this is again one evolved CNN and in
this upper left plot here they're going
to drop an they're going to drop objects
from above again but they're going to
drop them at a
diagonal
they're going to take the same evolve
ctrnn put it back inside the robot a
whole bunch of times drop the object a
whole bunch of times from directly above
the robot but those objects are going to
fall at different
angles what does this C Evol this one
evolved CNN that we've been looking at
throughout here caused the robot to do
under these environmental
conditions
it seems to like move and then stop and
look again and then move it seems to
move and stop and look again
except the robot can't look again
remember that the moment it starts
moving it's completely
blind so it go it kind of goes to the
point that it predicts it'll fall to um
ver sorry it goes the point where it
predicts it'll fall to on like the
diagonal path okay not accounting for
the actual angle of the
turn could
be any other
observations what's with this zigzagging
motion you're right it's sort of it
stays still so all of these trajectories
that don't change angle until a certain
point this is the robot staying still
and presume presumably looking at the
object and quote unquote thinking about
the object integrating some information
over time combining what it's sensing
with memory and then it starts moving
which is what these jinking lines here
mean why is the robot moving and then
reversing course and then moving and
reversing course and getting there right
when the object hits is it like someone
ball and of move from side to side to
Maxim
cover is it that sort you're trying
to you're not quite so you
go you could right if your eyes are open
right you're going back and forth and
trying to estimate remember that as the
robot is jinking back and forth it
started moving it's completely
blind can it see during the SE when it's
not moving like between the two no it
can only see at the beginning so if
sorry this is a good point it it sees as
long as it stays motionless the moment
it starts moving it goes blind and if it
stops moving again it does not suddenly
see again it remains blind I'm sorry
that's an important detail it's blind
throughout these periods in which it's
moving back and forth but successfully
ending up where the object
is
why doesn't it move straight towards the
object at a constant rate as it does in
the case when the object is falling
directly from
above I'm throwing you a fast ball very
early in the morning this is a tough one
it's a bit of a trick question there's
no reason there's no benefit to moving
back and forth back and forth and
getting to the object and catching it
compared to moving at a constant rate
and catching it the only thing we said
is catch the ball make sure that your
horizontal distance is zero when the
object hits the ground be where the
object is the fitness function says
nothing about how the robot should move
to get there so in retrospect we get
back things that seem very inefficient
right why this extra
motion I wanted to spend a minute just
focusing on this point because this is
one of the uh inevitable results we get
from anything that's evolved you get
some things that are inefficient as long
as they're not an actual drag on the
organism or the machine yourself your
bodies and my body are filled with
inefficiencies we're not perfect mother
nature often leaves things just as they
are unless there's a very strong reason
to clean up or make that behavior or
that piece of physiology more efficient
this might matter for robotics we don't
want robots that are moving around in
the real world at very high
accelerations and decelerations and
doing extra stuff we'd like them
generally speaking to do just what we
want them to do and no more it's not
easy it's not trivial to make sure that
robots always do what we want them to do
in sort of the most efficient calm
constant predictable way other day sure
doesn't necessarily work that way is
there an idea just like across most of
the things of like just minimizing like
energy expenditure okay minimizing
energy expenditure so we may or may not
get to our uh lecture 11 today on the
biomechanics of motion absolutely when
we're talking about physical robots that
are big and heavy that have to move
around Energy Efficiency is pretty
important so things like this tend to go
away but there are other more subtle
ways of being inefficient and a little
bit unpredictable if you're the result
of an evolutionary process but a good
good point this is just sort of one of
the more obvious examples we're going to
see of this side effect of evolving
machines in this course yep if you
wanted to sort of let's say train out
some of that inefficiency would you
choose to adjust the fitness function or
cre
where that efficiency is naturally not
SEL or selected for or maybe both that's
a great question so if we wanted to get
rid of it where in The evolutionary
process would we put something to get
rid of it we could build a term into the
fitness function that penalizes for
Jewels actual amount of energy that's
used or we could create an environment
in which the best way to do the right
thing most of the time is to move in an
energy efficient manner um it's a great
question there is no one good answer to
that it is still an area of active
investigation if you want a machine to
be reliable energy efficient don't
accelerate decelerate suddenly how do
you go about ensuring that that happens
under conditions that it didn't see
during Evolution or during machine
learning training not an easy thing to
do good question okay let's keep going
all right fourth and final event that
we're going to look at um this is my
favorite one this is selective attention
this is something that we humans also
struggle with not an easy thing to do
let's have a look at our minimal robot
here again we have a minimal robot that
has two uh rockets that exert thrust to
move the robot back and forth along the
bottom of the screen you'll see that
it's seven proximity sensors are drawn
with solid rather than dashed lines this
robot does not go blind when it starts
moving it can move and sense at the same
time as always we're going to drop some
objects from the top of the screen in
this uh in the selective attention
experiment we're going to drop pairs of
objects but these objects are not
connected together they fall
independently as you can see from the
black dashed arrows here this particular
object is falling down into the left at
a slightly slower velocity than this
object object which is falling uh down
to the right at a faster velocity given
this cartoon Which of these two objects
is going to hit the ground
first one's closer but Falling slower
one's closer to the bottom of the screen
but Falling slower the other object is
further away from the robot but Falling
faster which one is going to hit the
ground
first um
is there is there like it would be the
object that has the um least distance to
fall to velocity ratio correct did you
have an idea in the back there I
was absolutely right so this is a
cartoon you kind of have to eyeball it
but it gives you a sense of the problem
here the challenge right you're
eyeballing this the robot's going to
have to do more or less the same thing
it's going to it's going to be able to
collect information and try and figure
this out it's got to
select Which object to attend to it's
going to see these objects and these
objects one's going to be closer to it
than the other which one does it go
chasing after first the fitness function
over here as you can see on the right
hand side of the equal sign there are
two terms and uh it shouldn't take you
long to figure out that these two terms
are selecting or are rewarding for the
robot minimizing its horizontal distance
to the first object when that object
hits the ground and
then minimize its horizontal distance to
the second object when the second object
hits the ground by first and second
object we mean the first object to hit
the ground and the second object to hit
the ground make sense
okay okay
uh a student who took this course
several years ago actually tackled this
as their final project and uh coded this
up in uh at that time we used open
Dynamics engine a different physics
engine so here is an evolved uh CNN
controlling a robot in the OD physics
engine that has evolved to successfully
exhibit selective
attention
you can see that some of these
environments are easier than
others
question so with this is all that
matters that the two circles are in view
at some
point all that matters is they they're
in view at some point right if one of
these objects never
touches any of these seven proximity
sensors or are never registered by any
of the seven proximity sensors the robot
by definition doesn't even know there's
a second object let alone know where
it's where and when it's going to
hit is the number of like kind of I I
guess recur that's not the word that you
use for like the connections to give
memory the recur recurrent Connections
in the ctrn give the robot memory Y is
there like a limit on how far like do
there like to remember like 50
iterations down the line that's a great
question so if you incorporate recurrent
connections into a ctrnn and hopefully
most of you realized that first of all
this ctrn does have recurrent
connections because the robot needs
memory in order to solve this task great
question how long can it remember
for turns out that even with a few we
won't do the math on the board but even
with a few recurrent connections if the
if the synaptic weights of a CN and the
time constants are tuned correctly by
Evolution it can remember for a pretty
long period of time it keeps passing uh
what it remembered from the previous
time step on to the next time step and
it keeps doing that you can kind of
actually work it out with pen and paper
if you're interested clearly it does
need to remember for quite a while right
I see both and I decide that I think I
think this one's going to hit first so I
go over to capture this one and I can no
longer see this one at all I need to
remember a bunch of things which side of
my body was it on when did I last see it
where was it how fast was it falling and
off I go and depending on how these are
falling I might need to go do something
over here for quite a long time from the
robot's perspective before it's able and
allowed to go back and do that yeah I
don't know about you all but every
morning I open up my to-do list and then
my stom just drops the number of things
that are on there I look at the one at
the top is that the one that's going to
hit the ground first in that any given
day maybe not I move it down move
another thing then suddenly a text comes
in does this go on the list what am I
doing after class I don't know selective
attention tricky for humans to do right
what are you going to do with the rest
of your day what's on your to-do list
how you to prioritize I often chase
after one task and completely forget
what the other one was and try and
recover and not an easy thing to do okay
David was very successful with this
project he and his robot make this task
look easy as you can probably guess it's
not easy by all means tackle this for a
final project but it is not one it is
not an easy option doable clearly but
not easy okay okay so what exactly is it
that makes this problem so difficult
like many non-trivial tasks us
intelligent machines uh try and Tackle
in the real world you can break that
hard problem down into multiple slightly
less hard sub problems there are two
important sub problems that any agent
needs to be able to uh succeed at in
order to succeed its selective attention
as a whole the first one is the passing
objects problem there may one object
that is initially further away from me
it feels like a less urgent task I can
worry about it later but wait a second
there's something about that distant
either literally or figuratively distant
task that tells me actually I should
attend to that one first it's actually
going to be the one that's going to
erupt uh sooner in the future than the
other one got to I've got to figure that
out first I can't just chase after the
one that's close
wouldn't that be nice that would be a
very easy way to deal with lots of
things throughout your day not so
simple then there's the object
permanence problem one of you comes up
at the end of class and asks me a
question verbally I tell you that I'm
going to respond to it later in the day
when I get to my email I go do a
thousand and3 other things and
completely forget to write you back the
object permanence problem right how do
we mentally juggle things that we've got
of remember to go back and attend to
later not easy in the minimal cognition
experiment we can make these cognitive
problems actually literal and watch the
robot evolve the ability to solve them
or not solve them make
sense okay all right so as always in the
minimal cognition experiments they
evolved and evolved and evolved and
evolved C tier and ends to get better
and better at the task and then plucked
the most fit CNN out of the last
generation of the evolutionary algorithm
dropped it back into the robot one two
three four five times and during those
five evaluations of that evolved ctrnn
they exposed it to increasingly more
difficult environments so in this
particular task we can actually quantify
the difficulty of an environment based
on whether or not that environment
challenges the robot to neither one or
both of these sub
problems here we go let's have a look
let's start by taking this one evolved
CNN we're going to drop it into the
robot and put that robot into an easy
environment it does not need to solve
the passing OB objects problem not Po
and it does not need to solve the object
permanence problem not open P what does
it mean for the robot to not have to
worry about the passing objects
problem the lower one is if they're
moving at the same speed they could be
moving at the same speed whatever it is
the one that's
closest is going to hit the ground first
right just go after the closest one that
makes it easy okay it also doesn't have
to solve the object permanence problem
what does that mean what does that tell
you about this
environment
they could be moving at the two objects
could be moving at a similar angle so
that they're always in view however it
is that the RO the objects are moving
the robot can more or less easily keep
them in
view this particular figure here is
drawn so that you can see that reality
so again it takes a little bit to parse
some of these minimal cognition figures
so we'll take our time
here you'll notice notice that there uh
there are two straight black lines
descending from the top of the figure
one of them descends to halfway down the
figure and the other straight black line
descends all the way to the bottom of
the figure and vertical axis here is
showing us time increasing as we descend
this figure what do those two straight
black lines
represent
the path of the object right why does
this first black trajectory stop at a
certain point what is that telling us
that the robot CAU it not necessarily
the robot C we're not even talking about
the robot yet just the two
objects that this this whatever this
object was it was falling straight down
and hit the ground at this time yeah
this object over here is continuing to
fall and it hits the ground at this time
the end of the
simulation what is the jinking black
trajectory
representing robot the robot's movement
right so tell me what the robot did in
this
situation how well did the robot do in
situation it's showing off again right
it figures out very quickly that it's
this object that's going to hit the
ground first which is the closest object
to it and it's jinking back and forth
underneath the object and then the
moment that it quote unquote catches the
object what is the robot
do straight over and again is showing
off going right staying right underneath
the object and catching
it what do the two gray parallel
represent what are the authors uh
illustrating here the darker gray
represents the object that's going to
hit the ground second and the lighter
gray represents what's going to hit
first uh you're right in the sense that
the two parallelograms correspond to the
two objects but not where they're going
to hit that's the tra that's what the
black the straight black trajectories
are telling
us it's got It's got to do with the
viewing angles it's got to do with the
robot's perception what exactly about
the robot's
perception uh that's a good guess they
could have probably visualized where
they think the robot is going to
hit the cone of view so if you imagine
taking a horizontal cut at any height
through one of these parallelograms what
that means is that the robot could be at
any point along that horizontal cut and
see that object the light gray
parallelogram corresponds to the object
that's going to hit first so let's take
this horizontal cut right at the top of
this figure this means the robot could
be anywhere at at these horizontal
positions at the bottom of the screen
and comfortably see the
object why are these P parallelograms
narrowing as time progresses in the
simulation
biger the the object reference to the
robot true the object is getting bigger
from the point of view of the robot
also absolutely right as as these
objects are approaching the stem of the
cone of perception there's a narrower
width through which the robot can move
and still see the object assuming it
wants to see it which it doesn't
necessarily need to do okay everybody
now see how to read these
figures okay all right you'll see that
the jinking trajectory stays within the
parallelograms the whole time actually
while there are two
parallelograms the uh robot is staying
within both of them which means it sees
both of them at the same time everybody
see that so no object permanence problem
it's easy for the robot to watch both
objects while waiting to catch the one
that it knows is going to hit the ground
first easy peasy the the Evolve ctrn
enables the robot to solve this task no
problem let's make things a little bit
more difficult and take the same evolve
CNN play it back in a different
environment in which now we're going to
expose it to one of the two sub problems
we're going to we're going to drop these
two objects at a different angle and
velocity so that now the CN is going to
be challenged to solve the passing OB
passing objects problem but still
doesn't need to worry about the object
permanence
problem when does this passing objects
problem
occur Dash horizont L the dashed
horizontal line is telling us the moment
at which the further object which is
falling faster passes the closer but
slower moving object yeah how is the
robot
doing
yeah is it still showing
off kind of you'll notice that at least
be above the dash line so this is what
where when the object that's going to
hit first is still further away from the
robot it kind of looks like maybe the
robot doesn't know right it's kind of
jinking back and forth under between the
two objects that are above it and it's
still doing that for a while but drifts
over and catches the first object and
then goes over and catches the second
one when does the robot know what's
going to happen when does does it
realize that the object that's further
away is going to hit the ground
first when it's no longer further away
looks that way right the robot could
actually be lazy in this case and just
wait wait until this happens sort of
watch both of them and say aha now
there's an object that's closer to me
and falling faster now it's easy and I
know what to do thinking about thinking
is misleading it's not quite clear the
robot might actually know beforehand
it's just not telling us that with its
Behavior who knows okay let's look at
the converse case same evolves CNN no
passing objects problem so the object
that's closer to the robot at the
beginning is falling faster but there's
an object permanence problem how
so yeah when the first object lands it's
in a situation where the robot cannot
see the second object absolutely right
so when the robot catches the first the
object that hits first that uh the the
cone of perception can see that first
object but now the robot is outside the
darker parallelogram so it doesn't it
cannot see that
object did it know where the object
is absolutely right just goes racing
over here and gets there with more than
enough time to capture the
object okay let's make things hard
passing object and object permanence
problem you can see the two straight
black lines are falling away from one
another so the objects are falling and
also increasing their relative
horizontal distance as they fall there's
our dashed horizontal line so one point
the further faster object passes the
closer slower object
how does the robot do in this
case it does well right it's kind of
showing off it knows it gets there in
plenty of time and then races over to
catch the other one and gets there just
in the nick of
time um for the robot moving back and
forth is it like possibly being impacted
by Randomness where it's not exactly
certain that like it's calculating the
velocities correctly so it's keeping its
options open to try to catch one object
or the other yeah that's a great
question the question is about is there
Randomness in the environment and maybe
it's not sure again I've left that
detail out no Randomness in in these
environments these are minimally complex
they've tried to remove everything they
can including Randomness which is
something that exists in the real world
do you know how the rememb where the
other object is or is that something
evolved in the CN it evolved in the
ctrnn who knows right you could probably
crack this open and spend 20 years
trying to figure out what's going on and
it's hard it's hard to see it in the
brain we can only really see it in the
behavior of the the robot did they have
to build
framewor all they told the robot all
they told the evolutionary algorithm is
evolve a CN that minimizes these two
terms that's it The evolutionary
algorithm is discovering sets of
synaptic weights time constants biases
gains that allow the
ctrnn
to allow the robot to achieve the task
nothing nothing in here explicitly says
do it by remembering do it by moving
back and forth in if you're uncertain be
sure to go chase after it as soon as
possible take as much time as you want
none of that just here's what we want
you figure out how to actually do
it um is like this is the speed of the
robot at all a limiting factor of like
like I see it has this like long
diagonal L if the motors were like more
powerful could it just get there quicker
that's a good question um I it's unclear
from the paper the authors were
insufficiently detailed it's not clear
whether this robot could actually move
faster in the video I showed you from
David's final project that was the
fastest the robot could move it it was
definitely hustling in here I'm not
sure other questions or
comments okay so we made things pretty
hard on the robot and it still did
excellent the fifth and final case we're
going to expose it to the passing
objects problem and the object
permanence problem again but we're going
to make both of those sub problems hard
how you can actually see how this task
is more difficult than this task the
robot can only see both of them at the
very beginning absolutely there's only a
very short time window in which the
robot can see both at the same time What
Happens immediately after that window of
time has
elapsed it knows it knows right somehow
now what it could have done it doesn't
there's nothing in here that says the
robot has to look at both at the same
time and compare uh the direction in
which they're falling and the speed at
which they're falling it could in theory
if it was quick enough go back and forth
and look at one and then look at the
other and then look at one and then look
at the other and still solve this task
but it looks pretty much like this robot
has quote unquote decided very quickly
the ctrnn has evolved to to compare uh
what it's to compare when it's looking
at both objects at the same time races
over and catches this one but this one
is falling away from where the other one
is this robot quickly reverses course
and gets back just in time to catch the
second
object all good okay all right that
concludes our lecture on minimal
cognition
in my personal opinion it's a shame not
many other people other people in the
community have followed up on these
experiments this feels to me like a good
way solid way to make progress on making
incrementally smarter and safe machines
right what you just saw was a whole
bunch of different ctrn that enabled the
the robot to do individual building
blocks of cognition you could imagine
revisiting the minimal cognition
experiments and combining some of these
Fitness functions evolving robots to
selectively attend and distinguish
between self and nonself and then also
perceive affordances and and and and and
maybe we could construct a very long
running evolutionary algorithm where
over evolutionary time we keep adding
terms to the fitness function to select
for more and more of these cognitive
building blocks and gradually build up
smarter and smarter and smarter machines
while ensuring that in a lot of
different other conditions they still do
more or less what we
expect how well do these things actually
like build on each other though like ex
nobody knows they were all done in
isolation how well do they build on one
another is it easier to evolve a robot
that selectively attends and then
evolves the ability to perceive
affordances or is it easier for
evolution to avoid a evolve a robot that
perceives affordances and then evolves
the ability to selectively attend what
order should it learn these things in um
if you're interested in machine learning
there is a whole branch of machine
learning outside of Robotics that
focuses that studies exactly this it's
called curriculum learning right in our
faculty meetings we argue all the time
about what order of courses you all
should take you need to take CS ABC and
then CDE it's not so obvious sometimes
to know in which order to learn things
so that you build more complex compet
competencies on top of simpler ones
tricky to do for humans also tricky to
set that up for machines yet another
open problem in robotics and
AI okay so we're going to dive into
lecture 10 now where we're going to look
at a fifth and final building block of
intelligence which is active categorical
perception this task is is uh not really
minimal because the robot that we're
going to look at is definitely not a
minimal robot it's got a pretty complex
physiology we'll come back to the robot
in a moment but first let's talk about
ACP I want you to uh I want you to join
me in the following thought uh um
hypothetical
experiment I'm going to Place several
objects in front of you but you're
blindfolded
and I want you to I'm going to give you
a task which is separate the round
objects from the edged objects you've
got blindfold on so you don't know what
these objects actually look
at you need to solve this task you need
to categorize you need to perceive and
categorize the round objects from the
edged objects what do you do what
actions do you perform to C between the
round and the edged
objects most people most human subjects
when they're given this actual problem
they grasp the object pick it up and
hold it I don't this one feel I don't
know but put their hand on top and go
back and forth like this and what
happens if you were to place your hand
on top of each of these objects one
after the other and do this motion what
happens some some of them roll and some
of them don't suddenly we have a binary
category some are rollable remember
affordances from last time some of these
objects are rollable and some are not if
you look at these objects obviously
there is no binary distinction right
there is a gradation from round to Edge
where does this category come
from it's almost like a magic trick
there is no set of round objects and a
separate non-overlapping set of edged
objects here and yet when you
interaction with interact with them
there it
is where does this set come from from
importance it's not the category is not
necessarily in the objects themselves
the category is in the relationship
between in this case not just an
observer but an active participant who
is manipulating the objects right you
categorize things tens of thousands of
times every day right friend foe cable
object non- citable object we're doing
it all the time we categorize things in
the world but in the world itself there
are no categories right they they arise
from the way that we interact with the
world
and Mother Nature has tuned our bodies
and brains over Millennia and Millennia
to exploit that phenomenon so that we
keep going and survive and reproduce and
so on so the idea behind active
categorical perception is as we move
about in the world or as we'll see in a
moment as machines move about in their
world they have a need to do this to
understand the affordance of affordances
of things what things are safe and what
things are
dangerous Mother Nature has tuned our
bodies and brains so that we interact
with those things in a certain way that
causes us to discover that category and
hopefully Discover it quickly especially
if we're trying to distinguish between
safe and not safe I have a two-year-old
at home and he's very interested in the
knives that are up on the kitchen table
right he's got to figure out the
difference between edged and non- edged
objects there's an infinite number of
actions that he can choose in which to
learn that lesson most of them are not a
good way to learn that lesson right we
have been tuned luckily so that we
choose particular actions and ways to
interact to learn these categories as
quickly and safely as possible as we do
as we learn to literally reach out and
manipulate objects in the world around
us
over time in in the human species over
years and years we learn to start to do
that interaction more and more from a
distance I'm categorizing which of you
is actually paying attention and which
isn't and luckily I don't need to reach
out and actually manipulate you to
figure it out I can categorize from a
distance how do we learn to get so good
at categorizing from a distance we
learned from when we were little
creatures by doing it actively
manipulating objects and feeling these
category literally feeling these
categories
arise it's easier to categorize objects
when we physically interact with them
than it is to categorize objects by
looking at them from a distance it
probably doesn't feel that way to you
because you've been doing it for a long
time it feels like categorizing things
in your world from a distance is super
easy thinking about thinking is mislead
in what's it called when when we're
younger we're we're doing things in a
certain way where it's easier and then
as we get better and better at solving
that easier task that sets us up to be
able to do it do the same task but in a
more difficult way we've heard this
phenomenon we've encountered this
phenomenon several times already is this
scaffolding this is
Scaffolding in Psychology the dominant
theory is that for a lot of intelligent
agents
ACP
scaffolds distal perception being able
to perceive sorry distal categorical
perception being able to categorize from
a distance it's still a theory there's a
lot of evidence from years and years of
observing little humans and big humans
this is something we could test in
robotics we're not going to test that
today we're just going to look at a
robot that's evolved to do
ACP sound good is that even like a
reason reble thing to distinguish
between active and distal categorical
processor because it's still an action
to move your eyes across great yes so
cam has swallowed the red pill
everything everything is embodied right
in an action even when we look around in
the world you are scotting the muscles
in your eyes are moving your eyes so
your eyes are jumping around and
touching different things in your visual
field yes it's not really it's not that
it's non-embodied
and it's not that it's passive it's
probably not a good term you're right
it's all active let's let's say proximal
going up and actually doing it close up
and personal and distal doing it from a
distance that would have probably been a
better uh pair of adjectives to describe
these two behaviors one I com to like in
robots isn't is is the finess of touch a
lot more difficult to do than like
distinction visually
great question so super easy to slap a
whole bunch of cameras onto a robot and
get tons and tons of highresolution data
at a high frame rate not so easy to make
skin for robots so that when the robot
touches something it gets Rich high
resolution data there is a whole
subfield of Robotics uh basically filled
with chemists and material scientists
and mechanical engineers that are making
sensitive skin for robots for exactly
reason okay all right so regardless of
whether we're talking about organisms or
machines If an organism or machine an
agent wants to succeed at ACP that agent
has to choose actions that reduce within
category differences when you sweep push
your your palm left and right along
across the top of these objects the ones
that are rollable start to feel similar
to you you feel this object and this
object and this object and this object
all rolling they're all rolling you're
feeling the collapse of within category
differences these objects are different
geometrically different but when you
interact with them in the right way that
difference feels less make
sense you're also trying to magnify
between category differences rollable
objects feel similar and non- rollable
or slidable or pushable objects feel
similar and those two sets of Sensations
are
different there's an infinite number of
ways that you could touch or manipulate
this these objects that do not do these
two things they all feel different they
all feel the same we're looking and
we're going to see in a moment evolution
is going to look for ways to move the
robot so that that robot reduces its
felt within category differences and
that those actions magnify the robots
felt between category
differences make
sense okay off we go all right let's
talk a little bit about the robot itself
we're going to as we've seen now several
times we're going to evolve populations
of CNN's we're going to take each CNN
and drop it into this robot lot o uh and
each CNN we're going to evaluate that CN
eight times we're going to replay that
CNN um eight times on the
robot uh in the first four cases in the
first four environments we're going to
place a sphere underneath the palm of
the robot but for each of these four
sphere placements we're going to place
the sphere at different rotational
angles which doesn't make a lot of sense
because it's a sphere it's radially
symmetric so from the robot's point of
view it doesn't feel any of those
differences in the fifth sixth seventh
and eighth evaluation of the ctrnn we're
going to place an ellipsoid underneath
the robot's uh Palm a little egg and in
each of those trials we're going to
start by placing that egg at a different
horizontal angle underneath the Palm
underneath the palm of the
robot everyone getting what this game is
the robot's going to have to quote
unquote tell us is it touching a sphere
or an
ellipsoid uh sorry I misspoke we're not
going to play each CNN eight times we're
going to play each CNN 16 times we're
going to start by setting the robot's
arm and hand to this initial position
eight times for these objects and then
the the 9th through 16th trial of a cinn
we're going to start those trials by
putting the robot's arm and hand to this
set of initial conditions and then again
expose it to these eight eight objects
question why did they do that why didn't
they just evolve the ctrnn to
distinguish between spheres and
ellipsoids with one initial setting of
the arm and hand good question
why different scenar in different
scenarios they're going to try they're
they want this robot to be as robust as
possible that under different conditions
under different conditions of the object
itself and possibly the robot and
therefore different conditions about the
initial initial relationship between the
robots posed and the object that it can
tell whether it's in contact with a
sphere or an
ellipsoid make sense okay all right
let's have a look at the robot's uh body
itself this is uh if you look at the
title of this paper uh active
categorical perception in an evolved
anthropomorphic robotic arm
anthropomorphic meaning in the shape of
an anthro in the shape of a human so
they're building in uh some additional
uh human physiology here let's look at
it luckily for you this should be
relatively familiar um we've got a
shoulder elbow and wrist and I'm sorry
this might be difficult to see from the
back of the room so I'll just turn out
the lights for a minute you'll notice
that there are actually two joints at
the shoulder in this robot they're going
to simulate all each individual joint is
a rotational joint like we've talked
about many times before already if we
put two of them together in the shoulder
that allows the robot's shoulder to do
this and to do this so the robot's
shoulder can basically do this you have
a third degree of freedom in your
shoulder which is this one right so you
can do this the robot can't it can only
do this so it's not quite human but it's
getting closer question so in simulators
do you actually just put two joints in
The Identical location with like
different
uh yeah so you can try this you can
actually try this out in pi bullet if
you want you can you can create one
object and connect it to you can create
one link and connect it to a second link
with a joint where that second link is
just a little sphere sitting inside the
shoulder and then you connect that
little sphere to another joint to a
third joint uh sorry connect it to a
third link with the second joint that's
at exactly the same location and you can
get this
if you think about it and play around
with it and pball it you can add three
in the same place and you can get a full
shoulder
joint Okay so we've got two motorized
joints in the shoulder um we've got a
third joint in the upper
arm it's not your elbow there's your
elbow it's not your shoulder show me
what it's simulating here exact it's
elbow is the fourth motorized joint that
one makes sense there's another one in
the forearm fifth one in the forearm
show me which one that one is we're
getting our stretching in this morning
yeah it's this this one here that's
number five six and
seven wrist this and this but
not uh that's that's number five right
five six seven good I can see you all
waving there you go you got the idea
okay so we're up to seven motorized
joints we're g to we're going to arm
this robot no pun intended in a moment
with the ctrnn we've got seven motor
neurons and then we got a whole bunch of
things going on in the
hand in the human body there is one part
of your body in which most sense organs
are localized second most uh part of
your body in which you have localized
sense organs the palms of your hands
because we're primates and we learn a
lot about the World by grasping objects
like this right okay let's see how this
works we've got if you can you might be
able to see this from the back 1 2 3 4
five 6 7 8 9 10 additional
joints which are uh causing the arm to
pull get I'm sorry I misspoke sorry 1 2
3 4 5 6 7 8 9 10 these are these little
gray circles these are 10 touch sensors
in the hand if you look carefully you'll
see there's a whole bunch of light blue
cylinders these are all
joints these are not independently
motorized joints you can move your
shoulder and not move your elbow you can
move your elbow
and not move your shoulder you have
independent muscle groups in your arm I
challenge you to move your I'm going to
turn the lights back on now I challenge
you to move your distal fangi which is
the tip of your finger and don't rotate
your intermediate and proximal fangi the
two bits of your finger that are closer
to your hand most of us cannot do it
there are some people that
can so we've got 20 I don't know how
many it is there's a whole bunch of
joints motorized joints in the hand
they're going to assign to all those
motorized joints one motor
neuron at every time step in the
simulation and I'll play the simulation
for you that motor neuron is outputting
one floating Point number and that
floating Point number is going to all of
the motorized joints in the hand
simultaneously which causes the hand to
do the robot's hand to do
what this yeah now of course we can do
this our fingers are independent they're
going to kind of sweep that detail under
the hood so a fair bit of human
physiology built into this robot why did
they do it I don't know maybe just for
fun could you
exp yes yes yes yes so um there's one
two three joints in the thumb and then
one two 3 one two 3 one two 3 one two 3
in the remaining four fingers so there
are 15 motorized joints in one hand of
the robot so far so good so you can
imagine coating this up in py bullet in
in pyrro Sim 15 motorized joints in
everything we've seen so far there was
always one motor neuron assigned to each
each motorized joint right in this case
there's one motor neuron that fires and
that that whatever that floating Point
number is coming out of the motor neuron
it's copied 15 times and sent to the 15
motorized joints so that they all apply
identical
torque which causes this this this this
this this this this robot cannot move
its fingers
identically make sense
okay all right that's the body of the
robot let's switch and look at the brain
of the robot this robot has a total of
one 48 total neurons in the CNN so its
brain has 48 neurons in it this is a CNN
so down here we've written out the
ordinary differential equation for the
ith
neuron since there are 48 neurons that
means there are 48 differential
equations that describe the behavior of
the CTI andn for this robot so far so
good okay I like this picture I like
this figure from the paper because they
bounce back and forth between the
mathematical description of a ctrnn and
a visual depiction of the CN so these
two things are identical if you still
feel Rusty about OD and C TNS and time
constants this is a good figure to put a
few minutes of effort into okay here we
go let's start with the visual
depiction this should be familiar we've
got a sensor layer here this robot has a
total of 22 sensor neurons uh in there
and here's the uppercase i sub this term
is sending in that that sensor value to
that s
neuron we've got 23 24 25 26 27 28 29 30
we've got eight internal or hidden
neurons and then we've got a whole bunch
of motor neurons up here so
actuator actuators Motors means the same
thing and then we've got two neurons out
here the last two neuron 47 and 48 these
are the categorizations
neurons the robot is going to light up
these two neurons to tell us whether it
thinks it's in contact with a sphere or
an
ellipsoid so far so good okay we've got
seven proprioceptive sensors in the arm
where are they what are they
reporting what in the arm are they
reporting
position or angles of the joints right
proception is joint angle so we've got
all the seven arm angles coming into the
brain of the robot we've got a total of
10 tactile
sensors the 10 touch sensors in the palm
of the hand and this is how they're
distributed throughout the palm of the
hand of the
robot and uh did I get that wrong hand
oh and hand propri receptive sensors
we've got five proi receptive sensors in
the hand where are those five propri
receptive
sensors tips of your fingers it it could
be the tips of the fingers it's not
clear from this picture it's the
curvature of the finger remember that
the finger the different parts of the
finger are all curling in together so
we've got five numbers reporting the
curvature of the five fingers but I just
finished telling you that each hand has
one motor neuron which closes or opens
the entire hand so why does it need five
numbers it's kind of like the difference
like in a so when it tries to squeeze
some objects are GNA
like I I guess like the hand squeezing
would like meet resistance the hand is
going to meet resistance depending on
exactly the minute it interacts with the
object that it's trying to categorize
those curvatures of the finger are going
to change right that's some pretty
important
information what's that it tells you
like the shape does it does it tell you
the shape maybe may be depends on how
you grasp the object I could grab the
object the top of the sphere and the
ellipsoid like this not so much I could
go like this and maybe it does there's
actually an infinite number of ways that
I could grasp an object some are better
than others at helping me to reduce
within category differences and
exaggerate between category differences
yeah yeah
okay okay uh so those are the sensor
neurons they're all sending their
floating Point numbers into the hidden
neurons what is this Arrow that's
curving back on itself telling
usur recurrent connection so this robot
May evolve the ability to remember if
that's
useful yeah I'm hiding that detail from
you this is the whole punchline of this
entire experiment the way they're going
to handle 47 and 48 is everything in
this experiment we'll get there in a
minute um for like the the architecture
of the
crn is there a reason they only have one
hidden layer versus like wouldn't having
just a little bit
yeah so that's a good question we could
add multiple layers of hidden neurons
and turn this into a deep
ctrnn as the Deep learning revolution
has taught us there's good reasons to do
this they didn't do this in this
experiment and this experiment was
published when the Deep learning
Revolution was just
starting okay all right we've got 14
motor neurons assigned to the arm that's
strange 14 motor neurons but there's
only seven
joints there's two motor neurons
assigned to each
joint this we also have not seen before
this seems strange why any
ideas is it so you can hold it in
specific positions because they'll have
two lock me up in certain spots so like
you can get like stuck here or here it's
like trying to keep moving all the way
in it just like stop you're getting
close right so we've got two motor
neurons that are sending values and kind
of tugging on the same motorized joint
remember that they're trying to create
an anthropomorphic robot a robot that in
in uh that instantiates some human
physiology what human physiology are we
talking about in this case that our mus
can only in
one the 14 motor neurons in here
although it's not shown on this figure
they only out put positive numbers they
pull with more or less Force this is
known as uh
antagonistic and
agonistic
agonistic muscle groups in all the major
muscle groups in your body they're all
arranged in pairs your bicep when it
pulls it flexes your arm in your tricep
when it pulls you extend your lower arm
muscles are like ropes they can only
pull they cannot push so all the major
muscle groups in the human body arranged
in pairs in which they antagonistically
or agonistically uh pull on the
motorized joint that's what they're
adding here do they actually need this
detail for this experiment absolutely
not they probably just put it in for
fun Okay Hand actuators we we I told you
that there's one motor there's one motor
neuron per hand I lied there's actually
two why
two is it like a push and a pull not a
pull push on the inside and then a sorry
a pull on the inside and a pull on the
outside same thing they're simulating
roughly Agonist and antagonistic muscle
pairs in the
hand okay so someone asked in the back
about uh ner neurons 47 and
48 let's have a look at those now so any
questions about the CNN it's actually
pretty much like everything we've seen
before just with some
additional uh anthropomorphic details
okay we got five minutes left so let's
dive in and talk about neurons 47 and 48
as was pointed out a moment ago they
could have got away with just one neuron
and they could the investig s could have
decided that the robot gets a fitness
point if when in the presence of a
sphere this neuron is negative and when
the robot is in the presence of an
ellipsoid this neuron should be positive
for example right they could encode that
as the way for the robot to tell us
whether it thinks it's in contact with
the sphere or an ellipsoid they could
have done that they didn't do that
they've got two
neurons with two neurons neurons you
could do something like if neuron the
value of neuron 47 is larger than the
value of neuron 48 that's the robot
telling us it thinks it's in the
presence of a sphere if the value of 48
is larger than the value of 47 that's
the robot telling us it thinks it's in
the presence of an ellipsoid could also
do that it's not what they did let's see
what they actually did they did
something much more complicated and I'm
going to draw this for
you we're going to draw this visually uh
in two Dimensions we're going to draw a
plot where we're going to uh we're going
to look at the values of neurons
47 and
48 I'm going to put y sub 48 and Y sub
47 to just remind us that we're going to
be looking at the value of the 47th
neuron and the value of the 48th neuron
let's imagine at uh let's imagine at the
beginning of a simulation we put the
robot's Palm on top of a sphere the
robot doesn't know yet whether it's in
contact with the sphere or an ellipsoid
and at the very first time step of the
simulation sorry we're going to put it
uh yeah we're going to put it in contact
with uh a sphere it doesn't know whether
it's in contact with either it's the
very first time step of the simulation
so the value of 47 is zero and the value
of the 48th neuron is also zero and now
the robot starts moving the ctrnn
transforms sensation into action and
suddenly the value of neuron 47 and 48
changes to a pair of nonzero
values time Step Zero time step one time
step three 4 5 6
7 and we get
trajectory in two-dimensional space
where the trajectory is showing how
these two values change over time over
the lifetime of a single simulation of
the robot in contact with the sphere so
far so good if any of you have taken a
dynamical systems course before this is
a way to visualize a dynamical system
meaning any system that changes its
Dynamics or its motion over time what is
this visualization called there's a name
for
it no okay uh if you do take uh
dynamical systems of course this is uh
sorry this is a phase diagram just in
case you hear that
term it's a nice way of showing how a
system changes over time okay let's
imagine this is the robot in contact
with um the sphere and we're going to
look and we're going to record uh we're
going to record the uh we're going to
look at the lowest and highest value of
47 and the lowest and highest value of
48 during the last 5% of the simulation
so this is the last 5% in here we
started with t subz down here and we
went to T final down here this is the
let's see this is the maximum value that
47 ever achieves during this short time
window and the minimum value of 47
during the shorttime window is this
little Point
here during this short time window here
the lowest value of 48 is this point
here and during this short time window
the maximum value of 48
is this point here that gives us this
little bounding box in two-dimensional
space and we're going to call that
little bounding box R sub it's the
rectangle that we place around the
spherical uh
object so far so good okay seems a
little strange for a moment bear with me
was there a question yes are you looking
at the of the we're looking at remember
that each point on this trajectory it
represents the those two neuron values
at that point in time so yes we're
taking the last little curvy point but
it's really we're trying to ask what was
the maximum and minimum value of these
two neurons at the last moment La we're
going to we're going to challenge the
robot to tell us whether it thinks it's
in the presence of the sphere or
ellipsoid during the last
5% of the simulation time we're going to
give it the rest of the time to quote
unquote figure things out I don't know a
t about them but does that diagram
eventually like have an orbit yeah you
got it right so um we can get into the
dynamical systems in which it drops into
an orbit and repeats itself if you plot
the position of the Earth in in uh three
three dimensions it will start to repeat
itself in a phase
diagram okay we're out of time for today
so let's pause here you have a quiz due
night undergrads you're refactoring grad
students you're starting in on
differentiable simulation have a good
rest of your week


--- Evolutionary Robotics course. Lecture 13： Active categorical perception, contd..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning
everybody let's start with a riddle this
morning why don't plants have
brains why don't plants have
brains that we know of they don't need
them
because why don't they need
it it rains so okay it's CU part of the
answer don't have room for it maybe I
don't know there's some pretty big
plants out there bigger than us they
aren't like mobile they aren't mobile so
we are going to finish lecture 10 today
and we're going to move on to a two-part
lecture on really the fundamentals of
Robotics which we've been kind of
putting off for a while now which is the
problem of how to get from from point A
to point B so animals have hit on one
General strategy about how to survive
and thrive in this world which is
instead of waiting for the rain the mate
the food to come to us we go to it
plants have adopted the complimentary
strategy which is cross your fingers and
hope that the resources you want will
eventually come to you so what are
brains for um there is no simple answer
to that but what brains were originally
for was to orchestrate movement
everything else that brains do including
human brains are a hack or a series of
hacks on top of that so we're going to
talk about the origins of locomotion and
really dig into the challenges about why
moving from point A to point B is so
challeng
alling and how once you start to solve
that problem of self-displacement moving
yourself from point A to point B it
provides the foundation on which all the
other building blocks of intelligence
can be built upon okay A little preview
of where we're heading back to logistics
for a moment uh we will finish lecture
10 uh in a moment and then we will move
on to lecture 11 legged
Locomotion uh today under grads you are
moving on to assignment 7 uh hopefully
most of you successfully wrestled with
refactoring your code more or less uh I
know through office hours that some of
you are struggling a little bit hold
tight don't stress um assignment seven
is coming and assignment 8 will be
assigned next week but then you've got a
little bit of breathing room for the
spring recess so if you are starting to
fall behind you're going to have a
little bit of breathing room to catch up
in two weeks time um when it comes to
the refactoring how important is it that
we're like exactly on your intent of how
we refactored it versus just like being
aware of how it works for us absolutely
so if I may summarize your question do
you need to follow the letter of the law
or the spirit of the law the answer is
the latter you do not necessarily need
to follow exactly what I what I'm asking
for in refactoring the spirit of of
course is for you to try and clean up
and modularize your code so you
understand it better right for most of
you I'm going to guess that at this
point your code base is getting large
enough that you're starting to forget
where this variable is where is motor
values where the synapses how do I
update them that is part of the reason
for this for this refactoring and
cleaning things up so your code base is
more clean more structured it's easier
for you to dive back into it and find
what you need at a moment's notice in
order to push on through seven 8 n and
10 and ultimately your final project for
you to be successful in your final
project and be able to quickly identify
all the parts of the evolutionary
algorithm and improve that or quickly
identify all the parts of the neural
controller for your robot and improve
that you need to have a clean
modularized code base make sense that
being said within constraint so that you
can show us what we want to see at the
end of assignment six all
good okay those taking the course for uh
graduate study uh the second
differentiable assignment is now
available in which you're going to be
adding Springs to connect together the
mass points that you created in the
differentiable assignment
one uh grad students that are have made
it this far you realize obviously that
you're doing D1 through through D5 in
collab which is a browser based uh
programming environment in order to
clear the uh level the the play ground
for everyone so we don't have all the
installation issues we had with lud Bots
everybody is using exactly the same
resources which is Google's resources
yeah the other reason we're doing
everything in collab is so that you can
access the GPU resources that collab uh
that Google makes available through
collab you don't necessarily need those
GP resources yet because we're not
really doing any heavy optimization in
collab
yet however some of the grad students um
there are little prompts especially in
D2 that challenge you to actually start
to do some differentiable optimization
of your robot in its current state um be
careful if you do too much compute
within coab you can get bumped off by
Google for a day or a week or possibly
longer so for those of you that are
coding stuff up in go in collab Go
Lightly for
now when you get to D5 when you're
really going to do some differentiable
uh optimization or some differentiable
design of your robot we'll see how
things stand at that point if you're
able to run the codebase out R if you're
able to run your codebase outside of
collab on your own machine using GPU
resources that's fine too for now just
be
careful any other questions things that
have cropped up with the differentiable
assignments I know that one student was
struggling with actually viewing uh the
movie or viewing her simulation in the
collab window has anybody else had this
problem did have you managed to solve it
yet I just did what you said download it
and put it in the vcl player okay all
right so it's not an ideal solution but
for now if you can't see the simulation
in collab you're going to have to
download it every time you make a change
to the code which is a little annoying
so at some point you may want to just
wean yourself off collab and run it
locally we'll see I'll keep working on a
solution to
that any other questions about any of
the
assignments no okay uh looking ahead to
next week uh I am going to be traveling
to a workshop in the UK so there will be
no inclass instruction on Tuesday and
Thursday do not come to class next
Tuesday and next Thursday I will record
uh Tuesday next Tuesdays and Thursdays
lectures and I will drop them uh into
these cells at the time we usually meet
so hopefully for you there's not much of
a disruption to the way you are
currently absorbing this
course um when I travel uh and we miss
class I make it up to you by bringing
back something good to eat from the
country that I'm going to which in this
case is the UK so uh I will hold on to
what I bring back for you be sure to be
here on class in class the Tuesday after
spring recess and I will make it worth
your while Fair Deal that mean you do
and don't have office hours on that good
question it's a five hour difference so
I don't know whether I will be able to
host live office hours youon you won't
be I won't be here if if they're office
hours they will be remote I would say
probably to be on the safe side if you
want me uh the first week of March here
send me an email and let me know and we
can either do things through email or
set up a one-on-one Zoom meeting I think
that's probably better than trying to
orchestrate office
hours make sense
Fair okay all right so uh where were we
we were working our way through some of
the initial experiments in the field of
evolutionary robotics and we are
finishing with this last one which is
really not very much of a minimal
cognition experiment we've got a not
very uh not minimally complex neural
controller of this robot it's a
relatively complicated neural controller
and the body of the robot itself is also
anthropomorphic there's a lot going on
in terms of body and
brain we ended last time by focusing in
on the 47th and 48th
neuron inside this 48 neuron uh ctrn
that's controlling this robot and we
were looking at the ways in which the uh
investigators in this
experiment extracted signals from these
two neurons and interpreted that
extracted signal as the robot telling
the investigators whether the robot
thinks it's in contact with the sphere
or whether it's in contact with an
ellipsoid there's some simple ways we
could do it if the value of 47 is
greater than the value of 48 that's the
robot telling us it thinks it's in
contact with the sphere if 48 is firing
more strongly than 47 that's the robot
telling us it thinks it's in contact
with the ellipsoid that's not what the
investigators did what the investigators
did with something more complicated than
that which was to watch the values of
neuron for 7 and the value of neuron 48
during the last 5% of the time steps of
the simulation remember that in a phase
diagram in a 2d phase diagram like we
have here we're watching two values 47
and 48 and we're looking at what their
values are at a given point in time then
we're looking at a given point in time
then we're looking at what their values
are at the next point in time next point
in time next point in time and what we
get is a trajectory that crawls through
this two-dimensional space and reports
out how these two values are changing
during the last five% of the robot
interacting with whatever object we
placed in front of it so far so good
okay uh the first thing that the
investigators do at the end of a
simulation is draw a bounding box around
found a trajectory that was produced
when the robot was in contact with the
sphere remember the investigators know
but the robot doesn't know or we don't
know whether the robot knows so in this
case the investigators have placed a
sphere s underneath the robot's hand
during the eth trial so we're going to
draw a rectangle
r a rectangle R around the uh around the
trajectory produced when the robot was
in contact with the sphere during the
eth trial again I'm not a big fan of
this notation but this is what they used
so we'll go with it so we've got R Subs
sub the r representing a rectangle so
far so good okay they take the same
ctrnn drop it back inside the robot
after resetting the robot and now they
place an ellipsoid underneath the
robot's palm and the C andn starts
firing uh sensor values flow to motor
neurons the robot starts moving and
manipulating this ellipsoid and again
the investigators watch in this case
what the trajectory do the trajectory of
neurons 47 and 48
do when the robot is in the presence of
an
ellipsoid during the eth trial or the
eth Plus oneth trial so far so good
question so the face diagram is that so
that Arc is that the activation of the
neurons it's the activation of the
neurons yeah so here's our visual
representation or our geometric
representation of what's going on here's
the mathematical representation of
exactly the same thing question reason
start zero ah yeah
so let's start at zero so during the
first time step of the simulation we
place the robots hand on top of the
object we set all the values of the
output neurons to zero and you're right
we actually do start at 0 Zer the robot
starts doing something during the first
95% of the time steps of the simulation
and then this is what happens during the
last 5% of the simulation good point I
just wasn't drawing that part and same
thing here right for the ellipsoid the
robots these two values start at 0 0 and
maybe for for a while the robot is doing
the same
thing and then eventually this happens
um you might have already mentioned this
but is that last 5% like an orbit like
like is the last 5% the same as the 5%
that would happen after good question so
does this pattern repeat itself who
knows it depends on all of the settings
of this CNN we're just describing a
hypothetical situation with one ctrnn
which in our example we've only
evaluated that curin n twice once on the
robot in the presence of the sphere and
a second time with the robot in the
presence of an ellipsoid maybe it would
draw a a cyclical pattern maybe it would
repeat itself maybe the robot rocks its
hand back and forth over the top of the
object in which case 47 and 48 might
oscillate back and forth maybe the robot
I'll draw it over here maybe the robot
rocks its hands back and forth and comes
to a stop over the
object maybe the object maybe the robot
just is randomly manipulating the object
and we get some random trajectory it
depends it depends on the settings of
the ctrnn the investigators are not
forcing this they're just at this point
in the experiment watching and recording
what values of 47 and 48 a given CNN
produce so far so good
okay all right so let's go back to the
math for a moment so uh they're defining
these bounding rectangles and they're
going to define the bottom left vertex
of the the rectangle as the minimum
values of 47 and
48 and they're defining the top right
corner or the top right vertex of the
bounding box to be whatever the maximum
value of 47 was there's the maximum
value of
47 and the maximum value of
48 you'll notice there's a whole bunch
of other math sitting inside here what
is that math where is that coming
from hopefully it looks familiar is that
the activation absolutely right so
here's our activation function here it
is sitting in here and here so you'll
remember hopefully you remember during
our discussion about C tier and NS the
value inside a neuron the raw value can
be very large very positive or very
negative but when we go to read out or
extract the value out of a neuron we
pull it through the activation function
we add the bias we pull it through the
activation function and we get a value
back between minus one and one or zero
and one doesn't really matter for our
purposes we're squashing that value
Emily umor is it is it are
they connected being simple or is
there yeah so what is the connectivity
pattern inside the ctrnn is it fully
connected most of the ctrnn we've seen
so far we were wiring up every ner to
every other neuron is that the case in
this ctrnn and the the answer actually
you can see it in the visual
representation and if you're paying
attention you can also read it out of
the equations so they're they're
connected to the internal fully
connected
but not like directly to each other
absolutely so this is not a fully
connected Network you can see that for
neurons uh 23 through
30 which is uh down here these are all
fully connected to themselves and then
they connect out to the motor neurons
none of the motor neurons are connected
to any of the sensor neurons and none of
the sensor neurons directly connect to
the motor
neurons why did they make these
particular design decisions who knows
they don't give their reasons in the
paper seems kind of arbitrary to me yeah
I was going to ask like when you're
designing like the architecture of one
of these like is the like obviously like
the recurrence matters but generally
like you you kind of do just make
choices arbitrarily and train it right
another dirty secret of AI the choice of
cognitive architecture how you wire up
all the neurons in your neural network
kind of arbitrary not completely
arbitrary we've learned a few things
over the decades but it is really
difficult to know how how to establish
the appropriate cognitive architecture
what should be wired up to what to make
learning or in our case Evolution run
more smoothly yet another open problem
in AI I saw a professor saying recently
it's more like Alchemy than it is like
chemistry it's more like Alchemy than it
is like chemistry absolutely yes it is
somewhat arbitrary in this particular
experiment uh no not casting any shade
on the investigators I know them quite
well it was kind of an arbitrary choice
I think in this case Okay some things
are known as was just pointed out um
probably good to have recurrent
Connections in there for a lot of tasks
it's helpful for the robot to be able to
remember things that have occurred in
the recent
past okay all right back to our back to
our example here uh our cartoon example
here at this moment in time the
investigators have recorded
I've
recorded the activations of 47 and
48 uh from a presentation of the sphere
and one presentation of the
ellipsoid remember that for each ctrnn
we're going to evaluate that CNN 16
times we're going to set the robot's
initial position to position a and then
expose it to this sphere put it back to
a this sphere a sphere a sphere a
ellipsoid a ellipsoid a ellipsoid a
ellipsoid eight times take the same curn
n evaluate it 9 through 16 times
starting the robot's initial position at
B then in position B expose it to the
sphere reset the arm to B put the sphere
back under B sphere B sphere B ellipsoid
B ellipsoid B ellipsoid B ellipsoid 16
evaluations of an individual CN so far
on the board board I've only drawn two
of those
16 let's go back to the second
presentation of the sphere we presented
the sphere once to the robot now we're
going to present the sphere a second
time and we're going to rotate the
sphere horizontally under the robot's
Palm by a small
amount tell me about what 47 and 48 are
going to do in this new
case
it's going to do exactly the same thing
and we're going to get a second R Subs
sub that's identical to the first
one let's skip ahead let's imagine that
this particular pattern was produced
when the ellipsoid at this angle was
placed under the robot's Palm we replay
the same CNN but now we place the
ellipsoid back under the robot's palm
and rotate the ellipsoid a little bit
tell me about how 47 and 48 are going to
behave in this
case it'll it'll just look different
it'll just look different I don't know
what it's going to look like again it's
going to start here and do something for
the first 95% of the time and then do
something different during the last 5%
and we're going to put another bounding
rectangle around this one where this
rectangle represents another present of
ellipsoid under the eth trial so far so
good so at the end we're going to end up
with uh 16 bounding rectangles eight of
them are going to be lying more or less
right on top of one another and the
other eight are going to be distributed
somewhere uh in this two-dimensional
phase diagram everybody with me so
far okay we'll skip ahead a little bit
we we'll we'll assume that we finished
all 16
presentations of the objects to this
ctrnn and the last thing we're going to
do to finish up the evaluation of this
one
ctrnn is we're going to place another
bounding box around all of the sphere
bounding rectangles so we're going to
place a c Subs sorry this is getting a
little messy hopefully you could do a
better job we're going to place another
bounding rectangle called C for these
are the things that are classified as
the sphere from the robots perspective
and we're going to place another
bounding box around all the r sub
DS I should have brought a differently
colored marker to class today we're
going to put another one here a big
bounding rectangle around all of these
and these correspond to the category of
ellipsoid so so far so good okay we have
not yet said anything about the fitness
function for this experiment verbally
I've told you that the investigators
want this robot to be able to
distinguish between spheres and
ellipsoids what's the final step do you
think we need to calculate the fitness
function or the fitness value we need to
obtain one floating Point number which
represents how well the robot does at
distinguishing between spheres and
ellipsoids could you just like find a
number that
classifies well remember that the sphere
box we're placing that around all of the
activations of 47 and 48 when the robot
was actually in the presence of the
sphere and we've placed a bounding box
around all the activities of 47 and 48
when the robot was in the presence of
ellipsoid what do we do with C subs and
C subd to derive a single number we comp
the area the area of rectangle we could
compute the area of C subd we could
compute the area of C subs and then what
do we want to do with those two areas
those are two numbers yeah we compare
like they're close
together so you have if they're close to
together we're getting close to the
answer now other ideas do we want to
maximize the difference between maximize
the difference between the areas or
sorry sorry the the centers of them
maybe maximize the difference between
the centers we're getting we're getting
closer you also want to minimize the
area maybe minimize the area of the box
so if we want to maximize the distance
between the centers
you can imagine two massive
C's C subs and C subd imagine these are
huge so these two distances are also
pretty
huge um I was just gonna say we also
want
to have them be like the distance needs
to be on a certain axis right because if
we were just maximizing the distance you
could have
the categories be like totally FL and
maybe maybe other
ideas minimize overlap that's it that's
it minimize overlap we want the robot to
have maximally different felt
experiences when it's in the presence of
these two different objects everybody
got everything inside here I'm going to
erase it okay that's the key to this
whole complicated long experiment is to
minimize the overlap between these
bounding boxes what we want ideally is
whenever the robot experiences the
sphere it does something like this and
whenever it experiences the
ellipsoid it does stuff like this
remember that both sets of trajectories
are starting from here we want the robot
to diverge its
experiences we've heard that idea before
we're placing the robot in the presence
of two different objects and we're
creating a fitness function that is
selecting for or rewarding for uh
increasingly felt differences from the
robots
perspective where have we heard this
before we heard this last last
class we're trying to evolve the robot
to actively categorically perceive its
world and one way to do that is to reach
out in the world and say I don't know is
this piece of fruit is this food or is
this poison I remember that if it's this
color and it feels like this that's
actually a bad thing I can't quite tell
so let's reach out in the world and do
stuff to magnify the difference between
uh categories that's what this Fitness
function is going to select for to
bounding boxes in this cartoon example
on the board at the moment there is zero
overlap so where is the fact that the
bounding boxes are differentiating
between ellipsoids and spheres versus
like differences that these neurons are
creating between the objects that's it
47 and 48 behave differently they report
similar they're going to the fitness
function is going to select for the 47
and 48 to behave similarly when in the
presence of the
sphere and behave similarly in the
presence of ellipsoids regardless of
where the how the ellipsoid is placed
under the palm of the robot and 47 and
48 should behave very
differently when it's in the presence of
these different objects yeah okay let's
assume we've done Evolution and we
actually have evolved a CTI andn that
causes the robot to do this to do this
exact thing and now we take the
ellipsoid again and we put it back under
the palm of the robot but we rotate the
ellipsoid or we place it at some
particular horizontal position under the
palm of the robot that that robot or
that c tyann never saw during
Evolution how do we know whether the
robot knows that it's in the presence of
ellipsoid um well we would had a store
like the bounding boxes from before
right to decide if it is like whatever
trajectory of traces is in either one
exactly right so for that evolved CNN we
have C subs and C subd we know that for
the ctrnn if we place uh an ellipsoid
under the robot's Palm in a new
configuration and 47 and
48 do this that's the robot telling us
this is an ellipsoid if we place an
ellipsoid under the robot's palm and 47
and 48 do this this that's the robot
telling us I'm in the presence of a
sphere the robot is wrong in that case
what if it place a trajectory that's
like not in one of your Bing boxes what
if we place the ellipsoid under the palm
and it does something like this what is
the robot telling
us I saw a bunch of you do this exactly
the robot says I don't
know that's
it okay all right that's the intuition
let's look at the actual ual Fitness
function FF again terrible notation here
FF is a single variable they're going to
set the fitness function to be the sum
of two different
terms um FS1 and FS2 are just sitting
here by themselves there's no negative
signs in front of them they're not on
the denominator so whatever F1 and F2
are F1 and F2 should be maximized an
optimal robot gets very uh positive
values of fub1 and positive values of
F2 let's actually start with f sub2
because we were just talking about F
sub2 if you look at F sub2 inside you'll
notice there's an
intersection sign and this is exactly uh
the point that Eric was pointing out
here is that we are trying to minimize
this intersection is on the right hand
side of a minus sign we are trying to
minimize the area of the overlap between
C subs and C
subd we're trying to
minimize this area this is C subd and
this is C
Subs what's going on in the denominator
why is there a denominator um you're
like normalizing over the biggest for
the smallest area of
the yep absolutely right so this you can
imagine a perverse instantiation
case where this is C
subd
and this is C Subs C Subs is really
small there's actually quite a bit of
overlap between these two boxes the
robot actually can't tell the difference
very well between C subs and C subd in
this case so this denominator is
guarding against this particular case of
perverse instantiation and the fact that
it's there is usually a pretty strong
hint that the investigators probably ran
this experiment without this denominator
to start with and probably got something
like this and then said oh yeah right
okay normalize by the smallest of the
two bounding
boxes so does that have the effect of
trying to also like maximize the area
does this Fitness function also exert
evolutionary pressure to maximize the
size of the boxes great
question
thoughts I don't think so but it's a
good question I'm not 100% sure it might
be something to run and
see so if they wanted to could they have
like create a machine learning algorithm
to kind of create the lines that
separate the boundaries and then like to
not have it be like it doesn't really
know it or just in like it's more on
this side so it's to be it's more here
so they could have there's an infinite
number of ways they could have done this
right so your suggestion is interesting
we force it to just draw a line and
distinguish you're forcing the robot
then into making one of two choices it
has to say I think it's the sphere it's
on this side of the line or it's on this
side of the ellipsoid I like this
solution because there's actually three
options available to the robot the robot
can say I think it's an
ellipsoid I think it's a sphere or I
don't
know okay you notice that f sub2 is a
conditional so the robot gets or the
ctrnn gets Fitness points if F sub one
is greater than or equal to one if F sub
one which we haven't talked about yet is
less than one the robot isn't able to
get this F sub one is dinner and F sub2
is the dessert you don't get you don't
get your dessert if you don't finish
your dinner the this particular Fitness
function is an incremental Fitness
function we've seen this before when we
saw the Gantry robot this Fitness
function is set up so that Evolution
will evolve cnns that do very well get
better and better and better at F1 and
then when a CNN appears in the evolving
population of CNN's that gets an F1
above one then it also starts to collect
points for
this okay so let's have a look at F sub
one f sub1 is a function of d sub which
is the ukian distance between the object
and the center of the palm of the robot
at the end of the
trial and duub Max is the maximum
possible distance the robot's Palm can
get from the
object what is F1 selecting
for they want the hand to stay on the
object this is a very strong hint
actually it's a mandatory requirement
that CER and NS control the robots
Motors so that the hand stays in contact
with the object
because this robot has no cameras it
can't see the object it's got to feel it
in order to know the difference between
the objects everybody see that you can
imagine that starting from either
position a or position B here
99.99999% of random CNS you create are
going to cause the arm to do things like
this and maintain very little and
temporary contact with the object it's
going to be super hard and take you
years to start to evolve a CNN that
actually can distinguish between the
objects so they're building in some
pretty strong intuition that they have
about this problem which is that if
you're going to distinguish between
objects by touching them then touch
them everybody see that
okay okay here we go I'm going to turn
out the lights for this one uh hopefully
you can see this maybe I'll try
maximizing
this yeah that's
better okay here we go you're going to
watch what we're going to watch now is a
video of the robot being controlled by
one of the most fit cnns so the
evolutionary algorithm has run and has
produced a ctrnn that minimizes the
overlap between C subs and C subd while
you're watching this video and I'll just
put it on continuous loop here I want
you to jump back and forth between
watching what the robot actually does
and what's going on in the bottom left
of the screen and I apologize about the
colors uh it's a little hard to
see what is the robot
doing what is the robot quote unquote
saying trying to roll it straight back
and roll it straight back back on a
straight line that calls Sphere not okay
so some good observations here obviously
the robot has or the CN has hit on a
strategy of just rolling the object
backwards and the observation is that if
the robot pulls the object back and it
rolls back in a more or less straight
line that seems to correspond with the
robot saying it's a sphere otherwise it
says it's an
ellipsoid other obervations like curling
it fingers back it's curling its fingers
back a little
bit is there actually a difference
between the sphere and the ellipsoid is
there actually a difference between the
sphere and the ellipsoid you're doing
passive uh categorical perception you're
trying to perceive at a distance the
difference between these two objects
it's not easy is it they made this hard
on the robot the major and minor axes of
the ellipsoid are very similar to one
another this is a very spherical
ellipsoid but yes these investigators
were mean but not diabolical there
actually is a difference it's just a
subtle
difference my question is that like
would this strategy if it R it like
straight on the minor axis it would like
it wouldn't be able to tell I don't
think okay but also the the simulation
time like oh I guess the fingers help to
because it's curling it fingers remember
there's a lot going on here the robot's
getting a lot of touch and propri
receptive information and its fingers
its wrist its elbow its shoulder there's
a lot there's tons of subtle differences
going on in this video between the case
of the sphere and the case of the
ellipsoid some of which you can see some
of which you can barely see and some of
which you can't
see it's a great example of again
thinking about things is misleading the
robot doesn't need to do something
crazily different in all cases from the
robot's perspective these cases feel
very differently they don't look very
different to you
presumably tell me I get I apologize the
blue arrow is hard to see in the bottom
left what's what's up with the blue
arrow what is the blue arrow what is it
representing classifying it's
classifying how how how did they know
how to draw the blue arrow during the
rendering of this video so it's like
sitting up until the phase diagram goes
into one of the so if 47 if the value of
neurons 47 and 48 at the given time step
of a frame in this video If 47 and 48
are
outside are outside a bounding box that
they draw the arrow straight up if 47
and 48 wander inside to C Subs the arrow
switches and points to S to sphere if
the trajectory wanders back out and
wanders into C subd that's the robot
saying I'm in the presence of the
ellipsoid you know if they tested it
with like different sizes we're going to
see some more some examples of that in a
moment so if you watch if you watch the
blue Arrow the blue arrow is the robot
saying to us I don't know I don't know
oh it's the sphere no wait a second no
it's the ellipsoid yeah it's the
ellipsoid it's the ellipsoid it's the
ellipsoid next presentation I don't know
ellipsoid sphere ellipsoid it's the
sphere it's not sure and then it
converges most of the time on the right
answer everybody see that okay this is
the best evolved ctrnn and what you're
watching is a video of playing that CNN
back in initial position
a I'm going to show you exactly the same
CNN but now that CNN is going to be
played multiple times on the robot
starting in position B not position a
got it all right here we
go what's
happening moving it elbow a lot more
there's something going on with the the
robot is moving differently which is not
surprisingly it's in a pretty different
pose how is it doing how well is it
doing worse it's worse this is harder
this is a tough this is a tough task it
looks like the wrist is kind of getting
stuck it's kind of getting stuck on the
doesn't really know how to keep rolling
the wrist is getting stuck on the ground
and the robot doesn't know how to keep
rolling I love it very Valentino
brenberg esque language maybe maybe
that's helping maybe that's part of the
strategy who knows who
knows
okay all right let's look at some actual
data now rather than some video I'm
going to flip the lights back on
okay so as usual here's a plot of
evolutionary progress we have
evolutionary time on the horizontal axis
so evolving populations of cnns to do
better and better at minimizing the
overlap between C subs and C subd they
they evolved one population of CNS for
500 generations and the video you just
just saw was the most fit CTI andn from
that run then they rewound The
evolutionary tape started with a
completely different population of
random cnns evolved it again for 500
Generations got and plotted at each
moment in evolutionary time the fitness
of the best robot the best C tet in the
population at that time re rewound the
tape ran it Forward ran evolution again
a third time what happened during these
three evolutionary
trials they all kind of plateaued to 2.0
they all plateaued to 2.0 I'll leave it
as optional homework you can work
through these equations fub1 and F2 are
designed to range between zero and one
so the best the robot can get is two the
worst it can get is
zero it's doing pretty well it takes a
while but in all three cases The
evolutionary algorithm was able to
evolve a CTI andn that correctly
categorized all quote unquote 16 objects
robot doesn't know that there's not 16
we know yeah so pretty successful
actually let's dive into the brain of
one of the more successful robots so
among all those three trials this was
the best CNN and like we've seen now
many times in the minimal cognition
experiments they're going to take that
most fit CNN and play it back thousands
of times on the simulated robot in
conditions that the robot didn't see
during
Evolution you'll notice mentions of 180
rotations during Evolution they rotated
the ellipsoid to four different
horizontal rotations they played that
cerin back in the presence of 180
different horizontal rotations and
180 rotations of the sphere in in scare
quotes because obviously horizontally
rotating the sphere makes no difference
to the
robot the dashed rectangles that you see
are the C Subs C subs and C subd the
little rectangles are the r Subs sub and
the r R subd
sub what's going on in this
case what can you tell me about what's
going on in the head of this robot
during all these
experiences spher going to be a lot more
similar in like the outcome of the robot
whereas lipoids are like a lot more
sporadic absolutely right so the
bounding box for C Subs is smaller than
the one for C subd which makes sense
right there's not a lot of difference
and rotating the
sphere it's for one CN so they ran the
evolutionary algorithm at the end they
had a population of evolved cnns they
plucked out of the population the most
fit one and played it back many many
times on the robot the twoobs
inid arey
right yep what does that mean what does
that tell us about what the robot is
thinking or
feeling for 40 like for the value of 47
is that pretty much the same for both of
them yeah using 48 to distinguish the
robot's kind of showing off again right
it says I actually if you want me to
distinguish between these things I don't
even need the two neurons you gave me
just one will suffice thank you very
much when it comes to the fitness
function is there a reason they chose to
go with like a bounded Fitness function
ver like is is there like a reason that
you do that probably not they could
probably get away with not making it
bounded but I think probably just so you
can think through the math it's a little
bit easier I
think you could give it a
go other observations the rectangles
that are lying outside of both of the
dash what are the rectangles that are
lying outside of C subs and C subd what
do they
represent to be
what's going on here let's talk about
let's pick this rectangle out here what
what is this what is this rectangle
representing is that like an incorrect
categorization of an ellipsoid exactly
it's it's we know that the robot is in
the presence of an ellipsoid in this
case because it's in Black in this
figure everything that's black is the
Rob robots in the presence of an
ellipsoid everything that's gray is the
robot in the presence of a sphere so the
robot is in the presence of an ellipsoid
and it draws 47 and 48 do something out
here what does that mean what happened
in that case that particular
presentation of that rotated
ellipsoid what's the robot telling
us it doesn't know what it is doesn't
know the robot evolve the gtrn during
Evolution got
A+ perfect score we then exposed it to
more situations that it had never seen
most of the time it does the right thing
in one case it doesn't know we train an
autonomous car to distinguish between a
pedestrian right in front of it and a
shadow right in front of it the
autonomous car does perfectly during
training great let's let the autonomous
car loose on the Streets of San
Francisco
what could possibly go wrong this this
is what keeps anyone working in Ai and
Robotics up at night we cannot we do not
yet know how to guarantee that something
during training or in our case during
Evolution when deployed in the real
world in which it's going to see
situations it never saw during training
Revolution that it's always going to do
the right thing in this case the robot
doesn't know whether it's looking at a
pedestrian or a shadow we don't know
what it's going to do given that
uncertainty what else can you tell me
about this figure what else is going
on I told you that whenever the robot is
in the presence of the sphere 47 and 48
always do exactly the same thing that
was a little bit of an approximation
that's clearly not what's going on the
robot is seeing the sphere many times
but doing slightly different things
there seems to be two
clusters sphere sphere a or sphere B
sphere a sphere B good choice of words
what are these two clusters correspond
to why are there these two clusters
because of the two positions the two
position a and position B right so the
robot is ex is not completely able to
collapse intra or within category
differences the sphere doesn't feel
identical to the robot in all cases it
feel something slightly different when
it's in the presence of an a starting
from position a or sorry in the presence
of the sphere position a sphere position
B even Within These two clusters the
bounding boxes for the Spheres don't
completely overlap one
another that's actually because of a
detail of the experiment that I haven't
mentioned yet anyone can guess what it
is does it have to do with like the size
of the sphere like how the fingers kind
of curl around some of it not the sphere
is always exactly the same
size something's causing a slight
diversity slight difference in the
robot's felt experience they change the
weight they didn't change the weight of
the sphere it's it's exactly the same
sphere they keep placing it identically
under the robot's Palm how can the robot
be having slightly different
experiences
it's they could have placed it at
slightly different position under the
Palm they didn't do any of this they
added a little bit of noise to the
CNN as values were flowing in from the
sensors as vales were flowing into the
sensors they ran a a random number
generator and they change the numbers
slightly coming in and the same thing
with the numbers going out to the motors
they added a little bit of noise a
little bit of Randomness to those
numbers why do you think they did that
it's a minor detail of this experiment
but worth
mentioning uh they could be trying to
Aid Evolution so that the Rob the
evolution has to deal with slightly
different situations that's definitely
part of it does it kind of like have the
effect of normalizing so like some
inputs don't become like way more
valuable not
quite they're doing all this work in
simulation but the hope is ultimately to
run this on a real robot
I mentioned at the beginning of this
course heraclitus reminded us 2,000
years ago man never enters the same
river twice right in the real world
nothing is ever identically the same
unless we're in The Matrix we don't know
but assuming we're not things are always
slightly different in our experience
that's them sort of the investigators
being optimistic that someday this might
be try it on a real robot so they're
just trying to make this a little bit
more
realistic so far so good
okay let's keep going so we can finish
up this lecture
today we just saw this case this was the
best evolved controller from the first
of those three uh from the first of
those three
runs this is the best evolved controller
the best evolved CN from the second
evolutionary run this ctrnn also got a
perfect score during Evolution what's
going on in this case
they've drawn things a little bit
differently in this case my apologies on
behalf of the investigators imagine C
Subs drawn around these boxes and
imagine C subd drawn around these
boxes the gray and the black do not
overlap that's good that's what we
it could right it hasn't magnified
intercategory differences very well the
sphere and the ellipsoid feel very
similar to the robot this may be
difficult to see from the back look at
the ranges of the values on 47 and 48
they're really
tiny 47 and 48 are actually not changing
in value very much during this last 5%
of the robot's experience with the
objects maybe maybe it's it's actually
making these B these bounding boxes are
actually globally speaking very very
small right for some reason that seems
to be helpful for the robot to keep
these boxes from not overlapping so
they're probably wasn't pressure to make
these the areas of these boxes large
here's another here's another case over
here here's the second best CNN from the
second evolutionary run which also got a
perfect score during Evolution there is
also no overlap between these but these
boxes again are really really close to
one another an example of evolution
being a satisficer not an Optimizer or
you know it did what it was called it
min overlap but it didn't do the optimal
thing to also like maximize distance
between the two yes this is an example
of The evolutionary algorithm being a
satisficer not an Optimizer all you told
me to do was not not overlap these boxes
and I didn't you never said anything in
the fitness function about maximizing
the distance between them I'm doing
exactly what you asked for and nothing
else look at this one this is the third
best CNN from the second trial what's
going on in this
case small the sphere bounding box is
really really small it's really
reducing intra category differences the
sphere in A and B feel really really
similar to the
robot okay that's the last slide from
this lecture before we switch mental
gears and talk about
Locomotion cam was just saying
intuitively maybe it makes sense to push
these bounding boxes further away so
let's take two minutes and rewrite this
Fitness function in our head and then
mentally simulate an evolutionary
algorithm running with this altered
Fitness function if we added a term to
the fitness function that rewarded for
maximum distance between the centers of
the bound in box what is what are we
telling Evolution we're building in our
bias or our opinions about what what the
difference between spheres and
ellipsoids
is the investigators didn't do
this they didn't include this additional
term that maximize distance between Cs
and CD one issue with that is that it
would not NE necessarily like the you
could have a huge bounding box it could
be like really far away and that would
be really big and then you might not be
minimizing inner category differences
ideas um I suppose we're like suggesting
that a Speer can roll a lot better than
the lipoid so that's why it would be
able to figure out that the spere is
going roll like a lot further away
getting closer we're not necessarily
telling the robot or the CNN that
spheres are more rollable than
ellipsoids because it's up to the robot
to decide what to do it didn't in this
experiment but could it easily it could
have easily grabbed the object and
banged it up and down on the table a few
times I don't know whether that would
reduce intracategory differences and
exaggerate inter category differences
but it's a perfectly valid there's
nothing in the fitness function that
says You must roll the object other
ideas um if you told her a lot to do
that because these are so subtly
different it probably would increase the
rate that you might roll something along
the wrong end and not be able to make a
subtle distin between
two uh one thing you mentioned is
certainly true which is the robot would
no longer it would there would not it
would not feel a subtle difference
between these objects assuming a c tier
and N could evolve to support that
Fitness function that ellipsoid and
sphere would feel very different to the
robot but for such a
CNN I was I was going to say like if the
end goal of not this experiment but just
in general was to be able to categorize
like a set of objects it's probably
pretty nice that a sphere and ellipsoid
are in the same like category versus
like a triangle or like a prism okay
you've anticipated my next question so
I'm G to more or less repeat Verbatim
what you said let's imagine we rerun
this experiment and now we expose the
robot during evolution to ellipsoids
spheres and
cubes let's not change anything about
the experiment except well we've changed
the experiment by adding cubes change
the fitness
function how do we want the robot to
distinguish between ellipsoids spheres
and
cubes how do we modify the fitness
function just high level we don't even
need any math what's the
intuition
determine if it's like a cube or an
ellipsoid sphere first and then
determine if it's you know based on what
tree it takes it's either a cube or it's
use this Fitness function okay we could
design a fitness function that causes
the robot to categorize hierarchically
figure out first of all whether you're
in the presence of a sphere ellipsoid or
a cube and if you decide you're in the
presence of a SP sphere SL ellipsoid
tell me which of those two it is could
go that way if I were to ask you and you
can tell me with language luckily which
of those three objects ellipsoid sphere
and cube is different from the more
different from the other two which one
doesn't belong what would you tell me
presumably are we all in agreement it's
the cube right there's something about
humans that we actually agree in this
case we are aligned in the the new
language of AI we have value alignment
in that problem so we probably want to
teach this robot or evolve this robot to
feel that ellipsoids and spheres are
more similar to one another than either
is to a cube how do we alter the fitness
function for
that what do we want to see in these
three bounding boxes we're going to draw
for sphere ellipsoid and
Cube we want them all to be mutually
nonoverlapping but we would like the
cube to be further away from the sphere
or the ellipsoid so coming back to
something cam mentioned a few minutes
back is actually the distances between
these boxes we could manipulate this so
that the robot learns semantic
relationships similarly to humans we
could end up making this robot more
anthropomorphic it not only looks like
us but it experiences the world like we
do if you blindfolded grasp uh
ellipsoids and spheres they're going to
feel more similar than a cube does make
sense okay all right we've got 10
minutes left so let's pull out of active
categorical perception and the minimal
cognition experiments uh and dive into
Locomotion
okay we're only going to start to
scratch the surface of this topic today
it is a long and fascinating topic there
are whole courses course series on
biomechanics so we're going to treat
this at a very high level um one of my
favorite books of all time is the
principles of animal Locomotion written
by Alexander and one of my lab members
currently has this book and I've
forgotten who it is one of those lab
members is actually here today uh if I
had this book I would have passed it
around so you can all have a look it's
all good I'll give you the Cole's notes
of principles of animal Locomotion I
love this book because Alexander goes
through in one book more or less every
single way that Mother Nature has
discovered to get animals from point A
to point B he starts at the beginning of
the book with some of the basic physics
we need to think about uh Locomotion
goes into obviously the single building
block every single animal uses to move
there is one cell type more or less we
all use to move it's the muscle cell
okay this has come up a few times the
energetics of locomotion um as you've
probably noticed your three link robot
is not very energy efficient it can
under the right conditions bounce all
over the place generally not a good way
to get from point A to point uh B goes
into all the different aspects of the
physical body that affect your ability
to move from point A to point B and then
goes into all the different ways Mother
Nature has figured out to move animals
from point A to point B starting with
some of the earliest and simplest cases
like
peristalsis so the humble earthworm
expands the front of its body which ends
up being an anchor uh where it presses
against the inside walls of the earth
that it's moving through it contracts
the back of its body so the back of its
body loses contact with the tunnel and
causes the back of the body to contract
forward when it does it relaxes and
expands another part of its body and as
this wave of expansion moves from the
front of the animal towards the back the
animal actually moves forward this is
peristalsis we do not move with
peristalsis but you have peristalsis
going on in you all the time where is
it kind of here a little bit here more
elsewhere a little bit in the
intestines throat when you swallow
anything peristalsis pushes the food
back this little hack this combination
of shape deformation changing shape and
geometry and how things change over time
this little phenomenon is super helpful
and mother nature discovered it a very
long time ago and she's copy and pasted
and adapted that mechanism into all
sorts of animals all over the
place walking running and hopping this
is where we as humans tend to feel more
uh comfortable climbing and jumping this
particular primate the Gibbon is very
good at brachiation swinging from Branch
to Branch Homo sapiens sapiens were not
so good at it you can spend years
training and you can get better at it
but nowhere near as good as the Gibbon I
highly recommend getting on YouTube and
Googling videos of Gibbons brachiating
it's fantastic crawling and burrowing
something humans don't tend to do very
much gliding and soaring we need
machines for this hovering powered
forward flight moving on the surface of
water swimming with ores and hydro foils
Swimming by un undulation Swimming by
jet propulsion who swims by jet
propulsion octopus octopus the seapods
and so on right incredible diversity in
the ways in which Mother Nature has
found to get animals from point B point
A to point B I want to back up for a
moment this is going to Anchor our
discussion for next time all of this
diversity is Mother Nature trying to
strike different kinds of balances
between four antagonistic forces that
are at work the moment an animal starts
to move from point A to point B there is
no optimal way to move from A to B there
are just different trade-offs that you
can strike in the way that you do it
these trade-offs are summarized as
displacement robustness energy and
stability an animal that evolves to
maximize displacement and ignore these
other three deera how is that animal
moving regardless of whether it's on
land sea or air uh it's like sprinting
it's sprinting right so the minute you
sprint you're straight you're you're
choosing a particular way to get from
point A to point B you're striking a
pretty extreme
tradeoff an animal that values
robustness over the other
three robust to what do you think it's
not mentioned here like forms movement
like not just straightforward and
backwards but like in other planes could
be could be the like the way the
directions in which you move usually
when robustness is mentioned during the
biomechanics of motion it's robustness
environments you might move through if
you're moving over land it's differences
in friction and uh structure of the
ground over which you're moving are you
moving over ice are you moving over a
Boulder Field are you moving through a
field of wheat are you moving through
can you be robust can you continue
moving in the way that you normally move
under all those different
environments again as humans we can sort
of tune how we move how do you choose to
move so that you maximize robustness it
certainly ain't by sprinting not a good
solution you sacrifice robustness the
matter the moment you try and maximize
displacement I don't know how icy it is
out there
today you take little baby steps and
kind of yeah that this actually works
pretty well for pretty much most
environments you can imagine right
walking over ice walking over thin ice
good strategy
what about uh animals or humans that
prioritize energy over the
rest walking walking we evolved by petal
Locomotion we Homo sapiens sapiens are
the master the uncontested master of
moving where we maximize energy and
don't care about the rest I think I
mentioned this already there's a theory
out there about early hominids that one
of the things that made us successful is
that we hunted in packs and we did it by
just walking get a bunch of your friends
walk have the ones on the outer side
walk a little bit faster and if you keep
doing this all day you can actually
bring down some of the megap uh in North
Africa it's possible I don't recommend
it but it's possible we can sweat we're
very energy efficient we basically uh
counter our energy against the other
strategies of megap on the plains of
Africa which is they tend to maximize
displacement right run away
quickly what about
stability we are terrible at this one
how many of you seen somebody slip on
the ice this this winter right we're not
so good at this
one the minute we focused on this one
with bipedal locomotion we really gave
up on this one my 2-year-old at home is
still struggling with with this
one which animals are really good at
this one and terrible at the other
three four-legged animals four-legged
animals actually they're better than us
everybody's better than us but even
four-legged animals not so good you ever
seen deer jump on the road icy Road they
also wipe out they're not
great snake doesn't
BCE absolutely right worms snakes
reptiles excellent at stability for the
simple reason they can't fall down
why would you ever evolve away from
snake likee or reptilian Locomotion if
you've got four legs splay out
horizontally like the reptiles do and
you can never fall
over why evolve into
us why evolve into mammals that move
away from the strategy no pun
intend you can move faster and Traverse
like you can go up
can go vertically a lot better uh true
right so we as hominids as primates we
can climb although reptiles are pretty
good at climbing too snakes you wouldn't
think it but they're also pretty good do
it end being moreal to
Havey if you think about it right you
can try this don't do it with anyone
around but you can get down on your
belly and crawl around it's it's
exhausting right you're literally
dragging
the your body along the ground friction
is draining your energy it's extremely
energy inefficient to move in this way
there is no optimal way to move every
way of moving is just is just a tradeoff
okay I think that's a good place to
pause for today you have a quiz due
tonight undergrads are working on A7
grads you're working on D2 see you here
in class on Thursday


--- Evolutionary Robotics course. Lecture 15： Bipedal locomotion..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
good morning everyone uh as you know I
am currently in the UK uh this is a
pre-recorded lecture for uh Tuesday
March 5th today we are going to be uh
finishing lecture number 12 on bipedal
locomotion and that will conclude our
discussion uh admittedly brief about
Locomotion in animals and machines and
then we'll also close out uh our second
theme of the course apologies the Third
theme of the course on the admittedly
brief history of evolutionary Robotics
and we will push on next time to
challenges open challenges in the field
of evolutionary robotics uh as always
just a little bit of logistics uh first
you will see this lecture appear at 8:30
uh a in cell G30 of uh the schedule on
Tuesday uh on Tuesday March the 5th and
I will drop a pre-recorded lecture into
cell
g34 this coming Thursday March 7th you
will then all be off for spring recess
and we will all meet back in person uh
in class on Tuesday March
19 okay today March uh the 5th
undergrads you are now starting work on
assignment 8 and graduate students you
are starting in On differentiable
Assignment three which is dedicated to
adding Motors to your differentiable uh
robot okay okay we were discussing uh
last time how in robotics at least the
uh unspoken idea is that Locomotion
undergirds cognition we looked in
lecture 11 at all the different ways
Mother Nature has gotten animals to move
and today we're focusing in on bipeds
specifically us and all the different
ways one can
move with two legs most of them we don't
use for obvious uh reasons
we ended last time by looking at uh the
azimo robot which uh strikes a
particular uh balance between
displacement robustness stability and
energy Asimo maximizes stability it's
very statically stable but very energy
energy
inefficient at the opposite end of the
spectrum uh sorry as I mentioned last
time Asimo in this silver back back here
is carrying a b
battery very energy inefficient but very
stable we're now going to look at a
different robot which strikes an
opposite tradeoff it maximizes Energy
Efficiency at the cost of uh
stability and that is the passive
Dynamic
Walker you'll notice the passive Dynamic
Walker is very Loosely anthropomorphic
it looks a little bit like a human being
and you can also notice that obviously
the passive Dynamic Walker is much much
simpler than
azimo you'll also notice that despite
this Simplicity or actually because of
this
Simplicity the passive Dynamic Walker
walks in a much more humanlike way than
azimo
does you might also notice as you watch
the passive Dynamic Walker that it's
very simple and it's very hard to see
the sensors and motors and electronics
that's controlling this
robot and that's because there are no
sensors no Motors no electronics so um
sometimes this machine is referred to as
a passive Dynamic robot it's not
strictly a robot at all it's more
strictly known as a mechanism it's just
mechanical there's no active control
whatsoever um you can see that it's very
energy efficient it's actually not using
any energy from any Motors at all to
walk because there are no Motors so
where is the robot gaining the energy
with which to
walk it's gaining it by transforming
potential energy into kinetic energy uh
it may be hard to see in this video but
the passive Dynamic Walker is walking
down a very slightly declined slope at
the top of that slope there's more
potential energy than there is at the
bottom and so the robot uh can use that
potential energy to convert it into
kinetic energy extremely energy
efficient but as always with a movement
that comes at a cost the robot has to
sacrifice one or more of the other three
deera of movement in order to be energy
efficient I'll give you a moment to
think about what that deera a cidara
is I've already kind of mentioned it its
stability you'll notice that there's a
human watching very carefully um it took
them a lot of takes to get this video um
the passive Dynamic Walker is very
unstable it's very very easy for it to
fall over it is also minimally robust
meaning it's not robust to different
kinds of environments this passive
Dynamic Walker will only walk down
slopes of exactly this angle a little
bit less a little bit more doesn't work
it needs to walk down exactly uh a slope
with this particular uh texture and uh
friction properties and so on you'll
notice that the curvature the this robot
has curved uh undersides on its feet the
curvature of these feet have to be just
right in order to get this to to
work
okay so now that we have the passive
Dynamic Walker that Walker can work in a
very very narrow range of environments
but of course if we want to uh mature
this technology into an actual robot
that can actually bipedally walk in a
wider range of environments we're going
to have to sacrifice a little bit of
Energy Efficiency to gain uh robustness
and
stability and taking a small step in
that direction pun intended uh was
achieved by Martin visa and his
colleagues at the Technical University
of Del in the Netherlands back in
2004 and I'll show you this robot in
action I'll show you this robot in
action it looks quite a bit like the
passive Dynamic Walker this is known as
the hybrid Dynamic Walker hybrid because
it's a hybrid of passive Dynamics and
active Dynamics what do we mean by
passive Dynamics passive Dynamics means
that things move in this case the legs
move passively the forward swing of the
hybrid's legs is a result of passive
Dynamics gravity pulling on that leg and
pulling it
forward the moment that one of the two
feet hit the ground in front of the
hybrid Walker suddenly it switches that
leg switches from passive Dynamics to
active Dynamics there is a very small uh
impulse Force that's applied at a
particular point in the gate uh I'm
sorry I
misspoke there is a small amount of
force applied by a motor at the moment
the back leg leaves the ground a mo the
moment the back leg leaves the ground
there's a small imput impulse force a
motor pushes that back leg forward to
start or accelerate the swing forward
it's almost like um the motor is
cleaning up passive Dynamic walking
which would run out of energy if it was
done on Purely flat ground because
there's no energy there for the robot to
use to keep uh
going that's the hybrid Dynamic Walker
as always in robotics uh it's
interesting to see this particular
technology which is maybe not going to
be something that's going to be deployed
as a useful technology anytime soon to
view it as a good starting point for
increasingly intelligent machines here
is a somewhat energy efficient Walker
that's able to walk over a wider range
of environments than the passive Dynamic
Walker that you
saw the problem with both of these
Technologies is it took the engineers
involved hours and hours and hours and
hours of effort to tune the body of the
robot and exactly when to apply the
impulse forces in the case of the hybrid
Walker and where and when a lot of
manual engineering effort went into
these
machines in today's lecture we're going
to discuss a particular we're going to
discuss a particular evolutionary
robotics experiment in which the uh
investigator turned over the job of
Designing the body of the robot to make
it
passively uh to walk passively or walk
in the hybrid manner we just talked
about before we do just for fun uh it's
actually not that difficult to make a
passive Dynamic Walker of your own
here's one made from
paper and here's one uh in its natural
environment I want you to
check again these are experiments that
you can try at
home
okay so the research question uh from
this paper and that we're going to talk
about in the rest of lecture 12 here is
can we evolve passive Dynamic walking
into a robot and if so how can we do it
question that's sort of the first two
questions third question is if we can
evolve a robot to move down a decline
slope with no Motors at all can we then
continue Evolution and add Motors to the
robot so that it's then able to refine
that machine to also be able to walk on
flat ground so evolve passive Dynamic
walking and then continue evolving it so
that it achieves hybrid Dynamic walking
yeah as you can guess the reason that
we're talking about this paper is they
they were able to answer both or all
three questions with yes okay let's see
how they did that they created did the
following bipedal robot in a physics
engine uh it's got a hip and two legs um
we've got for each hip we've got two
degrees of freedom so if you'll permit
me for a moment one degree of Freedom
allows the leg to swing forward and back
and the other degree of Freedom allows
the leg to swing in and out so we get a
robot that's capable of this kind of
motion of the leg relative to the
hip same thing with the other side of
the body so two degrees of freedom over
here two joints uh two rotational joints
over here another two rotational joints
over here one rotational degree of
freedom in here which is your knee joint
which obviously allows your bottom leg
to swing relative to your upper leg
through one two-dimensional
plane and at the bottom of the leg of
the bipedal robot we've got again two
rotational joints that allow the Ang
anle allow the ankle to rotate the leg
up or down relative to the lower leg and
also to uh um to yaw relative to the
lower leg to tip the T tips of the toes
inward or outward which gives this kind
of motion to the
foot
okay uh they added some additional
morphological or body parameters to the
robot they attached some masses to the
thighs and to the shanks the lower parts
of the legs okay we'll see why in a
moment okay so we've got a total of uh 1
two 3 4 five six S8 nine 10 joints that
make up this robot um that means we have
11 parts to the
robot
okay okay so here we go here are these
red uh masses here in this experiment
unlike all of the experiments we've seen
so far um we are not going to be
evolving the neural controller for the
robot because there is no neural
controller for the robot yet it's
strictly speaking not a robot it's a
mechanical mechanism so the only thing
we can evolve is the mechanism itself
parts of the body and they evolved in
this first part of the experiment one 1
2 3 4 5 6 7 8 9 10 11 12 different body
parameters so in The evolutionary
algorithm we're about to see each genome
in the population had a length of 12
there were 12 numbers that specify how
to construct this
robot we've got the first number
represents the mass of the waste how
heavy is the the waste the next uh
second number M subt which we see see
here uh corresponds to the um the mass
how heavy are these masses that are
attached to the thigh M Subs how heavy
are these masses that are attached to
the shank and finally uh some masses
that are embedded inside the feet M subf
so we have one two three four Mass uh
four numbers but we have a total of 1 2
3 4 five six and you can't see the
seventh Mass which is inside the
leg in all of these biped robots they're
all made to be bilaterally symmetric
meaning however heavy m subt is on the
robot's right leg the M subt the mass on
the left thigh that mass is exactly the
same as the mass on the right thigh yeah
so we only need four numbers the mass of
the hip the mass of that's placed on
both of the thighs the mass that's
placed on both of the shanks and the
mass of the object that's attached to
both of the feet okay they also placed
under evolutionary control um the leg
segment leg uh length so how long is the
upper leg and the lower leg you can see
it's the same L attached to the upper
and lower
leg which tells us that in this
experiment the upper leg always had to
be the same length as the lower leg but
for different robots in the population
they might have different L's some
robots may be taller and some robots may
be shorter than
others there's some additional
parameters here s uh for example uh the
X and Y Offset you can actually see that
visualized here for M Subs so this is X
Subs the X
offset of the shank Mass how far inwards
towards the center of the body or how
far outwards away a from the body is M
Subs
placed and Y Subs what is the uh
forwarder backward displacement of this
mass is it placed on the front of the
shank or on the back of the shank or mid
or inside the shank and so on so they're
going to be evolving basically the SI
the the side of the the size of these
lead blocks that are attached to the
robot and where these lead blocks are
placed you can probably start to figure
out why they did that in order to get
this particular bipad to successfully
transform uh to cly transform potential
energy into kinetic energy efficiently
you got to get the mass distribution of
the robot just right it's very difficult
to know a priori what that mass
distribution should be they're going to
try and let Evolution figure it out some
other body parameters that they evolved
they evolve the length of of the foot L
sub L subf here how how long or how
short uh is the foot the radius of the
uh
waste so what does this mean this means
uh this means how much the legs can
rotate back and forth around the waist
so a narrow a small w means that the leg
can only ever do this and a large w
means the leg can do
this they then evolved a 12th and final
number B suby which is the starting hip
angle around the y
axis I think this is actually a typo I
think this is supposed to be around the
x axis so again if you permit me the x
axis is pointing parallell through the
hip and what they're going to evolve is
they're going to evolve the starting hip
angle of the right
leg when the robot is placed at the top
of the declined plane so this would be a
b subby of zero this would be a b suby
of about
45° B suby of 30 B suby of 10 in order
to get the passive Dynamic Walker to
start walking it can't start at the top
of the decline plane with both feet uh
with both feet on the ground it's got to
start with one foot in front of the
other
uh in the air it's a little difficult to
see in this
video you might be able to see it when
we loop around to the beginning of the
video I think they clipped a little bit
of the the Beginning video we need to
actually have the robots leg a little
bit up in the ground so it starts to
fall forward and movement starts you can
actually see it a little bit better uh
actually can't really see it here either
my apologies you have to trust me on
this one okay so we now have a vector uh
with 12 numbers inside and if we take
those 12 numbers we can we can treat
those 12 numbers as a blueprint which
tells us how to build this biped inside
the evolutionary algorithm there's a
population of these vectors so the
second Vector might contain a different
set of 12 numbers which when we use it
to construct the robot produces a second
robot with a different body from the
first robot so you can really visualize
this evolutionary algorithm as evolving
the body
of the this biped robot towards the end
of this course we're going to see a lot
more examples of evolutionary algorithms
that evolve the body and brain of robots
this is sort of the first time we've
seen this so take a moment to absorb uh
change okay they're going to actually
not just evolve those 12 numbers they're
going to evolve some additional numbers
and those are encoded as follows they're
going to add an additional morphological
detail to their robot which we've
mentioned in passing before but we
actually haven't taken any time to
discuss we're going to do so now you'll
notice that they also built some Springs
into the robot they took a one spring
and connected it to the top of the
robot's right hip and attach the bottom
of that spring to the front of the
robot's right front to the front of the
robot's right upper
leg they attached a spring from here to
here they attached another spring from
inside the pelvis of the robot and again
attached it to the inside part uh of the
leg same thing on this side and this
side what do these Springs do well what
they mean is that if you imagine the
robot's right leg swinging forward
that's going to compress this spring
Springs don't like to be overly
compressed or overly uh lengthened so
the the spring will actually apply a
restoring Force if the spring is
scrunched up when the robot's right leg
swings forward the spring will apply a
force that pushes down against the uh
upper leg and pushes the leg backwards
we're not introducing any new energy
into the robot this is just the nature
of Springs alternatively if the right
leg swings back and away that's going to
St stretch that spring and that spring
doesn't like to be overly stretched so
it's going to in this case pull the
front leg
forward so this robot remember has no
sensors no Motors no batteries no neural
network controller it's a pure me
mechanical mechanism but it's now got
some Springs in it as well we've got one
two three four five six Springs same
thing here we're going to attach the top
front of the foot to to the shank and
another spring attaching the right side
the outer side of the foot to the shank
remember there are two springs on the
other side as well everything is exactly
uh everything is exactly the same so if
we just think about one side of the body
we've got one two three four Springs and
what's not shown here is there is a
fifth spring at the
knee you can probably imagine where this
is It's a spring that attaches just
across the back of the robot's
knee okay so we have five Springs on one
side of the body here's a list of them
here I'm not going to read them all off
but we've got uh uh two at the ankle the
two A's we've got two Springs in the hip
the two h's and we've got one that's not
shown here at the
knee in order to simulate a spring we
actually need uh we actually need five
numbers sorry in order to describe any
individual spring or simulate any
individual spring we need two numbers
the stiffness of that spring and the
damping coefficient of that spring so
let's imagine an individual spring and
think about that spring having different
stiffnesses or having different damping
coefficients you'll have to apologize my
little Scrolls here they're not uh
perfect let's actually start in the
bottom right this is the easiest one to
understand in this case uh in this
case in this case we have an example
spring that has low stiffness it's very
easy to push and pull on that spring and
no damping and we'll see the damping in
a moment so if we imagine time along the
horizontal axis here and we imagine the
vertical axis as uh whether the robot is
stretched Beyond its natural resting
length Every Spring likes to just be at
a certain length if we uh pull it Beyond
its natural resting length it will
gradually try and contract back and if
we compress it Y is less than zero we
compress it to its less shorter than its
resting length it will push and try and
expand back towards its resting length
so a low stiffness no damping spring
means if we let it go it will bounce
back and forth forever that's low
stiffness low damping let's go to a a
different spring that has the same low
stiffness It's relatively weak it'll
bounce uh back and forth quite a bit but
it's going to have damping in it meaning
that as it uh bounces back and forth it
will gradually settle down to y equals 0
here which is its resting uh
length let's switch over uh from the low
stiffness low damping case to a high
stiff highly stiff um non- damped spring
over here a spring with high stiffness
is very hard to uh is very hard to pull
Beyond its natural resting length and
very hard to push past uh to push it to
be less than its natural resting length
this would be like a spring that's made
from very thick iron it's very hard to
move it so it's got very low amplitude
oscillations but it could it might have
no damping even if we can move it a
little bit and let it go it will
oscillate at low amplitude about its
natural resting
length um a a spring with high stiffness
and high damping is also highly stiff
it's very it resists with great force
being pulled or pushed away from its
natural resting length and it has
damping once you let go it will
gradually come back to rest at its
resting length so there are two numbers
uh the stiffness and damping
coefficients that determine how how
stiff and how damped that spring is
remember that in one leg we have five
Springs each spring has two numbers
associated with it so we've got a total
of 10 numbers required to specify how
the five Springs in one leg
behaves remember that there are also
five Springs in the other leg but
everything about the bipedal robot is
bilaterally symmetric every every
parameter on the left side of the
robot's body is identical to that same
corresponding parameter on the other
side so the stiffness for example of
this spring on this leg is equal to the
stiffness of this spring on the far side
of this leg and so on okay so just a
review imagine that we remember that
we're going to try and
evolve sets of parameters to set all of
these body parameters and these body
parameters how many total body
parameters are we embedding in this one
long Vector that encodes the genotype
that is the genotype for a particular
robot I'll take you I'll give you a
moment to think about
this as you'll recall we have 12 total
numbers here and 10 numbers here there
are a total of 22 different body
parameters that describe that tells the
evolutionary algorithm how to construct
a particular biped in the phys extension
okay okay I told you that so far this
robot does not have uh this robot does
not have a a neural network controller
it doesn't yet but it's going to in a
moment and we'll come back we'll come
back to this okay it is going to have a
brain but we'll talk about that in a
moment okay so we've got this population
of length 22 vectors one 22 length
Vector another 22 length vector and so
on so we have a population of 100 length
22 vectors there are 100 candidate
robots that we need to assess the
fitness for in the first generation how
do we assess how well that set of 22
numbers translates into a uh a robot
that's or a mechanism that's capable of
passive Dynamic walking well we could
create a fitness function that's equal
to D where D is just the distance
traveled we have our declined plane in
simulation we put we construct a
particular bipad with a certain height
and certain Mass distribution and
certain spring properties inside of it
we rotate the right hand leg to whatever
that angle should be let the leg go and
just watch how far down the decline PL
plane this robot gets and we measure
that distance it travels uh along the
declin plane and set that to be its
Fitness imagine running this
evolutionary algorithm at the end we're
going to have a robot that is able to
achieve a very large D how do you think
the robot behaves in order to accomplish
that
D if you've been paying attention in
this class at all you'll know that it
probably perversely instantiated this
Fitness function the easiest way for
something like this to uh achieve a long
distance down a decline plane is fall
forward and slide all the way head first
or hip first in this case to the bottom
of the declined
plane that's why in this experiment the
investigators did not use a fitness
function of F equals D I'm going to
guess they probably did at the beginning
but then they had to add on some
additional terms to this Fitness
function to maximize uh displacement but
minimize all the wrong ways of uh
moving so I'm going to skip uh I'm going
to skip ahead and talk about this
particular term for a moment you'll see
that it's one over 1 plus Z and if we
look at the legend here it tells us that
Z is defined as the hip rotation about
the uh about the Z
axis what does that mean um a robot that
has large hip rotation about the z-axis
and I promised you that the ministry of
silly walks video is going to be
important here's where it's
important a robot that maximizes
rotation about the Z axis is going to be
a robot that walks like
this if we uh measure the total amount
of hip rotation about the Za axis as the
robot walks down the decline plane in
the simulation if we sum all those
rotations and make sure that it's a
positive number maybe we take the
absolute angle about
Z we want to minimize this number we
want to have as little rotation about
the Z axis as the robot walks down the
decline plane so by multiplying D * 1
over 1 + z we're telling Evolution to
evolve a gate a way of moving for this
robot that maximizes distance and
minimizes this unnecessary rotation
about the vertical uh
axis okay um I'm going to skip over one
over one plus T this will come this will
be you there's no forces being applied
in this first uh
step this next term I want to talk about
is one over 1 plus X this is hip
rotation about the x axis so the x axis
is the one that points in parallel
through the hip I want you to think
about the opposite case imagine a robot
that gets high D it manages to walk down
the or move down the deine decline plane
not necessarily
walk uh and we want want to minimize a
rotation about X again apologies for the
silly walks a robot or mechanism that
maximizes rotation about X would walk
down the decline plane like this as well
as a robot that falls forward that would
incur a lot of rotation about the x axis
on its way down to fall on its face or
fall on the front of its hip on the
declined plane
so by minimizing in particular this by
minimizing X again assuming X is a
positive value the The evolutionary
algorithm penalizes robots that fall
forward and robots that walk down the
decline plane like this okay let's see
we've covered this one this one 1 over
1+ R this is feet rotation about the Z
axis this one's kind of odd they must
have got a lot of cases where the feet
were yawing a lot they were rotating
about the vertical axis quite a bit and
I will allow you in the uh privacy of
your own home to act out a robot that
maximizes y hip rotation about the y
axis can you see it okay are you doing
okay okay again my apologies for some
reason the investigators did not capture
any uh videos of successful or
unsuccessful robots so you'll have to
trust me uh at this point that in this
very first stage where they were
evolving passive walking they evolved
the body parameters uh they put the
robot on the declined plane and uh they
let the robot walk down the declined
plane you'll mention you'll see that
there's some additional uh details here
something about a cpg I just want to
make sure that we get this clear in our
heads first in this first phase of
evolution they're mostly evolving the
body and they're trying to get the body
right in order for this thing to
passively walk down the declined plane
okay let's back up a little bit
now this is the neural controller that's
eventually going to control the robot it
doesn't yet with the exception of one
small piece uh one small piece of this
network there is a particular uh neuron
up here called the cpg and we'll talk
about this neuron in a moment you'll see
that the cpg has synapses that connect
the cpg to the some of the Hidden
neurons and these hidden neurons connect
to two motor neurons one that controls
the uh X joint in the hip and the other
one that controls the
Y uh the Y rotation in the hip I'm just
going to back up for a
moment to where did we get to uh here so
remember there are two uh there are two
hinged joints in the
hip these are the to two motor neurons
that control it yeah so we're actually
in this first stage going to evolve
those 22 body parameters and an
additional one 2 3 four five 6 seven
eight numbers the weights of those eight
synapses so strictly speaking this is
not a perfectly passive Dynamic robot
it's going to be a little bit active
there's going to be a little bit of
force act acting upon the mechanism from
these two motor
neurons what is this cpg neuron the cpg
stands for Central pattern generator
it's a centralized place in this neuron
that generates a particular pattern in
this experiment you can think of the cpg
as a metronome it's going to emit a
pulse at a regular time
interval during those pulses the CP G is
set to one and during all the other
periods the cpg is set to zero okay what
is this time interval for now it doesn't
matter in this very first experiment the
cpg is going to send a signal a a value
of one to the right
leg which as you'll recall at the top of
the decline place has been uh rotated a
little bit off uh rotated a little bit
in front of the robot and then the cpg
is going to fire during the first time
step of the
simulation there's going to be a little
bit of firing and the weights of those
uh eight synapses are going to
influence how the leg moves in response
to that firing of the cpg so there are
going to be there's going to be some
Force applied by the motors to the Joint
to the The Joint in the hip at just the
first time step
and then the cpg will go quiet it is not
going to emit a pulse at a regular time
interval yet everybody see that okay
okay so um let's go back to this last
term here now we can talk about this one
one over 1 plus T in the very first time
step the motor neuron uh one one of the
motor neurons sends a force or a torque
a rotational Force to the uh hinge joint
that's controlling rotation about the Y
AIS in the right hip very specific we
want to apply as little torque as
possible we're really trying to keep
this to be a passively dynamic mechanism
we're trying to minimize in this Fitness
function we're trying to maximize D
minimize t x ZR and
Y okay so now we can come back here in
this first stage of evolution they're
going to evolve all 22 body parameters
plus the eight cpg to motor uh to to
motor neurons that we just saw so this
Vector is not actually length 22 it's of
length 22 plus 8 it's of length
30 when we go to evaluate each genotype
each set of 30 numbers we build our
robot set it up at the beginning apply
this one cpg pulse which kind of
electrifies the right leg for one time
step then goes quiet after that pulse
turn off the cpg turn off the whole
neural network and for the remaining
time steps the robot is a purely
passively Dynamic
mechanism okay again I'm so sorry you're
going to have to trust me there's no
video they manage to evolve a robot that
passively dynamically walks down the
declined
plane at this point in evolution they
now have a set of 30 numbers that can be
used as a blueprint to build a simulated
mechanism that successfully passively
dynamically walks down the declined
plane that's all it can do if you take
this robot and put it on flat ground
after Evolution there's no reason why it
should actually walk so in this
experiment they moved on to a second
stage in which they continued Evolution
they continued evolving these length 30
vectors to try and expand or actually
broaden the robustness of the robot that
it can walk down decline planes and also
walk over flat ground they're going to
start to slightly change the tradeoff
that this particular passive Dynamic
Walker has struck between Locomotion or
sorry displacement stability uh
robustness and Energy
Efficiency okay how do they do that
um let's uh talk about uh what's
familiar they're going to keep evolving
all 30 numbers the 22 body parameters
and the eight synaptic weights that
connect the cpg to the PO two po motor
neurons in the
hip during the evaluation of a of a
single robot at the beginning of
simulation they're going to put the
robot at the top of the decline plane
rotate the right leg to whatever angle
it should
be sorry I'm jumping around a little bit
here they're going to at time Step Zero
allow the cpg to send a pulse to the uh
motor neurons in the right leg so the
right leg will Jitter a little bit and
then the robot will start to hopefully
fall forward as the time step runs t0 T1
T2 T3 and so on at T subk some K * steps
in the simulation occur until the heel
the right heel of the robot strikes the
ground the right heel of the robot
strikes the ground okay at that time
they're going to assume that that period
of time K time steps should be the
natural Rhythm of the
cpg at that moment K the cpg sends a
value of one to the motor neurons in the
left leg and is sending zero to the
right leg so here we go we got the cpg
up here it sends a value of one to the
right leg boom K time steps go by the
right uh the the right heel hits the
ground it send the cpg sends a one to
the left leg and then goes quiet for
another ktime steps then it sends a one
to the right leg K time steps sends a
one to the left leg K one k one
K1 K becomes the frequency of the gate
for that robot everybody see
that okay that's what we mean by regular
time interval here we don't know what
that regular time interval should be we
calculate it based on the Dynamics of
the
robot okay so in the second stage
they're evolving the robot uh they
they're continuing Evolution on they've
already evolved these 30 vectors to get
walking down the declined uh
plane and they're now allowing the cpg
to apply an Impulse Force to uh to the
legs at a certain
frequency
okay at this point we're evolving I'm
going to go back to the brain for a
moment so you'll see the cpg actually
has synapses that
connect to all of the five motor neurons
neurons in the leg here's some more
connections it's is a little bit messily
drawn these are all the hidden neurons
here the cpg fires what you're looking
at here is the neural network a neural
network for the robot that controls just
one leg remember that the passive
Dynamic Walker is bilaterally symmetric
so there is this neural network inside
the robot's uh inside the robot's left
side of its body the same exact network
with the same set of synaptic weights in
the right side of the body so whatever
these weights are whatever they cause
the robot that leg to do in response to
the cpg signal the other leg does
exactly the same thing in response to
the cpg signal ktime steps later so all
the the five motor neurons do what they
do when they get their cpg signal and
then the other five neurons the other
five motor neurons and the other leg do
what they do K times steps
later
okay okay let's
continue so we just described uh this
three-part experiment where in the first
phase of evolution they evolved passive
Dynamic walking down a declined plane
and now they're going to continue
evolving the population uh of control of
controllers and bodies for these robots
to evolve them in into hybrid Dynamic
Walkers they're going to walk them along
uh an increasingly lower declined plane
so evolve evolve Evol evolve evolve
evolve for Passive walking down the
decline plane pause and now make a few
changes we're going to lengthen the
genotypes so that we're now
including I'm sorry we are not going to
increase the length of the genotypes
we're continuing to evolve the synaptic
weights that flow from the central
pattern generator so the motor neurons
we're going to continue to evolve the 22
body parameters but we are going to make
a change to the fitness function as we
continue evolution in this second phase
we're going to add a new term we're
going to multiply all of this by a new
term one over one plus V where V
represents the difference between the
robot passively walking down the decline
plane and the robot walking in a hybrid
manner down a gradually lowered decline
plane over evolutionary time during the
second phase they're going to gradually
make the declined plane more and more
shallow we've seen this concept several
times now this is the idea of
scaffolding by the end of the first
phase it's relatively easy for many
genotypes in the population when used to
construct a biped that bipad walks down
the decline plane that that passive
Walker has a harder and harder time
walking down a shallower and shallower
declined plane so they're going to
continue to evolve it to do so we now
we're giving the cpg is giving this
regular pulse at every K time steps for
each
robot and every uh every genome is going
to be evaluated twice during this second
phase once on the declined plane in the
passive walking mode and a second time
on this shallower declined plane and
they're going to take the velocities or
the way in which uh the robot moves
under these two environments environment
one environment two and we're going to
try and minimize the difference between
those ways of walking so we want the
robot to evolve the ability to walk
using the regular cpg pulse in the
hybrid Manner and to move very similarly
to how it moved in the passive walking
case when there was only one CB cpg
pulse applied to the right leg during
the very first time step of the
simulation okay
uh this K time step this is going to be
different for different robots during
the this evolutionary uh period so
taller robots there might be a longer
period until the first heel strike for
shorter robots it may take a a shorter
period of time until first heel strike
so each robot probably has its own cpg
frequency okay so during this second
phase evolve evolve evolve evolve evolve
evolve evolve evolve evolve until at the
end of the second
stage uh most of the robots in the
population at that time are able to walk
in a hybrid manner with the cpg doing
this and they're also able to walk still
also walk passively down the decline
plane with just the cpg doing
okay okay uh I like this experiment
because it just keeps going at the end
of this evolutionary phase they paused
Evolution but they kept their population
of Rob robots at that time and now
they're going to then make some changes
to the evolutionary algorithm and then
start The evolutionary algorithm back up
again to evolve sensor-based walking as
you'll as you can see if we go back to
the neural network for a moment the only
synaptic weights uh the only part of the
brain of the robot are values flowing
from the cpg into the uh Mo into the
five motor neurons all of these synaptic
weights here that connect the ERS to the
hidden neurons all of these synapses
currently have a value of zero the robot
is blind and cannot feel anything in
this third in this third stage what
they're going to do is uh reconnect the
sensors to the neural network with small
connection weights what does that
mean they're going to take all of these
synapses which currently have a value of
zero and assign very small all random
numbers to them random numbers that are
close to zero and I don't know how many
synapses are in here there's a lot
they're going to add all of those
randomly generated numbers onto the end
of every uh every genotype in the
population that's sitting there at the
end of the second phase so they're
basically opening the eyes of the robot
a little bit it can see a little bit but
because these synaptic weights are still
very close to zero they're not
disrupting the robot's Behavior it's
still able to hybridly dynamically walk
down the declined on flat ground and
but there's a little bit of sensory
information coming in to influence that
behavior okay so we now have a much long
longer uh
genotype and then we start up Evolution
and we continue evolving uh the 22 body
parameters and all of the Sy aptic
weights connecting the cpg to the hidden
neurons to the motor neurons plus all
these new synapses it's a lot going on
in this experiment take your time and
make sure you've ABS uh ABS you've
absorbed all that during this third
phase of evolution they continue using
this Fitness function that is also
multiplied by this term here so they're
again looking to minimize differences
between the robot uh walking uh walking
as a result of being influenced by its
cpg and being influenced by the incoming
sensory
information as ution now continues on
during this third phase mutations might
start to increase the magnitude of these
very low magnitude synaptic weights that
connect the the sensor neurons to the
hidden neurons in essence If evolution
finds it useful it will gradually Open
the Eyes of the robots and uh and also
start to allow it to feel more angle
information proprioceptive information
I'm saying Open Eyes in a metaphorical
sense the robot doesn't have any visual
input in this case it simply feels the
movement of its body and it feels
contact with the ground so let's have a
look at all of these sensors which are
now in this third phase becoming
increasingly available to the robot to
modulate or alter how it uh moves so
you'll notice there's a whole bunch of a
sensors here a stands for angle sensors
so we've seen these before these are are
referred in different experiments to
angle or proceptive information they're
providing a number which corresponds to
the angle of the joint we also see some
new sensors that we haven't seen before
and these are Force sensors and these
Force sensors are actually sitting on
the springs and a force sensor returns a
value of zero if the spring is at its
resting length the length at which it
likes to be and that Force sensor
returns a negative number if the sensor
if the spring is stretched Beyond its
resting length and is trying to pull
back to its resting length and a force
sensor will return a positive value if
the spring is compressed and the spring
is trying to push the two things uh that
are on either end of it apart yeah
that's a a force sensor you actually
have Force sensor in your muscles as
well you can Fe that's what you feel
when you feel stretched or you're
pulling in those four sensors that are
embedded in your muscles or giving your
giving your body information about how
stretched or how compressed your muscle
groups
are two other kinds of sensors that are
in here um that we haven't seen before
these are rotation uh rotation sensors
so we've got rotation X rotation y
rotation Z and this gives uh the robot
information about how much it's tilting
about the x axis the Z axis and what am
I missing the y axis
yeah these three sensors here are kind
of like your inner ear which is your
vestibular organ that gives you
information about how your head is
oriented relative to down which is the
pool of
gravity uh you also have information uh
acceleration information coming in here
as well so how much the robot is
accelerating about its xaxis how much
it's accelerating about
its y AIS Z axis and x axis I know I
just mixed those up so the angle about
those three axes and the acceleration
about those three axes your inner ear
your vestibular organ also gives you
information not just about how your head
is oriented relative to gravity but how
quickly the orientation of your head is
changing and that's why when you spin
around in a circle you SOS all that
fluid around in your inner ear and when
you stop your inner ear is telling you
that you're still accelerating even
though you aren't and you fall down okay
so a bunch of sensors here some that are
familiar some that are new to us
regardless this robot has a bunch of
sensors that during Evolution Evolution
can start to increase the magnitude of
synaptic weight connecting those sensor
neurons to the hidden neurons and make
increasing use of that information to
modulate the robots uh Behavior again uh
I apologize about this experiment it
would have been great if they showed us
some videos of the robot successfully uh
moving uh this is the best that we get
this is a plot showing how the best
robot the most fit robot at the end of
stage three is moving you'll notice that
this particular robot um when it's
uh when its right foot starts up off the
ground the first heel strike happens
about 28 time steps into the simulation
so that sets a frequency for the cpg
which is like a metronome to to fire
every 28 time steps in the simulation
and this simulation lasts for a total of
250 uh time steps during each step so
the robot hits with its right heel hits
with its left heel right heel left heel
right heel left heel right heel during
each one of those steps you can see how
the angle of the hip I'm sorry not the
angle of the hip you can see how the
value um of the motor neuron that's
attached to that hip is firing and you
can see the value of the motor output
the value of the motor neuron that's
attached to the knee how it's firing the
reason I want that what I want the main
message I want you to take away from
this picture is you'll see that the
motor neuron that's attached to the knee
is firing near zero for the second half
of each step of the robot sound familiar
this should remind you of the beginning
of our discussion about passive Dynamic
walking and that in you when you're
walking you're walk Walking mostly
passively uh for half of the time every
month muscle group in your leg is slack
it is the muscle fibers are not pulling
there is nothing in this Fitness
function that explicitly rewards for
Energy Efficiency it falls out as a side
effect of the way these investigators
evolved initially passive walking down a
declined plane then continued to evolve
those robots to walk hybridly on flat
ground and then finally to walk in a way
in which the sensors mod modulate or
control uh how that walking
occurs
okay they they kept going um this is the
experiment that just keeps going so
we've seen three uh we've seen three uh
cases now oh I'm sorry I I misspoke um
no Evolution here they took some of the
best uh they took the best Walker I
think it was this one from the end of
the third phase and they played back
that Walker many many times and that
Walker is walking over flat ground at
this point using hybrid Dynamic walking
pulse pulse pulse
pulse and they exposed the robot to
increasingly strong wind so when they
played back the robot the first time
there's no external perturbation to the
robot and the robot takes about 38 steps
before uh falling over or it might have
been 38 steps and that's when the
simulation ends doesn't matter for our
purposes they then took the ex exact
same robot with exactly the same neural
controller and set of evolved synaptic
weights and now as the robot was moving
they applied small external impulse
forces to the robot remember that
gravity pulls downward on the robot in a
simulation in the same way we can add
additional external forces to the robot
not just an external Force pulling the
robot down and we can apply it at random
angles those forces forces are vectors
remember we you can apply those Force
vectors anywhere at any angle at any
point on the robot's body and simulate
something like uh wind in very mild wind
there's no effect on the robot it also
takes 38 steps reset the robot uh and
allow it to start walking again in
slightly stronger wind stronger wind and
stronger wind and it isn't until wind is
at 5 and my apologies the physics engine
that they used like ours is also
unitless so it's hard to say how strong
the forces were of five but whatever
five was the robot starts to take fewer
and fewer steps but it's still taking
quite a few steps before it falls over
so for example at a on a windy day here
of 10 the robot is able to take 15 Steps
before it falls over and even in very
windy conditions here it's still able to
take five steps before falling over so
this is interesting because the robot
was never evolved in windy conditions
we're exposed osing the robot to
external perturbations it never saw
before and in this case it happens to be
relatively robust uh in the paper the
investigators actually mentioned that
when the robot was pushed too far to one
side the robot was OB observed to adjust
its foot placement by stepping inward to
regain its balance that should also
sound familiar to you remember the video
of the four-legged uh walking big dog uh
when it was kicked or it slips on the
ice it's able to change how it places
its feet very rapidly to recover its
balance same thing here
okay uh I'm sorry I misspoke uh this
they were evolving for another I'm sorry
they were evolving for another 100
Generations under uh windy conditions
I'm I'm sorry I misspoke so sorry of
phase one evolve passive Dynamic walking
down a declined plane step two continue
of evolving those robots to walk
hybridly on flat ground phase three
continue to evolve these robots but
allow the sensors to increasingly
influence how the robot walks and in
phase four evolve the robot in
increasingly windy conditions and the
fact that the robot uh changed how it
walked when it when it started to fall
over when it was pushed that's thanks to
the sensors a robot without sensors if
it's perturbed wouldn't know first of
all wouldn't know that it's perturbed
let alone know how to change its way of
walking to
recover they continued evolving for uh a
fifth phase and in this phase they
didn't introduce uh external
perturbations like wind they introduced
internal perturbations every time they
took this now very long genotype and
they pulled out the 22 numbers that
serve as the blueprint to tell the
physics engine how to construct the
robot they introduced mistakes into the
blueprint not into the genotype itself
they kept those 22 numbers as they were
but when the physics engine was reading
out those numbers to set leg length for
example and figure out where to place
the mass um on the thigh they'd
introduce small mistakes so here's an
example um this these two robots were
built from exactly the same set of 22
body parameters and you can see one
robot is taller than the other which
means this L inherited an overly large
number and this L inherited a pretty low
number uh and so again now on the
horizontal axis they look to see at the
end of this fifth phase of evolution now
passive walking hybrid walking
sensor-based walking walking in wind and
walking in the presence of manufacturing
mistakes the robot is still able to take
a large l number of steps even if its
body parameters are are about 7% on
average uh
incorrect why would the investigators
bother uh doing this well at the time
this paper was written there was this
brand new technology that was being
introduced called 3D printers and that
immediately woke up most roboticists to
the potential that in the future we
would be actually 3D printing robots
rather than making them by hand 3D
printers were probably going to be a
wonderful technology but like every
machine they were probably going to make
mistakes so in the future if we're going
to have 3D printers that are stamping
out and Manufacturing a large number of
robots they're going to make
manufacturing errors and we would like
those designs that are being
manufactured to be robust to
manufacturing
air okay all right now Evolution ceases
we're finally done they took the most
fit robot from the end of that fifth
phase this is a robot that can walk
passively down a declined plane it can
walk in a hybrid manner on flat ground
it walks in response to the cpg and its
incoming sensory information it's
somewhat robust to wind and it's
somewhat robust to manufacturing error
and like we saw when we talked about the
figures uh what we talked about at the
beginning of this lecture when we were
looking at the biome mechanics of animal
they performed an interesting experiment
where they altered the frequency of the
cpg they sped up the metronome and
slowed it down okay let's have a look at
this so what we're looking at on the
horizontal axis here is a total of about
a thousand time steps in one simulation
where they simulated this one most fit
evolved robot and the natural dynamics
of the robot set the metronome or set
the cpg to fire every 35 time steps 35
70 105 140 and so on so I want you to
pay careful attention to the widths
between the Peaks between uh neighboring
peaks of the cpg when it's firing and
you'll notice that in this period here
they've actually narrowed the width
between these strikes this is them at
this point in time speeding up the
metronome and you can see that something
is happening to the stride uh length
here so step length is plotted on the
vertical axis so these Blue Mountains
here correspond to how far out in front
of its body the robot rotates each leg
when that leg is the swing leg so here's
the robot taking a relatively large
stride and when they speed up the
metronome what does the robot do it
starts to take shorter faster steps to
keep up with the faster beat of the cpg
you can simulate this yourself again do
this in the privacy of your home where
nobody's watching is Count off to
yourself a certain a certain Pace one
two three four and take steps at that
pace and then in your head start
counting faster 5 6 7 8 9ine 10 what do
you have to do generally speaking unless
you want to really break a sweat you can
just take shorter steps and faster steps
to keep up with that fast fter
metronome in the last third of the
simulation they slow down the metronome
the metronome the width between the
Peaks or the strikes of the cpg in here
these widths are actually wider than
these wids over here it's a little hard
to see it's okay if you can't see it
what you can see is the height of these
mountains is even higher than the height
of these mountains during this
slower uh Pace in the cpg the robot is
taking much longer strides than it
evolved to take naturally not uh not
very uh
surprising this is something that humans
tend to do in bipedal walking when they
want to walk faster or
slower okay that concludes uh our our
lecture on bipedal locomotion in the
next lecture we're going to switch gears
and start to address and uh review some
of the open problems in evolutionary
robotics thank you see you then


--- Evolutionary Robotics course. Lecture 16： Modularity..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone um we are
Switching gears this morning we have
finished our uh discussion about the
admittedly brief history of evolutionary
Robotics and we're moving on to a new uh
module in the course open challenges in
evolutionary robotics since the field uh
is so young there are a number of
questions about how to go about
appropriately evolving and automatically
designing autonomous machines that still
don't have good answers to them as I
mentioned at the beginning of the course
I hope some of you enter the field as
well and maybe some of you will find
good answers to some of these uh open
problems or open
challenges uh we're going to spend uh
two lectures lecture 13 and lecture 14
looking at uh a conceptual issue in the
field which is how to map genotypes onto
good phenotypes what do we mean by that
we haven't really talked about this too
much yet just to refresh your memory the
genotype is the data structure that
encodes the blueprint of uh the robot uh
Andor its neural controller in the
previous uh lecture by petal Locomotion
we just looked like looked at a genotype
which was a vector that contained uh 12
numbers specifying aspects of the
robot's uh body and a whole bunch of
other numbers specifying the synaptic
weights of its neural controller turns
out that there's lots of different ways
to turn uh genotypes into phenotypes and
a lot of those ways sorry and the
phenotype is of course the robot's uh
body and how it moves Form and Function
that's
phenotype there's a lot of different
ways to transform genotype into
phenotype and some are better than
others um throughout this course so far
we've been looking at sort of the most
basic direct way to turn genotype into
phenotype we take every single number
and use that to set some parameter of
the robot's body or brain uh not so much
in lecture 13 but in lecture 14 we're
going to start to look at some more
complicated ways of taking the genetic
information stored in the robot and
turning it into the robot itself and how
that can go wrong and how to make it
better with an algorithm that's quite
famous in our field that's called the
neat
algorithm in lecture 13 we're going to
look at sort of a subset of uh the
genotype to phenotype uh mapping problem
which is that usually when we take
genetic information and and turn it into
uh the synaptic weights of a
robot uh that neural network is very
non-modular meaning that the synaptic
weights are all nonzero and every all of
the information from every sensor goes
to every motor or every hidden neuron
and all the information in every hidden
neuron goes to every motor neuron so any
incoming information to the robot
quickly spreads everywhere throughout
the brain of the robot as we've seen in
many of these neural
controllers uh most brains for our robot
every neuron is almost connected to
every other
neuron and even if not every neuron is
connected to every every other neuron
information sort of bleeds throughout
the brain of the robot and it's very
hard for it to divide and conquer to
break up problems into sub problems in
its head and then execute accordingly
that's known as the lack of modularity
problem and we're going to look at one
solution to this in the field which is
to uh allow Evolution to make more
modular brains so uh in starting lecture
13 today we're going to talk about
modularity first and then modularity as
it relates to robots uh modularity is of
course a very uh important Concept in
many many fields it pops up in different
places because it's such a general and
important idea um it's got different
definitions in different
fields but the underlying idea of
modularity in all of those fields is the
same we've got some machine or in our
case a neural network and we want to see
tighter coupling within modules and less
coupling across
modules an obvious example of this is
any phys complicated physical machine
like a like a car if you open up the
hood there are modules there is an
engine there are the brakes there is the
battery there's the windshield system
and so on by making a car in a modular
fashion you can obviously replace or fix
one part of the car uh without
disrupting all the rest of the car one
part can start to wear out a break down
that doesn't necessarily cause the car
to break as a whole it seems so obvious
that we would build that way that often
we don't even
realize that modularity is important and
that it's very easy in some cases to
start to make machines that aren't
modular imagine a car where if you get a
small scrape uh on the windshield the
entire car breaks not an ideal way to to
do
things another obvious example of
modularity is OB object-oriented
programming objectoriented programming
was invented to make it easier for
coders to create modular uh code so a
module and object-oriented programming
is obviously of often referred to as an
object and the reason why we try and get
better at object-oriented programming is
the same reason as for the car we want
to make sure that if we fix or modify
one small part of the code within one
module that doesn't necessarily break
all the other parts of the system so in
any modular system a well-written
modular piece of code or a car change
your removal of a module has relatively
little effect on overall performance
except of course if it plays a critical
role if something goes wrong with your
engine uh while you're riding a car
you're out of
luck okay so again just to reinforce
this idea if you're comfortable with
object-oriented programming you can skip
over this slide but for those that are
still learning about object Orient ented
programming it's worth reinforcing this
idea of
modularity in good objectoriented
programming we try and hide the internal
complexity of an object or a class from
the other objects or classes that call
its functions so going to skip over
pyrosim shape here for a moment um
you're in the process of modularizing
your code or you've recently done it um
here's one way you could do it you could
create a class called robot and inside
that class robot there are three
functions that other objects other
modules can call create draw and delete
the robot now as you all know now know
by by heart um there's a lot of internal
complexity to a robot it's got a neural
network controller we have to Define
aspects of its bodies its joints we need
to tell the robot how to move how to
sense and so on but from something like
an evolutionary algorithm that's just
calling a simul to create and draw and
delete that robot it might not that that
other piece of code or that other module
doesn't necessarily need to know about
all this internal complexity we want to
hide it from there so if you want to
make a change to the robot you can make
it in here and you don't need to make a
change in the evolutionary algorithm or
the fitness function you can divide and
conquer okay so as we start to uh
consider modularity in robotics and in
evolutionary robotics in particular we
need to pay attention to two different
kinds of modularity modularity in
general is
useful but when it comes to neural
networks uh that control robots there's
two kinds of modularity we can build
into or look for in a neural network the
first one and the most obvious one is
structural
modularity and to uh motivate the
description of structural modularity
let's have a look at a figure we've
looked at before this is a figure from
The Experiment where there was a small
humanoid robot that was shaking the
block left and right and then up and
down and forward and backwards and so on
in that case that robot had a whole
bunch of little motor Primitives left
right left right up down up down and so
on and in this figure just to remind you
you can think of these little colored
squiggles as the actions of the motor
neurons that produce that little motor
primitive so green is Left Right red is
up down blue is forward and back and so
on
the investigators could have created a
structurally modular Network in which
they made little uh Bunches of neurons
connected together that would produce uh
Left Right motion of the robot then they
could have created a separate little
neural module where they made a subset
of neurons and wired them all up that
together would produce up down motion
and so on and they might have included
little or no synapses connected ing
these little neural modules together the
robot could dream up in its head these
different ways of
moving and then we could imagine a
fourth and final neural module another
little collection of neurons that would
turn on or
off uh this gate selection module that
would turn on and off which of these
little ideas in the robot's head were
allowed to grab onto the neurons and the
robot would actually execute what it was
thinking about
this idea also relates back to the
subsumption
architecture that we talked about at the
beginning of the
course uh and that's inside AR Roomba if
you have one so that's structural
modularity we've got a whole bunch of
neurons but some sets of subsets of
neurons are wired up tightly together
and there are little little to no
connections between those neural modules
that's structural modularity if you
don't have structural modularity if you
have a neural network and in which every
neuron is wired up with a synapse to
every other neuron then as the number of
neurons n grows the number of synaptic
connections grows quadratically grows as
as a function of n SAR every neuron has
to be wired up to every other neuron
including itself so lack of
modularity lack of structural modularity
is problematic because as the robot
becomes more complicated and its neural
network controller has more and more
neurons in it the number of synapses
grows
incredibly an Evol and an evolutionary
algorithm is going to have to find a way
to set all of those weights correctly
the more synapses there are the harder
it is for evolution to do
this there's a second type uh of
modularity which we saw actually when we
talked about this humanoid robot which
is functional modularity in this case uh
we might not necessarily have a network
that's structurally modular so here's my
little cartoon of a neural network down
here that is not structurally modular um
you don't really see tightly
interconnected uh neural modules every
neuron is more or less connected to the
same other subset of a bunch of other
neurons it's kind of a
mess however this network as we saw the
neurons that can change their values
quickly that have low time constants
can be pushed by the slow neurons the
neurons that have high magnitude time
constants these purple neurons change
their values slowly over time these slow
neurons can push the fast neurons into
different discrete patterns the red
pattern then if the purple pattern or
sorry the purple neurons the slow ones
can push the fast these fast neurons
into the green pattern and then if the
purple neurons change their value they
push the fast neurons out of the green
pattern and into the red pattern and so
on so we get functional modules it's the
same neurons but they're producing
different discrete patterns at different
points in time that's functional
modularity in this particular lecture we
are not going to talk about functional
modularity we're going to focus mostly
on structural modularity but it's
important to keep this uh this
distinction in mind
okay so how does modularity or lack of
modularity why is this a problem for uh
evolutionary robotics so again we might
not we might not we we probably don't
want to have a robot in which every
neuron is attached to every other neuron
uh it's difficult and we would also like
the robot's Behavior itself to be
modular we would like uh to we would
like to break the task for the robot
down into several subtasks like we just
saw here into several motor Primitives
and maybe we would like to assign a
subnetwork to each task in the humanoid
robot uh experiment we saw um the
investigators wanted to avoid this idea
but for our purposes let's keep things
simple there's K different things we
want the K different subtasks we want
the robot to do and we want to create K
different neural modules that allow the
robot to achieve those subtasks and if
the robot is able to juggle these K
different subtasks and and execute them
in the right place at the right time the
robot will end up performing whatever
the overall task is that we want it to
perform correctly yeah sometimes that's
a better way to go than just sort of uh
create a fitness function that selects
for a very complicated task without
breaking it down into subtasks and hope
for the best um the robot or The
evolutionary algorithm is often not a
able to evolve that uh competency for
the robot because its neural network
controller is non-modular every neuron's
wired up to everything else and the
robot has a very hard time breaking
tasks down into
subtasks so we could ask the roboticist
before before evolving the robot to
actually do this try and bait break the
task down into several subtasks there's
problems with
that so alternatively we could ask the
evolutionary algorithm to try and not
only evolve synaptic weights for our
neural network but also to cut the
network into pieces actually discover a
good way to modularize the neural
network controller of the robot to make
it easier for that evolved robot to uh
execute these subtasks
independently
okay however uh thinking about thinking
is misleading the roboticist and the
robot may have different ideas about
what counts uh as a behavior and ways to
break down the problem so um again this
idea of thinking about thinking of
misleading it's got lots of different
reasons here's one of them which is when
we look at or we think about a
hypothetical robot that we want to solve
a particular problem we are actually
looking either literally or in our head
at the robot from a distance and this is
called the distal perspective of
behavior we're thinking about what the
the robot's behavior is or what it
should be from a distance and we
actually saw this idea when we first
talked about brenberg Vehicles when we
looked at that first simple brenberg
vehicle that had One Sensor One motor
and one wire and it was moving faster or
slower through warm or cold water
brenberg told us that when we look at
that robot from a distance we might say
that it's alive it looks like it's
thinking about or it feels cold and so
on things start to go wrong
when we start to reason about a machine
or even an organism from a
distance just to reinforce that idea uh
imagine this very simple robot here two
wheels and five proximity sensors
emanating out from the front of the
robot and at one point in time we as a
distant Observer see the robot drive
past a
cylinder and at another point in time we
see exactly the same robot drive past
this Cube here this block we might say
there's the robot driving past a
cylinder and there's a robot driving
past the block those two English
sentences those descriptions of the
robot's Behavior are different which
might lead us erroneously to think that
the robot is experiencing two different
things in those two different
situations you can see from the way that
I've drawn this cartoon that from the
robot's perspective what it feels at
these two different points in time is is
identical the five numbers arriving at
the five sensor neurons have exactly the
same five values the lengths of these
proximity sensor beams are the same and
you can see that down here so from the
proximal perspective proximal meaning
close by so literally in the robot shoes
seeing the world through the robot's
eyes or through its sensors these two
situations are identical so if we start
to think about these two things as
different situations that might lead us
to break the tasks down into deal with
the cylinder and deal with the block at
least in this simple example at these
two frozen instances of time the robot
cannot deal with the cylinder and the
block differently because the robot
considers itself to be in an identical
situation in these two cases so it might
be that what we think of as roboticists
is a good way to to break down a problem
into manageable parts and create neural
modules for the robot to deal with those
different T subtasks is not an
appropriate way for the evolutionary
algorithm to break down the task in
front of the robot into sub modules and
allow the robot to solve
it okay so we're going to look at
actually an old experiment we're going
back towards the beginning of
evolutionary robotics this was in about
the mid90s this experiment was conducted
the researchers asked the following
question how do we enable an
evolutionary algorithm to autonomously
discover discover neural modules
appropriate to the task they're going to
set the robot a relatively complicated
uh task which is to pick up all the
objects inside an arena move towards the
wall of an arena and drop those objects
off over the wall of the Arena that's a
pretty complicated task especially for a
little simple keer a hockey puck type
robot down
here so they're going to create an
evolutionary algorithm and a particular
type of neural network in which the
evolutionary algorithm can easily cleave
this neural network into different parts
and those different parts can control
the robots uh
Motors to solve this
task okay so remember that we're in this
uh module of the module of this course
in which we're talking about open
challenges
the challenge here again is evolution
tends to make nonmodular neural networks
everything tends to be wired up with
everything else the solution here is to
create or evolve particular kinds of
neural networks to give evolutionary
algorithm an option an option to create
modular neural
networks okay so um in this case our
robot has seven sensors there are six
infrared sensors so again it's got uh
it's able to detect things nearby on its
left side front side and right side with
these six numbers and it's got a seventh
little laser inside uh between the two
pincers of its gripper here and this is
going to be our light barrier sensor
when the robot goes to pick up an object
in its environment like a sugar cube for
example that object is going to pass
between the two pincers and break the
laser beam and that number is going to
be sent into the seventh sensor neuron
the robot is going to be equipped with
four motor neurons one motor neuron
controls the left motor the other motor
neuron controls the right motor neuron
the third motor neuron this is a little
bit different from what we've seen
before the third motor neuron is going
to trigger a preet motor primitive which
is object pickup when the third motor
neuron fires when it obtains a nonzero
value the the the Kea is going to do
this going to do
this when the fourth motor neuron
obtains a a non-zero value the robot is
going to do this when the third and the
fourth motor neuron are quiet they're
zero or near quiet the robot is neither
trying to pick up or release so this is
a little bit uh different from something
we've seen before the first two motor
neurons the for first two motor neurons
are controlling the wheels as the speed
of the wheels as we've seen before third
and fourth motor neurons trigger two
different kinds of motor
Primitives okay so let's think about the
task pick up all basically clean up the
arena pick up all the objects drop them
over the wall and out of the Arena I
want you to think for a moment about the
way you might divide and conquer this uh
task if we placed you in a big arena and
you had a bunch of jobs to do you might
for example break down what you need to
do into 1 2 3 4 five six different
behavioral modules the first one might
be move around and avoid walls let's
imagine that you're doing this task in
Pitch uh Blackness so you got to sort of
move around and find these objects if
you bump into walls uh move away from
them so we could further decompose this
first behavioral module into two subm
modules if none of your sensors in front
of you were firing you're reaching out
in the dark with your hands and waving
them around if you don't feel anything
move forward if you hit something on
your left turn to your right if you hit
something on your right turn to your
left and so on what we're describing
here is the coward brenberg vehicle so
we could imagine sort of the coward
controlling this robot uh so that it
moves around and uh turns away when it
bumps into the wall can imagine a second
uh a second behavioral module which is
if you or the robot happens to move in
in the in such a way that suddenly there
is an object between your two hands or
in the case of the robot it's two
pincers uh recognize the object and move
yourself so that you're ready for pickup
and then trigger your third behavioral
module some part of your brain that
coordinates the lifting of the object up
over your head now that you're holding
it uh now that you're holding it run a
fourth behavioral module this one might
be a modified brenberg vehicle that
causes you to move forward but not turn
away from a wall once you get to one
sixth behavioral module when you
recognize a wall position yourself right
up so that you're uh touching the wall
uh with your front then the seventh and
final behavioral module drop the object
over the the
wall okay you could imagine creating a
robot with seven
different uh neural modules in it that
if those any one of those modules is
allowed to control the
motors the robot will do that particular
Behavior that's one possible way we
could decompose the task you can
probably guess from my buildup to this
that in a moment we're going to see an
evolutionary algorithm divide this task
into a bunch of subtasks and they are
absolutely not what you might
expect okay um one of the elegant things
about this experiment that I like is
that the uh investigators snuck up on
this question about how to evolve robots
with modular brains by uh evolving the
robot to perform this task with an
incrementally complicated set of neural
networks this is not like the bipedal
locomotion lecture we just saw where
they're going to evolve for a while
pause make a change to the network and
then keep going they're going to do
separate evolutionary runs they're going
to evolve the robot uh they're going to
evolve robots with these kinds of brains
and see how well the robot does at the
cleanup task then they're going to reset
everything and start all over again
they're going to start Evolution all
over again with robots equipped with
these kinds of brains this kind of
cognitive architecture and evolve the
synaptic weights of this cognitive Arch
chitecture see how well robots evolve to
do the cleanup task when they're armed
with brains of type B redo it all again
evolve robots with brains of type c and
d and so on okay let's have a look at
these four different cognitive
architectures brains of type A are kind
of the simplest thing you could possibly
imagine we've got our
seven uh we've got our seven uh 1 2 3 4
5 six seven sensors uh down here seven
right yes six infrared sensors and one
light barrier sensor seven sensors and
each one of the seven sensors is
connected by a synapse to one of the
four Motors so this is a feed forward
Network the synapses are feeding forward
from sensors to Motors no hidden neurons
so no ability to remember anything uh no
nonlinear transformations of sensory
information into motor output and so on
okay next neural network architecture uh
of type B they've got the same seven
sensor neurons and the same four motor
neurons but they embed four hidden
neurons between them connect up every
sensor to every hidden neuron and
connect up every hidden neuron to every
motor neuron with a synapse no recurrent
connections here so robots armed with
brains of type B uh can evolve nonlinear
transformations of sensation into action
but they cannot remember anything there
are no recurrent connections
here cognitive architecture C we've got
our 1 2 3 4 five six seven neurons down
here and our sorry our seven sensor
neurons down here our four motor neurons
up here and we've got 1 2 3 4 hidden
neurons like we had in b but they've
been redrawn here uh we haven't seen
sensor hidden and motor neurons drawn
like this before you'll notice that uh
in this case all of the seven sensor
neurons are connected directly to the
motor neurons so direct uh direct
influence of sensation on on action is
possible in this cognitive
architecture these seven sensor neurons
each one of them also has a a synapse
that connects conect it to one of the
first two hidden
neurons the first two hidden
neurons have recurrent connections to
the third and fourth hidden neuron so in
type c we've got some recurrent
connections within the hidden neurons
which means that the robot has the
ability to remember if that's useful for
this task and the third and the fourth
hidden neuron have synapses that connect
them to
uh back to the two hidden neurons so
we've got a recurrent or Loops inside of
the Hidden layer and the third and the
fourth hidden neuron have synapses that
connect them to each of the four motor
neurons so this is a slightly different
wiring diagram to what we've seen before
but basically something we've seen
before sensor hidden and motor neurons
and we've got recurrent Connections in
case memory is
useful uh cognitive architecture D this
is the investigators the human
investigators attempt to force
modularity on the neural network and
thus on the robots Behavior we've got
our seven sensors down here and we can
see that each of the sensors is
connected to one of the four motor
neurons in motor module a and the same
seven sensor neurons are connected to
each of the four motor neurons in motor
module B
if you can imagine a robot equipped with
this uh neural network and it's driving
around in the arena all of these seven
numbers are turning on and off and
changing as the robot senses changes in
its environment and that is lighting up
the four neurons in each of the two
modules
differently in a sense robots equipped
with brain type D is are always holding
two different ideas about what to do
here in module a this is the robot
thinking oh maybe I'll rotate a motor
the left wheel like this and the right
wheel like this and I'm not going to
pick up and I'm not going to drop or
maybe I should spin both Wheels
backwards while I trigger the drop uh
motor primitive at any point in time
robots equipped with uh sensor
D are able to uh are are able it's
thinking about these two these two ideas
which of these two ideas which of these
four numbers are actually sent to the
motors again the human investigators
decided what that should be they decided
that when the gripper is
empty these four motor neurons grab
control of the motors and when the
gripper is full when the robot is when
there when that light beam is broken
there is either an object between the
pincers or the robot has is actually
holding an object these four motor
neurons grab control of the motor so
again this is kind of like subsumption
architecture the robot is holding
multiple ideas in its head
simultaneously and from moment to moment
these two different ideas can actually
seize control of the robot and make that
thought a
reality okay so just a review in neural
module a no modularity no hidden neurons
U neural uh brains of type B we've got
hidden neurons no modularity over here
we have memory and hidden neurons in
brain C but no modularity and in in uh
brain type D there is human enforced
modularity we're now going to look at
brain e the fifth and final type of
cognitive architecture they tried to
evolve uh on their robots this takes a
little bit to uh digest so from a high
level um this particular cognitive
architecture was designed by the human
investigators to make it easy for The
evolutionary algorithm to cut this
neural network in different ways to
basically if it's helpful and it may not
be if it's helpful for evolution to uh
evolve modularity or behavioral
modularity for this robot it can do so
in a flexible manner let's see how this
works sensor layer looks pretty familiar
we've got our seven uh sensor neurons
down here and you'll notice that there
are four groups of neurons up here here
each group corresponds to one of the
four actions spin the left uh wheel at
some speed spin the right wheel at some
speed trigger the pickup Behavior or
trigger the release Behavior there are
four neurons assigned assigned to each
of those quote unquote motor neurons
those ultimate actions that the robot
performs within that group you can see
there are two black and two white
neurons the white neurons neurons
correspond to Output neurons we'll talk
about those in a moment and the two
black neurons correspond to to selector
neurons Okay so we've got a total of 16
neurons at the output or at the motor
layer if you squint really hard you
should be able to see that each uh each
sensor neuron has a synapse connecting
to each of the 16 output neurons so
every sensor neuron is connected to each
of the 16 output neurons so if we drop
brain Type e into the robot and the
robot starts to move
around the Val the seven numbers
arriving at the sensor layer are
changing and the values of all 16 output
neurons are also changing as a function
of whatever these synaptic weights
happen to be okay at every moment in
time uh the the code for the robot looks
with uh visits each of these four groups
and when it's visiting a particular
group the code looks at the values of
the two selector neurons if the value of
the first selector neuron is greater
than the value of the second selector
neuron so if this value is greater than
this value the value of this output
neuron is sent to the left motor if the
value of the right hand selector neuron
is greater than the value of the leftand
selector neuron then the value of the
right hand output neuron is sent to the
left
motor so that's why these pairs are
called selector neurons they select
which module which neural module in here
it takes control of the motor at any
time so there are two different neural
modules for each of the four possible
motor Primitives the four things that
the robot can do so if we think of the
state of the neural network as which
selector neuron uh which selector neuron
is allowing control of uh of the of that
particular motor primitive how many
possible states are
there within each of the four group
groups there's four possible States
either the left part of that group is in
control or the right part of that group
is in control so we can imagine
assigning a binary value to this group
and a binary value zero or one to this
group 0 or one to this group or 0o to
one at this group at any moment in time
as the robot is behaving and since we
have four binary numbers we can imagine
that in this case uh the right part of
the group is in charge one left part is
in control zero left zero left zero for
example so 1 0 0 0 at another point in
time this uh one is in control zero is
in control one is in control zero is in
control one 0 1 zero that's another
combination of States inside the brain
of the robot we've got four binary
numbers how many states are there there
are two to the four possible States for
this robot it's morning here 2 4 2 * 2
is 4 4 * 2 is 8 8 * 2 is 16 2 4 16
possible States for the robot these 60
these different neural modular different
neural modules can grab sees control of
the motors at any given time
okay okay so again just to review
they're going to perform five sets of
experiments they're going to evolve
robots with a brain robots with B brains
robots with C brains robots with d
brains and robots with e brains and then
when they compare how well the robot
evolves to perform the task across these
five experiments they're going to start
to learn what is the role in this task
of internal uh internal units or uh
internal units or neurons is synonymous
with uh hidden units or hidden neurons
so if hidden neurons are useful for this
particular task which of these
experiments should be successful and
which ones shouldn't be I give you a
moment to think about
that if hidden neurons are useful then
robots equipped with brains a that lack
internal units should have a hard time
evolving to perform the task but robots
with brains b c and d should do a good
uh should do a good job at this
task you'll notice that in Type e there
actually aren't any internal
units so maybe e robots with robots
evolved with a brains and E brains
wouldn't do well but robots evolved with
B brains
crains and sorry not D brains would do
well there are also no internal units in
type D so only B and C would evolve to
succeed at the task and robots with a d
and e brains would not evolve to do well
at this task
if recurrent connections are useful for
this task so maybe memory is useful for
this task you would expect when
Evolution evolves SE brains the robot
should evolve to do better at the task
than in any of the other four
experiments finally if modularity is
useful for this task if it makes sense
for the robot to break down the task
into subtasks then a robots evolved with
a b and c brains should evolve to only
do so well at the task but maybe robots
evolved with d Andor e brains would
evolve to do well at this
task okay let's look at the actual data
here we go they created as always for
each of these five experiments they
created a population of initially random
sets of synaptic weights for however
many synapses there are in that
experiment remember there's five
experiments and as you can see for these
five different cognitive architectures
there's different numbers of
synapses they then took each one of
those sets of synaptic weights in that
initial random population took those
synaptic weights labeled the synapses of
that neural controller for the robot put
that robot into the arena and they
allowed the robot to move around uh for
200 actions so they did all of this work
um uh 200 actions you can think of this
as 200 time steps uh in the
simulation they watch what the robot did
for 200 time steps or actions or until
the robot corre until the robot actually
grabbed an object took it to the wall
and correctly released it over the far
side of the wall if that happened they
stopped the simulation uh early that's
what they Define as one Epoch they
basically give the robot armed with that
cognitive architecture and that set of
synaptic weights up to 200 time steps to
get rid of one of the
objects okay that they then took the
robot and Al uh allowed it to they moved
it to another if the robot uh if the
robot had performed 200 actions or it
had correctly released an object they
took that robot and put it to a random
place in the arena and allowed it to do
the same thing again another Epoch and
another Epoch and they did that 15 times
so the robot basically had 15
attempts to try and clean up the 1 2 3 4
five objects in its environment so you
can think of one simulation or one whole
evaluation of one set of synaptic
weights as lasting up to 200 times 15
time steps
long after that time they they they
computed the fitness for that set of
synaptic weights which is how many if
any of the objects the robot ejected
from the arena they then went to the
second set of synaptic weights the
second genotype in the
population labeled the neural controller
for the robot for that and evaluated
that neural controller on the robot for
15 epochs and they kept doing that for
each set of synaptic weights in the
population now they have a fitness value
assigned to every set of synaptic
weights in that initial random
population delete the controllers that
cause the robot to do a poor job of
cleaning up the arena make randomly
modified copies of the sets of synaptic
weights that allow the robot to do a
little bit better at cleaning up the
arena and then repeat that process all
over again for another generation and
another generation and another
generation and they did this for a
thousand Generations so we've got
evolutionary time as always on the
horizontal axis down here and up here we
have the number of successful uh epochs
how many how many of these 200 times
step uh time Windows did the robot
correctly grab and release an object
over the edge of the Arena uh I
mentioned that there are five objects in
the arena you can see that some of the
evolved controllers actually got scores
higher uh higher than five so they were
putting if the if a robot did manage to
drop an object outside the arena as that
robot was being randomly placed at a new
position to for the next Epoch they take
that object and put it back into the
arena at some random location so poor
robot it can never actually clean up the
arena it's just got to keep tossing
stuff outside the arena as we keep uh uh
dropping garbage into its
Arena okay you'll notice immediately
that robots equipped uh with brains a
never evolved to do a very good job they
could get rid of uh six objects but the
other uh the robots equipped with the
four other types of brains did much
better remember here's type A here so
this simple neural network controller or
this cognitive architecture is too
simple for this
task okay you'll notice that uh BC and D
did pretty well here's b c and d so
hidden neurons probably helps B did
better than a the only difference
between b and a is hidden neurons so
that's helpful um C did better than a so
having recurrent connections also helps
D did pretty well as well so even though
so human enforced modularity helped at
least compared to the simple neural
network but D is no better than B and C
it's they should have really labeled
these with different colors or shown
these lines differently whatever BC and
D do more or less the same so it's
useful to have hidden neurons it's
useful to have recurrence it's useful to
have modularity but this human induced
modularity is no better than just
throwing in some hidden neurons and
recurrent
connections e which is drawn in bold
here ultimately the other ones catch up
but e makes it possible for evolution to
make quick rapid progress so the clear
winner here are robots that were evolved
with cognitive architecture e and this
is the main takeaway message from
today's lecture is that at least in this
simple experiment it was better to let
Evolution discover and enforce
modularity on the brain of the robot
than it was to have the investigators
enforce modularity on the controller or
not enforce modularity at
all this plot here uh is kind of
interesting they took uh the evolved
controllers from simulation and dropped
it onto the physical keer robot and they
wanted to see how well the physical
robot did um they they counted here the
number of successful individual so they
played back the best controllers from
experiments a b c d and e these are
controllers that allow the robot to do
kind of okay or really well at the
task uh and in this case they uh counted
the number of successful individuals so
in this case in the physical case they
put five actual little five wooden pegs
not sugar cubes five little wooden pegs
and they counted how many times the
robot was able to successfully get all
five of the pegs out of the Arena they
did a bunch of
experiments uh they didn't say how oh
sorry for the best controller from the
10 replications how many right so they
played back a bunch of different
controllers from each of these five
experiments and only one of the uh
evolved controllers from experiment a
allowed the physical robot to completely
clean its
environment but the physical robot
equipped with some of the best e brains
seven of those individuals seven
different e controllers were able to uh
uh enable the physical robot to
completely clean up its environment I'm
sorry I forgot to mention uh this term
here replication so we've got five
different experiments for each one of
these experiments they ran the
evolutionary algorithm once then they
went back and created a different random
population of synaptic weights and ran
Evolution forward again for a brains and
again and again and again they ran the
evolutionary algorithm 10 times for
experiment a they replicated that
experiment another 10 times for
experiment in experiment B and so on
which gives us a total of 50 different
evolutionary runs that they
performed okay so that that gives us 10
Champions if they run Evolution 10 times
with experiment a at the end of each of
those runs they pluck out of the evolved
population the set of synaptic weights
that enabled the robot to do the best
they take the best evolved brain out of
each of those 10 trials which gives 10
champions for a 10 champions for B 10
champions for c d and e and they played
back each of those 10 Champions on the
physical robot in experiment a only one
of those 10 Champions completely cleaned
the arena in experiment B only 10 of the
B Champion or only two of the 10 B
champions the arena and so forth in
experiment e seven of the 10 e Champions
successfully clean the arena so not only
did robots equipped with EB brains
evolve quickly to do well at the
task the physical robot when armed with
those successful brains do better than
the others so just a different way of
measuring how good Evolution did at
evolving this particular behavior for
those five different types of cognitive
architectures okay so we can now uh look
at these results and go back to some of
our questions and ask very and we can
ask various questions about the results
first question you might ask is is there
a correspondence between evolved modules
and distal behaviors so we know we we're
going to look in a moment at how
evolution carved up uh how Evolution
carved up modules in E we're going to
focus on E brains for a moment the short
answer as you're going to see is that
there isn't a correspondence whatever
modularity Evolution found here and
evolution did find some modularity
because it was useful we know that it
was
useful it doesn't seem to map on what we
intuitively might think of as a good way
to carve things up into behaviors for
example
module a explore until an object is
found and then module B do what you need
to do once you found an
object okay so we're going to look uh in
to see that the answer is actually no we
can't understand the modularity that
evolution discovered we're going to look
at just one evolved controller from the
e experiments a single set of synaptic
weights this particular single set of
synaptic weights causes the controller
to switch between just two
states what do I mean by that uh in this
case Evolution uh only switched the two
modules back and forth for the right
motor so there were certain points in
time when the robot was controlled by
this set of evolved
ews in which the left output neuron was
controlling the right motor and there
were other points in time in which the
right output neuron controlled the right
motor so there were two different
modules or two different ideas that the
robot had about what to do with the
right motor and those different ideas
grabbed control of the right motor at
different
times in the other three
groups either the left selector neuron
was always greater than the right
selector
neuron
or the right selector neuron always had
a greater value than the left selector
neuron although Evolution could have
evolved these sets of synaptic weights
to switch to allow these two different
modules to control the other three
things the robot can do Evolution set
those synaptic weights to not make use
of those additional potential
modules make sense so this controller
only has two states either this idea is
controlling the right motor or this idea
is controlling the right motor and
whatever it was in the other three it
was either the left output neuron always
had control of the left motor or the
right output neuron always had control
of the left motor it's not clear in this
case makes
sense okay let's keep
going okay let's start with observing
what the robot actually does when it's
equipped with uh cognitive architecture
e and labeled with this particular sets
of synaptic weights that allows the
robot to successfully clean up the uh
environment again this experiment was
conducted in the
mid90s so no YouTube videos at this
point we're going to have to uh content
ourselves with this figure here so let
me walk you through it here's the robot
here and you can see it's two pincers
that make up its gripper so it's
pointing to the southeast at this moment
in time the squiggly line is showing you
the trajectory that this robot uh the
the trajectory of this robot while it
was controlled by this controller at
some point the robot was driving in this
direction and grabbed this object you
can see it's white now indicating that
there was an object here but they're no
longer there was an object here at the
beginning of this trial but not at the
end the robot grabbed this object came
down here and was facing the wall and
presumably dropped this object here
turned around started heading Northwest
came into contact with this object
picked it up drove uh over here and
dropped it out here it's a little hard
to see but from this trajectory but was
driving around and managed to come into
contact with these three objects at
various points in time take them to the
uh some edge of the arena and drop it
over the arena it never got to object 4
or
five
okay uh the time that it took for it to
do that is plotted on the horizontal
axis down here so this is not
evolutionary time this is plotting the
lifetime of this particular robot with
this neural
controller we're going to walk down each
of these rows in this figure one at a
time
let's let's start with uh mod up here
this is which module controls the right
motor remember that the selector neurons
here in the right motor are switching
back and forth between which which of
those two selector neurons has the
greater value causing these different
neural modules to grab the right
motor periods of time in which mod is
black that means that the right hand the
right side idea is in control of the
right
motor periods of white indicate that the
left idea is in control of the right
motor yeah so you can see you can see
the E brain switching back and forth
between these two ideas which of these
two ideas uh is translated by the robot
into reality you'll already notice that
the evolved modularity discovered by The
evolutionary algorithm looks different
from what we might have enforced as
modularity because these two modules are
f back and forth very rapidly you would
imagine that if one module corresponds
to holding the object there would be one
contiguous black band where that module
deal with a held object takes place and
then you'd expect very long contiguous
blocks of white where the robot is doing
looking for an object for example so
already our intuition is is broken here
um let's have a look at some of the
other rows here um what exactly is the
robot uh perceiving so is it is it
seeing a wall is it facing a wall or is
it facing a Target object if we look at
these black bands where it can see a
wall then it sees a Target then it's a
Target object and it sees neither a wall
nor a Target object then a Target object
again and then it's looking seeing a
wall for quite a long period of time
there's no clear correspondence between
the pattern of black and white down here
and the pattern of black and white up
here so this WT was the investigator's
first guess about what these modules
might correspond to maybe these modules
correspond to whether the robot is
looking at a wall or looking at a Target
object that's not
it here's the uh here's the speed at
which the left motor is spinning you'll
notice the left motor is spinning quite
a bit and then it slows down during this
period and slows down during this period
there's a little bit of a correspondence
between the speed of the left wheel and
the pattern of the different modules
switching on and switching back and
forth uh up here but again it's it's not
a perfect correspondence there is a
stronger correspondence between the
speed of the right motor and the
switching of the modules which kind of
makes sense because remember that these
this module these two modules are
switching back and forth and when one
switches on perhaps it causes the right
motor to do something else you can kind
of see that when the Black module is in
control the right wheel the right motor
is spinning
slower and when the white module is in
control the wheel is spinning faster
what that means again who who really
knows um then they looked at periods in
which the pickup motor primitive was
triggered here it's triggered here here
it's being triggered a little bit and so
on again no real correspondence between
when pickup is triggered and either of
these two modules so whatever this
module is it's not control pickup uh
it's not control
pickup RL is release so here's uh
release firing meaning the robot is
holding uh holding steady and then
here's a period uh here's a period in
which release is inhibited the robot is
not releasing uh the object it's a
little uh
counterintuitive so uh releases do this
and this is periods in which it's not
doing that so you can see that again
between these white gaps here and these
white gaps up here but again there's no
clear pattern it's very difficult to try
to understand what these modules are
controlling here's the pattern of
activation of the six infrared sensors
or the proximity sensors again we can
see there's not much of a correspondence
but there's a little bit it seems more
or less that when the Black module is in
control that happens to be when the six
uh infrared sensors are stimulated so
maybe there is an intuitive pattern here
we could we could detect but but it's
not clear exactly what it
is okay here here's uh the light barrier
sensor that little beam between the two
pincers and we can see that during this
period and this period and this period
the PE the beam is broken these
correspond to the three periods during
the robot's behavior in which it's
holding one of these three objects that
it eventually jettison out of the uh
Arena again no real clear pattern there
um finally the investigators came up
with 1 2 3 4 5 6
78 situations that can occur as the
robot is cleaning up the arena uh these
are periods in which it's carrying an
object and seems to be looking for a
wall that's exactly those periods in
which it's those three periods in which
it's holding an object those candidate
or hypothetical uh those
hypothetical behavioral modules don't
seem to correspond too well to what's
going on up here here uh gripper is
empty and it's looking for an object a
different candidate behavioral module if
we look at pattern B these are the
periods in which that behavioral that
potential or
hypothetical uh behavioral module might
be in control of the robot and they plot
exactly that just by watching the robot
those hypothetical modules don't seem to
correspond to the real modules and so on
so you can go through the rest of these
the takeaway from this very compli ated
figure is whatever modules the way in
which Evolution has carved up the
overall behavior of cleaning up the
arena here doesn't seem to map any of
the ways we might carve up this task
into
subtasks
okay uh here they had a look at uh as
we've seen several times before how this
robot how the evolved controllers do
when they replay that controller on the
robot at novel locations they put the
robot at new positions inside the arena
how well does the evolved Behavior
generalize to new
situations they looked at a total of
7200 new situations they placed the
robot near an object near an object near
an object or the wall with the robot at
180 different uh horizontal angle so
maybe it's facing it's near an object
and it's facing the object or it's near
an object and facing a away from an
object and so on and they did that at 20
different distances of the robot away
from either an object or the wall and
they set it in that situation with
either uh its gripper already gripping
uh an object or not so it gives a total
of
7200 uh trials uh if you look at just
the uh errors here these were the number
of errors that the robot made what
counts as an error uh the error might be
the robot is holding an object over the
edge of the Arena the right thing to do
would be to drop it an error would be to
back up and keep the object in the
environment or an error might be the
robot is close to an object facing that
object and isn't currently holding an
object the right thing to do would be to
go forward and pick that object up if it
doesn't that counts as an error so if
you just look at these four black bars
here you'll see that the black the B bar
and the E bar are lower than the other
two I have absolutely no idea why they
didn't plot this information for C maybe
this was just uh an
oversight so uh e is doing pretty well
and B is also gen for some reason
generalizing pretty well as well and B
is the neural network that contains
internal neurons but no
modularity okay um this PL these sets of
plots over here we're going to take a
few minutes to walk our way through them
um these were all generated by a single
evolved EC controller an EC controller
that did very well on board the robot
during Evolution and during Evolution
the robot never made a mistake whenever
it was near an object and wasn't holding
one it would turn and pick it up
whenever it was holding an object and it
was near a wall it would drive to that
wall and drop it over the
edge they're going to play back uh the
robot using this e controller a very
large number of times again actually
these are all 7200 cases so every pixel
in these upper four panels corresponds
to one of those
7200 possible situations okay let's see
how to read this we've got four
different we can break those 7200
situations down into four buckets
there's the case where the robot uh is
near a wall and its gripper is empty
there's the case where the robot is near
a wall and its gripper is full
an A C cylindrical object and its
gripper is empty and a fourth and final
situation where the robot is near a
cylindrical object but it's already
holding an object on the horizontal axis
here they're showing the angle of the
robot relative to the wall That's nearby
or the robot's relative angle head its
relative angle relative to the
cylindrical object that's nearby an
angle of zero means the robot is facing
that wall or facing that cylinder headon
a value of 180 means that robot is
facing away from the object uh near the
object or the cylinder so the wall or
cylinder is nearby but it's directly
behind the robot and every else in
between so as we March left or right
along any of these four panels we're
thinking about the robot oriented
differently relative to the object
that's nearby a cylinder or the
wall the vertical axis represents how
close the robot is to either that wall
or that cylinder so if we think about
wall gripper empty this particular pixel
here the robot is facing the wall head
on and it is very very close to the wall
up here top Center this is the robot
facing the wall but the wall is pretty
far away from the front of the robot
okay make sense okay so for every single
Pixel and there you have to trust me
there are 7200 pixels in these four
panels they painted the pixel white if
uh sorry they painted the pixel black if
the robot in that situation triggered or
the controller in the robot in that
situation triggered the pickup behavior
and you'll notice there is a small patch
of black here so the robot immediately
starts to trigger the pickup Behavior if
the robot is facing a cylinder head on
and that cylinder is very close makes
exactly makes sense right this this
particular patch out of all these other
patches this is exactly the conditions
under which the robot should attempt to
grasp the
cylinder the gray pixels correspond to
this uh the Set uh the subset of those
7200 situations in which the robot AR uh
immediately tried to do the release
behavior that also makes sense this
patch in here corresponds to those
situations in which the robot is facing
facing the wall and the wall is
nearby and the gripper is full sorry I
forgot to mention that that also is
important so these are the situations in
which it's literally holding uh the
cylindrical object outside the wall and
it's facing the wall white pixels
correspond to neither the pickup
Behavior nor the release Behavior being
triggered okay so that's uh this is a
robot that seems to be doing exactly the
right thing in doing exactly the right
thing in all of those 7200 situations
with maybe the exception of this little
patch here in this case the robot should
be dropping the cylinder and it isn't so
arguably it's not perfect
these four panels exactly the same as
these four panels up here but the the
data in these four panels was generated
by a different evolved controller one
that also uh that never made mistakes
during Evolution but when exposed to
these 7200 situations it did make a few
mistakes and I'll give you a moment to
look at these the this data to see if
you can spot where the problem is where
it's making
mistakes it's doing the right thing here
it's facing the wall its gripper is full
and it's dropping the object it's doing
the right thing over here it's facing a
cylindrical object close by and head on
and its gripper is empty it should
indeed try and pick up uh the object the
eror is over here in this case the robot
is uh very close to a cylinder there's a
cylinder just front right of it and it's
very close to it but its gripper is full
what does it do in this case there's a
small patch of gray meaning it triggers
the release Behavior it's already
holding an object there's a second
object front right and it drops the
object that it's holding not the right
thing to do okay I want you to keep your
eye on this part of the slide I'm going
to switch back and forth to a different
slide now but I want you to watch this
situation remember that this patch of
pixels corresponds to situations in
which the robot is holding an object
there's an object uh just off its for uh
uh just in front and to the right of it
and it's dropping the
object this plot again these four panels
correspond to exactly the same situation
in this case every black pixel is uh
which of those 7200
situations that controller encountered
during
Evolution every white pixel are
situations that that e controller never
saw during uh Evol ution as you can see
most of the pixels are white meaning the
more at least more than 50% of the 7200
possible situations the robot can
encounter its EC controller causes it to
behave in a way that it doesn't
encounter those other situations this is
an important point that we haven't
brought up before is that one of the
things that a neural controller for a
robot does or a biological brain does
for an organism is keep that robot or
that that organism out of all possible
situations so you'll notice if we go
back to looking at this particular patch
here the place where we forced that
robot or we forced that controller into
that those these situations down here
that controller never allowed the robot
to see those situations during
Evolution makes sense right it's never
seen these situations before so there's
no guarantee that it's going to do the
right thing after Evolution when we
deploy it out in the real world and it's
going to experience a wider range of
situations than it ever saw during
Evolution okay so to summarize this
experiment um the experiment was a
success in the sense that they were able
to evolve a neural controller that found
a way to modularize the brain of the
robot and they were able to find that um
neural modularity in that case is
actually useful so what the evolutionary
algorithm determined or what it sort of
coded into the brain of the robot were
actually four different things first of
all uh the evolved controllers
determined which sensor States would be
experienced by the robot while moving
and that's the figure that we just saw
this particular evolved controller only
allows the robot to see these situations
a different evolved controller allows
the same robot to see or experience a
different subset of all possible
experiences Evolution determined whether
a behavior should be divided into
modules or not if uh if evolution had
tuned the synaptic weights here so that
the selector neurons never uh change
their relative uh magnitudes it would
basically be Evolution saying I know
you've allowed me to switch between to
evolve and then switch between modules I
don't need the modules I'm just just
going to stick with a certain set of
connections from sensors to
Motors Evolution also determined uh so
Evolution did did break these up into
modules by evolving the synaptic weights
that go from the sensor neurons to the
black selector
neurons what exactly uh the motor neuron
was forced to do when those different
modules were in charge was set by the
evolved weights of the synapses that
flow from the sensor neurons to the
white output neurons so Evolution found
modules and then figured out what the
robot should be doing differently in
those different
modules uh uh and I'm and sorry what
situation should trigger those modules
and what each module should do how it
should control the robot's Behavior so
uh what experiences the RO Evolution
determines what experiences the robot
should have whether it should have a
modular brain and it
should what situations what
environmental situations trigger which
modules which modules are in charge at
any given
time and then finally what those modules
do when they control the
robot okay that concludes our discussion
of uh modularity as it relates to
robotics uh next time we'll move on to a
different open challenge in robotics
which also has to do with the neural
controller for our robots and we'll see
a very famous solution to that problem
but maybe not the final solution to this
problem until then thank you


--- Evolutionary Robotics course. Lecture 17： the NEAT⧸HyperNEAT algorithms..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone welcome back
I hope you had a good restful spring
recess um as promised for allowing me to
sneak away to England for a week before
spring RAC recess I brought back British
candies so grab a British candy and pass
it along there's no nuts in here we'll
start over
here there you go
okay all right so let's shake the rust
rust off our brains remember where we've
been where we are and where we're going
um if you can remember way back to
before spring recess we were working our
way through or we're starting to work
our way through the open challenges in
the field um my apologies I did not
manage to upload lecture 13 on
modularity uh I was caught up in
airports and had no Wi-Fi access and so
on so there was a quiz for the
modularity lecture if you took it great
if you didn't take it that's fine that
quiz will not be counted towards your
final grade I posted a little bit late I
think there was a typo in it so we're
all good yeah okay all right so uh in
this section on challenges as I
mentioned several times now the field of
evolutionary robotics is relatively
young uh obviously AI has made a lot
more progress than robotics there are
are a number of open problems about how
to create intelligent and autonomous
machines that no one has a good answer
for and my hope is that some of you may
continue on with this field and actually
find good and satisfying answers to some
of these open problems and start to
usher in new technologies in which we
have autonomous machines that load the
dishwasher and shovel snow and so on
until then uh we're going to spend the
next two weeks uh or so going through
some of these open problems to
understand what the problems are that's
the most important thing and then I will
give you a survey to what my colleagues
and I have come up with as the best
Solutions and as you will probably see
all of these Solutions are not very
satisfying there is clearly room for
improvement so that's what I want you to
keep an eye out for as we work our way
through the Section on open challenges
the field okay um before we dive back
into lecture as always just to get you
oriented in terms of where we are with
the assignments undergraduates you're
going to start T tackling assignment
nine uh this week in assignment n you
now have all of the basic pieces you
need in your robot your robot is made up
of a number of objects which in pull
that are called links you've connected
the links together with joints you've
instrumented your your robot with a
number of sensors and motors and you
spent the last two assignments
connecting sensors to motors with a
number of neurons and synapses so that
what the robot Senses at each time step
flows through to its motor neurons which
cause the robot to act which causes the
robots uh the robot's position and
orientation relative to its environment
to change changes sensor values changes
what it does next and around and around
we go in assignment 9 you're going to
start to create a series of increasingly
powerful search methods or evolutionary
algorithms that's going to search for
good sets of synaptic weights that cause
the robot to do the right thing at every
time step to respond to its current
sensation in order to walk forward jump
turn in a circle whatever it is you want
your robot to do so far so good any
questions about the assignments
yes what
is so this yeah exactly so W1 and so on
this stands for weekly reports so uh
when is it at the end of next week we're
all going to finish up with all the
assignments and you will then start in
on your final project and W1 your first
weekly report is something you're going
to submit to us on bright space telling
us what you plan to do for your final
project and we'll talk about final
projects uh next
week y okay grad students are those
taking this course for graduate credit
uh you are now tackling the
differentiable assignment number four in
which you're going to be adding Clos
Loop control to your robot and then next
week you'll tackle the fifth and final
differentiable assignment in which you
will uh differentiably optimize the
control of your robot any questions
about the differentiable
assignments no okay all right we're all
oriented okay so uh hopefully you did
watch the modularity lecture last time
when we evolve brains for robots what
tends the problem tends to be is that
the brains of the robots become
increasingly
nonmodular every sensor neuron tends to
influence every other hidden neuron
which means that when Evolution or any
Optimizer makes a change to just one
synapse in the neural controller for a
robot suddenly that has a global impact
on the behavior of the robot all of the
technology that we've created is modular
meaning that someone at least someone
who knows what they're doing can go in
and make a small change to one part of
the machine and that doesn't affect the
behavior of the machine as a whole how
to do that well for robotics nobody's
figured out how to do that yet so in
lecture
we looked at one attempt to force
Evolution or help Evolution to make
modular machines to make it so that
changes to one part of the brain of the
robot didn't affect its Global Behavior
yeah okay we're going to move on to
another problem today in lecture 14 to
which the solution is an algorithm
called neat so neat is the solution but
what is the problem that neat was
designed
uh to solve that problem is known as the
competing conventions problem and this
is a problem uh with neural networks in
general not just robotics okay so going
back to our discussion about neural
networks you'll remember that neural
networks regardless of whether they're
in a robot or not they're basically a
way of encoding a function it's a
function that transforms inputs into
outputs you might remember when we
talked about neural networks we coded up
a neural network that encoded a
particular function the or function then
we changed the synaptic weights of that
Network to encode a different function
which was the and function and then we
moved on to uh was it exclusive or
exclusive and exclusive or
right in that case we found that we
could not find synaptic weights for the
neural network so we had it to we had to
add in Hidden neurons which computed
subfunctions and then the values
arriving at those hidden neurons or
those subfunctions were comined at the
output to compute exclusive ore you
might remember that in that neural
network we had two hidden neurons one
that computed the and of its inputs and
one that computed its
or of its inputs and then the end if it
lit up would suppress the output of the
ore if you don't remember all the
details it's okay what's important for
us today is to remember that these
hidden neurons can compute sub functions
of the inputs and then at the final
output layer we can combine the results
of those subfunctions sound familiar
kind of make sense okay imagine if we're
evolving populations of neural networks
which is what you're going to be doing
by the time you get to the end of
assignment 9 you've got a population of
neural network
and you're applying a fitness function
to these neural networks you're trying
to evolve them to compute some function
imagine we are actually evolving these
neural networks to compute the exclusive
ore function you could imagine that in
that evolving
population some of these networks are
better or worse at evolving exclusive
Ora we're sort of partway through the
evolutionary process the neural networks
are getting better at exclusive ore but
they're not perfect yet inside each of
these neural networks in this evolving
population synaptic weights are evolving
so that maybe one of these networks is
getting pretty good at Computing or and
still not so good at Computing and
another one is pretty good at and but
not very good at or you got sort of the
beginnings of a good solution here in
most evolutionary algorithms one of the
things we do is at the end of each
generation
when we have some surviving neural
networks we take some of those survivors
and we copy them and we introduce
mutations we alter some of the synaptic
weights that's mutation some of the time
with the surviving neural networks we
take them and we try and sexually
recombine them we cut them in half and
try and glue the two halves of the
parents together to make new child
neural networks everybody remember that
from our discussion about genetic
algorithms okay so for evolving neural
networks kind of makes sense we're going
to do the same thing if this one happens
to be pretty good at exclusive ore we
copy it and introduce some mutations if
these two parent neural networks are
doing pretty well at exclusive ore let's
cut them in half take their two halves
and glue those two neural network halves
together to make a new child neural
network here comes the
problem in this cartoon example here
which which is going to illustrate this
problem of competing conventions we
obviously have neural networks that are
that have three hidden neurons not two
like in the case of exclusive ore so
forget exclusive ore for a moment let's
assume we're evolving these neural
networks to compute some function that
requires them to compute three
subfunctions a b and c so these networks
have to evolve sets of synaptic weights
so that they success compute internally
they compute A and B and C and we also
evolve the three synapses connecting the
hidden neurons to the one output neuron
so that it combines the results of these
three subfunctions in the right
way so far so good okay in this cartoon
example let's imagine that these two
neural networks are have evolved to be
pretty good each each of the two of them
have evolve to be pretty good at
Computing a b and c some one of them a
little bit better at a the other one a
little bit better at B doesn't really
matter so far so good okay now we're
going to cut them in half and glue their
two halves together in this uh this
little sort of notation down here we're
going to take ABC over here this neural
network and we're going to line it up
with c ba over here and let's imagine
that we cut here we're going to cut
we're going to separate the left two
neural the left two hidden neurons and
their synapses from the right hand
hidden neuron and we're going to cut
this neural network at exactly the same
place let's imagine we're just choosing
this cut point at random so we're
separating A and B from C in neural
network 1 and we're separating CB from a
in neural network
2 we've cut these two neural networks in
half so far so good okay how do we glue
them together we've got the left part of
parent one AB over here we're going to
glue it to the right hand side of
network two over here we're cutting
AB and we're combining it with a over
here now remember from our perspective
or The evolutionary algorithm it can't
see a b and c it's just sees a whole
tangle of synaptic weights the neural
The evolutionary algorithm is just
choosing a point at which to cut these
neural networks and glue them together
unbeknownst to The evolutionary
algorithm it's glued together it's
created this child network that commutes
computes A and B in its first two hidden
neurons and this child computes a
again in its third hidden
neuron what do you think the fitness of
this child is going to
be it's no good right it's missing C and
it's got two copies of a that's no
good with the same two cut with the same
cut we can create a second child where
we take the the left hand two hidden
Neons from parent 2 and glue the right
hand side of parent one on to produce a
second child that internally computes CB
and C everybody see that how well does
that child
do okay so that didn't work very well
again from The evolutionary algorithm's
perspective it just tried something by
chance and produced two children that
had lower Fitness than the two parents
let's try
again maybe we cut here and here what
happens in this
case we separate the left hidden neuron
in both parents from the two right hand
hidden neurons in both parents and glue
those halves together what
happens same thing there is no good way
to cut these neural networks together to
glue them together yeah
this is particularly tragic if for
example this parent happens to be doing
really well at A and B it's just not
doing so well at C yet it's kind of
evolved to figure out two of the three
sub problems and imagine that this
parent this parent over here has
happened to evolve to be really good at
sea but it's really it's still not doing
so great at A and B right what a lost
opportunity it would be fantastic to
take the good A and B from parent one
and glue it onto the good C from parent
to this is part of the reason why sex
evolved in nature there's lots of
reasons why sex evolved in nature one of
the most obvious reasons is if you can
combine genetic material from two
parents and you happen to bring together
The Best of Both Worlds you can produce
a child that is better than both parents
question
does this problem is is this applicable
to just like kind of generally trying to
cross nor works or is it like somehow
rying on the fact that there's like a
symmetry yeah it's it's a problem in
general this little cartoon is an
oversimplification of the problem in
general this is just meant to help you
illustrate and understand what the
problem is we can imagine neural
networks that are bigger have different
cognitive architectures different
subfunctions this problem arises quite
quite a bit in that basically it's very
difficult to cut neural networks and
glue them together and have any hope
that you're going to bring together The
Best of Both
Worlds this problem is made more
difficult by the fact that populations
of neural networks that are evolving
tend to have competing conventions what
is that mean both of these parents we
can assume have relatively High Fitness
but nothing says that the neural
networks need to compute subfunction a
in Hidden neuron number one right each
each neural network might be pretty good
but it might internally encode or it
might internally evolve a convention
where a is computed over here and B is
computed over here and C is computed
over here and then in another neural
network a is here B is here C is here so
we can't even rely on the fact that the
same subfunctions are being computed in
the same place in the neural networks
this makes things even more difficult
Emily does this a challenge for
something like scaffolding where maybe
you're not necessarily expecting a way
that something Lear a first
beh it it can be related to scaffolding
yes so if you scaffold a learner and it
starts to learn the problem problem and
you make assumptions about how it's
encoding its partial solution to the
simplified problem then your scaffold
might not work yes there is a connection
here not relevant for our discussion
today but yes there is a
connection okay everybody see the
competing conventions problem okay so if
we want to try and evolve populations of
neural networks and if part if some of
the neural networks start to solve some
part parts of the problem and we want to
bring this together we want to make it
easier for The evolutionary algorithm to
bring together good subfunctions from
different neural networks how do we do
it the neat algorithm was evolved to
solve this problem we're going to go
through this solution now neat for
evolving neural networks through
augmenting topologies they kind of
shoehorn their acronym in here but of
course it's kind of you want to have a
neat
uh acronym right okay okay so how does
this work actually before I go into the
details let me give you the
intuition they're going the neat
algorithm is actually very popular it's
still used today it was published over
20 years ago it's still a very popular
way to evolve neural networks for the
following reason neat is able to
identify or make a good guess for where
certain subfunctions are in the neural
networks so if you asked neat where is C
inside these neural networks it would
actually be able to tell you C is over
here in network one and it's over here
in network 2 how can neat know this this
is neat was designed to do exactly this
yeah question did you say that neat was
evolved neat is is an evolutionary
algorithm it's a type of evolutionary
algorithm designed to evolve neural
networks and it's going to evolve them
not not just evolve them it's going to
evolve them in such a way that it can
track where different subfunctions are
being computed in every neural network
in the evolving population and line
things up so that when we cut these
networks we don't end up with stuff like
this we always end up with children that
have one copy of everything that you
need a b and c that's the intuition
everybody get the intuition I haven't
told you how it does it yet but we'll
see that in a
moment
okay okay here we go so remember that in
every evolutionary algorithm we need to
identify what is the genotype and what
is the phenotype we've seen a few
different uh evolutionary algorithms now
that use different data structures to
encode their genotypes here's another
evolutionary algorithm neat that has a
different data structure for encoding
the
genotype every
genotype in neat is evolved as a pair of
lists of arbitrary length these are not
going to be fixed length lists we'll see
this in a moment so if we have a
population of genotypes or genomes in
neat we have a population of list pairs
so far so good okay what is the
phenotype we're going to translate we're
going to map or transform this genotype
as represented by this big Arrow here
into the phenotype the thing that we're
going to evaluate and the thing that
we're going to assign a fitness value
too what is the phenotype in neat it's a
neural
network we're going to take this
genotype it's going to tell us how to
construct a neural network we then
Supply inputs to the neural network and
observe the outputs and assign some
Fitness to how well this neural network
performs phenotypes that get high
Fitness their genotypes survive into the
Next Generation neural networks or
phenotypes that do poorly that get low
Fitness values their genotypes are
deleted and replaced with others and so
on yeah so all else being equal a
relatively familiar evolutionary
algorithm the novelty here is in how
neat encodes neural networks okay here
we go remember that a neural network is
made up of a series of neurons
represented by nodes here and by
synapses links that connect pairs of
nodes or neurons together so in an
individual genotype we're going to have
a list dedicated to nodes or neurons and
we're going to have a second list which
is dedicated to the
synapsis each element in the first list
describes a single neuron to be to be
constructed into the neural network so
in this cartoon example here you see
this genotype had encodes five different
neurons and there is an integer
label assign within each element of the
list and that integer indicates what
type of neuron that neuron is yeah so an
integer of zero could say that this is a
sensor neuron an integer of one could
say that this neuron is a hidden neuron
and an integer of two indicates that the
neuron is a motor or output
neuron so far so good okay so you can
see that we've got five uh neurons here
so when we start to turn this genotype
into a phenotype we we read from left to
right along this list of neurons and we
drop a neuron into our empty neural
network here we start constructing this
neural network we drop one two three one
two three sensor neurons then we drop a
hidden neuron in here and then we drop
an output neuron here at this point
forget all these black lines and arrows
in here these are just disconnected
neurons nothing's connected to anything
else yet so far so
good remember that the genotype is the
thing that we mutate and we're going to
also sexually recombine these genotypes
in a moment what happens if a mutation
hits by chance node number three here
the third element in the list and flips
this integer from zero to one sensor to
Hidden what happens to the
phenotype
we've mutated the genotype what's
changed in the
phenotype there's one
Lut so then there's like another hidden
neuron in the middle that's right we've
got one two we've got one two sensor
neurons and two hidden neurons and one
output neuron we haven't wired them up
yet we haven't supplied any inputs and
observed any outputs so the labels have
changed on the these five neurons but
nothing else yet yeah so as we go we're
kind of mentally simulating this
evolutionary algorithm what happens if
we mutate this what happens if we let's
imagine another mutation hits this
genotype that adds a new random element
to the end of this
list what happens to the
phenotype it doesn't change if you don't
have
as well well we've added an element out
here we we haven't even talked about the
synapses yet what's happened to the
phenotype down here if you had to draw a
picture of this new list with six
elements in it just add the new yellow
circle just add a new yellow circle
right we've got a sixth disconnected
neuron yes sorry this is going back to
something you said earlier I I just sort
of got confused you said there was two
hidden neurons I get why four is hidden
and then you point it to three is oh I'm
sorry okay so this genotype here it says
build your neural network from five
neurons and label three of them as
sensor neurons these three down here and
label the fourth one as hidden and label
the fifth one as output now to try and
just build an intuition for this
genotype and phenotype so far we haven't
talked about synapses yet to build an
intuition
I said imagine we take this genotype we
copy it and we introduce a mutation into
the copy and the mutation just happens
to hit this third node in the copied
list and it flips the label here from
sensor to Hidden the point is that if
you then construct a phenotype from that
from that mutated list it would look the
same you'd have five yellow circles it
would just be that two of them have the
sensor label attached to them two of
them have the hidden label attached to
them and the fifth one still has the
output label attached to them so far so
good question um this this is also going
back to what you said ear um so when
you're talking about like kind of the
idea of like sub functions um are is it
generally like the hidden nodes that are
responsible for sub
functions yes it's the it's the hidden
neurons that are responsible for
subfunctions neural network is a
function it Maps inputs onto
outputs and when we take the inputs and
we compute the values of the Hidden
neurons we have floating Point values
sitting inside these hidden neurons we
can view that as a mapping itself we had
floating we had numbers at the input
layer now we have numbers at the hidden
layer that's a mapping and we can view
each of those numbers sitting inside
those hidden neurons as sub
functions so far so good okay okay the
second list as you can probably figure
out here um is a list that specifies how
to wire the neurons together each
element in this list specifies a
synapse you can see in this cartoon
example there are six uh there are six
elements in this list and there are one
2 3 four five
synapses one of the synapses in the
genotype has been disabled this is
something we haven't seen yet in an
evolutionary algorithm this is something
that exists within our genetics within
our DNA certain mutations can occur
inside uh genomes natural ones and
artificial ones that disable them
they're sitting there in the DNA but
they don't code for anything they're
turned off
so the genome has information about six
synapses but one of those uh synapses or
one one of the descriptions of a
potential synapse has been
disabled so far so good okay so we're
now going to walk from left to right
along this list of synapses and I I
don't like the uh the terminology for
neat this is connection genes connection
meaning a connection between PA pairs of
of uh neurons just think of this as the
sensor list H sorry the neuron list and
this is the synapse list okay so we
visit the first element and we see
there's two integers which are indices
to
neurons if you've made your way through
assignment 8 you've seen this already
the way we specify a synapse is to
indicate who it connects together so
we're going to add as we walk from left
to right we're going to keep building
out our neural network we're going to
keep constructing it this first synapse
is supposed to connect neuron one to
neuron 4 here's neuron one here's neuron
four so we connect neuron one and four
together the third number inside this
element is 0.7 a floating point value
which is the weight of that
synapse there is a binary flag inside
each element which indicates whether
this synapse is enabled or disabled it's
enabled so we add it to the neural
network there is a fifth and final
number inside the description of each
synapse called The Innovation number
this is the thing that's new about neat
but we're going to come back to the
Innovation number in a moment so forget
about Innovation numbers for a
moment we go to the next element in the
list which tells us how to add a second
synapse the second synapse should
connect neuron 2 to four so we do so we
assign a weight of 0.5 to that synapse
we go to the next uh synapse we see that
this one is disabled so we skip over
this one we don't add anything to the
phenotype we wire up neuron 3 to neuron
5 aign a weight of 0. 2 go here attach
neuron 4 to five assign a weight of 0.4
and now we attach five to four and
assign a weight of
0.6 why is this synapse colored purple
it's a special kind of synapse that
we've seen
before recurrent it's a recurrent neural
network yeah okay all right so we've now
walked our way along the genotype and by
doing so the genotype is basically a
blueprint it's told us how to construct
a neural network and we get this neural
network so far so good okay let's build
up our intuition a little bit about this
second part of the genotype what happens
if this genotype survives into the Next
Generation and it produces an offspring
we copy all of this genetic information
and when we copy it we introduce a
random mutation and the random mutation
happens to hit this element and it
happens to hit by chance this weight and
changes this weight from 0.4 to 0.7 what
changes in the
phenotype for that
Offspring
anything this we've hit we've mutated
the synapse that connects neuron four to
five this synapse here we've changed its
weight from 0.2 to
0.7 everybody see that we've changed the
phenotype of that child that's probably
going to have an impact on how the child
behaves how the child transforms its
inputs to
outputs so far so good okay imagine a
second child same thing we take this
parent we copy it and uh that child
suffers a random mutation which also
happens to hit this element by chance
let's say but in this case we
hit uh we hit this integer and this
integer changes from five to
three how does the phenotype of that
child differ from its
parent four to are not connected anymore
now it's four th this connection has
been broken this this synapse which in
the parent connects four to 5 the
synapse now connects 4 to3 we've made a
change to to the cognitive architecture
of the
child question is is it like legal to
have two synapses between two noes or do
they get merged is it legal to have two
synapses in neat it's legal because as
you can see these synapses start to move
around or Evolution can move them around
it's perfectly fine exists in your
brains as well you have multiple
synapses from certain neurons to certain
other ones whether that's a good thing
or a bad thing who knows okay so a lot
of new you're going to see a lot of new
things in the neat algorithm that we
haven't really seen before the first
thing to notice is that neat is not just
evolving the weights of a fixed neural
network neat is altering not just the
synaptic weights but also altering the
cognitive architecture of this of the
neural networks if you imagine a whole
population of neural networks in uh in a
neat population and they have different
genotypes some of those neural networks
in the population might have more
neurons or less neurons some might have
more hidden neurons or less hidden
neurons some are going to be wired up
more densely some are going to be wired
up more
sparsely Evolution can decide on the
cognitive architecture of these neural
networks so far so good okay last thing
I want to show you let's go back to this
parent again let's imagine this parent
produces a third child so we take all of
this genetic information copy it to
create the child genotype and now a
mutation hits this element and it
changes this weight what effect does
that have on the phenotype of the
child nothing nothing this also happens
to you if you happen to have some
children and you pass on your genetic
information into your Offspring there
may be a mutation that occurs in your
genetic material as it's being passed
into your Offspring but if that those
mutations happen to hit genes in your
genome that are turned off no obvious
impact on your child whatsoever yeah it
exists in nature okay so let's go back
to the name of the algorithm uh this is
neuroevolution of augment topologies the
neat algorithm so we can see that this
is an evolutionary algorithm and we're
evolving neural networks so this
algorithm actually ushered in this new
term neuro Evolution which is just short
for here's a way to evolve neural
networks topologies the
topology uh refers to the cognitive
topology or the cognitive architecture
how many or how few neurons are there
and how are they wired up neural
topology and neural architecture mean
exactly the same thing what do they mean
by augmenting
topologies like shifting them around
versus just changing their
weights as Evolution proceeds mutation
might add neurons or add synapses to
children and grandchildren and
great-grandchildren over evolutionary
time evolution is augmenting the Topo
cognitive topologies of these ancestral
networks so far so good okay Cam you
help me understand the relationship of
just to the body like the number of
input neurons and output neurons exactly
so we correspond with sensors and Motors
yes we've Stripped Away we've Stripped
Away the robot for a moment what happens
if the robot has three sensors
but a particular genotype causes the
construction of a neural network with
only two input neurons we got three
sensors and two input neurons how do we
connect these things together it's not
so obvious we're not going to worry
about that for now we're just focusing
on evolving neural neural networks we'll
put these neural networks back into
robots in a few minutes when it comes to
the whole like it can add new neurons is
it it is the algorithm still limited to
only enabling or disabling ones that are
like preset by people creating or can it
just like add another item
to a mutation could add a new synapse
and disable it a mutation could delete a
synapse and then it could delete another
synapse and it could add add remove
modify
everything so in the neat algorithm
there are many many more mutation
operators than you're used to if you've
gotten as far as code assignment 9 and
started to code up an evolutionary
algorithm all of the evolutionary
algorithms you've been coding up so far
have one and only one type of mutation
operator pick a synapse at random and
change its weight that's the only
operation that your mut your
evolutionary algorithm can inflict on a
genome in neat there are many more
mutation operators add a neuron delete a
neuron mutate a neuron add a synapse
remove a synapse modify a
synapse everybody see that okay so
hopefully what I what you have in your
head now you can mentally simulate the
neat algorithm we start in generation
Zero by constructing n of the uh n
random versions of this data structure
to create our n neural network random
neural networks in the population at
generation zero yeah in that initial
population we now have n neural networks
which have more or fewer neurons
different ways of wiring themselves up
they're dense they're sparse they all
have different cognitive architectures
and different synaptic
weights I haven't talked about how we
evaluate these yet but let's assume you
evaluate them and you're able to assign
a fitness value to every neural network
in the population we delete the ones
that have low Fitness and we make
randomly modified copies of the
surviving neural networks repeat repeat
repeat repeat everybody see that it
could be if it's useful for whatever
problem we're evolving these neural
networks to solve if if it's a
complicated mapping or it's a
complicated function of transforming
inputs to outputs you would expect to
see that over evolutionary time these
neural networks evolve to become bigger
and bigger and bigger with more and more
internal hidden neurons so that these
neural networks get better and better
and better at approximating this
complicated mapping from inputs to
outputs if we evolve these neural
networks to solve the or problem two
inputs one output the or problem they
would probably evolve to get smaller and
smaller they only need two inputs and
one out outputs they don't need a lot of
neural Machinery to solve the
problem all of the interesting problems
that we want to solve an open AI is
trying to solve and everybody's trying
to solve an AI we don't know how big or
how small or how to wire up these neural
networks open AI solution is make it as
big as humanly possible train it forever
and hope for the best clearly that's
kind of working but maybe we can do
better yeah
this is an attempt to try and do that
let Evolution figure out what the right
size and shape of the neural network
should be for whatever the problem is
you want that neural network to solve so
far so
good okay so far we've been talking
about just mutations inside the neat
algorithm now let's talk about what neat
was really designed to do which is to
solve the competing conventions problem
here we
go uh oh I'm sorry no this is still on
uh this is still on mutation but we're
going to we're going to talk now about
the this Innovation number so if you
just look at the cartoon down here if we
just look at this parent phenotype this
parent phenotype has uh made a copy of
itself and that copy has suffered a
mutation which has added uh has added a
synapse here that connects neuron
through three to neuron 4 you'll notice
here that this new synapse has appeared
on the end of this list so the mutation
that occurred to the the mutation
suffered by this child was a ad synapse
mutation okay so they uh We've in this
little cartoon here they've simplified
things they are not drawing the neuron
list they are only drawing the synapse
list this parent has one two 2 3 4 1 2 3
4 synapses one disabled synapse the
child has 1 2 3 four sorry 1 2 3 4 five
synapses 1 2 3 4 five synapses and this
disabled
synapse everybody see that inside the
synapse list they put this little
notation here so you can see what's
wired up to what they're not writing out
the weight or disabled or enabled I'm
trying to simplify things you'll notice
that there are some integers that are
Marching along the top here these are
the Innovation numbers The Innovation
numbers are
integers every single synapse and every
single neuron in every neural network in
a neat population has an innovation
number assigned to it this is like the
social security number everyone has one
okay how is this Innovation number
assigned there is a global counter
inside the evolutionary algorithm by
global counter I mean it's the
evolutionary algorithm that's counting
not the neural
networks This Global counter every time
a new every time a mutation adds a
synapse to any neural network neat takes
the current value of the global counter
which in this cartoon example here
happens to be seven and it assigns that
number to that new thing that new
synapse or that new uh neuron and then
neat click updates the global counter
now the global counter is sitting at
eight if some other neural network uh if
some other neural network for example
suffers a mutation that adds a node here
you'll notice in this parent there is no
neuron six here we've got neuron six
it's added a global counter or the
global counter has been added to the
neuron question any reason it's missing
two sorry is there any reason it's
missing two uh yes there is a reason
okay so let's go back to generation zero
let's assume we're right at the
beginning of the neat algorithm we just
started we haven't even made any
genotypes yet any phenotypes the global
counter is at zero algorithm wakes up
and starts creating uh starts to create
a random genotype let's imagine it
creates this random genotype it adds by
chance five neurons click click click
click click we take well it should
really be Z zero let's start the global
counter at one the first the very first
neuron that's added to the very first
genotype in the first generation gets a
Innovation number of one next one it
adds it adds a second neuron it adds a
global counter of two three four
five uh and then it keeps going the
numbers here actually don't make sense
but we can imagine if we add uh we add a
random synapse where the global counter
is at six this should be 6 7 8 9 10 11
we're adding a whole bunch of random
stuff into the genotypes of this initial
random population and we're assigning
the global counter as we go so far so
good so in this initial random
population we got a whole bunch of
synapses and neurons everybody has a
unique number everybody has a every
neuron and synapse has a unique Social
Security number so far so good do you
toast we might have to add constraints
depending on what the problem is that
we're going to expose these neuron
networks too yes now the question is the
standing question is why is innovation
number two missing from this list I'm
going to come back to your question in a
moment is there another question about
clarification no this is going to wager
why it's not there but if you're go
ahead and wager why it's not there can
it delete synapsis it can delete
synapsis maybe maybe the let's say well
I guess it would be the first neural
network had an innovation number of two
and it died it it had a low Fitness at
the end of generation one never made it
into the Next Generation so that social
security number is gone from the
population it's not there
anymore
um when these like random mutations are
happening is is it like a uniform kind
of like distri distribution of what
happens because like for example you
were talking about like if there's a
Network that has to solve a big problem
like could it just never really reach a
big size CU it's just constantly like
adding and deleting kind of remaining
it's a great question so yes to your
first question there is a uniform
distribution of what mutations are
inflicted on a child when a child is
produced so for our purposes it's easy
to think of six different mutation
operators add remove or modify a neuron
add remove modify a
synapse when we take a
parent and copy it into the child
imagine we actually roll a dice with six
numbers whichever whichever number comes
up that's the operation we
apply six different mutation operators
applied with uniform probability your
second observation was that well if the
problem is complicated we need a big
neural network but the neural networks
are suffering add remove modify
mutations over evolutionary time with
equal probability how can the neural
netor Works get bigger they can get
bigger and they do get bigger why how
can that
happen the bigger ones perform better
the bigger ones perform better right
Charles Darwin started to realize this a
long time ago even if what's going on
inside he didn't know anything about
genes but if what was going on inside
was just random change it doesn't matter
selection will bias things kind of
reduces Randomness right things start to
move towards bigger and bigger neural
networks or towards smaller and smaller
networks or towards denser and denser
networks or to whatever it is that's
useful Evolution should be able to
figure it
out so far so good okay all right so
every time a mutation adds something we
take the value of This Global counter
and assign it to that new thing that new
thing gets it's a unique social security
number if you look at the The Innovation
numbers in this parent and then the
Innovation numbers in its child you'll
notice that my metaphor of the social
security number is now breaking down the
first neuron in the child has the same
Innovation number as the first neuron in
parent when we copy neural material from
a par par into a child we do not assign
a new Global counter that new piece that
new neuron or new synapse in the child
that it's inheriting from its parent the
child inherits that Innovation
number so far so good okay so you'll
notice this child has one synapse that
has an innovation number different from
its
parent okay okay so why are we doing
this this mutation number and This
Global counter seems like an odd thing
what is it designed to
do here we go oh question yeah when you
like move from a parent to a child do
you not reset the Innovation counter the
global counter is never reset by
definition it's always every time we
assign we assign the number seven to
this new neuron we update the global
counter to eight and then we just wait
until the next mutation comes along that
adds something a neur a new neuron or
new synapse and we assign a value of
eight to that thing so the go counter is
like outside of parent child it's
outside of parent children neural
networks it's inside the evolutionary
algorithm it's a ticker and it's adding
or it's tagging stuff with numbers as
Evolution proceeds from neural network
to neural network to generation to
generation children grandchildren
great-grandchildren one and only one
Global
counter so far so
good okay some of you may start to in it
what this is for let's see if you're
right okay here we go we're going to now
introduce the last piece of the neat
algorithm which is sex we're going to
now cut two parent neural networks apart
and glue their parts together and hope
that the resulting
child looks and acts something like its
parent if I grab your uh Apple laptop
and cut it in half and I grab somebody
else's PC and cut it in half and glue
those two halves
together it's super hard to do this it's
hard to take optimized machines whether
they're literal machines or neural
networks that have different internal
configurations and glue glue them
together and hope that you get the best
of both worlds in theory there should be
a way to combine parts from an apple and
parts from a PC to actually get the
benefits of what's done better in those
two machines super super hard to do for
legal reasons but also for technical
Reasons I'm just trying to impress upon
you about how hard this problem actually
is and neat is very famous very popular
well used because it does a pretty good
job of solving this problem not perfect
there is probably a better way to do
this but in the last 22 years no one has
come up with a better way to do this
okay here's how it does this we've got
parent one over here which is made up of
five neurons and 1 2 3 four
synapses parent two has a different
cognitive
architecture we've we've got 1 2 3 four
five six neurons and one 1 2 3 four five
synapses this is even harder than the
cartoon example back here at least in
this cartoon example both parents had
the same cognitive architecture they had
different sets of synaptic weights and
different internal
conventions this is even harder they
probably got different internal
conventions and different cognitive
architectures how are we going to
interbreed these two very different
animals okay
here is part of the genotype for this
parent and here's the genotype for part
of this parent again in this cartoon uh
in this illustration we're not showing
the neuron list only the synapse list
you know this is the synapse list
because you can see connect neuron 1 to
four Connect neuron 2 to four and so on
so far so good okay you'll notice that
this parent and this parent
share some of the same Innovation
numbers this is not a social security
number some of the stuff inside of
parent one and some of the stuff inside
of parent two has the same Innovation
number how is this
possible they had a common ancestor they
had a common ancestor so this particular
let's take synapse 2 here the second
synapse here in parent one one it's the
synapse that connects 2 to four and over
here in parent 2 it also H this that
synapse with the same inovation number
happens to connect neuron 2 to four in
that parent as well they probably these
two parents are probably the children of
a common parent or the cousins of a
common grandparent or the second cousins
of a common great grandparent whatever
it is they probably had a common
ancestor and in that common ancestor
that common ancestor probably had a
synapse that connect connected its
neuron 2 to its neuron 4 and that
synapse in the common ancestor had an
innovation number of two is it pretty
likely that things with the same
Innovation number kind of are
responsible for the
same like that's not a guarantee right
it's not a guarantee but what you just
said is the key to the neat algorithm
the Assumption here is that whatever
synapse 2 did in the common ancestor
whatever subfunction it helped to
compute whatever job it was doing inside
that ancestral neural network it's
probably doing a similar job maybe not
an identical job in this neural network
and in this neural
network Emily this inspired by sequence
alignment
AB absolutely so in you you are
obviously The Offspring of two parents
your two parents had slightly different
genetics how did how did uh how did
conception and integration of sperm and
egg how did that mechanism know how to
make sure not to put too much of one
gene into you and not and no copy of the
gene that regulates heart rate for
example if you don't inherit a gene that
regulates heart rate you are in a lot of
trouble yeah so there is a lot of
complex uh orchestration that goes on uh
during meiosis and then mitosis that
aligns sequences to make sure that you
get at least one copy of everything you
need that inspired the neat algorithm
here everybody see that
intuition okay they're going to then
exploit or trust the fact that things
with the same Innovation number in the
two parents do the same thing to guide
recombination we're going to recombine
these two bits of DNA these two
genotypes we're going to start uh with
parent one we're going to take the first
element of parent one and place it here
for the moment and we're then going to
align sequences like Emily just said
we're going to go to parent two and
we're going to ask parent 2 hey do you
have any neural material that has an
innovation number of one also I just
placed uh a piece of parent one and that
piece of parent one had an innovation
number of one is there anything else in
parent two that is analogous that has
the same Innovation number parent 2 says
yes yes I have one piece here it's this
piece so the recombination operator in
the neat algorithm takes this piece of
genetics from parent one and places it
underneath uh from parent two and places
it underneath the same piece from parent
one it's aligned these two pieces of
their two genomes so far so good okay
the recombination operator then steps to
the next piece of parent one puts that
here looks in parent two to see if there
is something that has also an innovation
number of two and places it underneath
yeah we keep sort of walking from left
to right in both
parents we get to this point here uh and
there is a gap here so there is a piece
of parent two that has an innovation
number of three but there is no piece in
parent one that has an analogous piece
of genetic material there's nothing that
has an innovation number of three so we
leave a gap in parent
one uh we line up these two
pieces this piece uh there is a piece
with an innovation number of five in
parent one no piece that has an
innovation number of five in parent two
and we keep going so we've taken all the
genetic material from parent one and
parent two and sort of spaced out all of
that material so everything is lined up
and now we're ready to create an
offspring we're going to start copying
genetic material from both both parents
into the child how do we do it we've
done the hard part now it's
easy for each of the ones that isn't
disjoint just pick one we're going to
walk from left to right along this align
these two aligned lists and if there are
two copies of the same piece of genetic
material we don't need both copies we
just need one flip a coin heads copy
parent ones copy Tails copy parent twos
copy Into The Offspring if we get to a
disjoint uh piece we can copy the
disjoint piece in or we can just leave
it empty doesn't doesn't really
matter everybody get it okay we now have
this particular genotype for the child
again we're not showing the neuron list
we do exactly the same thing with the
neuron list in this illustration we're
just showing how we recombine the two
synapse lists and we get this list of
synapses in the child and you can bounce
your eyes back and forth between this
genotype and this phenotype and you
should be able to see that the child's
cognitive architecture is different from
both of its parents cognitive
architectures but similar there's a
family
resemblance question so there's no way
remove uh
it's yeah it's a good point I I think
you know what I I think it's not
mentioned in the paper but I I'm pretty
sure that sometimes you just skip over
one of these things it wouldn't make
sense to always be adding material you
could do that recombination could always
like make the child a little bit bigger
and denser than the parents and neat
could rely on mutation to pair away or
delete stuff that's not used but I would
guess that they probably also doing the
same thing in the recombination
operation good good
observation okay how does this help with
the competing conventions
problem absolutely so going back to this
example imagine that these two parents
have a common ancestor and in that
common ancestor that common an Anor
let's say uh computed a but did a crappy
job of computing a it did kind of okay
but whatever it was those three red
synapses whatever they were that helped
compute subfunction a they had three
Innovation numbers with them you would
expect that these three synapses in
parent one have those three Innovation
numbers and those three Innovation
numbers appear here in par too so neat
would know to not put two copies of this
stuff into the child it would take one
and only one piece of these three red
synapses that's how neat solves the
competing conventions
problem okay uh I just I just said all
this line up the connection genes or the
synapse list according to their
historical markers sometimes when people
talk about neat they refer to this as
The Innovation number sometimes they
refer to it as the historical marker I
like historical marker because that
defines exactly what this number is for
yeah okay so disjoint genes those in the
middle that don't have a partner maybe
we copy them in maybe we don't we can
also have excess genes in one parent
compared to another mix and match but
we're ensuring that we only bring across
one and only one copy of what we
need okay that concludes our discussion
of the neat algorithm I would love to
tell you everything I can about the neat
algorithm and all the amazing
applications it's been applied to we
don't have time in this course to do it
so we're going to move on
to another algorithm called hypernet and
as the name implies it's the SQL
algorithm to neat it's going to take
neat and add some stuff that makes it
really useful for
robotics so for now you're going to just
have to take my word for it you can
actually try it out cating up meat isn't
that difficult it's a really good way to
evolve populations of neural networks to
do whatever you want them to do if we
want to then take these neural networks
and put them back into uh robots uh we
need to do some extra stuff and we've
got eight minutes left so we're just
going to start in on the hypernet
algorithm okay this is a uh this is a
little bit of a complicated algorithm to
go through as the name implies we've got
neat going on here so in hyper neet
we're going to evolve populations of
neural networks here we go here's a
neural network here okay so we're going
to use neat to mutate and sexually Rec
combine neural networks in the hyperneat
algorithm these neural networks look a
little bit differently than neural
networks we've seen so far we've seen a
couple of different neural networks so
far we've seen uh we've seen
ctrnn continuous time recurrent neural
networks that were designed to allow
continuous change to neurons we're now
going to see a different type of neural
networks which are called cppns my
apologies for all the
acronyms cppn stands for compositional
pattern producing networks which is a
mouthful we're going to spend the next
few minutes and into next lecture
unpacking each of these terms as we
go okay here is a neural network over
here it's a
cppn it's a neural network we've got no
we've got neurons like we've seen before
this particular cppn has one two input
neurons one two three hidden neurons and
one output neuron and it's got a whole
bunch of synapses that connect these
neurons together so despite the
alienness of cppn that we're going to
see in a moment remember they're just
neural networks neurons and synapses
which means we can use hypernet to
evolve them to do
stuff okay what are cppn designed to do
they're designed to paint regular
patterns the phenotype of a cppn is a
pattern that is painted in
space we just talked about neural
networks as being
phenotypes now we're talking talking
about neural networks which are
phenotypes and these neural networks
paint a pattern which is a phenotype
it's kind of confusing I see some of you
writing with pen onto paper your Form
and Function is phenotype you're doing
something you're affecting the world and
you're creating something that is also
considered sometimes part of your
phenotype it's often referred to in
biology as the extended
phenotype your genes cause all this to
happen the phenotype but my genes which
cause this phenotype also caused this to
just happen in the world yeah so we're
going to extend our definition of the
world word phenotype to the thing that
the neural network
produces I just painted a regular
pattern out into the world you are
painting patterns out into the world as
I speak this neural network is going to
do exactly the same thing yeah okay we
got five minutes left so let's start in
on this I'm going to draw for a little
bit
here okay that's
better in this particular particular
cppn it has two input neurons and we so
we need two numbers that we need to plug
into this neural network so far in this
course we've been talking about sensor
values arriving at the input layer this
is a little bit different we want this
neural network for now to paint a
regular pattern into space that's what
we want the neural network to do the
cppn to do we're going to take this cppn
and we're going to visit the origin in a
two-dimensional space we're going to
take this position which is0
0 and we're going to plug that value
into this
cppn from the point of view of this of
the neural network it's just received
some input so as usual we propagate that
input those input values down to the
output layer in the way we always do
there's nothing new here here in this
cartoon example we have one output
neuron the floating point value that we
get back from that one output
neuron what do you think we do with that
floating point
value we're painting a regular pattern
we're painting a pattern into this
two-dimensional space we've got this
floating Point
number any ideas
we're going to treat this floating point
value as the amount of ink to place here
the cppn is telling us put if the value
here is 0.7 put 0.7 of ink here we're
going to take the same cppn we haven't
changed the cppn yet no no Evolution no
mutation no recombination we're going to
move to a new
position an X of 0.1 one and a y of zero
here's X here's
y we're going to take
.1 and
zero plug that back into the input layer
cppn propagate those two input numbers
down to the output neuron and now we get
a value of 0.6
here in this second evaluation of the
cppn what do we do at this position
we got a value of 0.6
now what is the cppn telling us to
do
draw put a little bit less ink here
visit this position 0.5 let's say visit
this position the cppn outputs
0.4 we visit uh 0 0.1 feed that into the
cppn paint paint paint paint paint we
visit each point in this two-dimensional
space and this cppn will paint some
pattern into space so far so good seems
like kind of an odd thing for a neural
network to
do I think we will pause here for today
you have a quiz due tonight undergrads
you're working on assignment 9 grads
you're working on D4 see you on Thursday
St


--- Evolutionary Robotics course. Lecture 18： NEAT⧸HyperNEAT contd..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone uh not much
to report on terms of assignments all
good any questions things going well
okay all right so back to uh open
challenges in the field of evolutionary
robotics uh we started last time by
talking about uh one of the challenges
of evolving neural networks which is the
competing conventions problem we saw the
neat algorithm which is an attempt to
solve this neat has a lot of neat
problem properties one of them is that
it allows you to evolve neural networks
which as we'll see in a moment you can
then put back into robots for adaptive
Behavior we uh neat is very famous
hyperneat is another famous uh algorithm
which Builds on top of neat for a reason
which we have not talked about yet but
we will talk about in uh a few minutes
time we'll finish up our discussion of
hypernet uh in about half an hour and
then we'll move on to arguably the
biggest problem in evolutionary Robotics
and arguably in robotics in general
which is crossing the reality Gap no one
has figured out a good way to cross the
reality Gap despite several attempts to
do so okay before we get to the reality
Gap back to neat and Hyper neat just to
remind you of the problem competing
conventions neat was designed to solve
this by figuring out how to take two
different things like two different
parental neural networks and identify
parts inside of those two parental
structures that are likely to be
performing similar functions and the
idea behind neat of identifying this is
to keep track of The Descent of those
pieces if those two pieces in two
different neural networks have the same
common ancestral piece or derived from
the same common ancestral piece they're
likely to do similar things inside the
neural network and we're going to line
them up to do it yeah this has become
sort of the standard way the neat
algorithm has become the standard way to
evolve populations of neural networks to
do things we started last time by
talking about hypernet which as the name
of the algorithm uh implies Builds on
top of neat so in the hyper neat
algorithm we're still going to be
evolving populations of neural networks
to do things and we're going to mutate
and sexually recombine these neural
networks using the neat algorithm what
we just started to talk about last time
is what exactly are these neural
networks evolved to do in the hypernet
algorithm we didn't even get that far
what we started in on at the end of last
lecture was looking at how the neural
networks in the hypernet algorithm
behave we've seen a bunch of different
neural networks in this class so far
you've probably seen lots of other kinds
of neural networks in other classes the
neural networks that live inside of the
hypernet algorithm are known as cppns
not to be confused with
ctrnn that's a completely different
thing cppn the name stands for
compositional pattern producing
networks and as we saw at the end of
last
class they're called pattern producing
Network because they're neural networks
that produce patterns when we evaluate a
cppn we Define some space and for the
next few minutes we're going to
arbitrarily choose two dimensional
spaces because I can't draw in 3D so
we're going to choose a two-dimensional
space and we're going to construct
different kinds of cppn and see what
kind of patterns they produce inside
this two-dimensional space okay just a
refresher where we were last time any
questions about any of that from last
time before we push on okay so let's go
through this by actually creating some
cppns now and see how they work as you
can see uh in the cartoon up here the
input layer takes not sensor values or
pixels from some uh photograph that the
neural network is trying to categorize
cppn take as input coordinates positions
in some space since we're working
working in two Dimensions we'll do this
uh we'll do this with an X and A Y and
these can feed into an arbitrary neural
network with arbitrary cognitive
architecture to start with to build up
our intuition for cppn let's keep things
really really really simple we have two
input neurons X and Y and we have one
output neuron and because this pen is
failing I would use say black but we'll
go with gray this
morning okay here's our minimal cppn
architecture let's create uh let's
create let's add some synapses to this
let's take one synapse and connect the
left hand input neuron to the one output
neuron and we'll give this a weight of
one we'll keep things very simple you'll
remember back to our discussion about
neural networks we need one last thing
which is the activation function inside
of here when we take the weighted sum
arriving at this neuron we usually push
the result of that weighted sum through
a function for now we'll keep things
simple and again we'll assume the
identity function so whatever the raw
sum is that arrives here that's what's
going to come out of the output neuron
so far so good okay so let's now start
to evaluate this cppn let's take uh the
uh coordinate of
the origin 0 0 feed that into the input
layer and how much gray is the cppn
telling us to put at 0
0 hopefully you can all evaluate neural
networks in your head by now we're
feeding in 0 0 to the input layer what's
arriving at the output layer zero don't
put any gray here let's move to X = 0.1
y equal 0 how much gray is the cppn
telling us to put
here say that
again we've got 0.1 feeding in here and
zero
here 0.1 right we take the pre synaptic
neuron which is 0.1 at this time
multiply it by one drop it in here our
cppn is telling us to put 0.1 of gray
here put a little bit of gray how about
0.20 little bit more 0.2 you can see how
this goes I really need a different pen
here let's switch to Brown and hope that
this
works little bit
better
around okay we have evaluated part of
the cppn let's paint another row on top
so let's visit uh let's visit x = 0 y =
0.1 what is this cppn spit out when we
take that set of coordinates and feed it
into the input
layer nothing right we've got x equals z
and y equals 0.1 the amount of brown we
want to put here is zero what happens if
we put in
0.1.1 2.1 3. uh 3.1 4.1 1 Point
one comma .1 what's the pattern that
this cppn is going to produce in this
row same as the bottom one exactly right
we get a horizontal gradient where we
get increasing increasing amounts of
brown and you can convince yourself that
that continues this particular simple
cppn will paint a pattern of increasing
amounts of brown as we move from left to
right so far so good okay let's try
another
one let's create at random another
cppn what pattern does this cppn paint
into this two-dimensional
space same thing but rotated same thing
but rotated as there is more y as we
move up in this image this cppn is going
to dictate that we paint
more Brown into the
picture I'm really unlucky with my pens
this morning let me see if I've got
one black okay great all right
so let's try what's known as the inverse
problem instead of giving you a cppn and
having you run that cppn evaluation in
your head to predict what the pattern is
now I'm going to give you a pattern and
see if you can tell me a cppn that will
paint that
pattern increasing
amounts of black as we move up and to
the right can you construct a cppn that
would paint that pattern
twoes
two
synapses with a weight of one and one
okay so far so good okay so this is what
cppns do they paint patterns into uh
into a regular space why would we want
to do this we're almost at the
motivation for
cppns let's look at another detail of
cppns in the cartoon that you see over
here you'll notice that there are small
little inset figures inside each of
these 1 2 3 4 five six neurons that make
up this cppn what do you think those
little inset pictures
represent the fact that they're being
drawn inside the neuron is a very strong
hint activation fun they're activation
functions in a
cppn each neuron in a
cppn has a have different activation
functions this particular neuron here is
the identity function so it may be hard
to see from the back but inside each of
these neurons there's a little small X
and Y axes the x axis is representing
the value of the of the raw weighted sum
that's arriving at that neuron what's
coming
in the activation function takes what's
going in it goes to that position on the
horizontal x axis
and then according to its activation
function it finds the corresponding y
value at that horizontal position and
spits out that value along any outgoing
synapsis yeah so we're visualizing how
the activation function for each neuron
transforms its raw incoming signal into
a processed outgoing signal this one has
a uh identity function this one's got
something that looks vaguely like a
gaussian this one we haven't seen before
here's an activation function that has
some regular oscillatory repeating
pattern over time it's kind of
reminiscent of a central pattern
generator something that produces a
regular pattern over time but it's
hidden inside the neuron here's
something that is definitely a Galan
when we're when neat in the hyper neat
algorithm is evolving populations of
neural
networks the need algorithm can set not
just uh the number of neurons and which
neurons are wired up and what the
weights of those synapses are it also
encodes one additional detail that uh we
haven't included in the genome before
which is the activation function
associated with that neuron in
everything we've seen so far all the
neural networks we as the human
investigators usually picked an
activation function now we're going to
let hypernet do so or evolve activation
functions into these neurons why might
we want to do
that let's go back to our examp our
simple cppn over here and let's
place a sinusoidal activation function
inside and let's go back to our simpler
example of just a single synapse
connecting the X input neuron to the
single output neuron what pattern is
this cppn going to paint in our
two-dimensional
space a sign a sign of the amount of
black that we place right so maybe it
starts with a little bit of black more
black less black more black less black
more black and so on and then repeated
as we go yeah okay why did the authors
of hypernet construct such an
algorithm anybody have any intuitions
yet produces more diverse and complex
pns
same it it produces more diverse and
complex patterns is true it tends to
produce regular patterns so let's
imagine a slightly more complex
cppn let's create it at
random and we'll randomly throw a
sinusoidal activation function in here
we'll throw a Galan in here and maybe
the identity function into the
final output neuron down here we've got
two hidden neurons sorry two input
neurons two hidden neurons and one
output neuron we got a B we've randomly
wired up the neurons we've set some
random weights we've set some random
activation functions I don't know about
you but I haven't had enough coffee this
morning to actually work my way through
this and figure out what pattern it
produces but as you can probably guess
it's a mixture of regular gradations of
more or less black in this space and
maybe there's a little bit of gussian
noise here or there's a little bit of
Gan here so maybe we put a little bit of
black and then a little bit of more
black in the center and then less you
can imagine that what this cppn does is
to paint regular patterns and it's
composing these patterns together
question that kind of was my question
like with all those patterns it can kind
of compose any
absolutely so remember that no matter
what kind of neural network we're
talking about a regular vanilla neural
network a ctrnn a cppn ultimately all
these networks are functions they
transform their input into output
cppns embody a particular kind or class
of functions which is compositions of
coordinate
transforms which sounds intimidating but
you just saw that exactly right we're
taking all of the coordinates X Y and Z
and we're transforming them in a way
that we're painting patterns onto them
and the way that we're transforming and
painting these patterns is composed and
composed and composed together we get
gradations of uh regular patterns across
this two-dimensional space I constructed
this neural network at random and if
you've got time on your hands take half
an hour and code this up in Python and
connect it to matplot lib which you can
use to draw pictures and no matter how
randomly you make the ctrnn you are what
you're guaranteed not to
get is what you would do in the old days
with an old television set if you set it
to an unprogrammed TV channel You' get
white noise right that there'd be no
relationship between the color of this
pixel and the color of the pixel next to
it random cnns produce
nonrandom patterns that's why they're
called pattern producing not image
producing cppns guarantee that you're
going to get
non-random uh patterns you're going to
get things that slowly change over space
as we're painting into space everybody
see that okay I've held back the Y
why would you want to do this anybody
have a guess for why you might want to
do
this uh we're you're heading in the
right
direction you are not a random
collection of cells you are a set of
non-random patterns composed within
non-random patterns within non-random
patterns and so on there is a gradation
of physiological change across your five
fingers fingers aren't exactly the same
they're they're very close to one
another but they also are slightly
different as you walk from one finger uh
to the next the patterning in your arm
as you march from your shoulder out to
your fingertips as you start to M March
outward you see similar patterns of
bundles of muscle and bone and ligament
tendon and so on and that pattern
gradually changes as you move along the
body our uh insect brothers and sisters
that are made up of a whole bunch of
different segments now you can really
see not just regular patterns you can
see almost sinusoidal or repeating
patterns across the length of the insect
body there are segments but then in
these different segments there are
slightly different things going on
hypernet was inspired not by biological
evolution but by biological development
the way that every single multicellular
organism on this planet starts as a
single cell but as that single cell
divides and starts to make a larger and
larger and more complicated organism
made up of more and more cells what is
going on during that process of
development is fantastically complicated
and and a lot of that developmental
Machinery the stuff that's guiding
development the way you grow into a
multicellular organism is designed to
place patterns within patterns within
patterns within patterns you are a
composition of patterns all the way down
you are not some random collection of
cells development is not saying okay
there was one cell now there's two now
there's four now there's 860 now there's
a billion this IND idual cell you go
there this individual cell you go there
this individual cell you go there it's
too complicated you can't orchestrate
this huge mass of cells and things going
on by telling everybody exactly what to
do what you can try and do is influence
big masses of them so that they organize
into regular patterns across space and
time all the variety that we see out
there in nature if you look at every
single multicell cellular species there
is fantastic diversity but one of the
things we all share in common is we are
not just some random blob of cells there
is organization it's different
organization but it's organization of
patterns within patterns within
patterns okay that's uh this little
cartoon here was the author's Best
attempt to try and visualize this we've
got a two-dimensional space and in
theory you could probably invent a cppn
that would paint if we just imagine this
is a black and white picture it would
paint a sinusoidal pattern along the Y
AIS and they've shown this over here and
that might be composed with another part
inside the cppn that's painting black in
a gussian manner across the
xaxis and that could produce something
like you see here something in which
there is a go running up the YX AIS
we've got more than less than more than
less than more than less of black and
all of that black is bunched up at the
middle of the x axis everybody see that
okay so that could give us a regular
body plan here for some of these
segments we could have additional pieces
of the cppn that paint uh again some
more repeating patterns patterns with
slight variations as well and then it's
also possible if you compose a bunch of
Gans together Gans can kind of squash or
compress or Focus one part of the cppn
to paint one and only one unique pattern
at one and only one place in this
two-dimensional space you can sort of
get everything you need for creating
something that looks vaguely like an
organism repetition variation on a theme
symmetries uh and so and unique patterns
as well all within the same
cppn so far so
good okay all right let's test our
intuition about cppn we now know why
they are invented if we evolve
populations of
cppns we're searching the space of all
possible networks that can paint all
possible patterns I could draw any
unique pattern of black inside this
two-dimensional space
and with enough neurons and synapses you
or at least a machine could figure out a
cppn that would produce that
pattern if it was a random pattern of
white noise you'd need a very very very
very very very big cppn to do so smaller
random cppns tend to produce regular
patterns in space so when we're evolving
populations of cppn we're actually
forcing Evolution to spend most of per
time in one part of the space of all
possible patterns it's the space of all
patterns in which there is repetition
variation on a theme and so
on if we wanted if we created a fitness
function that said draw White Noise
Evolution could do it but it's got to
move out of this of its comfort zone of
patter of painting regular patterns If
instead we had a a fitness function that
said paint oscillating waves of black
from left to right in the
two-dimensional space it would be much
easier for hypernet to evolve such as
cppn this is something we haven't seen
before it is an evolutionary algorithm
but it's an evolutionary algorithm
designed such that the genotypes which
are the
cppns tend to produce phenotypes in a
particular part of the space the space
of all possible regular repeating
patterns in two-dimensional space make
sense question that's similar with
Evolution like
nature think all the different shapes
animals that there are absolutely yes so
in nature mutations are random so a
random Photon of light from the sun can
uh hit some part of your DNA
unfortunately and make a random change
anywhere in the DNA completely random
but the effect of that mutation if it
hits uh if it hits your sperm cell or
your egg cell depending on your sex and
that results in an offspring the result
of that mutation is going to be
nonrandom luckily your child is not
going to be a random collection of cells
it's a mutation into a different regular
pattern of cells absolutely so
biological evolution mutations are
random but the effects of mutations are
non-random and that phenomenon itself
has been evolved for very good reasons
if you need to survive long enough in
the world to eat and reproduce a good
way to do so is to be a regular
arrangement of cells not a random
arrangement of cells y good
observation okay all right so let's test
our intuition about cppn so far we've
kept things simple we've been painting
patterns of uh black and white into a
two-dimensional space in the cartoon
example here you can see that they're
actually painting in
color how might you alter the cognitive
architecture of a cppn so that now it
Paints in color rather than just
dictating amounts of black what would we
change four different
output different colors okay let's have
four output neurons what what are those
four colors or what are they going to
we're going to get numbers at these four
output neurons how are we going to
interpret those numbers in order to
paint and
color I guess like the of the
pixel uh we could the thickness of the
pixel we could pick whatever we want any
other ideas
like RGB plus
Al
okay for the non-computer graphics folks
in the audience what's Alpha uh opacity
opacity okay so now we're going to set
at least the input layer and the output
layer we're going to evolve with
hypernet populations of cppn where each
cppn has two inputs and four outputs and
maybe there's one cppn in the population
that looks like this and maybe elsewhere
in the population there's another cppn
that looks like this and remember we can
have activation functions inside of all
of these we are now going to paint
regular colored uh images inside here
where some of the pixels are going to
have more or less
opacity okay
great what happens if we want to paint a
regular pattern into three-dimensional
space let's stick with our colored
example
here what do we need to change about
cppn to paint inside a threedimensional
volume
absolutely XY Z and now we're going to
Define an empty 3D Volume and every time
we evaluate some random
cppn we're going to visit in a regular
pattern we're going to visit each
three-dimensional coordinate of that
lattice in that 3D space and we're going
to paint a color a
colorized image inside a 3D
Volume let's say we want to make a movie
we want to cpb and a generate a movie
how do we do
it this is part of the reason why
hypernet is so popular it's very
flexible okay let's go back to two
dimensions
and we'll add a third input which is T
or actually maybe let's call this F
which is the frame index of our movie
there's one last thing we need to do how
do we evaluate this cppn to produce a
movie we're going to make a movie frame
by frame let's start by painting frame
zero of the movie
first each time at each frame each time
at each frame so we're going to create
the zeroth frame in the movie so we're
going to set this input neuron to zero
and then visit all the XY in the frame
paint color onto all of those pixels in
frame zero we've now created the first
frame of the movie now we set f equals
to one we haven't changed the cppn it's
one cppn that's painting all the frames
in the movie and off we go make sense
everybody see
that let's say we want to now modify our
cppn to paint music I give you an empty
sheet of uh of musical bars and we
wanted to paint music onto
it it's five lines right for music
okay
we've made images we've made movies now
we're going to make
music
theut could be it's different ways we
could do
it other
ideas again the inputs are going to have
to match the space that you're trying to
fill correct so it might need to
each place on staff but also
tempor absolutely right
so I'm not a music person what are these
called these
lines
spots okay anyone watching this movie
who's a music person my apologies okay
spots along the staff right so we're
going to visit it each spot and then we
might have a binary output neuron that
tells us whether or not to place a note
at that position or not and we now need
again pardon my ignorance frame zero is
this we visit the next point in time on
the musical score and now maybe it
paints some
other notes uh at that point in time and
we now have a cppn that is generating
music yeah in all three examples
painting images painting movies painting
music we haven't said anything about the
fitness function yet like how good or
how poor this music is but you can
imagine the last step in evaluating the
phenotype the phenotype is now the image
the movie the musical score we apply a
fitness function for how good that image
is how good that movie is how good that
Musical score
is okay this is not a music class
however this is a robotics class so you
can probably guess where we're going
we're going to see an example uh in
that's taken from this paper here uh the
uh where the authors took the hypernet
algorithm and used it to paint behaviors
onto
robots
Okay okay this is just to rephrase what
we just said the dimensionality of the
hyper Cube the 2D space the 3D space the
4D space is determined by the dimension
of the input coordinates this is an
important point I want you to hold on to
this this is going to come back when we
apply this to
robotics okay here we go we as always
want to evolve a quadraped robot to move
as quickly as possible from left to
right so coming back we've taken quite a
Divergence away from robotics as usual
let's start by seeing if we can use this
hyperne algorithm to evolve quadruped
gates for a four-legged robot in
simulation first of all before we see
how this was done why might we want to
do this for those of you that have made
it to assignment 10 you've taken this
minimal three-link two-joint robot and
replaced it with a four-legged
quadrupedal robot
and you can probably evolve a gate for
this robot why would we go want to go to
a much more complicated evolutionary
algorithm to evolve gates for a
four-legged
robot what is it about hypernet that
might be of potential utility
here itat PN you
want we remember our discussion about
legged Locomotion we want patterns what
patterns
specifically patterns in space patter
patterns in
time yes both right remember the
ministry of silly walks all of those
walks were silly because they did well
actually they did have a rhythm to it
but not the one we're used to right
random commands to the muscles in your
legs are going to produce a sillary
possibly dangerous gate right not a good
way to move so what you're going to see
in this experiment is some things that
are familiar we're going to evolve
quadrupedal Locomotion the fitness
function is the same as always
displacement along the xaxis away from
the origin but this particular
evolutionary algorithm is going to bias
The evolutionary process towards
hopefully regular
Gates the problem of course is that the
evolutionary algorithm is not acting
directly on the motion of the the legs
of the robot what the evolutionary
algorithm typically acts on is the
synaptic weights of the neural
controller that controls the movement of
the legs so what do you think hypernet
is going to be used to do
here we know what we want it to do which
is indirectly bi a search towards
regular motions of
legs what do we want hypernet to do
this little cartoon should be a strong
hint okay so maybe paint sinusoidal
patterns through time that's kind of
what we want the legs to do right we
want the legs to describe some rhythmic
pattern through time but we are not
going to be painting in time
I'm reminded of some of the diagrams you
showed in previous classes like when the
feet were touching the ground those it's
like we're trying to go from those
patterns to movements of the limbs
rather than the other way around just
mapping where
the happens exactly so we're getting
there right we're trying to work kind of
Upstream we know where we want to get to
we want to get to a four-legged machine
that moves with some rhythmic pattern we
don't know what that rhythmic pattern is
if we did we just program it into the
machine we know generally that we want
something that
repeats for the Motions of the legs but
we're still there's still a bit of a gap
here right we can't the cppn can't regul
can't directly tell the leg go here go
here how are we going to close this Gap
there's one last step
here
it's a little difficult to see here but
what you're looking what you're looking
at here is a neural network that's got a
whole bunch of input neurons and you'll
notice that these input neurons have
certain uh names associated with them
we've got a hidden layer in here and
we've got an output layer back here so
this should be starting to look
familiar this is a neural network that's
going to control a quadrip we've got an
input layer with a whole bunch of
sensors in here a knee sensor or a knee
angle sensor touch sensors in the feet
uh angle sensors in terms of how much
the hip is rotated forward and back how
much the hip is rotated Inward and
outward starting to look familiar the
output layer here next is the next
torque sent to the
motors
so a lot is looking familiar here but
we're missing there's one thing that's
not drawn here what's not
drawn synapsis the synapses that's the
hint what is hypernet going to
do we've seen hypernet
paint images it's painted movies it's
painted music now for this neural
control of the robot hypernet is going
to conne Bingo there it is it is going
hypernet is going to paint regular
patterns of synaptic weights across the
synapses inside this neural network and
this neural network is embedded in a 3D
Volume that's what this cartoon is meant
to show
you the hope is that if the hypernet is
painting regular regular patterns of
Weights across a neural controller for a
robot that is going to translate into
regular oscillatory motions of the robot
that's the hope it's not obvious that
that's going to happen and that was the
goal of this project basically this
project embodies the following question
If evolution paints regular patterns of
uh synap weights across synapses in a
neural controller will that translate
into regular motions of the machine
that's being controlled by that
Network everybody get
it you can probably guess because we're
talking about this paper the answer is
yes and we'll see that in a moment okay
let's go through
how how hypernet paints regular patterns
into space this can be quite confusing
so bear with me remember that we're
running the we're running the hypernet
algorithm which means we're evolving
cppn okay each we're going to take each
cppn which is a neural network and we're
going to use that cppn to paint synaptic
weights onto a different neural network
so in this experiment that we're now
talking about there are two different
neural networks at work the former is
painting patterns onto the
ladder the cppn is not controlling the
robot the cppn paints regular patterns
onto the network that controls the
robot so far so good okay they have
chosen as I just mentioned to embed the
neural controller for the robot in
three-dimensional space which means that
every neuron in the neural network has a
unique XYZ coordinate that's going to be
important in a moment yeah in this
picture let's walk through this picture
so you can see how this works you can
see that the all of the 5 * 4 all of the
20 input neurons all of the 20 sensor
neurons they're all embedded in a 2d
sheet which in turn is embedded in this
three-dimensional space that's this gray
uh Square here the five * 4 20 hidden
neurons are embedded in a separate
two-dimensional space two-dimensional
sheet and then finally um they've got 20
motor neurons but they as you'll see in
a moment they only need three times 4
they only need 12 motor neurons for
their quadrupedal robot so we've got 20
input uh 20 sensor neurons 20 hidden
neurons and what did I just say 12 motor
neurons again all of those neurons have
their own unique XYZ coordinate so far
so good okay let's go back to the sensor
layer for a moment inside the sensor
layer they have arranged uh each row of
sensors is dedicated to one of the four
legs that makes up the quadrupedal robot
I haven't shown you the quadruped yet
but you can probably guess how this goes
okay so leg one let's just assume this
is this is the front left leg of the
robot there are five sensors inside uh
inside that leg um there is uh there is
one there three of these or sorry three
uh one two three three of these sensors
are proprioceptive sensors the first
proprioceptive sensor in the front left
leg indicates the angle of the hip how
forward or back the leg is is at the hip
the leg is attached to the main body at
the hip how much is that leg rotated
forward or back that's a floating Point
number the second proceptive sensor in
the front left leg reports how much that
front left leg is rotated inward towards
the body or outwards away from the body
how much that leg is flexed inward or
extended
outward third number is the uh angle of
the knee so we've got two propri
receptive sensors s sitting in the hip
and One proceptive sensor sitting in the
knee same thing for the front right leg
back left leg back right leg so far so
good okay fourth sensor in each leg
pretty straightforward it's a binary
value whether or not the tip of that leg
is in contact with the ground or not
ah sorry I misspoke there are not five
sensors in each leg there are four
sensors in each leg four times four and
then they snuck in some additional four
sensors here yaah pitch and roll it's a
little it's not drawn very well these
are not associated with any one leg
they're associated with the main
body they're obviously measuring the
yaah pitch and roll or orientation of
the main body you can also sense y'all
pitch and roll As you move about through
your
day
how thank you right inner ear right so
our robot has an inner ear and then
finally the 20th sensor neuron is
emitting a SOS soidal pattern this
should look familiar what is that neuron
simulating which is called in us in your
spine
Central pattern generator right in case
that's useful so not that we've seen
this before the only Innovation here is
they're embedding this in in a spatial
embedding in a two-dimensional
plane these are somehow going to be
wired up to the hidden layers we'll
assume for our purposes that every each
one of the 20 sensor neurons sends out a
synapse to connect to uh one of the
Hidden layers so we're going to have a
fully connected sensor to Hidden layer
so far so good so each of the 20 sensor
neurons connects to each of the 20
hidden neurons we have 20 * 20 400
synapses that are move that are uh
connecting the sensors to the hidden
neurons so far so good
question they not trying tot any
particular hypothesis onto on
conne are not
start correct exactly exactly so again
they haven't drawn the synapses here so
that you can paint your with your
imagination what those synapses might
look like so imagine we drew all 400
arrows coming out the back of these and
into the front
of these and imagine we drew the lines
of those synapses thicker if they were a
stronger weight or thinner if they were
a weaker weight a a weight closer to
zero if we did this in the way you're
doing it in the assignments you just see
some random collection of thick and thin
lines but with hypernet no matter what
cppn we create that paints weights onto
these synapses if we looked inside and
across these 400 arrows you'd see
regular increases and decreases of
thicker and thinner lines that would
visualize the internal uh regularity of
synaptic weights okay why you
whyw
not great question because it's harder
to think about it that way by embedding
it in a three-dimensional space we can
at least try and draw the cognitive
architecture what this neural network
looks like there's nothing that says we
couldn't take all of these neurons and
embed them in a higher dimensional space
and do exactly the same thing maybe it's
advantageous who knows it sounds like a
great final project idea to me you just
wouldn't be able to draw what that
neural network looks like easily you
could also embed all these neurons in a
two-dimensional space and paint regular
patterns in there as well is that better
or worse who knows hard to say they just
picked
3D okay let's keep going so we've got
400 synapses going from the input to the
hidden layer and imagine we fully
connect all these 20 hidden neurons to
these 12 output
neurons we've got four rows again each
row uh allocates motor neurons to that
leg so these are the three motor neurons
assigned to the front left leg these are
the three motor neurons assigned to the
front right leg and so on it does not
say on this picture where those three
motor neurons go in the leg but given
our description of the sensor neurons
you can probably guess where do the
three motor neurons go inside the
leg thep forward backward the
that's exactly it right so here's our
hint we know that the leg can rotate
Inward and outward at the hip and the
leg can rotate forward and backwards at
the hip which tells us that there are
actually two hinge joints there it is
not like our knee it's like our shoulder
or your our hip forward and back and
Inward and outward so we've got two
motor neurons that are controlling those
two degrees of freedom in the hip and
then the third one is controlling
pulling the knee got it okay so that's
the neurons we know uh we know the
distribution of sensors we've we've got
full full connections between inputs to
Hidden and hidden output finally thanks
for your patience now we can do the fun
part let's imagine a
cppn that's going to
paint patterns onto each and every one
of the synapses so when I introduced you
to cppn we walked through positions in a
two-dimensional space and at each point
we obtained a single floating Point
number which was the amount of black to
place at that position now we've got
synapses embedded in a three-dimensional
space we're going to visit each synapse
in turn and take the coordinate the
position of that synapse feed that
position in and we're going to have a
single output neuron
actually let's draw
this we've got our synapses in three
dimensional space so we need the XYZ
coordinate of a synapse and then we've
got a bunch of stuff going on inside and
we have one output neuron that we're
going to call W to remind us that the
value arriving here the floating Point
number is going to paint that weight
onto the synapse at that position
same cppn we're going to call that cppn
400 times to paint 400 weights onto the
400 synapses between the input and hi
hidden layer take the same cppn and
paint all weights onto all the synapses
that are going from the hidden to the
output layer so the neurons are arranged
in XYZ space y so this would generate
one value for each neuron but you need
one value for each yep and so each
individual neur
needs
vales okay we a good observation so
deliberately I'm making things simple
and it's too simple it's not going to
work but we're going to see I want you
to see if you can see exactly why it's
not going to
work we can uh if we take this synapse
it's got a if we take a position if we
take a synapse that is in
three-dimensional space it starts at
some ner NE that has a unique XYZ
coordinate and and it ends at another
neuron that has a unique XYZ coordinate
the center of that synapse also has some
XYZ coordinate everything in here all
neurons and all synapses are embedded in
a three-dimensional space so when I said
we're going to take the cppn and visit
each synapse let's actually visit the
centroid of each synapse we're we're
dealing with this neural Network
geometrically now we're going to visit
each centroid take the XYZ coordinate of
the centroid of that synapse and get
back a weight from the cppm 0.4 let's
say so we're going to get floating Point
values for all of these synapses but as
Nate has started to in it there's
something wrong with this process what
is it not necessarily wrong but there's
something that's limiting us
we're using cppn so we know it's going
to paint arbitrary regular patterns
across all of these synapses which is
good that's what we want but we're
actually hobbling ourselves here a
little bit some there's something that's
holding us
back some have the same thank you
exactly so let's look at this sensor
neuron up here and Visually I want you
to paint a synapse that goes from this
neuron to this hidden
neuron imagine now we we visit this
neuron and imagine the synapse that
connects it to this neuron those two
synapses which both are embedded in
three-dimensional
space are going to have the same
centroid so tell me about the two
weights for these two synapses that
share a
centroid they're going to get the same
weight right no matter what the
cognitive no matter what cppn we apply
to this network it's going to be forced
it has to assign the same weight to sets
of synapses that share a
centroid now this might not actually
even be a problem we might be able to
evolve neural controllers for a
quadruped such that it exist exhibits
regular patterns over time but if you're
mathematically inclined something
doesn't quite sit right with this it
would be nice to roll back this
unnecessary constraint how might we do
it there's different ways we can do it
there's one particular way that the
authors did it they weren't they didn't
like this they made one change so that
this they made one change to the
cognitive architecture of the cppn so
that it could paint different weights on
synapses that share a centroid how do
you think they did
it any
ideas inad of looking at C look at the
point little bit along the line show you
the vector yeah you could so instead of
the centroid maybe we take a point 34s
of the way along the synapse towards its
post synaptic neuron that that would
work that's not what they did you could
still I guess maybe you could still end
up with them like Crossing maybe yeah it
depends yeah you'd have to work it out
you probably could pick a point at which
they don't if you went in and actually
measured things and like all good
scientists these scientists who I know
well they were a little lazy they didn't
they didn't do it that
way they introduced a little
mathematical trick so that they didn't
have to measure anything they could be
pretty secure that the cppn would feel
free to paint unique weights even if
synapses shared a
cite any
ideas they introduc a random number to
the uh you could introduce a random
number but that makes things hard for
evolution right because now we're
changing things every time Evolution
goes to evaluate a
cppn this is not trivial so it's okay
I'll give you a hint cam mentioned a few
minutes ago why not embed these things
in higher
Dimensions uh okay you're getting very
close now so this neural network the
network that controls the robot is
trapped in three dimensional space but
they started
to uh they started to add in put neurons
to the
cppns that we're painting patterns onto
this so this gets a little bit tricky
we're juggling two different kinds of
neural networks the cppns and the robot
neural controllers and now we're going
to start juggling dimensionalities the
neural controller is embedded in
three-dimensional space but the cppn is
going to paint in higher dimensional
space you you mention one idea which
could be we're going to add some sort of
neuron or synapse index in very much
like we saw in in the movie example
right where we had a frame index for
frames in the
movie that's that's actually one way you
could do it that's not the way they did
it they added three additional input
neurons which means they now have a cppn
that's painting regular patterns inside
a six dimensional
volume I hope you had your caffeine this
morning okay there's the hint three
additional uh input neurons what are
they first are the starting neurons
location the T
absolutely okay so here we go remember
that every synapse has a pre synaptic
neuron the place where the synapse
originates and every synapse has a post
synaptic neuron which is the neuron at
which that synapse terminates we've got
pre and post that's two p
so that's not going to work for us let's
go for pre R is in Pre and O is in post
so they're going to feed they're going
to visit each Nur uh each synapse in
turn and they're going to feed into the
cppn the X Y and Z coordinate of the
pre synaptic neurons 3D position and
they're going to supply the XY and Z
coordinate of the post aptic neuron at
which the synapse
terminates okay let's
summarize we're going to evolve neural
controllers for a simulated quadrupedal
robot that neural controller looks more
or less like we're we're comfortable
with the neural controller of the robot
is embedded in three-dimensional space
we're going to evolve not the neural
controllers we're going to evolve
populations of cppns
so the genotype in this evolutionary
algorithm are
cppns each genotype is going to paint
synaptic weights onto this neural
controller using Six
Dimensions once the cppn has finished
painting the synaptic weights onto the
controller this neural controller is the
phenotype of the
cppn the neuron
in the neurons and synapses inside the
cppn is the genotype the stuff that neat
is going to operate
on the phenotype is the neural
controller to which we're going to
assign
Fitness so far so good we're putting
everything together here so we've got a
population of cppns we've taken the
first cppn painted weights onto the
neural controller we let the simulated
quadrip be controlled by that neural
controller we measure how far that
simulated robot travels from the origin
which gives us back a floating point
value how far it traveled that's the
fitness of that
cppn go to the second cppn it paints
neural control under the quadrip head
and rinse and
repeat got it
Emily the the cppn is painting regular
patterns into a six-dimensional space
which is then interpreted back down into
three dimensions
right this this is the advantage of of
higher Dimensions when you work in
higher Dimensions things tend not to
overlap as much right the lower
Dimensions you go to whatever it is
you're working with sets of synaptic
weights mathematical structures you tend
to get a lot of overlap you can pull
stuff apart by going to higher
Dimensions it's a very very common trick
in mathematics hopefully here you see
exactly why we're doing
it
okay okay so here's my little cartoon of
how this works we're feeding in uh the
coordinates in six-dimensional space of
each uh synapse passing it through a
cppn and it gives us back the weight
this is kind of the the key of this
whole thing okay okay we already
actually said this
you can fill this in on your
own okay so here we go remember that the
question the authors wanted to answer
was does hypernet make it easier for
evolution to discover regular gates for
the quadruped compared to other things
so what they did was to create the other
thing this is called the control the
thing that's missing
hyperne they called this um f neat or
fix topology neat this is a little
confusing um I don't really like this
control but this is what they use so
here we go um they use the same neural
controller the same neural net as in
hypernet they use this
thing um but now uh that allowed for
mutation and crossover but not the
addition removal of neurons and
synapses so they're they're sort of
fixing this uh they're removing all of
the good stuff about hyperne the ability
for hyperne to paint regular patterns in
space I think just you'll have to trust
me on this if you're interested in the
details you can go and read the paper
but we're going to look at two different
uh algorithms hypernet is the algorithm
we just talked about the control is
everything is exactly the same but
they've removed the ability of hypernet
to paint regular patterns in space
they've hobbled hypernet in a certain
way it's kind of collapsed back down
from hyper neat to neat I think we won't
go into the details just have to trust
me on this okay all right okay let's
watch some
movies okay this is the best most fit
gate or the most fit neural controller
they got from the control experiment The
evolutionary algorithm that could not
paint regular patterns of synaptic of
regular patterns of Weights across the
Sy
axis how's it
doing it's
okay there's a little there's a little
bit of rhythmicity here but not quite if
you watch any one leg you'll see that it
might be in Phase it might be moving
with one of the other legs but then kind
of falls out of phase with it
if this robot could sweat it' be
sweating right this is there's a lot of
exertion here there's a lot of points in
which the leg hits rotated forward which
stops motion it's lost its momentum this
is not this is a silly walk this is not
a very efficient way to move this is the
best neural controller they got from the
control experiment that was evolving
sets of synaptic weights for this neural
controller but no regular patterns
within the neural
controller this is a little confusing
I'll explain this as we watch it this is
the worst evolved gate which actually
means the the worst of the best so they
evolved with hypernet so they're
evolving regular patterns of Weights
across the neural network they ran
hypernet once and got the best the most
fit neural controller out of that
evolutionary algorithm then they went
back and created a different random
population of cppn and ran hypernet a
second time and took the most fit neural
controller out of that second run now
they've got two highly fit neural
controllers ran hypernet again third
time a bunch of times so they had a set
of Champions these were the most fit
individuals from a whole set of
independent evolutionary runs and among
all of those
Champions they took the worst one the
worst Champion it's a little confusing
the worst of the best it seems like it
wouldn't be that hard to like just
directly program a robot just like all
his legs at once yes absolutely isn't
the point that we're trying to get it to
do stuff that's harder than we can
design ourselves yes yes absolutely th
for this simple robot you could probably
go in and you're all good enough
roboticist now you could probably pre
preprogram it to do so you might
remember the hex the nonap from the
beginning of this course that weird
metal tubing type robot that had nine
legs that you also wanted it to move in
that particular robot there were 12
Motors so you'd have to control 12
Motors give that a try see if you can
sit down and figure out a way for that
thing to move with a regular gate it
doesn't take a lot more mechanical
complex it I can put a few more joints
and links on here where it suddenly
becomes very difficult to figure out how
to program a regular gate for it
especially if it's moving over uneven
terrain and it's being buffeted by wind
and somebody comes along and drops a
200b backpack onto its back not so easy
to do in that case so you're right this
demonstration is maybe a little bit
underwhelming because you could probably
do just as well you can try and run this
on a more complex robot and see how
things go okay so this is the best of
the worst how is this one
doing got a regular gate right so it
works you can actually uh you can use
cppns to paint regular patterns of
synaptic weights inside the neural
controller of this robot and you tend to
get regular patterns of
motion we've spent most of the morning
talking about how uh how synapses are
tuned inside of a maybe not complicated
neural network but getting there what do
you think's going on in your own
head you tend to do most things with a
regular pattern arrayed over space and
time it's not quite known yet about
synapses but neurons definitely seem to
have regular patterns inside our Central
and peripheral nervous system it's it it
looks on first pass it looks like some
random jumble jumble of uh neurons most
of the last hundred years of
Neuroscience and neural physiology
dissecting neural networks has been to
answer that question is it actually just
a random tangle of neurons and synapses
the answer is at least in the way it's
wired up absolutely not there are
definitely regular patterns and not just
regular
patterns but compositions of regular
patterns you get teeny tiny little
neural modules that are made up of just
a handful of neurons that are wired up
in a particular way and that little neat
packet seems to be replicated into a
larger structure that's made up of these
smaller structures those larger neural
modules are again replicated in the
brain some of them are replicated with
variation you see pattern composed
within pattern composed within pattern
within biological neural systems which
suggests although it is not yet been
proven that that tends to bias our Form
and Function towards forms and functions
that unroll over time and space in
regular ways rather than random ways so
maybe hypernet which was only designed
to help with AI and Robotics problems
might suggest or give us ideas about why
biological nervous systems are arranged
in the way that they're
arranged
eighto like the sensory mot neurons in
the brain are actually spatially
organized oh yeah that's right the and
the organization is not necessarily
non-intuitive it's organ the as you
mentioned the sensory and motor parts of
your brain are arranged in a regular
pattern which actually matches more or
less one to one your actual physiology
and actually we'll see this we're going
to see what's called the motor
homunculus in a few weeks in this class
we'll come back to exactly this
point okay I think that was all the fun
movies I had for
today the best of the best well if this
is the best of the worst you can imagine
the best of the best is even better than
that okay all right we've got a grand
total of 2 minutes left so all I want to
do today is just introduce the next
problem we're going to try and solve
which no one has solved yet the reality
Gap um the re we're going to see I guess
on Thursday we're going to see an
evolutionary robotics experiment that
dates all the way back to the beginning
of evolutionary robotics which was in
1994 in that paper they introduced this
term they introduced this problem the
reality Gap we're going to see that they
simulated some robots and then tried to
transfer them to reality and it didn't
work so well um that was
1994 in
2018 this lovely company here came along
and said listen there's this problem in
robotics that none of you have
identified yet we're going to call it
the domain randomization problem and we
are the one and only company that's
going to be able to solve this problem
all great all great problems are
reinvented or rediscovered every 20
years or so so uh this is a very big and
very real problems that some very big
and powerful corporations are trying to
solve it all started with a modest
evolutionary robotics paper from
1994 which we'll talk about uh not on
Thursday we'll talk about it next
Tuesday you have a quiz due tonight some
of you are working on assignment uh nine
some of you are working on D4 see you
then


--- Evolutionary Robotics course. Lecture 19： Crossing the reality gap..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone let's dive
back in uh couple of orienting remarks
before we get back to the next challenge
in evolutionary robotics undergrads you
are uh about to start in on the 10th and
final assignment so you're nearing the
end I just linked it in there uh now
through assignments 1 through n we've
tried to keep everything as simple as
possible so in the spirit of the minimal
cognition experiments you've had a
minimally complex robot Three Links Two
Joints a minimal complement of sensors a
minimal complement of Motors no hidden
layer just a few neurons as few synapses
as possible simplest possible
environment you can imagine for the
robot an infinite flat plane and we've
been using relatively simple optimizers
very low powerered simpl to code up
evolutionary algorithm in assignment n
so everything has been minimal minimal
simple simple simple all the way along
until assignment 10 in assignment 10
you're going to go in and make your
robot more complicated there's only so
much we can do with the three link
two-joint robot so you're going to
replace that very very simple robot with
uh the quadraped which is made up of
eight links and sorry nine links and
nine joints still not very complicated
but it gets easy to get lost pretty
quickly in assignment 10 you remember
our discussion about absolute and
relative coordinates when we were doing
the joints assignment that gets very
confusing when we start to play around
with more and more links and Joints so
my advice to you if you haven't tackled
assignment 10 yet is to do everything
incrementally add one link and connect
that new link with a joint to your GR gr
robot debug the position and orientation
of that link the position uh of the
joint make sure the joint normal is
correct there's a temptation to add all
the Links at once and and connect them
all up with joints cross your fingers
hit compile and hope for the best you
all are probably sufficiently
experienced coders by now to know what
happens when you do things in that
manner so take your time do things
incrementally in assignment 10 and when
we reconvene here uh when we reconvene
here next Tuesday
Morning uh the undergraduates and those
taking this course for graduate credit
you will have done with all the weekly
assignments and you will be on your own
for the rest of the semester so next
Tuesday we will talk about final
projects how to navigate the final
project how to do well what's worked for
students in the past what hasn't worked
for students in the past uh and so on
all
good okay graduate students uh you are
about to also tackle the very final
assignment which is the fifth and final
differentiable assignment which I
haven't finished coding up yet I was
hoping to finish last night I am racing
to stay one week ahead of all the grad
students in this class I'm falling a
little bit behind I will put it up
around 3:00 this afternoon which means
for The Graduate students D5 will be due
at 3 P.M next Tuesday I will still give
you a week to work on it fair okay I
know everybody's busy myself included
we'll get there any questions about
assignments the differentiable
assignments all good okay all right so
uh we are working our way through open
challenges open problems in the field of
evolutionary robotics uh we looked at
modularity or lack of modularity we
looked at the competing convention
problem and the solution to the
competing conventions problem which was
neat and then we looked we ended last
time by looking at hyperne which is a
solution to a different problem what's
the problem that hyperne helps to
solve if you remember why hypernet was
designed it's basic the basic idea
underneath hypernet what does it help
with
regular behaviors or shapes whatever you
want regular behaviors regular shapes we
are bilaterally symmetrically shaped the
left side of our body looks like the
right side of our body because that
helps with a particular regular behavior
that is important to us which is usually
bilateral uh Locomotion as by bipedal
locomotion in the direction in which our
primary sensors face right so if you
look across nature organisms are not
random collections of body parts and
they don't move in some random
uncoordinated way there is regular
pattern over time in the behavior of
organisms and there is regular spatial
ordering in our bodies and also in our
brains so hypernet was designed to bias
evolutionary search Evol hypernet is
still an evolutionary algorithm we're
searching among the space of all
possible things could be neural
controllers for robots robot body plans
themselves but hypernet tends to focus
search in one part of the fitness
landscape and it's that part of the
fitness landscape in which can be found
regular patterns okay today we are going
to start in on arguably the biggest the
hardest and the as yet unsolved problem
in the field of evolution and Robotics
and many other branches of Robotics
which is it's not that difficult to
evolve or train a simulated robot in a
simulated environment if you've just
finished assignment nine you've had a
little bit of experience with that it's
not trivial but it's not that difficult
once you have something in simulation
that works you have a robot that does
something useful and presumably safe for
humans to be around how do we take that
robot and transfer it to reality and
Ensure or guarantee that the physical
counterpart the physical robot is going
to exhibit that safe useful interesting
entertaining behavior in the real world
that is known as crossing the reality
Gap and uh this has been an open problem
since the beginning of evolutionary
robotics the early 90s but arguably
going back even earlier than that and
again although some people think they
have good solutions to this problem
like Nvidia I would argue that it is
still a difficult problem to
solve okay in this segment we're going
to look at four different projects four
different attempts to cross the reality
Gap they're all very different there are
many many more attempted solutions to
cross the reality Gap than just these
four I picked them to be a
representative sample we're going to go
back and look at uh the first one in
evolutionary robotics which was
published at the beginning of the field
uh in the 9s and the basic idea behind
this very first attempt to cross the
reality Gap is to sprinkle a lot of
noise into the simulation itself so that
Evolution cannot latch on and exploit
some feature of the simulated robot or
its simulated environment that is
constant that doesn't change inside the
simulation but isn't real in reality
there are many of these constant
features in your simulators that don't
exist in reality what are some of
them at the end of assignment now you
should have a minimal minimally complex
creature running around in a simulated
environment which is pretty fake fake in
which way which ways there are many is
like flat absolutely right this carpet
looks pretty flat it's not other
features of the environment that are not
real if you were to take if you got a
nice gate for your three-link robot and
I gave you a Lego construction kit and
some Motors to actually build it in
reality what's going to literally or
maybe metaphorically trip trip up the
physical counterpart of your evolved
robot LS can go each other the
absolutely the parts the links the parts
of the robot can
interpenetrate not allowed in reality
unless we build the parts out of like
Nerf or foam and then we could argue
that interpenetration is kind of okay
because it's soft but what else what
other rules of this universe is your
physics engine
violating absolutely so if you're
prototyping a robot for NASA and we're
saying this is moving around on a on a a
comet or a meteor uh or it's moving
around in a vacuum with no wind no air
pressure no oxygen then okay fine but
not on this
planet other things that are not
real oh it's got discreet time steps
discrete time steps also not true right
so from the point of view of your robot
it doesn't have a camera but it's got
touch sensors it's basically closing its
eyes and then it suddenly teleports a
small distance in its world and then
closes its eyes and teleports again we
can make those moments of
unconsciousness very very brief but
they're still
there
you you may have seen this in assignment
9 you'll definitely start to see it in
assignment 10 as always Evolution
regardless of whether she is biological
or artificial is a satisfies her she
will exploit whatever she's given what
uh inaccurate features of the simulator
have you seen your robots start to
exploit
this one's a little trickier is your
robot exploiting the fact that it's
using through a moving through a
vacuum not really right there's not
literally nothing in a vacuum with of
which to
exploit doesn't
toter but also absolutely right so there
is some friction set in your in the
ground floor it's relatively low at the
moment so it's like moving over lenium
or maybe like rough ice it there's a
little bit of friction but not much and
you can see that the robot tends to
evolve in many cases like walking on
tippy toes takes lots of many small
steps which is actually maybe not a bad
strategy if you're moving over low
friction but it's definitely exploiting
that fact and if we took that robot and
built it in reality out of Lego and put
it on this High friction carpet that
strategy is probably not going to work
very well and your robot would fail to
cross the reality
Gap when we do more complex simulations
like you see the Nvidia one here there
are many there are much there's much
more physical detail in the physics
engine and in the construction of the
simulated robot itself and a lot of
those details are actually inaccurate or
completely inaccurate and there's more
opportunities for an evolutionary
algorithm to exploit all all of those
inaccuracies so how do we keep
artificial Evolution from exploiting
things that don't exist in the real
world in the simulator how do we keep
her from doing that but make sure that
she does focus on evolving or tuning or
optimizing those aspects of the robot
and its interaction with the environment
so that the robot does what it's
supposed to
do that's what we're going to look at in
this first experiment it's an old idea
and Nvidia has convinced themselves that
they rediscovered it in 2018 and you can
see that idea visualized in this
screenshot what's the
trick like every possible situation
every possible situation so it may be
difficult to see from the screenshot if
you're in the back they're trying to
trade a robot arm to pick up this or or
to hang this yellow cylinder on a string
and drop the cylinder into the hole in
the blue
cube and if you give one robot arm one
string one cylinder and one blue cube it
will learn to do it by exploiting some
aspect of the actual geometry of that
one yellow cylinder the geometry of that
one blue cube that's not what you want
to train the robot to do you're not
trying and video is not trying to train
the robot to drop that cylinder into
this Cube It's to drop cylinders into
cubes so pretty makes sense right very
intuitive train it on a whole bunch of
different situations so you'll notice
that there are all sorts of different
cubes there are holes in these Cubes at
different relative positions the holes
are bigger or smaller the cylinders are
bigger and smaller basically force it to
generalize across all these
instances so that if Nvidia takes one of
the neural controllers that results from
this experiment in simulation and drops
it into a physical robot arm from the
point of view of that neural controller
it's experiencing yet one more cylinder
and cube with a hole in it right just
one more case it's just from our
perspective it's a it's a particularly
unique case it's the first real cylinder
and real Cube that the real robot has
experienced but from the point of view
of the neural controller it's just
another situation yeah okay so you can
see from this picture what's being
varied what's not being varied in this
picture the robot itself is the same
yeah the
environment the EnV the environment
itself right it's all a flat floor so
there's features of the environment that
are invariant here but mostly it's the
robot that stays the same remember our
discussion about Rene dayart way back
the beginning of the course divide body
and brain body doesn't matter let's
forget about the body you look at modern
robotics you can see that all the time
right the focus here is on the neural
controller that they're training and the
environment of the robot the cylinders
and the cubes they've forgotten about
the robot's body
itself there's the simulated robot's
body you can imagine the physical
robot's body looks more or less
identical to
that is it likely to be identical the
simulated robot arm and the physical
robot
arm okay most of you are students of
embodied cognition right now you know
that they may look similar but there's
bound to be mechanical differences
between the simulated robot and the
physical robot no matter how accurate
the simulator is and no matter how many
fancy High futin gpus we run this
simulator on there's bound to be
differences the reality Gap is is tricky
it's
significant okay all right so let's go
back in time to 1997 towards the
beginning of evolutionary Robotics and
uh at that time as this field was
starting this idea of evolving uh robots
and simulation and then transferring
them to reality was starting to occur to
folks and already there was people were
starting to realize there's going to be
a problem whatever we evolve in
simulation how do we transfer that uh to
reality now this is a little tricky
because physics engines didn't exist in
1997 actually they did exist they were
being coded up at uh games companies but
they hadn't been released to the general
public
yet before there were physics engines
there were simpler models that we people
were using and we're going to look at
some of those simpler models today so
throughout today's lecture I'm going to
talk about simulation and for most of
that most of us that sort of equates
with physical simulation the physics
engines that you're working with those
didn't exist yet we're going to just use
simulation as a catchall term for some
simplified computational model in which
we can do Evolution and then try and
transfer stuff to a real
robot okay all right so the the
observation back at that that time will
was Evolution artificial Evolution will
probably create neural controllers that
are going to exploit details of the
simulation perverse instantiation has
been known uh in Ai and Robotics for a
very long time uh that's another problem
obviously related to the reality Gap so
if evolution exploits the details in
this simulation and those details don't
exist in the reality we have the reality
Gap what whatever evolves in simulation
is unlikely to transfer to re uh to
reality so the hypothesis that was
tested in this paper is to add noise to
the simulator and for our purposes noise
is going to be every time you construct
and run a simulation randomly alter one
or more features of the
simulator but what features do you
decide to add noise to to ensure
that evolution is not going to exploit
details uh incorrect
details and then you won't be able to
transfer to reality we could add noise
to everything place the robot in high
wind every step it takes across the
ground is ice then sandpaper then
Boulders uh then loose sand then shallow
water we could add tons of noise to
every feature you could imagine the
robot's body changes is at every time
step it's Mass distribution is being
juggled from time step to time step just
if we don't know what kind of noise to
add let's just throw tens uh let's just
throw tons of noise at the simulator
what's going to
happen evolution is certainly not going
to be able to latch on to any constant
detail and exploit it to evolve the
behavior we want in simulation that's
good what's the
problem won't evolve to do anything it
won't evolve to do anything you can try
this yourself with your setup now
artificial Evolution will say I'm just
going to keep the robot where it is it's
too windy it's too noisy the robot keeps
changing I can't find any way to climb
any Hill in the fitness landscape so
there's a balancing act here there's a
goldilock zone between adding too much
noise
so that Evolution can't make any
progress in
simulation and adding too little noise
so that Evolution starts exploiting
facts uh invariance in the simulation
that have no correspondence in reality
yeah okay so there's a question then
that arises in this hypothesis which
intuitively makes sense which aspects of
the simulation do we
noisy and the more complex the simulator
there it is
the more things we have to decide to
noisy or not friction of the ground the
mass distribution of the robot's body
its geometry the geometry of the robot
itself the properties of the joints the
properties of the sensors the properties
of the motors properties of the
batteries on and on and on we go so this
sounds terrifying because the more we
want our robot to do the more
complicated a simulator we need to
evolve it to do that the more decisions
we need to make about what to noisy and
what not so the solution that the
authors came up with the author came up
with back in 97 was minimal simulation
what is the simplest possible simulation
we can make uh and the minimal
simulation inspired some of the minimal
cognition experiments that we saw last
month they're related okay so we're
going to be looking at a minimal
simulation now contains as little detail
as possible but enough that Evolution
evolves something that transfers to
reality okay so how are they going to do
this they're going to think about how to
create a simulator for their robot first
and they're going to think about all the
physical details that might exist in
that Simulator the mass of the robot
gravity friction wind resistance air
pressure and they're going to take all
of those physical details and drop it
into one of two buck buets the first
bucket is the base set of robot
environment interactions so you can
think of one inter one type one kind of
robot interaction is Collision detection
and
resolution friction is a part of that
that uh detail so in the base set these
are things that we might get wrong so
friction definitely exists in the real
world so we want to put friction into
the simulator we might not know how much
friction to add but some kind of
friction needs to be in the simulator so
that goes into the base set those are
things that we might get wrong but they
need to be in there they're important if
the robot has no friction it's going to
go nowhere in simulation no matter how
smart evolution is the second bucket is
basically artifacts they call this the
impl implementation set of interactions
it's not a very uh good term in my
opinion implementation meaning to
implement the simulator they needed to
put it in there but it has absolutely no
basis in reality completely different
from
reality what are some things we kind of
have to put in the simulator but have
absolutely no basis in reality this is
not so obvious to think of examples
here any
ideas is it again
we need to like have some sort of
surface we need to have some sort of
surface that would probably go in the
base set we might not get the friction
right and no floor is perfectly flat but
yeah we probably need a
floor everything being a perfect shape
yeah that that certainly something we
can't get we can't get right what we're
going to see in a moment is what one
example of an implementation set are the
sensors so we've talked about uh we've
talked about infrared sensors in this
class sonar sensors things that send out
a signal that hit something in the
environment and bounce back and the time
it takes for that signal to go out and
come back to the robot or in the case of
organisms for a bat for example when it
sends out sonar getting the details of
all of those signals going out and
hitting something and bouncing back
correctly as it does in the real world
it's it's impossible we could take all
the computers on the planet at the
moment and dedicate them to simulating
one pulse of sonar and we wouldn't be
able to to simulate it very well it's
basically impossible to simulate that
well so how an infrared sensor behaves
in uh is would probably be dumped into
the second bucket any detail that
Evolution starts to exploit about how an
infrared sensor works on a simulated
robot if it's exploiting that fact
that's a bad bad thing Evolution's
getting addicted to something that's not
going to exist in reality or it's going
to exist but it's going to be so
different from whatever we simulate we
shouldn't simulate it so seem sounds
like a catch 22 right we want to evolve
a robot with infrared sensors but we
can't simulate the infrared sensors what
do we do this is actually tricky okay so
we're going to see how this works so
what they're going to do in this
experiment they're going to run things
in a not a physics engine but a simpler
uh simulated world for their robot and
they're going to sprinkle noise on a
whole bunch of different things they're
going to sprinkle tons of noise on the
things that they know that they can't
Implement well like how infrared Sensors
refle how infrared light reflects back
to the robot they're going to put 100%
noise on that and they're going to put
only a little bit of noise on the base
set so going back to this picture here
the Nvidia folks know that the physical
robot is going to encounter cylinders
and boxes with holes in them so vary the
cylinders and the boxes a little bit in
this experiment it was 10% an arbitrary
number yeah so they're basically
poisoning some aspects of the simulator
that Evolution should not latch on to
and varying mildly the things that it
should exploit so that it generalizes to
those features what does 100% of noise
mean yeah we'll I'll give you an example
in a moment yeah okay we we'll see what
100% basically it's every time the robot
encounters an instance of that
phenomenon it's completely
different okay we'll see an example in a
moment okay so uh you might recognize
this robot it's not the Roomba roombas
didn't exist yet although roombas were
inspired by this robot
anybody
remember the Kea robot the hockey puck
type robot just to refresh your memory
we've got six infrared sensors on the
front two infrared sensors on the back
and two ambient I'm sorry this should
say ambient light sensors so ambient
meaning these sensors are not
directional they're just picking up the
ambient light level around that sensor
infrared sensors again they send out a
pulse of infrared light and the sensor
measures the amount of time for the
pulse to come back the longer it takes
for that pulse to come back the further
away is the object that that caus the
infrared beam to bounce back to the
robot yeah okay two wheels two wheels on
a robot so eight uh I'm sorry eight plus
two sensors 10 sensors plus two
Motors they're going to evolve this
robot in a simulator to solve a very old
problem taken from psychology
psychologists love to put rats in mazes
as we all know this is the maze this is
the t- maze we're going to place a robot
in the te- Maze but imagine we put a rat
in the te- Maze instead we put the rat
in the base of the tea the rat starts
wandering around and if it wanders far
enough up the stem of the tea suddenly a
light will flash either from uh through
the wall to the right of the rat or a
light will flash through the wall to the
left of the Rat and then the light will
blink off
again if the rat continues to wander up
into the junction of the tea and turns
in the direction in which it had seen
the light there's going to be a piece of
lovely cheese waiting for it on that
side and sure enough if you do this
experiment with rats long enough and
randomly Flash the light on the right or
the left over and over and over again
the rat will tend to stop turning left
or right with 50% chance at the junction
it will tend to turn in the direction in
which it saw the light from which you
can conclude that the rat is capable of
memory it remembers on which side it saw
the light and when it gets to the
junction it knows I should turn in that
direction and get the cheese we can uh
throw away the rat and take organism X
and do the same experiment and over time
if organism X or species X starts to
turn in the right direction more often
than not we can conclude that that
particular species is capable of
memory make sense seems great right it's
a test of memory or whether you can
learn to hold use short-term memory
thinking about thinking
is difficult dangerous this experiment
is flawed you do not need to remember in
order to solve the
te-as you were all students of embodied
cognition how if we put you in the Maze
and you hadn't had your morning coffee
and you didn't feel like trying to
remember which side you saw the light
on there's an easier way to Sol this
task fantastic it took you all less than
60 seconds to see the flaw in this 100y
old psychology experiment right the
minute you start thinking about the body
or the interaction of the body with the
environment suddenly this becomes
trivial I see the light and I learn or I
discover that if I just touch the wall
where I saw the light and then I just
keep going I don't need to remember
where I Saw the Light When I get to the
junction whichever wall I'm holding on
to I turn in that direction so they're
going to evolve this keera robot with a
little neural controller inside that
connects the 10 sensors to the two
Motors they're going to evolve it to
solve the teamas and if they put some
recurrent Connections in here maybe the
evolutionary algorithm will evolve
memory for the robot or maybe evolution
will ReDiscover this solution yeah
there's multiple ways to solve this task
okay so we're going to evolve the robot
to do this we know the robot we know the
sensors we know the motors wire them up
we now need a fitness function so we're
going to create a fitness function as
follows every time we drop a robot with
a given neural controller into the base
of the te-as we let it run around in the
te-as in simulation for 10 seconds and
then at the end of the 10 seconds we
measure D1 and D2 D1 how far did it
travel up the stem of the t- Maze We
want to obviously reward robots for
traveling up the stem if they stay at
the uh if they stay at the base of the
tea that's no good we also want to
evolve them when they get to the
junction to move uh along either to the
left or the right so we're going to also
reward for d two which is the amount uh
of distance they travel either in the
upper right part of the T or the upper
left part of the
T so basically reward for travel and
then they get an extra 100 points if the
robot happened to turn in the right
direction at the junction pretty
straightforward right okay we have a
population of random neural controllers
we drop each neural controller onto our
simul ated robot in the t- multiple
times and for each neural controller we
drop it into the simulated robot
multiple times and randomly Flash the
light at the left or the right and sum
up this term sum up this equation for
multiple evaluations of the same neural
controller that's the fitness of that
controller run our evolutionary
algorithm delete neural controllers with
low Fitness make randomly modified
copies of the surviving
controllers and you can imagine it
doesn't take very long to evolve a
neural controller for the simulated Kea
robot to solve the te-as I now give you
the physical Kea robot you download your
most fit neural controller onto that
physical Kea I give you a physical
tze what do you think the chances are
that that physical Kea is going to do
the right
thing we wouldn't be talking about this
if it did the right thing usually it
doesn't okay so the hard part here is
not formulating the fitness function
making the simulator coming up with a
good way to evolve weights and all the
rest of it it's how do we ensure that it
evolves to solve the task yet doesn't
glom on to any details of our simulator
that are
incorrect so they're going to start to
sprinkle noise into this situation
here's the first strong hint about what
they're going to do they're not even
going to simulate a tze they're going to
simulate the stem of the te in phase one
and if any given neural controller
drives the robot sufficiently high up
the stem of the te they're going to
teleport the robot into the center of
the intersection and then measure
D2 they are not simulating the
intersection itself why
not it just hug the wall it could hug
the wall but that's perfectly valid here
hugging the simulated wall and hug
hugging the real wall perfectly valid
the walls might be slightly different in
reality that's okay the friction if it
does touch the wall and assuming we
simulate a wall with a little bit of
friction that friction or the
interaction with the wall would probably
go in the base set the walls are going
to exist in simulation and reality
what detail of this environment is
probably going to be very very very
different between simulation and
reality the fact that they're not
simulating the intersection at all is a
strong hint there's something about the
intersection that is particularly
problematic particularly inacurate
Rob not necessarily no as the robot
travels up the stem of the simulated or
real teamas the intersection is
approaching in simulation and
reality is it the Gap in time between l
a light and like because it just
teleports to the center it'll po
immediately or something uh no not
necessarily so we're we're going to if
the robot uh if the robot has large D1
or a particular controller achieves High
D1 that controller is driving the robot
all the way up the stem of the tea past
the light it's seen the light the light
is turned off all good then it
teleports
it it could be we're getting close right
something about the geometry of the tze
relative to the
robot no okay okay we'll come back to
that then okay let's talk about the
simulation itself I I kind of mentioned
the t- this is three years before
physics engines were existed the
simulator in this case is an Excel
spreadsheet it's a lookup table sounds
crazy right turns out you can do it here
we go this is about as minimal as you
can get this is the simplest simulator
you're going to see in this entire
course there are two tables in this
Excel spreadsheet did Excel even exist
back then I guess so anyways okay table
one uh it's basically a lookup table so
in that lookup table we take um we take
the robot's
orientation what angle is the robot
currently facing so you can imagine 360
rows in this lookup table one for each
angle that the robot could be at uh each
each degree of orientation that the
robot could be at which is visualized by
these arrows here and we take the forces
arriving at the two motor neurons
remember this neural controller has two
motor neurons that's trying to send
torque to turn the wheels there's no
simulated wheels so what do you do with
the motor neurons
if both motor neurons are firing with
positive values that's the motor neurons
trying to spin both Wheels forward and
move the robot
forward you could have one motor neuron
firing with a negative value and with
the second motor neuron firing with a
positive number and that's the neural
controller trying to spin the left wheel
back and the right wheel forward so
we've got these 360 rows we can imagine
actually many more than 360 rows where
we have now three columns we have the
angle the robot is facing the value of
the first motor neuron and the value of
the second motor
neuron the motor neuron values are
floating Point values so we could have
an infinite number of rows so let's
discretize this a little
bit so basically we're going to this
table and we have our neural controller
we know the current angle of the robot
we know what the two values are that
have just arrived at the motor the two
motor neurons we go look up those three
numbers in table
one and there are two additional columns
the fourth and the fifth column in this
lookup table that indicate the new X and
Y of the
robot everybody see
that seems kind of strange but a very
simple way to do things so in this
lookup table they basically ran a
physical Kea around for a little bit at
random and measured the the orientation
of the robot and the values arriving at
the two motor neurons of the physical
Kea and just wrote that out into a table
so these are sort of lookup table
snapshots of the robot's physical uh
experiences table two a little bit
trickier given the robot's orientation
again its current angle in degrees Theta
and its distance from a wall whatever
the close the wall is that it's facing
when the robot is in the t- Maze no
matter what its orientation is it's
always facing a wall
somehow look up the robot's current
orientation and its current distance
from its closer closest
wall and the third and final column in
this SE table is time the time it takes
for an infrared uh signal to go out and
come back from that robot at that
orientation that far from the wall so
table two is basically containing a
simulation of the sensors table one is
containing a simulation of how the
physical robot might
move make
sense okay so we're running on a
computer we're running the neural
controller we set the the the values of
the sensor neurons according to table
two propagate the sensor neuron values
through to the motor neurons take the
motor neuron values and the state of the
simulated robot look up the new position
of the robot update the X and Y and
orientation of the robot look up its new
sensor values plug them back into the
neural controller and around and around
you
go the neural controller running on your
simulated robot that neural controller
is affecting the robot uh robots
interaction with the physics engine
which changes the input neurons in this
case same thing we're evolving neural
controllers but these neural controllers
are talking to or interacting with an
Excel
spreadsheet everybody see that okay so
when I we were talking about a simulated
tze there there isn't really a simulated
teamas there's just these tables there's
one third table which is about the light
sensor but it's more or less the same
the same
thing okay okay given all of that
information why do they not simulate why
do they teleport the robot when it the
when it enters the intersection of the
t-
maze what is it about this simulator
these tables that you can particularly
not
trust a lot of the DAT all of the data
sitting in these two tables it all came
from the physical robot but some of the
some of the data sitting in these tables
is more trustworthy than
others which data do you trust the
least
if the robot is here sitting in here
it's got its eight infrared sensors
those eight infrared sensors are sending
out signals into this environment and
we're trying to measure the time at
which those signals come back forget
about it very very tricky particularly
unreliable if the robot happens to be
sitting right here and it's actually
facing the wall we've got the
orientation of the robot uh facing the
wall and
Dy Dy here is very small the robot is
very close to the wall and it sends out
an infrared signal directly into the
wall we contrust that signal it's going
to be short and if the physical robot
does that 100 a thousand times we're
going to get more or less the same time
interval back very trustworthy if the
robot is sitting in a more complicated
environment a junction or it's facing a
piece of black cloth we can execute we
can record from the infrared sensor over
and over again and even if the robot is
still or maybe just moving a little bit
the values coming back are going to be
very very different super super
difficult to simulate these sensors when
the robot is inside the
junction so when the robot is inside the
junction I'm going to just skip ahead
for a moment when the robot is inside
the T Junction we're going to add 100%
noise at that moment when D1 is high the
robot is near the junction but the
junction it hasn't even entered the
junction yet there is no Junction
there's just this lookup table or D2 is
very low it's just entered the
junction that neural controller is still
running that neural controller still
needs values for its input
neurons for its input neurons we send in
completely random
numbers you can imagine the robots
driven into the junction and we start
dropping mirrors and cloth into the
intersection we're completely bedazzling
the robot it can't trust it's completely
disoriented when it enters the junction
we're simul ating that by returning from
this lookup table not the values in the
lookup table but completely random
values right you've been inside all day
wearing sunglasses you go out at noon
and suddenly take off your sunglasses
you're disoriented you can't really
trust your perception for a few seconds
until things settle down that's what
they're doing to the robot that's the
implementation
set make sense
okay I see a few puzzled glares any
questions before we push
on
yes great question okay so what exactly
is it about the junction that's so
problematic as you're going to see in a
moment they're going to actually
transfer this to reality so imagine a
physical teamas let's say we're were
researchers we made this out of
cardboard we cut a little hole in the
cardboard for the light to go through
the robot happens to be uh sitting right
here it's about to enter the junction
and it's its infrared sensor sends out a
a signal in this
direction maybe this outgoing infrared
pulse happens to graze the inner corner
of the cardboard and gets a little bit
corrupted maybe yes maybe no maybe it
doesn't hit the corner and keeps going
we made this thing out of cardboard out
of corrugated cardboard so maybe the
forward-facing piece of the cardboard is
completely uh flat but just behind that
that piece of the front of the cardboard
there's a little bit of corrugation
inside the cardboard it's a little
denser or a little less dense that
messes up an infrared pulse it's going
to reflect or or disperse in some Str
strange way maybe there's some dust in
there or there's the logo of the company
on the cardboard it's a little bit
darker it's a little bit lighter there's
a gazillion things that can go wrong
some of those things can also go wrong
in other parts of the maze as well but
things get really hard in here the
geometry gets a little more complicated
let's not even bother let's just
completely bedazzle the robot when it's
in the
junction so that from Evolution's
perspective
the evolution should just assume don't
rely on your sensors at all when you're
hear when you get to hear or and or you
magically are transported to
hear what does that mean what does that
mean for evolution to say it can't rely
on its
sensors to decision
based it has to real has to just do
blind Reckoning right you're stumbling
in the middle of the night to go use use
the restroom you know the layout of your
room you kind of just do everything from
rot memory and hope for the hope for the
best right your sensors aren't working
you can do it right this robot can do it
presumably hopefully that means that
when they take this physical robot and
drop it in the physical teamas there's
something about the leadup to this it's
the robot remembers that it Saw The
Light pulse about 3 seconds earlier and
the robot remembers that it's been
turning its wheels for 3 seconds since
it Saw The Light okay okay okay I should
now stop relying on my sensors and turn
either left or right and then go
straight that's in essence what we're
hoping Evolution does make sense okay as
mentioned there might be other things
about the physical Taz that are also
unreliable so they're also going to add
a little bit of noise to the Bas set
these are physical features of the
simulator the lookup tables that had
probably has some correspondence in
reality for example how does the robot
move in response to its motor signals so
in table one whenever the neural
controller look is trying to figure out
the new position of the robot this table
sends back the new X and Y position of
the robot and it randomly Alters X and Y
by a small amount by about 10% yeah okay
so that's true as the robot is driving
around its Motors aren't perfect maybe
there's a little Pebble on one of its
wheels so that it bumps a little bit as
it's driving along probably a safe
bet okay how the infrared sensors
respond in the stem or in the top of the
t- maze again maybe there's a company
logo on the cardboard so don't trust the
the time of reflection of the infrared
pulse by too much just by a little bit
and keep going okay how the ambient
light sensors respond add a little bit
of noise to the light sensors and we'll
see how things go so far so good
okay additional things that they also
modified so these uh this researcher set
a good precedent by saying be paranoid
like a good coder assume that everything
can possibly go wrong in reality so
every time they ran the robot through
this simulator they altered the side
from which the light comes this is an
important thing for the experiment
itself Flash from the left Flash from
the right the width of the corridor the
starting orientation of the robot in the
base of the t- is it pointing up and to
the left up and to the left in the tze
is it pointing up and to the right in
the tze they're varying everything the
length of the light zone how big is this
little window through which we Flash the
light the length of the
corridor when I say they varied all
these things what they ultimately did is
went back to those three lookup tables
the lookup table for movement the lookup
table for the IR sensors the lookup
table for the light sensors and they
modified things that simulated varying
these aspects of the robot in
reality so far so good
okay
okay question when do you like when do
you decide that you're like changing
enough versus that you're like changing
too many things that
like because if you change too many
things it's going to not move but if
youve changed all these things how do
you know which one
like no one has a good answer to that
question yet right how do you know when
you varied things too much you
definitely know when you varied things
too much because Evolution will not be
able to make any progress it'll evolve a
it'll evolve controllers will continue
to cause the robot to move around
randomly in the base of the Tas right
that's Evolution saying you keep
changing too many things I just don't
know what to do I don't know how to
evolve a neural controller to even
increase D1 let alone D2 or go after the
cheese so you tuned down noise and
suddenly Evolution starts to make
progress from one generation to the next
neural controllers start to evolve that
get bigger values of D1 D2 the
controllers tend to get the cheese more
often than not but maybe you've put too
little noise and will'll fail to cross
the reality Gap we're back to this uh
we're back to this Goldilocks problem
right not too little not too much but
how do you
know the answer here is they don't know
this is what they did and they managed
to evolve a controller that evolved the
ability to always turn at the top of the
teamas in the direction in which it saw
the light so what did the investigators
do cross fingers hope for the best we'll
see the result in a
moment let's have a look at the evolved
controllers looks pretty familiar from
what we've seen before here's 1 2 3 4 5
6 78 here's the eight infrared sensors
here's the one two light
sensors they impose bilateral symmetry
so they only evolved weights for the
left synapses and whatever the values
were for the left sens uh synapses they
copied those values onto the right
synapses right we've seen this before
generally speaking bilateral symmetry is
a good thing we all know that don't
Evolution doesn't have to reinvent rent
reinvent it just give it to her but
she's got to figure out which weights to
assign to these uh synapses you'll
notice that some of the synapses are
inhibitory those are the ones with white
arrow heads some of these synapses
evolved to be excitatory these are the
ones with
black uh arrow heads you'll notice that
there are some recurrent connections and
self
connections what you're looking at here
is a visualization of the most most fit
neural controller in the minimal
simulation this neural controller caused
the robot to always get the cheese no
matter which side they flashed the light
from did this neural controller evolve
to cause the robot to fall hug the wall
when it sees the light or did this
neural controller evolve to remember
where the light was and turn in that
direction when it gets to the junction
or when it gets teleported into the top
of the
te not easy to tell but you've had a few
tries at
this any hints you see here one way or
the
other uh the um two front sensors
they're they have uh they're connected
to the L the opposite left and right
motor so like if you see on the left
side the right one will spin faster so
it'll go that direction like it's
hugging the wall That's so you see that
there is an an ipsilateral connection
going from the front left infrared
sensor to the right motor and there
should be the same thing on the other
side there it is but these are the
Infrared sensors these are just the
proximity sensors the robot can only see
the light from this sensor and from this
sensor tricky light sensors like inhibit
each other ah there's a very strong hint
yeah and then they
inhibit
oppos
director yes so some good observations
in there it's a little bit strange we
see an outgoing we see outgoing synapses
that are outgoing from sensor neurons
inating or connecting to other uh sensor
neurons it's a little confusing you can
basically think of these black circles
as hidden neurons that are connected to
the the sensors little confusing you
mentioned that the two light sensors are
mutually inhibiting one another it turns
out that they didn't build this in this
is something that evolved and it is
ubiquitous in us as well there are many
many neurons and clusters of neurons in
your head and in your spine and
throughout your body that mutually
inhibit one another this is one of the
greatest hacks Mother Nature has ever
come up with and she's come up with some
amazing hacks what does mutual
inhibition
do it's often hard to see but in this
minimal
experiment it makes
sense remember when we talked about
brenberg vehicles and we kind of
mentally simulated these neural control
rollers in our head if this light sensor
fires then it it excites it
inhibits what's going on
here is it like it's focusing on that
like cutting out all other inputs it's
cutting out it's inhibiting everything
else so let's imagine this neural
controller is sitting inside the
simulated robot it starts to drive up
the stem of the tea and we Flash the
light from the right bam ambient uh this
particular sens sensor neuron uh obtains
a very high positive number and there's
a little bit of light that also falls
across the robot's body onto the other
light sensor as well but less at this
moment in time at which the right hand
light is flashing on the robot this
ambient light sensor is firing more
strongly than this ambient light sensor
and then click the light goes off what
happens
could it be one that didn't see it
becomes negative the one that doesn't
see it becomes negative becomes more
negative why well it's because the one
that saw it is inhibiting it so then
that one becomes negative and so then it
not inhibits like all the way around Mak
one more S one positive correct so this
is a tricky thing about neuroscience and
neural networks right it's a double
inhibition we've got two things that are
inhibiting one another but at a given
point in time the right hand light
sensor is stronger which means it's more
strongly inhibiting the other one so at
the moment that the light is on the the
the delta or the difference in values of
these two light sensors may be slight
they're both High because the light is
on one is a little bit stronger than the
other starts to push down this one this
one is also inhibiting this one but its
value is dropping so it's in its ability
to inhibit this one is decreasing and so
as the light switches
off this happens one goes to its maximum
positive value and the other drops to
its maximum negative value and the robot
keeps
driving what's happened what is this
Mutual inhibition done for the robot
memory memory it's remembering yeah okay
so it may or may not also be hugging the
wall or exploiting some aspect of its
interaction with the tze but this one is
definitely has evolved to remember on
which side it Saw The Light okay not
really important for the reality Gap
discussion today but just to reinforce
this idea of what's going on in the
heads of these
robots okay here we we go all this build
up for this I'm going to turn off the
light for a
moment okay here we go 1997 no fancy
cameras this is the best we get no
YouTube videos what's
happening it's doing pretty well it's
doing pretty well right that should be
the first obvious thing they stuck a
little uh a little LED on top of the
robot and they shielded that led so that
the ambient light sensors couldn't see
it it was just for the camera person
from above what else what other
observations can you take away from this
attempt to cross the reality
Gap it doesn't seem to be hugging the
wall it doesn't seem to be hugging the
wall so if it's exploiting its
interaction with the environment it's
subtle it's something that's beyond us
to see it may or may
not it's definitely remembering as we
just saw what else is going
on someone else almost looks like
it's wall yep so it's exactly remember
that when it gets into the intersection
it's probably kind of it's the neural
controller is not relying on its current
sensory information how this neural
controller evolve to ignore the incoming
sensory information in those situations
that's tricky and complex you'll just
have to trust me there's a way that
neural controllers can do this in the
same way that they can remember things
they can also inhibit or ignore their
current sensory information and drive
their Motors just from internal
memory so the again this is like us
stumbling around in the middle of the
night right they go a little bit too far
but then they still manage to remember
enough to know in which direction to
turn in fact they remembered which they
know which direction to turn in in every
case at least all the ones that the
investigators reported what else is
happening what else did they test here
the investigators different starting
different starting positions so you can
see down here they tested the robot in
this t- maze starting from two different
initial
positions and at two different
orientations and even though they were
varying the initial conditions of the
physical robot it's in all of those
cases this evolved neural controller
could handle
it C crazy simple robot crazy simple
experiment but this feels like a pretty
trustworthy robot it doesn't guarantee
that there isn't some teamas and some
situation in which it's going to go
Haywire but pretty good what else did
the investigators do on the other side
of the reality Gap
here absolutely remember in simulation
they were V among other things they were
varying the width of the Tas so they
wanted to to test that in reality did
that altering the width make this neural
controller robust to the width of the
Maze and the answer is
yes any other
observations they they reset it every
time right so every time it gets the
cheese they take it and put it back at
the bottom of the stem of the
teamas
okay okay doesn't look like much but
this was the beginning of at least in
I'm going to turn the light back on in
the case of a simple robot you can cross
the Gap it's not the Gap is can be large
but it's not infinite there are ways to
train or design robots and simulation
that transfer to reality so everyone got
very excited about this experiment when
it came out and I was just starting as a
master student in this lab at Sussex
when this all started there was a lot of
excitement that it was possible
if only we could have better simulators
than these bloody lookup tables this is
ridiculous this isn't going to get us
very far in 1999 in the UK a games
company visited some of the roboticists
at Sussex and said hey we're making
these new things called physics engines
would they be of any use to you and we
all said oh my gosh yes thank thank
goodness for this so the rest of what
we're going to see in this section and
as we've already seen in most of this
course we're going to now look at
physics engines we've got 8 minutes left
so we'll start in on the second attempt
to cross the reality Gap in 1997 we
learned that okay you can sprinkle noise
but you got to know what to sprinkle
noise on okay okay all right still not a
very satisfying answer can we do better
can we automate things
more in 20003 years later there was a
publication in nature magazine of a
second attempt to cross the reality Gap
and this got quite a bit of media
tension it ended up on the front page of
the New York Times in August and the
scientist uh the rep the journalists
reported that scientists had made the
first robot that makes its own robots
right here we go Terminators coming it's
the end of the world great science
journalism on the front page of the New
York Times
obviously crossing the reality Gap isn't
something that's going to make it onto
the front page of the New York Times the
way in which these researchers attempted
to cross the reality Gap made use of a
new technology that excited and scared
the hell out of a lot of
people it wasn't a physics engine
although that was also new in this
experiment there was one other thing
that was new in this
experiment that scared the hell out of
everybody any
ideas here's the physical robot all the
white parts of the robot that you see
here are made from thermoplastic it's a
particular type of plastic that has a
very low melting point so in 2000 there
were also manufacturing firms that were
starting to make these new things called
3D printers they they came to see these
researchers at the time and said do you
have any use for these 3D printers and
these researchers said you know what if
it's difficult to cross the reality Gap
we evolve something in simulation and
transfer it to reality and it doesn't
work okay maybe we can't always
guarantee that everything will cross the
Gap but if we make or evolve a whole
bunch of things in simulation and make
not just one robot but hundreds or
thousands of millions of robots some of
them presumably by chance will cross the
reality Gap
but who wants to sit down and manually
build hundreds or thousands or millions
of robots wouldn't it be great if there
was a machine a robot that could make
robots
automatically so what became known as
the Golem project was an attempt to
cross the reality Gap by bringing
together two new technologies evolve
robots in physics engines evolve lots of
robots in physics engines and then print
a whole bunch of them in reality with
the hope that some will cross the Gap
okay again the the SC the reporters were
referring to robots making robots which
is a topic we will actually come back to
later in this course where we're going
to look at self-replicating machines
this is an idea that was actually
formulated by John Von noyman uh just
after the second world war we'll talk
about that in a moment this is the what
you're going to see at the moment are
not self-replicating machines at least
not yet you're going to see 3D printers
that make robots not robots that make
robots Okay so this experiment this
attempt to cross the reality Gap this
experiment is made up of three different
Steps step number one evolve a robot not
a robot
controller several things that are new
in this experiment the first one is that
they're evolving not just the brain of
the robot but they're also olving the
body of the robot uh we're approaching
the end of this course as we continue on
you're going to see more and more
experiments in which the investigators
are going to broaden The evolutionary
algorithm so now it's not just
optimizing synaptic weights for a fixed
neural controller for a fixed robot it's
going to The evolutionary algorithm is
going to start to Tinker with body and
brain uh simultaneously here's we're
going to see an example of that
here once they evolve the body and brain
of a virtual robot send that body and
brain to a 3D printer which will
manufacture the robot and then step
three in 2000 these 3D printers could
only print plastic so we could only
manufacture parts of the robot and then
we're going to manually snap in all the
parts that 3D printers at that time
could not print which were Motors and
electronics okay our focus of course is
on step one here how did they actually
evolve these robots they evolve these
robots with an evolutionary algorithm
we've seen many here's another one in
this case the genotype is uh a list
that's made up of four lists this is the
blueprint the blueprint is a list of
four
lists the first list is a list of
vertices it's a list of
triplets where those triplets
specify the links or the parts of the
robot each ball here has an X Y and Z
coordinate in three-dimensional space
mutations in this evolutionary algorithm
can add triplets or remove triplets from
this list so we can add or remove parts
to the robot's body the second list is a
list of one two three four quadruplets
or four
tupal each four tupal describes a bar a
bar connects some vertex of the robot to
some other ver vertex that makes up the
robot and we have a relaxed length and a
stiffness for that
bar that language should sound familiar
where have we heard that language
before there's a spring so you don't see
the spring in this picture but you can
imagine that every bar connects a pair
of vertices together we cut each bar in
half and stick a spring in the Middle
with a given relaxed length and a given
stick
so far so good okay so these first two
lists tell us how to build the body of
robot the second two lists tell us how
to build the brain of the
robot the second uh the second or sorry
the the third list here is a list of
neurons in that list if there are n
entries in that list there are n neurons
inside that robot each the description
of each neuron there's a threshold
associated with each neuron that should
also sound familiar threshold of
what what do we threshold in a
neuron activation the activation
function right so as always the neuron
is getting some raw weighted sum and
then we're going to threshold it somehow
an evolution is going to set that
threshold and every neuron is followed
by a list of synapse coefficients this
is a synonym for synaptic weights every
neuron is going to send out synapses
that connect to every other neuron in
the neurons list so we end up with a
fully connected neural network like you
see here we've got one minute left the
fourth and final list is a list of
actuators each actuator is described by
three numbers the first number indicates
which bar uh which bar is the neuron
attached to and which is the actuator
attached to and which neuron does it
attach to so an actuator is connecting a
neuron to a
bar which turns that neuron into a motor
neuron that's sending a value to the
spring inside that bar and that value is
going to tell the motor inside that
spring whether to extend that string
that spring or compress that spring we
have a genotype that encodes the body
and brain of a robot we'll pause there
for today you have a quiz due tonight
undergrads your working on assignment 10
grads you're waiting for me to drop D5
which I will do at 3M thank you


--- Evolutionary Robotics course. Lecture 19： The GOLEM project..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone uh let's get
started uh we are approaching the end at
least of the assignment streams so for
the
undergrads next Monday you will be
submitting your results for the 10th and
final assignment you're almost at the
end good news bad news it's not the end
it's the end of the beginning when you
finish assignment 10 you will have an
experimental platform that you can
complexify in pretty much any way you
want within reason uh and to elaborate
that into your final project and we will
talk about next Tuesday we will talk uh
about what that final project should
look like what the expectations are for
you as you're working on your final
project uh between next Tuesday and the
end of the semester for those taking uh
the course for graduate credit as I
mentioned I was running a few days ahead
of you creating the differentiable
assignments for you to do I fell a
little bit behind I didn't finish making
the differentiable assignment until
Tuesday so I pushed back this submission
deadline for those taking it for
graduate credit so you all can submit T5
by 11:59 p.m. next Tuesday rather than
next Monday and then grads you're also
tackling the final project and we'll
talk about expectations for the grad
students uh as it relates to the final
project next Tuesday so we're almost
there we'll pivot next week all good any
questions about this final
mile terms of assignments question um
for the undergrad assignment is that
like I I just is that like a pretty big
assignment like TimeWise yes it is a
pretty big assignment TimeWise it's not
the most intellectually challenging of
all the assignments it's basically
ripping out this minimal Rob b nine nine
links eight joints relative absolute
coordinates joint normals there's a lot
of finicky pieces so leave yourself time
to work on assignment 10 and as I
mentioned last time don't race do
everything in baby steps add one link
one joint at a time debug everything
make every make sure everything is
literally in the right place and moving
in the right way before you add the next
piece to the
quadruped okay any other questions
okay so back to our lecture material we
are in this module on looking at open
challenges in the field these are major
challenges that are keeping evolutionary
robotics from designing a dishwasher uh
cleaning up robots and snowblowing
robots for us and all the rest where are
all the robots they're not here at least
in terms of evolutionary robotics
because there's a number of problems we
got to solve first um most of these
problems are known there are partial
solution solutions that have been
formulated in the literature and we've
started to look at some of these and we
started in last time on uh looking at
some of the potential solutions to the
most challenging problem not just in
evolutionary robotics but robotics in
general crossing the reality Gap there
are many attempts to cross the reality
Gap in the literature I picked four
representative examples we looked at the
first one last time it's got a fancy
name but a relatively simple idea
sprinkle noise into the simulator so
that when uh the artificial when The
evolutionary algorithm simulates robots
over and over again The evolutionary
algorithm never steps into the same
river twice which heraclitus said 2,000
years ago right everything is always
kind of changing so the evolutionary
process can't exploit artifacts in the
simulation that are not real in reality
works okay but that solution in turn has
some problems are some open challenges
which is where do you put noise how much
noise do you put and so on so a solution
but a partial
solution last time we started to look at
the Golem project which is a completely
different way to attack the reality Gap
problem what's the overall intuition
behind the Golem project that we
introduced last
time did we look at it last time I
mentioned men it last
time divers is like having many examples
variation absolutely you shoot an arrow
at the Target and you miss the
bullseye shoot another arrow and another
and another and another until you
eventually get lucky okay so that's the
idea behind the Golem project which was
reported in the literature in 2000 and
ended up on the New York Times the next
day basic idea is we're going to use
this brand new technology at the time
which was a 3D printer to evolve robots
as we've seen many times in this course
now and then hook up the simulator to a
3D printer and have and basically reduce
the time and effort it takes us to
actually manufacture one of our
simulated robots and if we do enough
automated design by Evolution and
automated manufacturer by 3D printers we
can design manufacturer design
manufacturer and if a lot of those
robots don't CR cross the Gap who cares
we keep going until we get one that does
that's the intuition underneath the
Golem project yeah okay we ended last
time by starting to walk through uh
exactly how the Golem project works it's
broken this experiment is broken up into
three phases first phase is going to
look very familiar to us we're going to
evolve a robot to locomote in
simulation uh and then step two we're
going to manufacture the robot with a 3D
printer step three at that time we
couldn't print all the parts of a robot
so there's still a manual part to the
manufacturing process okay something
that was kind of new that we saw last
time is that when the Golem
researchers evolved their robots in
simulation they were not just evolving
sets of synaptic weights
for a manually designed robot with a
manually designed cognitive architecture
inside they're broadening The
evolutionary algorithm and they do that
by modifying the data structure that
encodes the genotype they've got a more
complicated data structure here where
this data structure is now a blueprint
dictating how to build the brain and the
body of the robot yeah and we were
walking through this data structure last
time so top Lev a genotype is made up of
four variable length lists in your case
you have one single Vector which is the
set of all synaptic weights here we've
got uh four variable length lists as the
names imply uh the first list encodes a
set of vertices which become the points
uh that you see in the robot here the
next list is a whole bunch of bars that
connect pairs of points together the
third list is a whole bunch of neurons
in this cartoon example here this
particular genotype is specifying this
phenotype down here phenotype is now not
just the brain of the robot but the body
as well the phenotype in this cartoon
example has five neurons inside and you
can see that each of the five neurons
has a synapse connecting it to every
other uh neuron and you can see that in
the description of a single neuron down
here one element in the neurons list we
have a threshold for the activation
function of that neuron and then inside
this list is another list which is the
synapse coefficients or the synaptic
weights so this genotype is a little
confusing it's a whole bunch of lists
embedded in lists embedded in lists
hopefully you get the idea yeah okay the
last piece that we ended with last time
the fourth and final list is a list that
specifies all the actuators that make up
the robot these are slightly different
actuators from what you've seen before
an individual a description of an
individual actuator that description
specifies some bar inside the body of
the robot so we pick a bar it also
specifies a neuron so we have we're
holding on to a bar we we uh find the
neuron that's being specified let's
imagine it's this neuron here we're
going to the actuator takes the value
arriving at this neuron and sends it to
the actuator that's going to be embedded
in this bar so the minute an actuator
points to a neuron that neuron becomes a
motor
neuron okay question so um how do the
actuators move how do the actuators move
exactly okay there's a hint here which
is the third and final number that
describes an actuator is the bar range
again it's kind of cryptic but it might
give you a hint so what do you think is
going on here in terms of the
actuator we're embedding an actuator in
a bar not maybe where you might expect
which is up here we're not dealing with
rotational motorized joints which you've
been dealing with in all the assignments
something
different piston shape to it that's is
the length of the Piston the length of
the Piston what is the maximum and
minimum length of the bar that can be
achieved by a piston that's going to sit
inside the bar so you can imagine that
as you walk as you walk along the
actuators list that actuators list is
going to contain a bunch of these things
each one points to a particular bar and
every time an actuator points to a bar
imagine we cut that bar in half pull it
apart a little bit stick a piston into
into it and then connect a neuron to the
Piston imagine that neuron at a given
point in time is containing a positive
floating point value what do you think
that motor neuron is telling the Piston
to
do expand if that motor neuron is
encoding a negative floating Point
number at a given point in time it's
telling the Piston to
pull got
it okay so that's it we've got a
genotype which tells us how to construct
the body and brain of a robot we've got
our phenotype here we do what we
normally do drop it into a physics
engine which was brand new back in 2000
and assign a fitness value to how well
that robot moves from left to right
along the virtual floor in this in the
physics engine exactly like we've seen
before okay so let's talk a little bit
about the evolutionary uh algorithm they
start with an initial popul
not of random genotypes you could
imagine just creating a whole bunch of
random uh lists with random floating
Point values in it and that would
construct some random morphology and
some random neural network they didn't
do that in this experiment they created
a population of 200 genotypes and each
genotype is
null null meaning it's an empty list of
empty lists of empty lists there's
nothing in the genotype kind of an odd
choice so we know by definition that
each of the 200 phenotypes of those
robots are null phenotypes they're all
going to get a fitness of zero they
don't even create a robot that moves at
all kind of a strange Choice we'll come
back to that in a moment Fitness this is
very familiar displacement of the center
of mass how many time steps do they
evaluate the simulation for if you go
and read the paper it doesn't give you
number of time steps it says fixed
number and that fixed number was 12 of
cycles of the neural control this sounds
kind of cryptic again but we've seen so
it should give you a hint about what the
neural control is doing what what does
12 Cycles mean or what could it
mean it's kind of like attempting 12
steps like if local motion is a cycle
okay if Locomotion is is a cycle this
thing is going to breathe 12 times the
motors are going to increase or the
Pistons are going to increase and
decrease but those Cycles are being
dictated by the brain by the neural
network and they said Cycles not of
locomotion but of the neural controller
itself is
it CES uh that's a good guess in in your
assignments it is right during each time
step if you have a 100 time steps St in
your simulation or a thousand time steps
in your simulation you're doing 100 or a
thousand sense think act Cycles it's a
good guess that's not what they mean uh
parameter updates parameter updates uh
par parameters of what weights uh it
could be but remember the weights are
ultimately going to be updated by the
genotype so we're just talking about
evaluating a single robot in a
simulation during the simulation during
your simulations the parameters of the
neural network the synaptic weights do
not change so another good guess this is
just evidence that they should have
worded this more
carefully do you mean like 12 Evolution
Cycles uh not quite no we're we're
inside the evolutionary algorithm we're
evaluating one robot in the physics
engine does the neural network have one
of those like pulse neurons in it it has
a pulse neuron inside which they don't
mention explicitly I know the authors
very well shame on them there's a cpg
sitting somewhere in here it's a cpg
neuron that is emitting a sinusoidal
pattern and they wait for that
sinusoidal as they're running the
physics engine and the time steps are
elapsing in the physics engine they let
that cpg emit 12 cycles and when it's
done repeat that sosal pattern is done
repeating 12 times they end the
simulation they measure how far the
robot has traveled in the simulator and
assign that single distance that single
floating point value to that robot and
its genotype um can that like pulse
evolve over time or is that like
constant every step it sounds it's a
good question again they didn't specify
but I would infer from this that it's
fixed that all the sinusoidal patterns
in every robot no matter what its body
or brain looks like has more or less the
same frequency I think
so far so good okay so some familiar
Concepts some new Concepts
here why did they start with a null
robot let's draw the null robot right
down here I've drawn nothing there's no
phenotype so the first generation the
first generation of this evolutionary
algorithm is kind of odd they're
stepping through each of these 200
genotypes there's nothing there so
there's no robot to create don't even
need to bother running a simulation you
assign a fitness of zero to all of these
200
genotypes how do you delete the ones
that have lower Fitness you can't
because everybody has exactly the same
Fitness zero flip a coin delete half of
them half of them survive and now we
start to make randomly modified copies
of the
survivors so far so good okay so
randomly modified copies they're going
to take these null genotypes that have
survived and they're going to start to
randomly modify them they're going to
apply mutations remember that in your
underlying code base at the moment you
have a fixed Vector of floating Point
numbers which specify the synaptic
weights for the neural controller for
your robot you have one and only one
mutation operator whenever that mutation
operator is called it picks some number
it picks some index in your vector and
then generates a random number and
sticks it into that element right one
and only one mutation operator in the
Golem project there are 1 2 3 4 5 6 7 8
nine 10 different mutation operators 10
different ways that the evolutionary
algorithm can take the genotype this
thing and make a random change to it
question the
I don't know I I don't see why they
couldn't have done that probably an
arbitrary
choice I think um in the original neat
paper they were arguing that you you
start with the simplest thing and you
add complexity only as it is Justified
seems like similar to what they're
trying to good point actually that's a
good point maybe they wanted to make
sure that they were starting with sort
of the simplest robot you could imagine
and then let Evolution gradually
complexify things if it's needed and
what's the simplest possible robot you
can
imagine the null robot just nothing okay
so we have these 100 surviving null
genotypes we're picking one at random
and that becomes the parent and we're
allowing it to cre create a child we're
going to copy that null genotype but
when we do we're going to roll a
10-sided dice we're going to pick one of
these 10 mutation operators at random
and whichever one we pick we're going to
let that mutation operator mutate that
null
genotype so far so good okay so here's a
cartoon showing a possible way this
might happen here's and all we're seeing
here are the phenotypes the B the bodies
and brains of this lineage of robots
we're starting with the first ancestor
which is a null
phenotype we roll a 10-sided Dy whatever
that Dy is we apply that mutation
operator which one turned this null
phenotype into a single bar with the
short
length out of these 10 which was the one
which is the the one that was
chosen which one turned this null
phenotype into this non-null phenotype
uh
three add a dangling Bar number three
add a add a dangling bar absolutely so
we've got a little bar here so this is
the child you take this little bar and
you drop it into the physics engine and
that little bar travels forward by
0.01 millimeters in the simulator it's
got a higher Fitness than its parent
kills off its parent and now it enjoys
the privilege of being able to produce
an off spring of its own which it does
it it whatever the genotype is for this
phenotype is copied and when we're
copying that genotype The evolutionary
algorithm again rolls a 10-sided
die and that mutation causes the child
to look like this which mutation
operator uh was applied to the
grandchild number one change the length
of the bar everybody get it okay
question what are the percentages
account for like that doesn't add up to
100% 20 21 22 23
24 25 26 27 28 29 30 you're right good
question uh I I'm imagining that's a
typo it should add up to
100% okay next one what what turned this
into this
one so we lengthened the bar now there's
a red circle what's the red
circle is that a neuron it's a neuron y
five number five number five add
unconnected neuron so now this robot has
a brain but the brain is not inating the
body whatever the value is in this
neuron which is probably the cpg value
it's not affecting the behavior of the
robot are the percentages representing
the like percentage of times that those
options were selected or is it something
about like the impact of them on
Evolution uh more the former so I I
mentioned a 10-sided die which assumes
that it's a uniform probability of
picking these 10 mutation operators it's
not imagine it's a weighted die this
should these percentages should have add
up to 100% And The investigators had
some intuition that some of these
mutation operators should be applied on
average more often than
not
why why not just leave everything as a
uniform probability distribution any of
these 10 could happen with equal
probability not everything should have
the same impact on the behavior of the
robot at the end some of these mutation
operators you can probably guess have a
bigger or smaller impact on the brain
and body of the robot and thus on how it
behaves in the simulator but if you do
that for the mutations why you start
from like a robot like you should make a
guess that that's probably like I take
extra computation to get to some point
Pro probably yes I I don't know it's
also balanced against them trying to
start with something simple because
again computation is expensive so they
want to start with a very small robot
very simple robot a lot of arbitrary
choices here I think in this
experiment okay how about this one to
this
one what mutation operator or operators
hit this genotype as it was being
copied that's length a bar lengthen the
bar number one yeah add a neuron and
also add a connection add a neur neur
and although there is it doesn't say
here every time we add a neuron all of
the other neurons that exist in the
brain connect to it yeah so it's always
an it's always a fully connected Network
every time we add an unconnected neuron
it doesn't stay unconnected for long
everything else attaches to it which
means we need new numbers in the
genotype we need to specify the
weights we need to specify the weights
of those connections that are arriving
at that neuron so they've got to
generate more random numbers so some of
the ways in which these mutation
operators are being carried out is sort
of implied but hopefully you get the
idea let's Jump Ahead to this one to
this one you'll notice something special
has happened here what's
happened body okay how so what mutation
operator caused that to happen
number nine attach neuron to Bar yeah so
we're going to attach this neuron to
this bar you'll notice this bar is now
cut in half which is a visualization of
the fact that this piston has been
placed in the midpoint of this bar so
we're adding an actuator and innervating
it with a synapse although the name of
the mutation operator kind of implies
that it doesn't say it
explicitly so far so good okay so you
could imagine somewhere else in this
initial population of null uh phenotypes
and genotypes another set of random
choices of mutation operators will
create robots with different bodies and
different
brands questions
okay okay I think we we worked our way
through this okay again I apologize for
the image quality here hopefully you can
see here are a whole bunch of samples of
the kinds of robot bodies that existed
partway through Evolution and we're
looking at not all 200 robots but just a
sampling of them they're partially
evolved so they move to the right a
little bit at this point in evolution
What observations can you draw from
what's going on in this particular
evolutionary run pyramids are cool
pyramids are cool why are pyramids
cool they are cool there's a reason why
they're stable yeah I'm I'm guessing
there doesn't need to be a lot of
coordination to get it to move in a
direction like two things can expand and
it'll push it whereas like a worm would
be harder to do absolutely right Mother
Nature is wonderful but she's also lazy
she's a satisficer we asked her to
design something that moves from left to
right using this kind of encoding of
genotypes and phenotypes turns out that
uh pyramids are cool they're a
relatively easy way to do things I was
going to ask does the sort of set of
mutations that you had on the previous
side does that makes it pretty difficult
to evolve a big brain right I don't know
does this particular choice of how to
encode the robots bias The evolutionary
algorithm to small brains big brains
small bodies big bodies remember our
discussion about hypernet last week
hypernet was designed several years
after this experiment to try and solve
this problem we actually want to
control where we focus Evolution's
attention we want to focus Evolution to
search the space of all symmetric
repeatable types of patterns no matter
what genotype and phenotype and coding
we pick whether we know it or not we're
biasing Evolution to search more more
intensely in certain parts of the space
of all possible robots than
others maybe we're biasing Evolution
towards towards pyramids maybe that's
the reason why we get pyramids in this
experiment not necessarily that they're
useful but that's where it tends to
focus its time are we focusing
evolutionary search on the subset of
robots that have small brands or big
brands
maybe yes maybe
no one thing that come to mind why
attaching of detaching the neurons to a
bars is one choice of the mutations and
it should not just as soon as a neur is
added you connect it to the Rob okay you
will have like some robs that are not
connected to then okay right so we could
decide we could make a change to the way
we map genotypes on to phenotype that
every time we create a neuron it's a
motor neuron and it's got to attach to
some part of the body that's also a
choice how is that going to bias
evolutionary search what kinds of robots
is the evolutionary algorithm going to
try generate more often than
not if we're using that kind of mutation
operator is it going to create robots
that are like
um they're not they don't have like a
very developed like Brain before like
they begin making impact on the robot
itself that that is true now whether
that's a good thing or a bad thing who
knows but that's right as the brain as
mutations start to elaborate the
cognitive architecture the number of
neurons and connectivity in the brain of
the robot every one of those neurons is
going to connect to some actuator in the
robot's body which is going to mean that
all of the bars are actuated or most of
them are going to be actuated which may
or may not be a good thing right it's
hard to say we could try it we could
alter the mutation operators run
Evolution again we're going to get
robots that have more Active Components
inside their body and maybe the
evolutionary algorithm can evolve
synaptic weights to coordinate that
motion or maybe that's too much too soon
it's not a The evolutionary algorithm is
not able to you could make an argument
either way so this is part of the reason
why a lot of these choices tend to be
arbitrary it's hard to know in advance
whether what you're putting into your
genotype and phenotype is going to make
things easier on the evolutionary
algorithm or harder on The evolutionary
algorithm it seems like the goal of this
is to evolve a body that doesn't really
require much coordination to to move I
don't know whether they planned that in
advance but that was a result of this
experiment that you as you'll see and
I'll place videos for you in a moment
you don't need much these robots don't
need much to get going to start
moving okay one of the things you can
take away from here is again there are
some common themes you tend to see a lot
of pyramids but also a fair bit of
diversity the bodies look kind of
different we haven't converged on one
and only one body plan you can infer
from this that if the bodies look
diverse the brains are also probably
divers verse as well there are probably
different brains in these robots with
more or less neurons so different
cognitive architectures different
synaptic weights in them that's usually
a good
thing here's this is a horizontal cut
through an evolving population so
evolution is running at some point they
paused Evolution and looked at all the
bodies and brains at that point in
evolutionary time sorry it's a vertical
cut here's a horizontal or longitudinal
cut
through the same evolutionary run it may
be hard to see in the back here but this
robot has a number four so they're
assigning a global counter they're just
keeping count of all the robots here's
robot number four here's robot number 60
number 82 117
117 down to
198 so here's some here's a fossil this
is from early in the evolutionary record
and here's an existing organism this is
something that exists
towards the end of The evolutionary
trial again it may be hard to see
there's some Fitness values assigned to
all of these f equals a lot of these f
equals are zero so these are not
necessarily good robots these f equals z
means the robot doesn't move at all some
of them have a nonzero value associated
with them some are moving some are not
they're just trying to take slices
through this evolving population to kind
of see what things look like
like
okay here was an attempt to try and do
this not in an anecdotal Way by just
looking at screenshots but to do this in
a quantitative manner if you've ever
taken a biology class you've probably
seen a picture that looks like this
before these are philogenetic trees
we've got usually a root up here
somewhere this is a common ancestor in
this example here this particular uh
robot uh existed in the population for
many many many
generations without producing any
Offspring so it actually survived
somehow at this point in evolutionary
time it produced One Two Three Offspring
and those Offspring in turn started to
produce a lot of Offspring and so on
different ways to there's many many
different ways to draw a philogenetic
tree the choice that the investigators
made here is to to draw evolutionary
time on the vertical axis so here's the
first generation and here's the last
generation down here usually we've been
drawing evolutionary time on the
horizontal axis where time uh unfolds as
we move to the right kind of an
arbitrary Choice the horizontal axis
represents ancestral
proximity what do you think they mean by
that like if if you have like the the
phenotype vectors it's like probably
like the distance between the two I I'm
sure it's there's a way to calculate
just like how close they are there is a
way to calculate how close they are it's
not based on the phenotype strictly
speaking you could take the phenotype
and measure the similarity of phenotype
the more similar they are the closer
they are horizontally the more different
their phenotypes the further away they
are horizontally you could absolutely
draw a philogenetic tree like that it's
not quite what they did is it like like
the performance it's not performance
good point actually nothing here has to
do with Fitness Fitness is not
visualized at all
here ancestral
proximity is it based on like number of
steps of evolution since they were the
same since they were the same so
brothers and sisters most of the time in
this picture should be drawn close to
one another horizontally first cousin
a little bit further apart horizontally
second cousins and so on it's not quite
true it's a little more complicated than
that because you can see there's one
parent up here and three siblings down
here these three siblings should be
drawn right next to one another
horizontally there's some other things
going on in the way they drew this but
generally speaking you get the ideas to
get a family tree you have the ancestor
at the top and then you have more and
more children
if that particular lineage or that
family is successful and is producing
highly fit children and grandchildren
and great grandchildren you see a lot of
these trees tapering off as branches of
this tree die out so let's just take
this little tree down here here was sort
of a cluster of the family A branch of
the family that for whatever reason got
some Fitness but not as much Fitness as
this branch of the family and this
branch of the family family eventually
outcompeted this branch of the family
that's why it's drawn in this way to
help you see those kinds of evolutionary
Dynamics going on okay so let's have a
look at oh and last thing I forgot to
mention is links themselves connect
parents to children okay first thing to
notice uh in this particular
evolutionary run they got Divergence so
they had way up here at the top one
ancestor this was probably uh the first
nonnull phenotype the first thing that
actually moved in the simulator It
produced one two three children way up
here at the top and all three of those
children were successful they started to
produce their own branches and by the
time we get down here to the end we have
uh we have familial
diversity meaning we've got some
brothers and sisters we've got some
first and second cousins we've got
second third cousins fourth fifth 6th
7th 17th 18th 22nd cousins we've got a
diversity of individuals that have to go
further or shorter back in time to find
a common ancestor that's good news right
that generally suggests you've got a lot
of diversity in the population 17th
cousins that have to go back 17
generations to find a common ancestor
they have probably diverged quite a bit
in terms of the makeup of their bodies
and brains so we've got a lot of
diverent phenotypic Divergence which
isn't being plotted directly we're
inferring it from the fact that we have
a lot of familial Divergence or variance
question convergence could mean that and
that happens in nature as well you have
individuals that have common ancestor
way way way back in evolutionary time
but evolutionary pressure is tending to
push everyone in the population to
towards one and only one solution
because there's one and only one way to
do things that that's actually also
possible maybe all of these things down
here seem diverse but if we actually
looked at them they're all pyramids
you'll have to trust me that that's not
the case in these experiments is that
like everything is evolving to become
crab everything is evolving to become a
crab right what is it Carino I forget
what the term carcin ajacent thank you I
can never say that term exactly right
turns out funnily enough there tends to
be certain ways to be in this world or
at least on this planet that are better
than others and the winner at the moment
seems to be crabs not not us crabs okay
good point thank you okay they reran The
evolutionary tape they started Evolution
all over again with a set of 200 null
genotypes and ran Evolution forward
again but now these null genotypes were
being hit with different mutation
operators and different sequences of
mutations that led at The evolutionary
uh scale to very different Dynamics here
we get convergence as was mentioned in
the back there we've got a whole bunch
of individuals down here we've got 200
individuals down here here which all
have a relatively recent common ancestor
it's in it's in here somewhere everybody
see that they're probably they these 200
robots probably all look very similarly
if not identically and probably all move
similarly if not
identically over here we got we get the
emergence of species we had two uh
individuals way way back early in
evolutionary history that were both
successful and spawned massive families
families so big that maybe we want to
refer to these as species this is a
little bit tongue and cheek these aren't
exactly species why
not they don't
share not
quite if they were species in the strict
sense of the
word what would they be able to do or
not able to do they they they would not
be able to like sexually reproduce they
cannot sexually reproduce there is there
is a sexual recombination operator in
here but in the interest of time we're
not going to talk about it these species
can sexually reproduce whether that
produces viable Offspring I have no idea
they just wanted to show that even in
this evolving population you can get uh
in some cases just by chance you can get
uh distinct subgroupings of
robots uh over here we we have a uh we
have all uh uh all except one individual
this individual in the population that
are all similar these are all dinosaurs
they're all doing fantastically well for
a very long period of time and then this
one individual here that had pretty good
Fitness Fitness good enough to compete
among all of these but unlucky in the
sense that it never produced any
Offspring until at this point just by
chance it happened to produce three
offspring that very quickly started to
exhibit faster motion than the
dinosaurus over here and the mammals
over here quickly started to proliferate
and drove this sub population of robots
Extinction so even a relatively simple
evolutionary algorithm you can start to
get rich evolutionary Dynamics your
evolutionary algorithm is probably too
simple to see any of that that but again
I wanted to spend a minute on all this
might be an interesting idea for a final
project can you complexify your
evolutionary algorithm so that you start
to see ecological or evolutionary
Dynamics like speciation Extinction
events and so on if you're interested in
that come and see me in office hours and
we can talk about it
okay okay crabs right crabs are a good
way to do things pyramids are another
good way to do things here's a few
examples of what they got from two
different evolutionary runs in one they
got robots that look like
this and you should already start to see
now at this point why pyramids are
good why are pyramids good good in the
sense that it doesn't take Evolution
much to put to Cobble together something
that actually moves in a forward
Direction
does it like consistently like make it
so that the force that's being applied
is only being applied in like One
Direction exactly right if you push
directly against the floor with a normal
force you don't go anywhere but if you
have a body and a brain that allows you
to continuously push against the ground
at an oblique angle and you always push
with that oblique angle you're going to
consistently keep moving in a given
Direction uh for a while right a simple
Hack That Evolution tends to find in
this space so in these top ones is there
only one motor that's being used uh is
there only one
motor uh I think there's two it's a
little difficult to see there's one here
and I think there's another one in here
somewhere one or two one or two it
probably doesn't need the second one one
is probably
sufficient okay carcon whatever it's
called is at work not just on this
planet but on that planet
also how well do you think these designs
are going to cross the reality
Gap I see a lot of you shaking your
heads
vigorously these things look like
they're going to drop into the abyss
right
why they're not really at least to me
they don't look particularly statically
stable ah okay so remember statically
stable remember our discussion about
legged Locomotion to be statically
stable you have a polygon of support on
the ground and your center of mass has
to stay on top of that polygon of
support at every
point it may not look like it but this
simulator was actually made by hand and
they constrained the speed and strength
of the motors in such a way that it's
always statically stable it's a little
tweak of this simulator which we don't
have too much time to go into they
actually pause the simulation after each
time step and they run the simulator
forward in a slightly different way to
let the robots settle so what these
robots are really doing is kind of going
stoping it doesn't you can't see that in
the simulation but these are all
actually always statically stable
because these were good mechanical
engineers they knew their mechanics and
Dynamics they were scared of the reality
Gap they knew that if they evolve
something that was not statically stable
they probably had no chance in heck of
crossing the
Gap it really feels like these are very
dependent on having a flat surface
exactly the right friction the flat
ground with exactly the right
friction what else um I feel like this
this requires that the the simulation is
really dealing well with the connection
of things and kind of they they like
especially the cowd kind of looks like
it has tension in it almost okay yeah so
there's a lot of things that are not
quite accurate in this physics engine
physics engine were invented in the same
year that this experiment was reported
in the literature I know these
investigators they wrote this simulator
by hand this was a brand new thing at
the time people were just figuring out
how to do this so we'll take all this
with a grain of salt you can see they
didn't get the connections quite right
you are all physics engines experts at
this point so you can see some of these
uh things inaccuracies in the simulator
what what's wrong with the joints what's
happening at the joints or what's most
visible at the joints that is not going
to be real in reality clipping what do
you mean by clipping uh the different
bars are interpenetrating they're
interpenetrating right Collision
detection and resolution really hard to
do right in 2024 people are still
working on this problem and Reporting
papers in the literature about how to do
this better It's Tricky hard to do yeah
so there's a lot of things here that
should be causing you to catch your
breath and be nervous as we approach the
gap
but that's what the Golem project is all
about so here we
go okay let's look at the arrow
first they observed this one and decided
to put in the effort to actually build
it just as a reminder everything that
you see in white here in the physical
robot this is thermoplastic so the 3D
printer has printed all of the white
chassis of the robot and you can see
they've snapped in some Motors and
electronics and this thing is dragging a
bunch of wires that are supplying power
and signals to the the
Pistons how'd they
do the physical robot only travels
onethird as far as the physical robot or
travels with onethird the speed probably
for the reason that Nate mentioned
the friction is different you can see
that they're they've got this robot
moving over a very thick carpeted floor
like the one in this room so the
friction is probably slowing the robot
down but also helping easier to move
over thick carpet than it is over sheer
ice so it's sort of
helping why you could argue that this
one crosses the Gap it's not perfect but
it's more or less moving in the way that
we observed in simulation
why was this one successful it's doing
like parsis it's par uh it's kind of
peristalsis yeah you're right there you
you might be able to see a bit of a
traveling wave across the body
peristalsis always a good place to
start it's uh robust like it doesn't
need balance at all remember the four
Deiter of locomotion right one of them
is robustness you got to move without
falling down that's a huge problem for
our species but if you're lying flat on
the ground you don't have to worry about
falling over so it doesn't matter what
kind of ground you're on you won't fall
over and as long as you're pushing
obliquely against the ground and ground
has high
friction it works right so first thing
to take away from the Golem project is
you can cross the reality Gap and some
bodies make it easier to CR cross the
Gap than others if they had evolved a
Hopping bipad robot in their simulator
that's less likely to cross the Gap much
more difficult if it was not statically
stable more difficult yeah so this idea
to try and cross the Gap a whole bunch
of times was sort of brilliant in
retrospect and perhaps uh maybe this
wasn't anticipated beforehand but
actually the choice of body makes a huge
difference okay
here's one of our uh here's one of our
uh pyramids here called The Pusher for
obvious
reasons okay but not so great not quite
in the same direction
[Music]
slower Le less successful
why I think partially because it's less
uh it has more mass that is in contact
ground has more friction because of that
it's got It's got more friction this
one's got quite a bit too which is also
slowing it down how about the
tetrahedron the clear winner from the
Golem
project the camera angles they didn't
shoot from the same camera angle so it
looks like the simulated physical robot
are moving in different
directions very good approximation very
successful crossing of the Gap
why it looks like it's doing an
interesting thing where it's like kind
of pulling up on the back as it pushes
so it has very little friction with the
ground exactly right it's pulling itself
up so it's overcoming whatever friction
there is and the inaccuracies of
friction Visa V what it was in
simulation pushing a little bit more
vertically but still reliably obliquely
so off it
goes so it's kind of about whether the
the strengths of the evolved body align
well with the things in simulation that
were accurate versus the things that
were not correct so if it's strong
enough to match the things in reality
that were correct and it overcomes the
things that are not yes in this simple
case we are poor humble humans those are
the only aspects of this that we can see
that affect whether or not this thing
crosses the Gap what is harder to see is
how close the mass distribution is
between the simulated and physical robot
which also affects whether or not it
crosses the
Gap how much is the set of wires
dragging behind the robot tugging back
on the robot when it moves maybe a
little maybe a lot maybe it matters
maybe it doesn't there's dozens if not
hundreds
of little micro features that are
different between simulation and reality
that you can't see all of the
observations that you made were great
observations but they're just the tip of
the iceberg right and they can lead us
and they led many of us at the time to
think oh reality gaps not so hard
actually okay we're close to a solution
24 years later with more complex robots
and we're going to see a more complex
robot in a moment it's not so easy it's
possible and choosing the right body can
help okay all right so we've spent all
our time so far talking about automated
design and we've looked at some of the
automatically manufactured robots this
is not a a mechanical engineering class
but I think it's fun to just go back in
time and have a look at the advances
that were being made in terms of 3D
printers at the time so let's spend a
little bit of time talking about the
second step of the experiment how did
they actually make these robots has
anybody actually used a a 3D printer
before okay okay great all right so at
the time this was a brand new
technology this is a greatly sped up
version of uh the 3D printer that was
being used at that time one of the very
first 3D printers uh that existed in an
academic lab and you can see it starting
to print one of the cylinders that makes
up uh the robot here's a zoomed in
version of it building a different robot
you you can see here uh a partial build
most of you know by now a 3D printer is
called a printer cuz it's it was based
on the metaphor of an inkjet printer
which splashes ink onto a piece of paper
3D printer does more or less the same
thing it splashes heated up Liquid
plastic onto a base plate which cools
fast enough that they can then splash
another layer and another layer and up
and up you go you're depositing 2D
layers of thermal
plastic but depending on the geometry
the 3D geometry of the thing you want to
build building it in 2D layers is
difficult so these early 3D printers and
a lot of 3D printers today print
additional stuff this is just uh weak
scaffolding to literally hold up the
parts that are being built it took about
eight hours to print each of these
robots um they would print it during the
day and then in the evening they drop
this into a uh into a liquid solution
that would eat away at the plastic
slowly and it would eat away slowly
enough that by the next morning it had
eaten away all the scaffolding but
hadn't done a good enough job eating
away the actual thing you wanted so you
got this you got a whole bunch of
connected Hollow cylinders that's what
3D printers could do at that
time how do you make how do you make a
shoulder joint a passive shoulder joint
in the robot remember that there's a
piston that's pushing and pulling on the
bar but if you have two bars that are
attached by a piston and the Piston
pushes on these two bars the passive
joint has to be able to rotate so they
got very creative in a CAD program and
came up for of with a way of printing
all of this stuff to produce basically a
shoulder joint yeah
passive then they put in the actuators
here's the little here's the little box
of electronics that's controlling the
actuator supplying the power there's a
little battery in here so this little
box is placed just out of camera view
here that's the thing that the robot is
dragging behind
it
okay the nice thing that was realized
about this at the time is that uh when
this was published in 2000 maybe in the
distant future it would be possible to
print these things from recyclable
plastics so they put uh they put the
robot here in a little uh toaster oven
and heated it up remember this is
thermoplastic which has a high melting a
low melting
point and so they melted away and
drained off all this liquid plastic most
uh thermoplastic based 3D printers today
can do this you can actually melt down
whatever it is that you printed and send
that back in as a Raw Feed stock to the
3D
printer 3D printers are a little bit
scary because it allows us to print lots
more stuff cheaply suggesting there's
going to be a lot more trash and plastic
waste on this planet but there is an
attempt to uh to make this part of the
circular economy that once you're done
with something you can literally melt it
down and reuse the parts again
tangential to what we're talking about
in this class but kind of an interesting
way to approach robotics in
general if we can do that if we can melt
down and reuse if we can uh if we can
melt down to
recycle maybe we can reuse it
also just because the journalists
weren't frightened Enough by this
experiment they generated this video as
well just for fun
okay okay so that's the Golem project
another attempt to cross the reality gap
which is the Brute Force attempt right
just design manufacturer design
manufacturer 3D printers were being
invented at the same time so uh I joined
the lab that had just finished the Golem
project at that time and at that time
they were developing an offshoot which
is wouldn't it be great if you coulde if
you could make a 3D printer at home the
way that you most of us have a printer
at home so the Fab at home project was
basically a do-it-yourself project where
you could re buy a lot of these parts
they're very cheap and you could
assemble them at home with common tools
not that difficult and if you knew how
to use CAD uh you could actually make
one of these things and the idea would
be maybe 3D printers would become like
personal computers in the ' 80s what
made computers so ubiquitous it was that
in the 80s everyone started to be able
to afford one had one at home and
started tinkering with it what could you
do with this new thing called a personal
computer The Hope was you could do the
same thing with 3D printers that hasn't
quite materialized yet anybody have a 3D
printer at home okay all right so
maybe okay we'll finish with this uh
this project the rep WP project which
also started about the same time
uh and this was uh this was conducted in
the UK let me see if I can speed this up
a little
bit the rep WAP project a 3D
printer that prints
itself this is uh if you ever make it to
London and you get to the Science Museum
you can see exactly that machine in the
museum it is arguably the first machine
that can print all of its own parts
it still has to rely on those darn
humans to do the last little piece which
is to put all the pieces together into a
new rep wrap machine oh and also buy the
parts and so on so not completely
automated you can see it's a machine
made up of a lot of parts with complex
geometry and
interconnectedness just for fun Imagine
a hypothetical evolutionary algorithm
attached to this you can evolve the
design and function of this rep WAP
machine to print a copy of
itself what kind of Fitness function
might you apply to this evolutionary
algorithm user satisfaction score user
what do you mean by user satisfaction
score this is still a product for people
who want to do 3D prints how happy are
they with the results awesome absolutely
yeah involve humans in this and get them
to put a score from one to 10 about how
fun it was to build the next version of
a rep rap machine it's like the score of
it it depends on how well the child does
ah the score of the child depends on how
well the grandchild does so we we can
assign let's you're right we could keep
going let's imagine a fitness function
that actually is a combination of how
well the parent and the child does what
do you mean by does what do would you
measure about the parent and child I
think you would need a benchmark build
like just a template object that they
would have to build every generation and
you would measure the speed and accuracy
with which okay right so we modify this
rep wrap machine so that it doesn't just
print rep wrap components it makes
something else as well and the speed or
the Precision or the quality
at which it makes this other thing
becomes the fitness function and let's
run that hypothetical evolutionary
algorithm in our head over evolutionary
time we'd get rep wraps that are able to
better build the thing we actually want
them to build faster cheaper and so on
that's one possible way to go what else
um so could we could we evolve it for
the speed at which it can produce
another rep absolutely so you you can
try this yourself go to the rep WAP
website it'll send you to Amazon to buy
all the parts and you got to assemble
them it takes a while it's very
frustrating user satisfaction score I
can tell you as a user is very low it's
very frustrating lots of swear words so
maybe we evolve it to facilitate the
speed at which you can build another
one this first rep wrap I forget how
what percentage of Parts it's able to
print it can't print all the parts of
its child it's like 70
90% maybe we include that in the fitness
function evolve self-replicating
machines that can print more of Their
Own
Parts evolve rep rap machines that print
a version of themselves that's 10%
larger than the parent or 10% smaller
than the parent lots of ways you could
go with
this okay that's just for fun okay we've
got 10 minutes left so we looked at the
radical envelope of noise hypothesis
from the mid 90s 5 years later the Golem
project in 2000 we're now going to talk
about the resilient machines project
which was reported in the literature in
2006 by Yours Truly this was a project
that I was involved with this was a
collaboration between myself and hod
Lipson one of the uh workers on the
Golem project so I teamed up with hod
let's come up with a new way to solve
the sim tooreal problem I'll show you
how the resilient machines project
solves the sim toore problem uh in a
moment there was a second goal for this
project not just come up with an
algorithm that guarantees that robots
transfer from simulation to reality this
was work that was funded by NASA and so
we had to also satisfy NASA what NASA
Engineers are particularly terrified of
is using millions and possibly billions
of taxpayer dollars to develop a very
complex and expensive Rover take five or
20 years to send a Rover somewhere in
the solar system Rover gets there and
things don't work something goes
wrong for that very reason NASA is is
probably the most conservative
engineering firm on the planet there's
redundancy within redundancy within
redundancy every single project that
nask tackles is super expensive tons of
people hours and takes you know unfolds
over years or decades so they're very
very careful however on the flip side
they also know that wherever they're
sending their probes it's a very
uncertain environment so there's lots of
things that can go wrong there's lots of
unknown
so NASA also spends a lot of time
working on what they call methods of
Last Resort if a very expensive Rover is
uh sitting somewhere in the solar system
on an extraplanetary body and the
mission is about to fail you're about to
lose the whole thing then and only then
will NASA consider seeding autonomy to
the Rover meaning Mission Control takes
their hands off the joystick Mission
Control says I don't know what's going
on on where you are but clearly
something's really wrong Rover you try
and figure it out so they funded us not
to solve the sim toore problem but to
develop a method of Last Resort what
algorithm should you package onto the
Rover so that someone on Mission Control
can just push a button and it starts
that algorithm the the Rover or the
robot itself starts to try and figure
out what's gone wrong diagnose the
problem and find a way to recover
okay so we did that here it
goes so here's uh here's the RO here's
the robot which has taught itself to
walk and as you can imagine we did this
in simulation first and then transferred
it to reality so the mission here is
just get from the left side of the table
to the right side of the table this is
phase one of the experiment in the Golem
project this was everything in your pro
in your assignments it's everything
that's all that matters but what happens
if after it's evolved the ability to
walk something goes wrong so you'll
notice now that we sent a grad student
in with a screwdriver and he has
mechanically separated the right lower
leg of the robot and the motor that used
to sit at the uh at the knee of the
robot is still connected to the robot
the robot is still still sending
commands to the motors but it's not
walking anymore something has gone wrong
you can clearly see what's gone wrong
and you might even be able to dream up a
way for this robot to walk with three
and a half legs rather than the original
four legs that it has the trick here is
that the robot can't see what's gone
wrong and neither can mission control so
I just want you to assume that you can't
see what's actually gone
wrong the robot is sensing that
something has changed the way the kinds
of sensory information that it was
getting from here is different something
has happened so the robot has two
problems it's got to solve it's got to
diagnose what's gone wrong and it's got
to come up with a compensating
controller it's got to come up with a
new way to move because its mission is
still the same get from the left side of
the table to the right side of the table
so in this 10,000 ft view of this
experiment which is made up of these
three parts between the second and third
phase of this experiment the robot has
successfully figured out what's gone
wrong and it's come up with a way to
recover I haven't told you how it does
that
yet
it's not going to win the Dancing with
the Stars competition not the most
graceful machine you've ever seen but it
does recover the ability to move from
the left side of the table to the right
side of the table it's moving slower
it's not moving as straight as it does
before but from NASA's perspective this
is way better than having to hold a
press conference the next morning and
tell the US taxpayer sorry game over we
got to start
again perhaps this machine can still
extract some of the science or whatever
it is that the Rover is meant to do so
far so good okay all right we got 5
minutes left so let's dive into each of
these three phases of the experiment to
see exactly how the robot diagnoses
problem unexpected problems and recovers
from
them okay before we dive into the
details let's just sort of step back for
a moment we're going to see how this
experiment contrasts to all the other
evolutionary robotics experiments we've
seen so far one of the things that tends
to underly everything we've seen so far
is evolve a controller for a robot or
evolve the robot itself like we just saw
in the Golem project evolve the
controller Andor robot to automatically
discover near optimal Behavior we never
know whether the evolutionary process is
found optimal Behavior we just hope that
it's getting better and better how how
do we go about doing this there's three
at the time there were three existing
ways to do this evolve controllers
directly on the physical robot obviously
the first experiments that we saw in
this field that's what they did because
there was no other way to do it at the
time there was just the physical robot
with the Advent of phys uh the problem
with this of course is it takes a long
time to do this we got to valuate
hundreds or thousands of controllers on
the physical robot first of all NASA
hates this imagine you have a damaged
Rover that is sitting on the slope of a
crater on some planet or moon and the
robot just spends just starts to
randomly try
things it's the last thing NASA wants
most of the things a machine might try
are going to make things worse not
better better yeah so this is
unsatisfying for us as roboticist it's
it's labor intensive and also very
dangerous for a machine in the wild to
do so the most common solution we've
seen in this class is create a
simulation of the robot and do all of
the evolution in the
simulator then cross your fingers
transfer the controller to reality but
of course there's a problem with that
approach which
is the Gap right okay there's another
problem with this which we haven't
really mentioned which is you need to
make the simulator itself for the grad
students that are on D5 you've spent D1
through D4 making a physics engine from
scratch for uh the 10 assignments I gave
you most of the physics engine but still
it took a lot of effort to actually make
the simulator before you actually
started to evolve the robot so there's
actually two big problems with evolve in
simulation and then transfer to
reality third approach we haven't talked
about in this class but used to be
popular is uh create a controller by
hand use your Genius as a robotics
engineer to figure out how sensation
should be transformed into action to
produce whatever Behavior you want and
really hard to do but make something
that's kind of okay and then allow
Evolution to tune up that hand created
controller on the physical robot
obviously there's a problem with this
approach as well what is it it Rees IM
amount
inition absolutely super super hard to
do isn't that what reinforcement
learning pretty much to uh yes and
reinforcement learning is very
successful but requires the physical
robot reinforcement learning has not yet
figured out how to learn the body plan
itself so there's an implicit assumption
here as well is that ultimately all
these methods have to decide decide on
the body and brain as well as we just
saw in the Golem project the body
matters matters a lot but you're right
if you think you have the right body
plan for the job then you probably don't
need evolutionary Robotics and you can
go use reinforcement learning but if you
don't quite know what the body should be
and actually that's true for NASA they
tend to send wheel Rovers but there's
now an ornithopter up there as well n is
in the process of trying lots of
different body plans for robot probes as
well it's not clear what the optimal
body plan is for exploring a particular
planetary
body okay so uh the resilient machines
project it's got a lot of different
names and there's a lot of different
goals so we just saw uh one of the goals
of the resilient machines project which
is to enable a robot to recover from
unexpected
situations the other thing that I
designed the experiment the resilient
machines project to do was to try and
overcome uh these
problems we used to call the resilient
machines project the estimation
exploration algorithm it's a mouthful
and it's kind of boring and it doesn't
really capture what it does so you can
sort of skip over
this what we're going to what you're
going to see in the resilient machines
project is we're going to uh or the
resil this algorithm is going to evolve
controllers in Sim
and transfer them to the physical robot
like we've seen now a couple times but
the algorithm is also going to uh it's
going to evolve the simulator itself we
are not going to create a simulator from
scratch we're going to evolve a
simulator what do you think the fitness
is of a population of physics engines if
you're going to evolve a good physics
engine what do you want that physics
engine to have given specific conditions
in the real world how well does the
simulators next time step match the
actual experience of next time
absolutely so you're going to see uh
you're going to see an evolutionary
algorithm inside the resilient machine
project which is not evolving robots
it's not evolving controllers for robots
it's evolving simulators to be accurate
how do we know if a simulator is
accurate we need information from The
Real World so what what you're going to
see you're going to see several new
things in the resilient machines project
the first the thing that we'll see at
the beginning of next time is not sim to
real but real to sim the physical robot
is going to collect sensor motor
information and send it back to the
evolutionary algorithm and that
evolutionary algorithm is going to use
that as raw material to evolve an
accurate simulator we'll pause there for
today you have a quiz due tonight you're
working on either A10 or D5 we'll talk
about the final project when we meet
again on Tuesday until then


--- Evolutionary Robotics course. Lecture 19： The Resilient Machines project..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone you made it
it's the end of the
beginning hopefully all of you finished
assignment
10 yes no awesome okay I'll take that as
a yes everyone finished all five
differentiable
assignments grad students almost not
quite okay you got one more day to work
on that almost there okay as you were
coding up the evolutionary algorithms
and maybe refactoring the quadrip and
possibly struggling with gradients in
the fifth and final differentiable
assignment it occurred to you to ask
what would happen if we mutated two
synaptic weights rather than one what
would happen if the motors were a little
bit stronger a little bit weaker what
would happen if my quadruped had two
extra legs and was a hexapod rather than
a quadruped we been evolving the robot
to walk what would happen if we evolv
the robot to jump or climb up stairs or
navigate over a rough terrain what would
happen if what would happen if what
would happen if you now have one month
to try and figure it out so hopefully uh
by the end of assignment 10 you now have
a relatively stable code base on which
you can conduct some evolutionary
robotics
experiments with the fifth and final
differentiable assignment hopefully you
have a relatively firm foundation in
which to try and optimize the body Andor
brains of robots in a
nonrandom way so what we're going to do
today probably we're going to take most
of this morning is to actually walk
through what the expectations are for
the final project and I will try to give
you a good sense of what works and what
doesn't work for a final project but
that's only advice the final project is
in your hands so obviously you got a lot
of room to maneuver you can come up with
an idea of your own but we want to make
sure you come up with an idea that's
doable um in a month's time I understand
that some of you have some other things
going on in other classes as well yeah I
realize it's a busy time of year it's a
tricky time of year to summon enough
focus and willpower to come up with a
scientific question and try and test it
with your code base but we'll do the
best we can okay so I'm going to go over
a lot of material today I'm sure there
will be more questions that arise about
the final project uh over the uh final
month of the course so I will set aside
a few minutes at the beginning of every
class from now until the end of the
semester to field questions about final
projects to clarify anything anything as
we go any questions so far so far so
good okay so you will see that on today
now you are being assigned the very
first of your weekly report reps so
you're no longer submitting screenshots
and videos demonstrating that you've uh
completed assignments you are going to
continue to submit on bright space
screenshots and videos demonstrating
that you're making progress towards your
final project that's the weekly report
so all of you now whether you're taking
this class for undergraduate or graduate
credit at
11:59 p.m. next Monday
uh eclipse or no Eclipse you're going to
be submitting a demonstration to us
you're going to show us that you've made
some progress towards your final project
and we'll talk about what these weekly
Reports look like in a moment okay so if
you click on through to uh the first
weekly report it will take you to Bright
space and you will find as always
something that is due next Monday at
11:59 p.m. exactly what is due is
describ in this Google doc here which if
you click on it will bring you to the
evolutionary robotics final project
instruction this document is almost two
pages long my apologies we're going to
read through it from top to bottom this
morning just so we're all literally and
metaphorically on the same page okay all
right so um undergraduate students
you've got three options for your final
project there is a list of preformulated
ated projects these are ideas that uh
some former students and I came up with
that are reasonable they're things that
are doable in about a month's time
assuming you were relatively successful
implementing all 10 assignments we've
broken as you'll see if you click
through to this list you'll see that
some of these projects have an easy
label attached to them and some of them
have a hard label attached to them for
obvious reasons some are easier than
others you can pick one of those from
the list or you can Define uh devise a
final project of your own read through
that list and it'll give you sort of a
sense of what's possible and you should
be able to come up with an idea of your
own okay for those taking the course for
graduate credit you do need to come up
with an idea of your own okay if you
choose your own idea it must involve
modifying the code base somehow either
the code base from assignments 1 through
10 or the code base from the
differentiable assign m ments one
through five for the those taking it for
grad credit we don't mind you can modify
A10 or D5 to suit your final project
idea fine with us okay uh I I'd prefer
that rather than you coding up something
from scratch it's much easier to go Ary
If you're sort of starting over from
scratch I don't advise trying to create
your own physics engine and then do
something interesting with it in a
month's time so your own idea but using
the codebase that you currently have
okay final project ideas using the
differentiable assignment codebase are
here I forgot to put a link to here
those taking this for graduate credit if
you go back to the diff design wiki page
at the bottom now there's a list of some
final project ideas things you can do
with the differentiable simulator okay
I'll put the link back here later okay
all right there are four Mondays
remaining in the semester you're going
to use this time to Divi devise an
Implement in four increments four weekly
increments your final project okay how
do you decide on whether you want to do
an easy or hard project if you found you
were struggling with the programming
assignments I recommend the easy an easy
project if you want to try something
more challenging go with the hard one
you will not be penalized if you choose
the easy uh project okay uh if you want
to try an idea of your own please email
frya or myself so we can basically just
sign off or give you some suggestions
about how how to either reel it back in
if we feel it's a little bit too
ambitious if it sounds like something
that could be done in about a week or
two weeks time will suggest maybe some
ways to elaborate or enrich your final
project idea
okay what you need to do between now uh
and Monday is think of a final project
and then think how to break it down into
four bite-size chunks or at least weekly
chunks for each of those four uh
increments you also need to think about
how you're going to demonstrate it to us
with a couple of screenshots or a video
as always we're not going to have a look
at any code you got to try and make
things easy on us where we can
relatively easily see in your screenshot
or a video that you're making progress
on your final project okay so what
you're going to do in the next week is
write out those four milestones and they
all have to be about a sentence or two
no paragraphs no essays keep it keep it
short and simple write out these
milestones and a sentence or even half a
sentence on what your planned
visualizations are to demonstrate that
you've completed that Milestone so
here's an example okay if you click
through to the link above you're going
to see a long list of projects one of
those projects is the Up Up and Away
project which is to modify your codebase
so that instead of evolving for forward
Locomotion you're evolving for jumping
jumping sounds like a trivial thing has
anybody tried to evolve jumping yet in
their
robot I can guarantee you it's not a
trivial thing to do okay so um this is
me writing as if I was the student if
you copy if you write something along
these lines and drop it into Milestone
one by next Monday night that's that's
good so I would like to implement the up
up an away project where I'm going to
evolve my robot to jump in order to
evolve it to jump I'm going to modify
simulate. py so that when the simulation
of each robot ends simulate. py is going
to write out not a single floating Point
number which is how far forward the rep
robot traveled but instead the file is
going to write out all of the touch
sensor values for the four feet of my
robot in a binary Matrix so we're going
to have a whole bunch of col colums in
this Matrix which correspond to each
time step of the
simulation each of the four rows in this
binary Matrix are going to correspond to
the four feet in my robot I haven't put
those details into my description that's
kind of too much detail for frya and I
but this is sort of how you want to be
thinking over the next week okay I'm
going to write out all of these numbers
they're all plus ones and minus ones
whether or not that foot is in contact
with the ground for each time step of
the simulation and I'm going to write
that I'm going to have simulate. py
write that out to a file when it ends
rather than what it currently does which
is to write out the distance traveled by
the robot so far so good
okay uh there we go okay sorry I should
have said I
will include a screenshot of
simulate.
py writing out this Matrix so perhaps in
this first week you might not even have
a simulation going yet but you're you're
going to demonstrate your code doing
something like for example writing out a
matrix to a file you can just record
your screen make a sure a screenshot or
a short video of simulate. py ending you
double click on a file that file opens
and we see a whole bunch of ones and
zeros right 10-second video or a couple
of screenshots shows us that your code
is doing what you wanted it to do
by the end of this first
week show don't
tell any questions about that seem
reasonable
okay second milestone what am I going to
do in the second week okay so now
simulate. py is writing out this Matrix
now I'm going to switch from simulate.
py Back to the search process The
evolutionary algorithm so in the second
week I'm going to modify search. py so
that it reads in this binary Matrix
when simulate. pyns and it's going to
boil down that Matrix to a single
floating Point number we're going to
apply our fitness function to this
Matrix and the fitness function is going
to spit out a floating Point number okay
what seems reasonable I want this robot
to jump so if a robot or a human is
jumping their SP their feet are in
contact with the ground for as little
time as possible so I'm going to compute
in search. py Fitness function which
just counts the number of minus ones in
the
Matrix if you modified your parallel
hill climber that's in search. py to
evolve that what are you going to get do
you
think if you evolve with that Fitness
function for the quadraped what is the
evolved quadruped likely going to be
doing at the end of search.
py try to get as many things off the
ground as possible okay so probably
going to get
jumping balancing on two legs balancing
on two legs or tap dancing even with
something simple like jump. p uh jumping
you're unlikely to get what you want you
may not know that in advance but this is
what I want you to try and think about
over the next week you're all becoming
experts on running evolutionary robotics
experiments we're seeing a whole bunch
of them up here at the front and what
works and what doesn't work you can
almost run this idea in your head right
you imagine running the parallel hill
climber and it's evolving controllers
for the quadruped and the quadruped is
evolving to generate more and more minus
ones thanks to the fitness function does
that always mean jumping what would be
some some easier ways for it to do that
you may or may not be right in your
predictions but I want you to try and
come up with a plan and if you don't get
if you think there's a there's a a
chance of perverse instantiation you're
not going to get what you want what are
you going to do in the third week to try
and guard against it or or improve or
help with whatever it is you want your
robot to do so uh this hypothetical
student here is thinking this through
and says this will lead to the evolution
of robots that keep as many feet off the
ground as possible which is not
necessarily jumping and I'm going to
show that to you all with a video so
that's the plan for for the second week
plan for the second week is I'm going to
modify the fitness function to compute
the number of consecutive time steps in
which the robot keeps all of its feet
off the ground right so clearly this
student has thought a little bit about
what might go wrong and has come up with
a different Fitness function they're
going to try out in week three that more
explicitly asks for exactly what you
want which is not just to keep feet off
the ground but to keep all the feet off
the ground for as many time steps as
possible okay um I'm going to implement
that I'm going to rerun my code and then
I will demonstrate with a video that
this causes the robot to jump and stay
in the air as long as possible so this
this hypothetical student who wants to
evolve a robot to jump has sort of
sketched out what they plan to do over
the next 3 weeks that they hope will
lead at the end of the third week to
what they want what are you going to do
with your fourth week in your fourth
week you're going to be doing what's
called AB testing and we'll talk a
little bit about AB testing first before
we talk about this fourth deliverable
anybody heard of AB testing
before anybody ever visited a website
and then come back a week later and it
looks a little bit different the fonts a
little bit different the color a little
bit different that's whoever makes the
website subjecting you to AB
testing you create a website uh you
create two slightly different versions
of the website with slightly different
fonts and when any person arrives at
your website you flip a coin heads they
see version a of your website Tails they
see version B of your website next user
comes flip another coin
ABAB and this company over a week's time
starts to collect a whole bunch of web
traffic data about people landing on
version a or version B of their site and
doing whatever they want to do and at
the end of the week the user interface
members of the company have to decide
are they going to move forward with just
version a or version B of the website
how do they decide they've got all this
Raw web traffic data version a version B
of their website what's the
test if you're the company what are you
hoping for they'll call you or buy your
product how many people actually click
through to buy your product how much
time did people spend on the site if
you're able to detect whether the user
that landed on your website was a bot or
a human
maybe a gets rid of bots quicker than
version B does there's lots of different
metrics you could come up with where you
apply that metric to the web data you
have for version a and version B and
you're looking to see whether that
metric is different between A and B if
more people buy products when they land
on B rather than a throw away a and and
version B becomes your website
this is very standard practice in
engineering software engineering web
design and it turns out robotics as well
so at the end of week three this
hypothetical student is hopeful that
they now have an evolutionary system in
which they can evolve jumping but
they're now going to come up with
variant a or version a of their codebase
and version B of their code base in this
fourth week and evolve robots slightly
differently in these two versions of
their code and they want to see which
one works better which one actually
leads to better jumping in this case so
this student proposes to us here's how
they're going to start to do ab
testing I'm going to modify my the
simulation side of my code again to
write out not just the touch sensor data
like I've been doing over the last three
weeks but I'm also going to go back to
writing out the horizontal distance that
the robot travels which is what
simulate. py currently does the end of
assignment 10 okay so now at the end of
every simulation they have distance
traveled by the robot and this binary
touch sensor uh data set they're going
to compute Fitness now as D * T inside
of search. py they're they're proposing
to modify their Fitness function yet
again where D is the
horizontal distance traveled by the
robot and the the consecutive number of
time
steps consecutive number of time steps
that all feet are off the ground so if
you did evolve the quadraped with this
Fitness function what kind of behavior
do you think you're going to get you're
trying to maximize D distance traveled
and maximize T the number number of
consecutive time steps with all feet off
ground what are we evolving
for long jumping long jumping right you
remember the Olympics theme song where I
showed you some of the final projects
from last year so now they can start to
change the fitness function to select
for different kinds of jumping so now
they're going to evolve for long
jumping and they're going to then
compare evolving for the standing jump
which is what they did in the third
Milestone they were just evolving at the
end of the third week for number of time
steps off the
ground and they that's their version a
and version B is they can evolve for
long jumping so a evolve for high
jumping B evolve for long jumping and
which of these two versions A or B
produces better
jumping to say because a standing jump
and a long jump are just different kind
of
jumps for this student they want to just
see which of these two versions A or B
causes the robot to jump as high as
possible there nothing that necessarily
says the standing jump or the long jump
will produce a higher y component a more
positive or negative y component they
want to compare these two versions
of their
code seems like kind of an arbitrary
choice but that's okay in the final
project yeah you're trying out two
different ways of doing things yeah
another another way they might have gone
so uh third Milestone I'm going to
evolve I'm going to evolve a standing
jump and in the fourth Milestone I'm
going to evolve standing jump with a low
mutation rate every child uh suffers a
change to one synaptic weight that's
version a which is what you already have
version B I'm going to increase the
mutation rate whenever a child is
produced I'm going to allow one two or
three synapses to suffer a random change
maybe it's easier to evolve jumping if
more things can change between parent
child parent child parent child then
less things you can make Arguments for
or against a higher mutation rate it's
not clear so for that student that
becomes a or b
any questions so
far this is obviously a hypothetical
example but just to give you a sense of
what we're looking for okay so what we
want you to submit by next Monday night
is exactly is exactly this a write up of
these four things which is your plan for
the next
month and we want you to
include your evidence that you've done
the first part seem
reasonable okay an obvious question that
might be occurring to you is what
happens if your plan changes right what
happens if at the end of week two you
actually do get jumping exactly as you
want it right good for you you're done
two weeks early afraid not change your
plan when you submit when you submit
your second milestone leave a note to us
here was my original plan for week three
and week four but I managed to
accomplish my goal early so now I'm
going to try some other things right or
I didn't accomplish my goal things
turned out to be even harder than I
thought so here's my revised plan for
week three and week four it's okay with
us if you change your baby steps your
four baby steps that you're taking
towards your final project it's also
okay as you go from week to week maybe
your ideas change about what you want to
do as long as you tell us this was my
plan last week this is my new plan and
I've got a new plan I know what I'm
doing over the next two weeks long as
you do that no problem yeah
okay okay so again by next Monday night
uh by next Monday night you're going to
be telling us what you're going to do
your four milestones and a link to some
proof that you actually implemented it
there's one other thing you need to do
you need to do a little bit of house
housekeeping there's a couple of minor
things that need to be fixed in your
code base these are things that are
going to cause you a bit of a headache
if you don't fix them before you start
modifying your code base for the final
project shouldn't take you long you
don't even need to show us any evidence
that you did it I just recommend that
you fix these few things okay following
Monday the 15th you complete your second
milestone uh you complete your your
second milestone and tell us your four
Milestones again so here's what I did
last week here's what I did this week
here's my modified plan for week three
week four and proof of Milestone 2 same
thing for the Monday after that proof of
Milestone 3 and uh and in the last week
uh of classes you're going to be showing
us preliminary results from your AB
testing here's a video of my high jump
here's a video of my robot doing the
long jump and as you can see just by I
by looking at these two videos the robot
that did the long jump actually got
higher than the one that did the
standing jump that's preliminary results
of your ab test we get what your A and B
is and you're pointing to us something
in a short video or a couple of
screenshots we can see the thing that
you're comparing between your two
variations any questions about that
okay all right uh sorry that's not the
that's not the last week that's the
penultimate week of the semester the
last week of the semester you're going
to be submitting materials uh m a
written report and an oral presentation
this is a short YouTube video that
you'll be presenting during the exam
period which is the following day
Tuesday May the 7th so what you're going
to be submitting uh the night of May 6th
and what we're going to be doing in
class here on the morning of Tuesday May
7th we'll talk about later we're not
quite there yet I want you to just focus
on these four milestones for the next
month or
so all good okay all right the thing you
probably really want to know your final
project if you may recall is worth
30% I broken this into 16% for your four
weekly milestones and 14% for what
you're submitt the final Monday night
and what you're doing in class Tuesday
morning during the exam period 16% for
the four weekly Milestones so 4% each
more or less like the 10
assignments all
good okay ah I guess that's it okay so
what I would suggest you do is when you
get some time go and have a look at this
list I might go through this list next
time we meet in class and uh can point
out a few things about some of those
easy and hard projects all good
okay all right good luck with ideation
this
week all right back to lecture material
we're talking about open problems in the
field things for which no one has a good
answer for yet maybe some of you might
come up with a good answer we're working
our way through trying to cross the
reality Gap arguably
the hardest and the least Wells solved
problem in robotics in general AI
designs a robot in simulation and we try
and realize it in the real world and it
doesn't work we fail to cross the
reality Gap first idea sprinkle some
noise in the simulation that tends to
help second idea connect a physics
engine to a 3D printer and just print as
many evolved robots as you can with the
hope that at least one of them crosses
the Gap and we started last time by
talking about my own humble attempt to
try and solve this problem the idea
behind the resilient machines project is
don't just evolve robots in a in a
physics
engine evolve the physics engine also to
more closely match the reality of
wherever your evolved robot is going to
end up so as we'll see in a moment when
we return to the resilient machines
project the resilient machines is not
just about Sim toore evolving in
simulation and transferring to reality
there is also real to sim we have a
physical robot that's moving around in
its environment it's collecting Intel
it's collecting data about what works
and what doesn't work in reality and
it's sending that data back and that raw
material is being used to
evolve simulators or physics engines to
more closely match the physical robot
and its surroundings that's the basic
intuition behind the resilient machines
project
okay okay so I think we got to here last
time forget about the EA this was this
clunky name we'll call it the resilient
machines project from here on out in the
resilient machines project unlike
anything you've seen in this class so
far there is not just one evolutionary
algorithm at work there are one one two
three evolutionary algorithms at work
the first evolutionary algorithm is
going to be evolving populations of
simulators we talked about what would be
an obvious Fitness function or Fitness
what would be the fitness of Any Given
simulator in that population what makes
for a better or worse
simulator
what makes for a bad simulator low
Fitness absolutely the fitness function
as you'll see in a moment is going to
measure how well the simulator matches
reality so we've got one evolutionary
algorithm that's evolving populations of
simulators we have a let me skip to the
third one for a moment come back to the
second one the third one should look
very familiar to you
this is an evolutionary algorithm that's
evolving a useful controller for a robot
in a
simulator but it's not an off-the-shelf
simulator it's evolving uh robot
controllers in the evolved
Simulator the evolved simulator singular
not
plural we have a whole population of
simulators here which one do we choose
from this population of evolving
simulators in which to evolve simulated
robots for those robots to do whatever
we want them to do as we usually
do you've got a whole choice you got a
whole population of evolved
simulators one the highest Fitness the
one with highest Fitness let's be
optimists and assume that the one that
has highest F Fitness is the most
accurate reflection of reality so that's
the one we should use for evolving robot
controllers so far so good two
evolutionary algorithms one evolving
simulators the other evolving virtual
robots in a simulator the best one from
population question what what vares
between simulators yeah we haven't said
that yet I'm trying to give you a 10,000
foot view of how this works we're going
to dive down into each of these three
evolutionary algorithms in a
moment okay the third one this is a
little
trickier uh we're going to use a third
evolutionary algorithm that's going to
evolve controllers for the robot so that
when the physical robot uses one of the
controllers from this third evolutionary
algorithm that physical robot is going
to liberate or discover new information
about the world it's going to act in a
way in reality that provides new raw
material for this
one this is a little trickier so we I
mention here
curiosity if you're learning an
instrument or you're learning a sport or
you're learning a new branch of
mathematics once you start to get a
little bit of the basics down you might
try some stuff out what would happen if
yeah get some new information from the
world okay we'll come back to this third
evolutionary algorithm towards the end
of this lecture but I want you to focus
on these two for a moment the shorthand
for the first evolutionary algorithm is
the estimator it's the thing that's
trying to estimate reality that's what a
that's what a physics engine does it
doesn't reflect reality as you all now
probably know full well it estimates
it's not perfect right the second
evolutionary algorithm I'll refer to as
the exploiter it's going to try and
exploit one of these evolved simulators
to get the behavior that we want for our
robot right we're trying to exploit this
evolved simulator to do some useful work
which is to evolve a robot that does
useful work for us in reality the third
one we're going to call exploration
because when this evolutionary algorithm
gives a controller to the physical Rob
robot the physical robot is going to do
something new in the world to explore
its world and get some new information
back for the
simulators everybody get this so far all
right okay so here we go we're going to
walk through the next 12 slides or so a
one run of the resilient machines
project you're going to see how these
three evolutionary algorithms uh fit
together so we're going to start with a
physical robot we already have our
physical robot it's this one and you'll
see a video of it uh in a
moment we don't know how to control it
NASA wants to send this to an
extraplanetary body and have it move
across the surface of that
extraplanetary body it's not quite clear
how it should should move it's even more
not clear how it should move if
something unexpected happens to this
machine yeah okay so we have this
physical robot we're going to start by
giving this physical robot a little bit
of information which is we're going to
tell it that at least at the beginning
to the best of our knowledge you are
made up of 1 2 3 4 5 6 7even 8 nine
Parts this physical robot uh does not
have a camera on board it cannot see its
own body it doesn't know we're just
giving a a little bit of
information this robot has no idea how
all these parts are put together this
robot or really The evolutionary
algorithm is going to discover how all
these nine pieces are fit together it's
going to
construct this evolutionary algorithm is
going to estimate or construct or
discover how all these parts are put
together here we go okay so at the very
beginning of this project the robot the
physical robot doesn't know how to move
it knows it's got nine parts doesn't
know how they fit together has
absolutely no information where should
it
start best thing to do is probably to
start in real the robot's going to do
something to generate a little bit of
data in the real world and we're going
to feed that small bit of real data back
in to start evolving the simulators to
explain that small bit of information
from The Real
World if you're this robot or you're a
baby you don't know much about your own
body you don't know how it works what
would you
do it's not a rhetorical question what
do you probably did do this way back at
the beginning you just don't
remember move around just move around
just do something at random okay which
is exactly what this robot
does does this robot look familiar
radially symmetric quadraped yeah Okay
so we've got these nine Parts as you can
see it's got these four legs r Al
arranged around its body each leg has a
shoulder and a knee the shoulder and the
knee each have one degree of Freedom so
the robot knows it's got nine parts and
it knows it has eight
Motors at this point the robot has
randomly chosen
to rotate Motors one and five sorry one
and five one and five down and rotate
all the others up
ah why can I not run this
now we had
it okay as I mentioned this robot has no
camera on board so it can't see what its
body looks like and it can't see how its
body moves this robot has only two
sensors on board it's got two vestibular
sensors you also o have two vestibular
sensors where are
they right so this robot has two
vestibular sensors in its main body
here and these two vestibular sensors
tell it how it can move how much it's
rotating left and right how much the
main body is tilting left and right and
how much the main body is tilting
forward and back so at the end of this
what is this
5c uh experim in the real world the
robot has run some random controller and
it's gotten back at the end of these 5
Seconds two floating Point numbers how
much it's tilted left or right and how
much it's tilted forward or
back okay I want you to try and put
yourself in the shoes of this robot I
lock you in a big metal box and in front
of you inside that metal box are eight
levers where you can pull some of those
levers you pull lever one and lever five
and suddenly you feel yourself tilt to
the right what do you conclude you're
sitting inside a machine what can you
conclude about that machine you've
pulled motor one and five down and
you've tilted to the right what does
that mean what does that tell
you doesn't tell you much tells you a
little bit of
information any ideas
the left side of my body is moving up
and I'm tilting to the right so if I
pulled Motors one and five down and the
left side of my body went up then where
must Motors one and five
be I pulled Motors one and five
down they're on my left side somewhere
yeah so we've got a little bit of
sensory motor information from The Real
World
the motor information is one and five
down and the resulting sensory
information is I tilt 30° to the right
everybody see that that's the kind of
sensory motor information this robot is
able to get from The Real World okay
it's not a lot of information so this
robot could start pulling other leevers
and doing all sorts of things but
remember we're doing this project for
NASA and this makes NASA very very
nervous this robot has high uncertainty
not even not just about even where it is
but how it's even put together it knows
very little if you know very little or
you're uncertain stay still do nothing
try a few things and then see if you can
make sense of that little bit of
information that you get maybe the robot
s sitting on the lip of a massive crater
and one more pull of the lever and
that's it for 10 billion taxpayer
dollars yeah very very gentle and slow
so now we've just visited real we're
going to do real to
sim this robot is going to stop moving
and it's going to communicate by
Bluetooth with an offboard computer and
it's going to send that information and
we're going to start up the first of the
three evolutionary algorithms which is
going to start to evolve
simulators which for the moment is the
simulated
robot I mentioned earlier that we're
evolving the physics engine as a whole
that's a bit of an approximation
ultimately that's what this project does
but for our purposes let's assume that
we have a base layer of a physics engine
but we're not quite sure how to
construct our robot in that physics
engine so we're evolving these virtual
robots in an underlying simulator so far
so good okay what's
happening as always I'm showing you a
video that's taking some snapshots over
evolutionary
time when I shot this video almost 20
years ago now I wasn't very good at
controlling the virtual camera inside
the physics engine so I want you to
mentally rotate the the virtual camera
and imagine the virtual camera is here
and pointing to the robot here virtual
cameras over here it's pointing at the
robot
here what's
happening what's the virtual robot
evolving to do trying to mimic the real
one
randoming it's trying to mimic what the
real robot did which was the real robot
just tilted 30° to the right so my
apologies if the virtual camera was here
pointing here you'd see that this green
block starts to rotate 30° to the right
everybody see that okay so over this
short snippet you're seeing the most fit
simulator in the population of evolving
simulators over about half an hour
running on a 2003 desktop computer and
you can see
that the estimation algorithm the
algorithm that's evolving these
simulators is getting more accurate it's
matching it's matching the physical
robot you'll notice that the robot is
discovering there's lots of different
ways it can put all these nine pieces
together and explain or match that real
data there isn't just one virtual body
that causes the robot to rotate 30
degrees to the right there's lots of
them what does the robot conclude at
point you're an infant you don't know
much about your body you've done
something your visual system hasn't
developed very well yet you feel
yourself rocked to the right you start
thinking in your head about how all your
body parts might be put together and you
can come up with lots of different
theories that explain the data Maybe I'm
put together like this maybe I'm put
together like
that what do you conclude you might be
doing this subliminally you don't know
you're doing this but what do you
conclude lots of different body plans
explain the same data set we got a
problem we need more data
because they can all be right I don't
yet know how my body's put together but
I can't be a snake I can't be a linear
arrangement of nine parts and and a
quadrip and a biped simultaneously I
can't be all these things whatever I am
I'm only one thing so I need more data
so we've gone from real to
sim now we're going to go back to
real okay so we go back to this robot
and this time I don't know why we're
having a problem with videos
here
okay we go back to sim and this time the
robot does
this now the robot is pulling some other
levers down and letting the other ones
rotate up and this time the robot tilts
10° to the left so so now the physical
robot has two pieces of data from The
Real World one and five down tilt 30
Dees to the right rotate seven down
seven down and now I tilt 10° to the
left what do you think the robot does at
point it's got several ideas about how
it's put together several ideas that
explained that first piece of data now
it's got two pieces P of data what does
the robot do
next do you
think does it Nar down the possibilities
from the first simulation say oh it
can't be this this or this because when
Ive like this it didn't go C go this C
absolutely it's going to narrow down
it's going to narrow down its
possibilities how is it going to narrow
down its possibilities
exactly can we be a little bit more
specific how does it
know possibly right that's an
explanation but how does it get to that
explanation how did it make the leap
that you just made just run the motor
and the motor of witch body plan
remember we have several different ones
all of them okay so we run all of them
remember we have this population of
virtual body plans we run each of them
with this new plan rotate motor 7 down
motor 7 is going to be a different
places on these different bodies so now
all those different bodies are going to
rotate in different
ways we need to recompute the fitness of
all of those those current virtual
bodies that we have how does the fitness
change for all of those virtual bodies
that we have in the population all of
them by definition explain the first
action we've just supplied all of them
with this second action rotate motor 7
down how does Fitness
change for these
bodies which which do well and which do
not do
well absolutely if in those virtual
bodies one of them actually manages to
rotate 10 degrees that one gets to
continue to enjoy High Fitness and the
fitness of all the others drops because
they all explained the first action or
they could replicate the first action in
simulation but they couldn't replicate
the repercussions of the second action
so their fitnesses drop and this one
just by chance is now more fit than
everyone else in the population
everybody see that so far if I lost
anyone okay what's the chance that among
all those bodies there was one or at
least one that happened to also describe
perfectly this second action that
actually did rotate 10 degrees to the
left
probably not very likely why should they
they own they were evolved to explain
the first action Mother Nature is a
satisficer not an Optimizer she
explained very well she came up with a
whole bunch of different body plans that
explained action one no reason why they
would explain action to so likely the
fitnesses of all of them would
drop what do we do now this seems
problematic we now have a whole bunch of
virtual bodies that have low Fitness
they're not explaining real very
well what do we
do you're a baby you know nothing about
your body you do something you update
your ideas about how you're put together
that explain that action now you've done
something else and suddenly H all the
ideas you had
what do you
do try again you could try
again but you have this new piece of
information that's unexplained so far
you could go get another
piece dangerous whether you're a baby or
a Rover sitting on an unknown
surface what do you
do you have a whole bunch of ideas about
your body that explain the first action
but not the second generate new ideas
generate new ideas we just continue the
first evolutionary algorithm keep
evolving
bodies not having much luck with my
videos this
morning which is a shame because we have
a lot of
them okay so what you're going to see in
a moment eventually is you're going to
see the first evolutionary algorithm
that's evolving these virtual bodies
just keep
going question yeah why chose to start
Evolution from
just great question why didn't we just
tell it how it's put together or vaguely
vaguely yeah how long did it take many
of you to build the quadruped in the
10th
assignment maybe not too long got to
figure out joint normals joint ranges
body
parts that's for a robot made up of
eight nine parts and eight joints The
Rovers that are up on Mars at the moment
have uh upwards of 3,000 moving
components it is not trivial even to
make an approximation so one of the
things we wanted to just try in this
experiment was how little aiori
information could you give this
algorithm for it to reconstruct a
simulation of the robot you're right in
this simple case we probably could have
just given it to it we wanted to see how
well it could
do okay so at this point in the
experiment we started in real we bounced
back to sim back to real for a second
time we're now back at sim a second time
so what happens in the resilient
machines project is we go back and forth
real Sim Sim to real real to sim to real
what you're watching in this actual
video is not the second attempt at Sim
this is actually the eighth attempt we'd
be here all day if we went through a
whole bunch of these so you'll have to
bear with me we've jumped ahead at this
point the physical robot has carried out
eight actions and at the start of this
video the robot has a whole bunch of
different bodies it's got a whole bunch
of different bodies like these that
explain
the seven actions but don't explain the
eth one they all fail terribly on the
eth
one at the end of this video after we've
continued to run this evolutionary
simulators we now have body plans that
explain all eight
actions why am I skipping ahead to the
eighth one there's something that
happened during this eth
attempt that made a big difference
what's
happening got data from
all uh good point we
um I think that's actually true now it
wasn't that it tried the first motor on
attempt one motor two on the second
attempt but just by chance on this
eighth attempt I think now it has
sufficient data from all the motors and
enough combinations so that
what
happens what does the robot discover
during this eth attempt to evolve
descriptions of itself you have four
legs two SE of absolutely so this is the
moment during this particular
evolutionary trial this experiment in
which the robot had its Eureka moment up
until this point it says there's I can
imagine lots of different ways of
putting together my nine parts that
explain all seven actions but now with
this eight eight action suddenly there
appears in the population one simulation
and you're going to see it briefly in a
moment in which the robot gets three out
of the four legs
right and that suddenly explains like
seven and a half actions it's suddenly
starting to understand everything that's
been happening 7 and a half and then a
few more mutations couple more
generations of this evolutionary
algorithm evolve that three-legged robot
into a four-legged robot and this one
suddenly starts to explain all eight
actions when we run all eight of those
controllers on that last virtual robot
that virtual robot tilts in all the ways
that the physical robot tilted during
those eight
actions absolutely so every time we're
running this evolutionary algorithm
Fitness tends to drop things get harder
and harder because each individual
virtual robot has to explain every
physical
action at this point in the experiment
we have eight pieces of data from The
Real World so we have to evaluate each
virtual robot eight
times we rotate motor one and five down
then rotate motor seven down and we see
how the virtual robot does in all of
those eight cases yeah you and the
fitness function is measuring how well
do you do at explaining or tilting the
same way the physical robot did in all
trials uh good point uh boy this is 20
years ago now we multiplied the tilts
together right so it has to do well at
all of them so he said goes up goes down
goes down so if we imagine at the
beginning when we were running Sim the
very first Time Fitness went up up up up
up because it was relatively easy for
The evolutionary algorithm to evolve
bodies that tilted 30 degrees to the
right no sweat easy Evolution Made Easy
progress we got this second piece of
data suddenly everyone in the population
could not explain this second so
everybody dropped but a little bit more
slowly This Time Fitness started to rise
again as we kept running this
evolutionary algorithm and finally we
started to get bodies that could explain
both experiences from The Real World up
down up down during this eighth trial
down down down up up four
legs okay we let this experiment
continue
here's the robot we're going to skip
ahead now this is the 16th trial this is
the physical robot performing its 16th
action and in this case it just happens
to rotate Motors in this way we take
that 16th piece from real and go back to
sim what do you think is happening at
Sim at this point at this point in Sim
we still have a population of virtual
bodies that are all good at explaining
all previous 15 actions and now it's got
a 16th one what do you think's happening
at this point are
all they're all still
good if I can play
apologies
this is what's happening in The
process The evolutionary algorithm
saying no problem you keep throwing you
keep giving me more and more information
World and nothing is changing in The
evolutionary algorithm we have this very
highly fit body plan and it looks all of
the body plans in this population they
all look like this they're all
explaining the data 9 10 11 12 13 14 15
16
no drop in Fitness this particular body
plan continues to describe everything
that's coming in from the physical
robot what can the robot conclude at
point remember the robot has no camera
it can't see itself but what can the
robot conclude
now we do another 16 actions 32 no
change they're all every virtual robot
in the population is a radially
symmetric four-legged
roboted it's converged the robot says I
know I look like this I can't actually
see myself but I've indirectly inferred
my reality this is it this is how I'm
put together the robot now has the
physical robot now has high certainty it
knows how it's put together
great okay we haven't even started the
NASA NASA Mission yet right this is just
tuning up or evolving a simulation of
the physical robot so now we start up
the second evolutionary
algorithm which you're more familiar
with is just going to evolve populations
of neural controllers for this robot the
one that just evolved so far so good
okay I won't even bother talking much
about this uh evolutionary algorithm you
know how this goes this is what it comes
up with at the end so we finished the
first evolutionary algorithm we're now
finishing the second evolutionary
algorithm second evolutionary algorithm
says this this neural controller if you
drop it into the physical robot I
predict this is what's going to happen
you're going to complete the mission
you're going to successfully walk from
the left side of the table to the right
side of the table I see some of you
smiling which is a good sign you're all
becoming good skeptical roboticists you
respect the Gap mind the
gap okay what
happens it's not perfect there's
definite
differences it works okay we crossed the
Gap so the reason we're talking about
this project is because of this part
right this is a way to cross the reality
Gap by tuning the Sim automatically
tuning the simulators to be closer to
reality any questions at this
point okay however we're being paid by
NASA so we can't finish here we need to
continue this experiment on to what NASA
actually carries cares about which is
methods of Last
Resort
so we sent the grad student who worked
on this project Victor we sent him in
with a screwdriver and he mechanically
separated the robot's uh front lower leg
did not remove the wiring so you're
inside the Box you still have your eight
levers from your perspective nothing has
changed from time to time this
particular robot carries out some of
those 16 actions that it performed
during the first evolutionary algorithm
when this robot rotated motor 7 down
before it rotated 10° to the left but
now when the robot repeats that action
it rotates motor 7 down it
rotates 5 degrees to the left it
performs the same action but gets a
different sensory result what does the
robot do at this
point like learn how to walk or
something it's got to relearn how to
walk but why does it bother relearning
how to walk it already knows how to walk
this its body plan has
changed maybe maybe it's lost apart
maybe it's stuck its foot into mud or
regolith or you know who knows what's
out there maybe it's walked onto the
surface of a crater and its environment
has changed this robot has no camera it
can't tell so something has changed
either I've changed or the world has
changed in this first experiment we
cheated we told the robot we said your
environment never changes you're always
walking across an acrylic sheet put on a
workbench so it knows that its
environment hasn't changed so it's body
must have changed so it goes back to the
first evolutionary
algorithm the one in which it thinks
that it's a four-legged robot the first
evolutionary algorithm that's
evolving virtual robots and it of those
16 actions it takes the action in which
motor 7 rotated down and replaces it
with this new data it says now when I
rotate motor 7 down I got this result so
it's got 15 of the original pieces of
data and the 16th is one new piece of
data what do you think happens to the
fitness of all the virtual
quadrupeds at this
point they all drop what do we do just
start running the first evolutionary
algorithm
again you'll see when this video repeats
in a moment the robot starts with the
quadrupedal description there and that
quadrupedal description is the one that
suffer to drop in Fitness so it's
rapidly bred out of the population and
replaced with some of
these I see some of you squinting in
confusion what's going on
here I haven't given you many details
about this evolutionary algorithm I just
told you that it's evolving populations
of virtual robots we've got a whole
bunch of different mutation operators in
here some of which add and remove Parts
they disconnect parts and connect them
together in new ways and some of the
mutation operators shrink or enlarge
some of the parts why the heck would we
include those kinds of mutation
operators you'll notice that the robot
actually briefly entertains the
notion that it's got a shrunken front
leg which actually gets kind of high
Fitness that's why it showed up briefly
in this video every every model that you
see here is explaining 15 15 and a half
16 of the actions some of these crazy
ideas are actually doing a pretty good
job
why
I feel like you youve needed that
originally because when we only it only
didn't know like how it was it's made up
it had no like relative way to know what
parts were bigger than others so uh
that's true it doesn't actually we also
didn't tell it how big these parts are
it's also trying to estimate that I kind
of glossed over that
detail it also turns out it's helpful
when the robot loses a part at least
it's helpful temporarily and it's rapid
ly replaced with a more accurate
description actually the correct
description which is that it's now a
three and a half legged robot rather
than a four-legged
robot you crash into the surface of an
extraplanetary body or you bounce down
on the surface a little bit faster than
you should have part of one of your legs
or a wheel breaks off some of the metal
shears and your leg is slightly bent you
step in some wet material sand grit
regolith and now you start carrying a
little bit of that material on your leg
it turns out that shrinking and
increasing the size of objects although
physically impossible in the real world
at least with robots that are made out
of metal that's impossible it actually
ends up estimating or approximating a
wide range of things that can actually
happen we didn't want to put particle
physics into this physics engine that's
very comput ation Al inefficient but a
lot of The Rovers that NASA cares about
are going to move over particulate
matter sand Clays all those kinds of
things it turns out we don't need to
simulate all that the robot can come up
with a pretty good explanation of itself
even if that internal description or
model is a little crazy doesn't actually
make
sense when we published this paper in
science back in 2006 in the in next
week's issue there was a response to
this paper from a dream
psychologist said this is what we in the
dream Community have been saying all
along there's a reason why you have
crazy dreams that's your brain trying to
fit your experiences and the way you
interaction interact with the world
trying to come up with a better
description of what you are and aren't
capable of what others are and aren't
capable of and one path to get to the
right explanation or a good explanation
is often through Crazy Land through
things that can't possibly be true in
reality but they make a strange kind of
sense right I imagine you've all had
this experience you wake up in the
morning you're like wow that was such a
crazy dream but actually there were
parts of it that were metaphorical or
they kind of led me to a more literal
understanding of what happened last week
who knows right this is evolutionary
robotics but at least for the dream
psychology Community they found this
kind of interesting
it might provide an idea for the
Adaptive advantage of dreaming who knows
there you go okay all right for our back
to our back to reality actually not back
to reality yet we're still in simulation
so the robot says aha now I know that
I'm a three and a half legged robot what
do I do now what's the next step in the
experiment what do we do what does a
robot do
it's got to try and walk so it takes
that neural
controller that caused the four-legged
robot to walk takes that evolved
controller and reruns it on the three
and a half legged robot what do you
think
happens Fitness is going to drop in the
second evolutionary algorithm where
we're revolving neural controllers all
those neural controllers drop in Fitness
because they were all good at
controlling a four-legged robot they're
probably terrible at controlling a three
and a half legged robot so we run that
second evolutionary algorithm we keep it
going and this neural controller
evolves you can go back and compare
these but this neural controller causes
the three-legged robot to move in a very
different way than the four-legged robot
does
what's going
on lip it's limping all
right the mission is to move from the
left side of the table to the right side
of the table how are we
doing does it it does it right maybe
pervers L it does it by walking in a
semicircle so that when it ends it's
facing backwards although this is a
radially symmetric robot so maybe there
is no backwards maybe it's not perverse
we didn't say anything about how it
should move from left to right just that
it should move from left to right for
those of you that are evolving quadrip
heads at the moment you probably got
things as crazy if not crazier than this
okay it works what do we do we take this
evolved controller and run it
on
sorry on our physical three and a half
legged
robot and we've just rescued several
million of US taxpayer dollars from
being flushed down the drain it's able
to this robot at this point has
diagnosed what's gone
wrong it's got diagnosed what's gone
wrong it's come up with a accurate
description of itself it knows it's lost
half of its front leg and it's come up
with a way to recover without the help
of Mission Control because Mission
Control also has no idea what's going on
okay we've got uh one minute left so let
me just set the stage for next time what
we just talked about was bouncing back
and forth between the estimation
algorithm which is trying to estimate
the state or the makeup of the robot's
body and the exploitation algorithm
which is trying to exploit the best
evolved simulator so far to get the
robot to do whatever it is we want it to
do how did the robot actually choose
these 16 actions I didn't actually tell
you how it came up with these 16 things
to try I will tell you it didn't come up
with random ideas it used a third
evolutionary algorithm to evolve these
16 actions we'll talk about that next
time you have a quiz due tonight you are
now working on your first weekly report
see you all on
Thursday


--- Evolutionary Robotics course. Lecture 20： The Transferability project..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone happy snow
day um we are going to jump right back
into lectures uh but just as a reminder
all of the uh undergraduates and grad
those taking the course for graduate
credit you are both working on your
first weekly report in which you're
going to map out for us how you're going
to approach your final projects uh final
projects over the next four weeks uh if
you're coming up with an idea of your
own rather than picking something from
the predefined list remember to please
come see Fria the TA or
myself uh to vet the idea okay so uh
back to lecture material we're working
our way through uh open problems in the
field and we've been uh wrestling with
arguably the hardest problem in the
field which is to cross the reality Gap
we looked at the original formulation
back in the 90s we looked at the Golem
pro project in 2000 and we are just
about to finish lecture 17 which was my
own attempt to try and cross the reality
Gap uh back in
2006 where the idea was to evolve
simulations that more closely match the
robot's reality uh in this particular
experiment the the simulators are trying
to match basically the body of the robot
so we're evolving not necessarily the
simulator itself but the simulated robot
so that its body more closely matches uh
the
robots as you may remember from last
time I told you that the resilient
machines project contains three
different evolutionary algorithms the
first one evolves populations of
simulations the second evolutionary
algorithm uses the most fit uh
simulation you can see that this
simulation is more fit than these three
this one more closely matches the
robot's
reality the second evolutionary
algorithm evolves neural controllers uh
inside this evolved simulation where the
fitness function is whatever we actually
want the robot to do which is surprise
surprise to move from the left side of
the table to the right side of the
table okay so just to refresh your
memory and build uh help to strengthen
your intuition about how all this works
I want you to think about the
phenotype in this first evolutionary
algorithm the genotype is some data
structure which we don't need to talk
about
here the phenotype is how all the parts
are put together how big or small these
parts are basically the robot is trying
to construct in a simulation a
description of its own body what is the
fitness of any one of these bodies in
the simulator the simulator
itself the fitness is calculated as the
similarity between the simulated robots
sensor values remember that this robot
has two vestibular sensors on board one
that measures how much the main the
robot's main body tilts left and right
and the second vestibular sensor
measures how much the robot tilts
forward and back so two
numbers the physical robot collects two
physical sensor readings how much it
tilted left and right or forward and
back after moving and each of these four
simulated robots also collects two
numbers which is how much its main body
tilted we take the difference between
the simulated and physical robots sensor
value
and fitness tries to reduce this value
the more similar uh the more similar
virtual and real simulated and real
sensor data is the more fit that
simulator is
okay going to come back we'll come back
to this green one in a moment I've been
holding off on this one for a little
bit in the uh in the third one uh this
is the more one that's probably more
familiar to you the phenotype is the
robot neural controller and fitness is
how far does that neural controller get
the virtual robot to move okay so let's
back up for a moment and think about
this third evolutionary algorithm you
remember that when we were watching the
videos last time the physical robot
would do something then the simulated
the simulators would be evolved to match
it then the new physical robot would do
something else and the simulators would
be re-evolved or evolve further to
explain the first and the second
experience of the
robot but I haven't told you yet how
that robot chooses how to move it turns
out that there are better or worse ways
that this robot can move to explore its
own
body you might remember uh from the
videos I showed last time that the very
first thing the robot did was to rotate
Motors one and five down its left uh its
left knee its left hip Motors one and
five down lift all the others up then it
evolved uh it evolved virtual bodies to
uh explain that experience what is the
worst possible action the robot can
perform next to learn more about its own
body give you a moment to think about
that the worst possible thing the robot
could do would be to perform exactly the
same action rotate Motors one and five
down and collect that data now that's
not always true from time to time it
makes sense to repeat previous
actions just to test whether something
has changed like for example the robot's
leg has broken off and I showed you in
an example of that last time but for the
moment we're going to assume that that
the robot's relatively sure things are
unchanging It's relatively safe in that
case obviously doing the same action
over and over again is the worst
possible thing you could do the best
possible thing to do is to explore is to
try something new but what exactly do we
mean by to try something new it could be
just something other than rotate Motors
one and five down and there's obviously
a ton of things that it could
do some of those things may be a little
bit redundant it may end up uh
experiencing a familiar sensation how do
we truly ensure that the robot does
something that extracts new information
about itself from the
world here's how I I'm going to explain
that by now talking about this third
evolutionary algorithm called
exploration which is going to evolve
ways in which the physical robot should
move next so the robot is going to quote
unquote think using this third
evolutionary algorithm about what to do
next where the goal about what to do
next is to make sure it gets new sensory
information
that helps it improve its understanding
of
itself okay let's imagine that at this
par particular point in time the
physical robot has performed performed a
couple actions it's got a fair bit of
experience and it's evolved these four
different simulators these four
different
understandings of itself and as you can
see one of them actually is correct and
the other three are wrong but remember
the robot doesn't have a camera it can't
see itself it it doesn't know that this
one is correct these four let's assume
for now are all able to reproduce the
sensations of this robot when we Supply
however many actions the physical robot
has performed to these virtual robots
every time this physical robot moved in
a particular way when we cause any of
these four to move with that action that
virtual robot generates the same sensory
information so the robot is looking for
a way to try and figure out which of any
of these is correct or maybe determine
that none of them are correct they
should all be thrown away and rep
replaced with something better so what
should the robot do next to investigate
or figure out where and where these uh
models of itself are wrong okay let's
imagine a the robot uh generates some
random neural controller it thinks up
some random way to move move the
physical robot doesn't carry it out yet
so the robot is thinking to itself I
wonder what would happen if I ran this
neural
controller the robot takes that neural
controller it's perhaps random and it
drops it in to each of the four under
models it has of itself at the moment so
these four different bodies are running
exactly the same
brain but as you can see with these
cartoon green arrows the way in which
each of these four virtual robots moves
is very different and remember we're
going to collect vestibular Sensation
from this main block we're getting back
two numbers from each of these green
blocks how much the robot tilts left and
right and how much it tilts forward and
back you can see that in this case all
of the green blocks are tilting in
ways in essence these are the robots
four self models it's four
understandings of itself saying okay if
you carry out this if you if you run
this neural controller you're going to
move in this way this self model says no
no no you're crazy you're not going to
move like this you're going to move like
this the third model says you're both
nuts you're both wrong if we run this
neural controller this is what's going
to if he runs this neural controller
this is what's going to happen and so on
these self models disagree in their
predictions about sensory data if the
physical robot runs it they disagree in
their predictions about the sensory
repercussions of that
action that's a lot I'll give you a
minute to soak that
in so in the exploration algorithm over
here every time the physical robot is
about to move it's going to run this
algorithm for a bit using the current
self models
to figure out a good new way to move if
all of these four self models disagree
about what's going to happen then if the
physical robot actually runs that neural
controller they can't all be right some
of them are going to be wrong the
physical vestibular sensation uh
experienced by the robot is going to
have a mismatch with the vestibular
sensation of some of these models and in
this case these three models which we
know are wrong are probably going to
drop in Fitness and this one be because
we know that this self model is very
close to the robot's actual
self there is going to be a good match
between this vestibular sensation and
this vestibular sensation so the fitness
of this individual probably will not
change the fitness of these three will
drop when the robot goes back to
evolving models of itself and this
model will produce randomly modified
copies of itself and very quickly this
population is going to be filled with
slightly different versions of
this okay so this exploration uh
algorithm is evolving uh it's evolving
actions or things to do it's evolving a
set of synaptic weights for a controller
that causes the robot to act and the
fitness of each of these individual
neural controllers is the amount of
prediction disagreement among the four
self models or however many self models
there are this is all done in
simulation okay um this has an
interesting connection to developmental
psychology developmental psychology
being the study of children or how
children develop into adults um if
you've ever spent any time around a baby
or a toddler you will know that they are
always moving and they never seem to
repeat the same action twice they're
always doing crazy things putting stuff
in their mouths hitting their brothers
and sisters with a toy Mallet you you
name it this is known as motor babbling
this is the idea that a newborn baby or
a newborn organism is trying to figure
out how to operate this fantastically
complicated machine and they're randomly
trying out all sorts of things if you go
back and watch the videos in this
lecture series of just the physical
robot all the actions that it performs
which are being sent to it by the
exploration algorithm if you watch all
the actions that that robot performs
they all look different they kind you
don't really see any pattern to them or
repetition to them they look random but
as you now know those actions are not
chosen at random these actions are
actually carefully designed Inside the
Mind of the robot if you
like to break its own predictions it has
ideas about what's going to happen and
it's trying out things for which it's
least certain about what's going to
happen when we wrote this paper that
suggested to us U an interesting idea
which has yet to be confirmed or denied
in actual human children which is maybe
children are not actually acting
randomly they are actually choosing very
very carefully what to do which is an
action designed to try and break or
disprove their current understandings of
themselves just a just an
aside okay all right we are going to
finish the resilient machines uh
discussion here and returning to the
schedule for a moment we are going to
now uh talk about the fourth and final
attempt to cross the reality Gap that
we're going to look at in this class as
I mentioned there are many many attempts
to do this um we're going to look at
this one here which has uh some
particularly interesting aspects that
might be useful for your final project
okay
okay so this is known as the
transferability project for a very good
reason what they're going to try and do
now is evolve controllers in simulation
uh on a virtual robot like we've seen
many times before and then send some of
those evolved controllers to a physical
robot but they're going to evolve these
controllers not just to maximize the
movement of the virtual robot they're
going to try and Maxim the fitness
function is also going to try and
maximize
transferability of a controller how well
it will transfer to reality if we send
it to reality so the question that the
authors of this study started with
is could the transferability of a
controller be added to a fitness
function that's their question like
every good question in science it
immediately breeds a whole bunch of
other questions the first one that might
have occurred to you as you first saw
this question is what exactly do you
mean by
transferability okay we'll come back to
that uh how to define it in a
moment if we're going to try and add
transferability to a controller that
means we're going to have two we're
going to compute two values in our
fitness function one is going to compute
the desired Behavior which as you're
going to see in a moment surprise
surprise how far the robot moves from
the left to the right so we're going One
Fitness term is going to reward for
displacement the second uh term in the
fitness function is going to reward for
transferability which the authors Define
as the similarity between the simulated
and real Behavior so if the if the
simulated robot moves like this and the
physical robot moves like this uh low
transferability if the simulated robot
moves like this and the physical robot
moves like this High transferability
pretty pretty straightforward right so
we've got these two terms that we're
going to uh Evol uh these two terms are
going to be used to compute the quality
of a given set of synaptic weights for a
neural controller in an evolving
population of neural
controllers okay instead of multiplying
these two terms together or adding them
together in the way that we've seen many
times now in this course they're going
to do something different this is known
as moo uh an easily to easy to remember
adjective which stands for
multi-objective
optimization what the uh the best way to
understand multiobjective optimization
is to understand it geometrically so
here we go we're going to create a
two-dimensional plane and we're going to
Define two different axes the horiz Al
axis down here is going to represent how
transferable a given controller
is and the vertical axis is going to
represent how well that controller
causes the robot to move from left to
right the behavior that we want imagine
we have a population made up of 1 2 3 4
5 6 7 8 9 10 11 12 a population of 12
controllers so we've got a population of
12 vectors where each Vector encodes
synaptic weights for a neural controller
we can take each of those 12 controllers
drop it into the virtual robot evaluate
that virtual robot in simulation and
measure the behavior of that virtual
robot how far does that robot move and
we can plot uh the height we can drop
that point at a height corresponding to
how well that controller causes the
robot to move so this controller which
is high in the plot caused the robot to
move uh a far distance from left to
right and this point this controller
down here caused the robot to barely
virtual robot to move barely at
all if we can also measure the
it transfers from simulation to
reality we can plot that transferability
on the horizontal axis so let's imagine
for the moment we have these 12
controllers we've evaluated each of them
on the virtual robot we know how well
they uh cause the robot to exhibit the
behavior we want we take each of those
12
controllers and we evaluate it on the
physical robot as well and we look at
the Gap in Behavior between the virtual
robot and the physical robot if there is
uh if there is a big gap so up here we
know that that controller caused the
virtual robot to move a far distance
distance when we transferred it to the
physical robot let's assume for the
robot for the moment the physical robot
didn't move at all there's a big gap
between simulated and physical Behavior
which means
low
transferability this one this controller
out here caused the robot to barely move
at all caused the virtual robot to move
barely at all and when we transfer it to
reality let's assume the physical robot
also did not move very much there's a
good match there's a low difference
between the behavior of the simulated
and physical robot we have high
transferability if we do that for all 12
of the controllers we get a picture that
looks like this some are good at
objective two and poor at objective one
some are good at objective one but poor
at objective two some are pretty bad at
both this one is kind of okay at both
everybody see that
now you might already be wondering if
we're trans if we need to compute the
transferability of every
controller and in order to do that we
have to send every controller to the
physical robot why are we using
simulation at all why don't we just
evaluate every controller on the
physical robot it's a good question um
that's not what the what the authors did
they came up with a way of estimating
transferability for each controller
after it had been run on the simulated
robot without having to send it to the
physical
robot I'll come back to that in a moment
but I want us to focus on
multi-objective optimization because
some of you in your final project are
already thinking about multiple terms
for your Fitness function if you want uh
if you want a robot to jump one
objective might be for uh all four feet
to spend as little time on the ground as
possible
and the second objective might be height
of the main body of the robot you can
actually formulate two different
objectives for
jumping and you could uh evolve jumping
for your robot in a multi-objective
optimization way okay so let's come back
to move for a moment we'll come back to
how to actually compute transferability
for a controller before we send it to
reality but for now let's let's assume
we're just able to compute
transferability you can see that we now
have these 12 initially random neural
controllers spread throughout this
two-dimensional space in an evolutionary
algorithm we now need to delete the ones
that have low Fitness and make randomly
modified copies of the surviving
controllers given this picture which
controllers do you think we delete in
this case I'll give you a moment to
think about
this
the way we choose which ones are to be
deleted in a multi-objective
optimization method is to find all of
the controllers which are dominated what
do we mean by dominated a dominated
solution is one in which there is one at
least one other controller in the
population that is better at both
objectives for example if we look at
this controller down here we see this
controller here is is more transferable
it's further to the right than this one
and this controller also produces more
of the desired behavior that we want
this controller is higher than this
controller so this particular controller
is
dominated by this controller so we would
delete this
controller in turn if we now look if we
now come to this controller and try and
decide whether this one should be
deleted we see that it is also dominated
it's dominated by this one this one is
both more transferable is better in
terms of objective one and it's better
at objective two than this one so this
this controller dominates this one this
one is also dominated we would delete
this one you can probably see where this
going this one is dominated by this one
so we delete this one and
now there is for this controller there
is no other controller that is better at
objective one and objective two there is
no controller that is above and to the
right of this controller so this
controller is non
dominated you can probably do this by
eye or better to even do this with your
cursor by picking one and finding
another one that dominates it you can
probably go through and determine who is
about to be deleted in this population
and who's going to
survive Okay so so here are all the ones
that are dominated and here are all the
ones that are
non-dominated uh when I made this slide
originally I made a mistake one of them
is mislabeled and I'll give you a moment
to see if you can figure it
out it's this one this one is actually
non-dominated you'll notice that if you
look at this one there is no other
controller that is above and to the
right of this controller okay so you'll
see the I've connected all of these
non-dominated Solutions with a line
there should really be a line going from
this one to this one and then from this
one to this one okay okay so we've
deleted all of these and we have 1 two 3
four five six seven survivors and we
have five empty slots in our population
how do we know now choose who to uh who
how who do we choose sorry among these 1
2 3 4 5 6 6 seven among these seven
parents how do we choose which one gets
to produce a child we do it at random
among all of these seven
individuals none of them are better than
any others for every single one and you
can do that by walking along this line
uh they're all for each of them there's
another one that's better at one
objective but worse at the other
objective so this is what's a little bit
confusing about move for most people
your evolutionary algorithms and all the
evolutionary algorithms we've seen so
far we compute the fitness for
everything in the population and then
there is always a champion there is one
individual in the population that has
the highest Fitness there is the best
solution so far in moo that's usually
not true they're usually a subset of
solutions that are all uh optimal um
this is known as parito uh uh parito
optimality
you can Google it p a r e t
o Paro
optimality okay so we choose one of
these seven parents at random with
uniform uh with uniform probability so
any of the seven has an equal chance of
being chosen we choose it we copy all
the synaptic weights of that neural
controller into a new child controller
to fill one of the five empty slots and
as we're copying the synaptic weights we
make a few random mod mod ified changes
to the
child so now we filled one of the five
slots we go back and pick another one of
the seven parents at random uh it's
allowed to produce a child which fills
fills a second uh slot and we keep going
until we now have five new children and
we have the original Seven
parents in my example here let's imagine
that this particular parent produced
this child when we got this child we
when we've created all five children and
we evaluated this child it had this
transferability and this ability
to uh generate the desired behavior in
the virtual robot you'll notice that
this child is a little above and to the
right of its
parent so when we come to the end of
this new generation in which we've just
evaluated all five of these new children
what do you think happens now which
individuals are
deleted
obviously this child dominates its
parent so this parent was non-dominated
but it was non-dominated it's now become
dominated and it is in turn deleted and
if you now imagine running this
multi-objective optimization over time
you can imagine this Pito front p a r e
t o this Paro
front uh pero is the name of the
economist actually who came up with this
idea uh you can imagine this parito
front starts to March up and to the
right we basically end up with a line of
non-dominated solutions up here all of
which are pretty good at
transferability and pretty good at
Behavior okay so far so good
okay okay here's some actual data from
the experiment uh you'll notice there's
a number of differences from my
simplified cartoon version here and the
real thing um we've got the the vertical
axis is still the same as over here
they're measuring for each one of these
each one of these points uh these
circles and Crosses each one represents
an individual neural controller the
height of that point represents uh the
distance covered by the by the virtual
robot in simulation measured uh in me
meters and we're trying to maximize that
on the horizontal axis here they're
plotting uh simulation to reality
disparity and we're trying to minimize
that so we're trying to minimize the gap
or the disparity between uh the
simulated robots Behavior and the real
robots Behavior better controllers are
further to the left there's less
disparity between the behavior of the
simulated robot for that controller and
the behavior behavior of the physical
robot using sorry using that
controller okay so in this case here
we're trying to maximize transferability
and a Max maximize displacement so we're
trying to push up and to the right here
we're trying to maximize displacement
and
minimize uh the Gap the Sim to real Gap
so now optimization is trying to push up
and to the left everybody see that okay
again I haven't really told you exactly
how they compute uh this disparity yet
but for our purposes just imagine they
send it from simulation to
reality okay let's have a look at all
the X's first you can see all the X's
down
here um these are all the controllers at
generation I so this is partway through
an evolutionary process you can see most
of the X's are hugging the bottom right
part of the the panel these aren't doing
very well at all they have high
disparity and they're not causing the
simulated robot to move very much when
we go from crosses to circles black and
white we now the circles all represent
controllers in the Next Generation in
the i+ one
generation first thing you should notice
is that the circles tend to be higher
and to the left of the ex's so the
optimization has made a little bit of
progress here and again you'll see that
the like in my cartoon here dominated
Solutions are shown as white circles and
non-dominated solutions are shown as
black
circles you'll now notice the black
circles describe a Paro front these are
the non-dominated
controllers and all the dominated
controllers are behind are below and to
the right of that line so what this plot
is showing us as a whole is that
evolution is starting to make progress
it's starting to evolve better
controllers controllers that cause the
robot to do more of what we want and
they're more transferable controllers
these controllers are narrowing the gap
between simulation and
reality okay I think in the interest of
time I'm going to skip over I'm going to
skip over this plot okay okay so let's
come back to uh where this experiment is
going we just had a look at the
particular kind of evolutionary
algorithm they're going to use to do
this they're going to evolve uh they're
going to evolve controllers to be
transferable and reward for the desired
Behavior but how do we compute
transferability to compute
transferability at the moment all we
know is the only way to do this for each
for each controller is to evaluate each
one on the real robot it's a bit of a
problem so how do we solve this problem
how how do we compute transferability of
a controller before we send it to
reality okay here's how the authors
solved this problem let's imagine uh
we're starting this evolutionary
algorithm we have a population of random
controllers in this case uh uh we can
see them all here we take each one of
these random controllers and we drop it
into the virtual robot one after the
other and measure how well that
controller causes the robot to move so
we have the heights for all of these
gray
points okay we do not know how well any
of these controllers transfer from
simulation to reality so geometrically
let's imagine that they all collapse
down uh onto a one-dimensional line so
the only thing we have is the height of
these points we do not know their
horizontal position in this
two-dimensional plane so look at all the
gray dots lined up on the black vertical
line here you can take one of these 12
controllers 1 2 3 4 5 6 7 8 9 10 11 12
you can take one of these 12 random
controllers and send it to the physical
robot to measure that controller's
actual transferability which one do you
send okay hopefully uh like me you're an
optimist and you choose this one this is
the one that's causing the virtual robot
to exhibit more of what you actually
want so let's give it a try maybe the
reality Gap is not so wide in whatever
application this
is okay so here we go we're going to
take this
one
okay here it is in simulation as you can
see it causes the robot to move from
left to right
maybe not in the way the investigators
were originally expecting but does what
we
want okay as you can see on the right
they're now going to take this one
random neural controller and drop it
into the physical
robot
okay how do we
do as you can see here we failed to
cross the Gap this particular neural
controller fell into the Gap so this
controller is good at objective two the
vertical axis that I showed you before
it extracts a lot of the desired
behavior in Sim but on the
transferability axis it's far to the far
to the left it has low
transferability okay so going back to
our evolutionary algorithm uh we now
take this uh neural controller and we
move it far to the left we now know the
actual transferability for this
controller which one do you send
next let's imagine you get to send
another
one you're probably not going to send
this one because this controller barely
causes the virtual robot to move at all
so even if it's transfer has high
transferability who cares it's not
useful to
us you might also not want to transfer
this one because this one this one is
actually quite close to this one at
least in terms of behavior so it's
possible that this neural controller
it's causing the robot to move in a
similar way that doesn't transfer well
to reality so maybe want to stay away
from this stuff and maybe we want to
stay away from this stuff and maybe we
take this one or maybe we take this
one okay so the idea here the intuition
that you're going to see is they're
going to start to estimate the
transferability of the other controllers
based on how similar the behavior is
produced by that controller compared to
controllers that have been sent to
reality and for which we know their
transferability so said more simply
controllers that are closer to low to
controllers that have low
transferability we're going to estimate
their transferability is
low and controllers that are far from
controllers we've sent to reality we're
going to assume we know relatively
little we're not going to be able to
estimate their transferability very
well okay let's see how they did this
okay so we're going to uh the solution
to uh Computing transferability for our
evolving controllers before we send them
to reality is to estimate each of their
transfer abilities based on how similar
they are to controllers we've already
tested on the physical
robot okay this raises yet another
problem which is how do you measure the
similarity between Behavior so going
back to the cartoon here for a moment
just because this controller produced uh
about the same Fitness value is this one
do we actually know how similar these
behaviors are we need a way to measure
similarity between Behavior not just
similarity between Fitness Fitness is
just a single number how far the robot
traveled we'd like to actually compare
how two Ro how the robot moves when it's
running two different controllers this
one and this one for
example okay so let's see how they
Define similarity between two behaviors
they're going to Define similarity by
defining a distance measure between any
two
behaviors so whatever this distance
measure is if we take two behaviors
produced by two different controllers
and the distance between them is zero
that means the robot exhib exhibits
identical
Behavior Uh when controlled by those two
controllers okay before we can define a
distance measure for behaviors we need
to define the behaviors themselves in
this case in this experiment uh instead
of measuring every single sensor value
at every time step they came up with
something that was a little simpler they
boiled down the movement of uh of the
robot into three floating Point numbers
F1 F2 and
F3 F1 the total distance traveled by the
robot F2 is the mean height the average
height of the robot during
travel and uh Fitness three was the
final orientation of the robot you might
remember from last time I showed you the
injured uh quadraped that started facing
forward and as it walked it ended by
facing backwards so they're going to
compute the final or horizontal
orientation of the robot uh in radians
it's just a third number so we've got a
neural controller which is defined as a
whole bunch of floating Point values the
synaptic
weights we take that Vector label the
neural controller of the robot let the
robot do its thing in simulation and as
it's doing its thing in simulation we
measure these three numbers how far does
the robot traveled what's its mean
height and what's its final
orientation we can then compute the
distance between any two behaviors by
taking the ukian distance between these
uh between two length three vectors
that's what's shown down here so the
behavioral distance between controller
one and controller two is in this
experiment defined as the ukian distance
between B1 this behavioral vector and B2
yeah since this is a a triplet of
numbers you can think of these three
numbers uh as Xyz coordinates so you can
think of a controller producing a
behavior that sits somewhere in
threedimensional space so controller one
produces B1 that sits here in
three-dimensional space controller two
produces B2 which sits here in
threedimensional space and the
behavioral distance is the ukian
distance between these two points in
three-dimensional space that's what it
is yeah if these two points B1 and B2
sit right on top of one
another those two controllers produced
identical behavior in the robot that
behavior could be in both cases the
robot sits still or in both cases the
robot does this or in both cases the
robot does this doesn't really matter
yeah so we're going to see as we move
forward we're going to see a lot of C's
and B's remember C subi is going to is
going to reference the ath controller in
the population and B subi is going to
denote the behavior produced by that
controller okay so now that we've Define
the distance between any two behaviors
how do we Define the transferability of
a single controller eye I give you a
moment to think about
that
we're going to define the
transferability of c subi as a function
of uh as the
controller
uh as the as the behavioral distance
between the the behavioral distance
between the behavior produced by
controller eye and simulation and the
behavior produced by controller I in
reality
yeah remember be behavioral distance
between two controllers behavioral
distance between the same controller but
evaluated in two different robots the
simulated robot and the real
robot okay and we're going to define the
transferability of C subi as the minus
the negative of that give you a moment
to think about why the negative of
behavioral distance is a distance metric
every distance metric by definition is a
positive number a negative distance is
an IL defined term so everything in this
particular term here uh behavioral
distance is always a positive number and
the more positive that number is the
bigger the distance or the bigger the
difference between the two
behaviors so we can set transferability
to
the minus of that the more negative the
right hand side of this equation is the
more uh sorry the uh the Le sorry the
less neg the less
negative this uh this thing is to the
right of the equal sign the more
transferable it is so because behavioral
distance is always positive we know that
whenever we compute this thing it's
always going to be negative and the more
negative it is the bigger the Gap the
bigger the reality Gap so
transferability is trying to minimize
that Gap get it as close to zero as
possible okay some of these sort of
double negatives a negative difference
between things yeah we want this thing
to be as high as possible to be as uh
leastly leastly leastly negative as
possible okay again we're back to uh
Computing transferability of a
controller based on simulation and
reality so this is only we're going to
use this we're going to use this
equation only for those controllers that
we have sent from simulation to
reality okay
so as I mentioned before uh imagine we
have 12 controllers and we take the best
one and we send it to reality and so now
we know the transferability of that one
neural controller we need to
estimate the transferability of the
remaining 11 neural controllers that we
have not yet sent to reality how do we
do that well let's go to the second
controller the first of the 11 that
we're going to try and estimate
transferability for we can't compute
transferability for it because we
haven't sent it to reality yet we're
going to estimate it uh in the following
way assume this controller is called
called
C we're going to compute the behavioral
distance between controller C and
controller C where controller CI belongs
to the set of already transferred
controllers at this point this set CT
contains only one member it contains the
control that the best controller the one
that we sent to reality so we're
Computing the behavioral distance
between C take C and drop it into the
virtual
robot and compute and watch Its Behavior
and we have we also know uh how C subi
the one that we sent to reality we know
how that causes the virtual robot to
move so we can compute the behavioral
distance between C and C
subi and we're going to sum up these
behavioral
distances we're going to sum up these
behavioral distances over all the ones
that we've sent to reality which the
moment is only one we're going to
actually take a weighted sum we're going
to sum up the transferability how
transferable was C subi the one that we
sent to reality how well did it cross
the Gap and we're going to add it to our
estimate of the transferability of C
we're going to we're going to decrease
the weight of this particular weighted
sum by the behavioral distance between C
and C subi
so we're summing up all the transfer
abilities we're basically taking the
average of all the transferability of
all the controllers we've sent to
reality so if we're trying to figure out
how transferable this one is we can look
at all the ones we've sent so far and
say our best guess for the
transferability of C is the average
transferability of all the ones we've
sent to reality so far that's okay
that's a good guess but we can do better
instead of just taking the average we
can take the weighted average the
influence on the weighted average is
going to be modulated by how close C
subi is to
C the more similar the behavior produced
by C subi and C the greater this weight
we're dividing by behavioral distance so
going back to my cartoon for a
moment this one if this one actually had
been uh sorry if we're trying to compute
the transferability of this one the
transferability of this one has a
greater weight or greater influence on
the estimate of transferability for this
one then for example this one if we did
send it to
okay takes a moment to wrap your mind
around that right here's a here's a
geometric way of thinking about it we're
trying to estimate we're trying to
estimate the transferability of C we
have a bunch of other C's out there that
have been transferred to reality and
they have different transfer abilities
if one is close and that one had low
transferability then I I'm going to
estimate that I have low
transferability one that's very far from
me that had high transferability that
might increase my my estimate of my own
transferability a little bit but only a
little bit because that other one is far
from me it's behaviorally
distant okay so we can use this equation
to estimate the
transferability of this one this one
this one this one this one this one this
one and using that estimate you would
get something that kind of looks like
this this one this controller that's
close to this one and estimate it has a
close it has a a similar transferability
this one is probably not going to differ
that much from the
mean okay
Okay so we've in my cartoon example we
took that really good controller sent it
to reality it had terrible
transferability we've got 11 remaining
which one would you pick we've estimated
the transferability of all of
these which one do you send
next the intuition of the
authors
is that you're going to send the
controller which is most different from
those in the current population so among
the remaining 11 you're going to pick
the one out of those 11 that's as far
from the other 11 controllers in the
population as possible or that's most
different from the others in the
population what do we mean by most
different how do we know for any given
controller in the population how
different it is from the other 11 we can
use behavioral distance again okay so
we're trying to determine how different
C is one of the 12 controllers in the
population so we're going to compare it
we're going to compare it against all
the other controllers that we've sent to
reality so far and we're looking we're
going to set the diversity of C to be
the minimum behavioral distance of C
from all those we've transferred to
reality and we're going to call this
diversity so let's go back to my cartoon
for a
moment in this case we've sent this one
to reality we visit this one and we
compute its behavioral distance to this
one and that distance is very very very
small let's assume we send this one to
reality also and it ends up with a high
transferability so we've we have we have
this one here which we've transferred to
reality we have this one down here which
we've transferred to reality
sorry about jumping around
here we're taking we're trying to
compute the diversity of C so we want to
take the minimum behavioral distance and
set that as the diversity of
C this one has a low behavioral distance
to this one and it has a high behavioral
distance to this one down here so we're
taking the minimum of those two
behavioral distances one that's very
large and one that's very small so the
diversity of this one is very
low okay let's compute the diversity of
this one let's assume again we've
transferred this one to reality and this
one to reality so this one has a
behavioral distance that's pretty
high and this behavioral distance here
which is less so the behavioral distance
between this controller and this one is
much it's but it's the it's the smaller
of the two between this behavioral
distance and this behavioral distance
this one is smaller so we set the
diversity of this one to this distance
remember that the diversity of this one
was this
distance so this controller is more
diverse or more unique than this one
this one is more similar to one we've
already trans transer everybody see
that okay let's do one more this one
down here it's got a behavioral distance
of this and a behavioral distance of
this of the two this one this is the
minimal one the minimum one is this
behavioral distance so this one is also
quite unique this one has high diversity
this one has high diversity this one has
very
diversity
okay so we're Computing diversity for
all the controllers in the
population and then we're going to take
among all of those the one that we send
next is the one that has highest
diversity it's the one that's most
different in the
population okay all right let's go back
let's go back for a moment
to let's go back to here okay so we have
all of these controllers we've evaluated
all of them on the virtual robot for one
of them or a couple of them in the
population we've actually sent them to
reality so for those we know their
actual
transferability and for the rest we have
estimated transferability in the way we
just talked about we can assume that
these 1 two 3 four five six seven have
survived these five have died off and
we've reached the end
of one generation and now at each
generation at that generation we can
send one new one to uh reality and we're
going to send the one uh that has
highest diversity which is not shown on
this picture here so among these seven
parents among the seven survivors we
compute the diversity of them we are not
going to send this one or this one if
we're assuming that we've sent both of
these to reality already we're going to
choose one of these five compute the
diversity of these five and try and it's
probably going to be this one this one
is for probably has the greatest
distance from the two that we've sent so
far so every generation like in your
code we're evaluating every controller
in simulation and among all of them we
get to send one to reality keep going
and we evolve this we evolve this
population and we start to evolve uh
controllers that cause the virtual robot
these points start to rise in the space
we start to evolve controllers that
cause the virtual robot to exhibit more
of the behavior we want and these points
are also moving to the right generally
speaking as we take these controllers
and transfer them from simulation to
reality the Gap is narrowing what does
it mean that the Gap is narrowing well
as you'll
recall when we transferred the
first when we transferred the first
random controller in that in generation
zero it had low transferability there
was a big gap between what the simulated
robot did and what the physical robot
did at the end of The evolutionary run
after 200 Generations oops I'm sorry
after 200
Generations they had this
controller that had high uh
had high was good at objective
two and also High estimated
transferability The evolutionary
algorithm thinks that this one actually
will cross the
Gap and it was
right so this bottom pair of images is
showing you a controller that is up and
to the right in that cartoon it's good
at objective one at crossing the Gap and
it's good at getting the robot to do
what we want it to do move from left to
right okay the last part of this
experiment that I want to leave you with
is a mystery that nobody's been able to
solve since 2010 so we're going on 14
years
now look at the left pair of
images it's not the same controller but
it certainly produces something that
looks very similar it produces a very
similar behavior and yet one of them is
very transferable and the other one is
not you might remember in the Golem
project when we were looking at all
these pyramids being printed out by 3D
printers we could kind of come up for
with an intuition for why some robots or
some
behaviors transferred from simulation to
reality this uh quartet of videos is a
good reminder about how difficult the
reality Gap is it's actually not very
intuitive I've watched these videos
hundreds if not thousands of times and I
cannot tell what it is about the mass
distribution of this robot the friction
properties acceleration deceleration uh
jerk snap crackle and pop if you know
what those are very difficult to tell
what's going on
here
okay all right we have uh 15 minutes
left left um so we are going to return
to our schedule here and we'll start in
on lecture 19 but just to recap and
review where we've been uh we have
finished uh our section on crossing the
reality Gap uh hopefully I've convinced
you for how difficult this problem
actually
is we're going to in lecture 19 look at
one final challenge that exists uh that
existed and still exists in robotics
which is
scalability um so there are 61 of you in
this class each one of you I hope has
successfully implemented all 10
assignments Andor all five
differentiable assignments you're all
coding up new kinds of robots now in
your final project or coding up
different Fitness functions or creating
different environments for your robots
I'm sure you're all going to be
successful over the next four month over
the next four weeks and then your Co
there we will have 61 abandoned codeb es
and I will have to start all over again
with a fresh set of students next year
that's also true of our graduate
students they work on a robot or robots
or the projects that you just saw for
example for two three or four years and
then move on to something else H if
we're really going to solve robotics
robotics is a really really hard problem
we're probably going to have to have
hundreds or thousands of humans building
training uh uh build uh building robots
in simulation training them
manufacturing them in reality deploying
them out there how do we how do we build
a larger and larger human team which is
all bent to the same purpose which is to
design increasingly competent and safe
machines okay to scale that up uh one
obvious approach is to try and use the
idea of crowdsourcing to incentivize
people to want to come and participate
um even if they have relatively little
technical skills is there a way we can
build a large human team to collectively
design robots where some folks in the
team are more technically inclined than
others so in lecture 19 we're going to
look at a project uh that that started
in my lab and is now known as Twitch
Plays robotics um which is an attempt to
recruit uh large numbers of people from
the internet to collectively guide The
evolutionary process uh of an
evolutionary robotics experiment okay
all right so before we talk about uh
robots and twitch and crowd sourcing
let's go back to uh an unlik likely
Source let's start with the Chinese room
problem um if we want a large number of
people um some of whom have relatively
little technical skills to collectively
guide and experiment we can't assume
that they know how to code or that they
know math the most obvious thing to do
is to allow them to use natural language
to guide The evolutionary robotics
experiment um so what you're going to
see in Twitch Plays robotics is a
website that allows people to speak
directly to robots they can talk to them
in natural language you might remember
from the Chinese room problem that uh if
we have now a robot inside the Chinese
room and someone in Mandarin tells the
robot to jump all the robot hears is the
letter J followed by the letter U
followed by the letter M followed by the
letter P that word is meaningless to the
robot so we got a problem we want to
bring together a large number of
non-technical folks um in which the only
common language they have is literally
language a natural
language but robots don't uh understand
natural language so how how are they
going to how are we going to con connect
these two groups the evolving robot that
doesn't understand English we're going
to switch to English in a moment and a
whole bunch of non-technical folks who
are trying to tell the robot what to do
in
English okay there's been attempts to do
this for a very long time um this is
just optional and is an aside if you're
interested in the history of AI you
should definitely check out the psych
project by Doug lanat it's arguably one
of the longest running AI experiments uh
in history it's been going since 1984 if
you Google it you can go to the psych
project
website okay um I think uh in the
interest of time I'm going to skip over
this um how do we understand language uh
language seems like something that is
very uh non-embodied we've spent a lot
of time in this course talking about uh
embodiment but in recent years
neuroscientists have started to discover
that there is actually a very strong con
connection between language and our
embodiment um and I'm going to show you
some of that evidence first it turn as
you're going to see in the Twitch Plays
robotics project we can use some of
these ideas from Neuroscience to allow a
robot to actually start to understand
natural language to understand English
okay so how does this
work it turns out that in your brain
there is what's known as the motor strip
uh if you're to wear some headphones or
ear muffs exactly where the St strap
would go that's where the motor strip is
um if uh if I were to put you in a a
brain scanner and to touch your thumb
this particular part of the motor strip
would light up if I were to then tap
your index finger the next Point uh I'm
sorry I misspoke we're talking about the
motor strip motor meaning muscles if I
put you in a brain scanner and I asked
you to Twitch your thumb this part of
your motor strip would light up if I
asked you to Twitch your index finger a
place right next door in your brain in
the motor strip would light up so it
turns out that along the motor strip
here is all of your body parts organized
in this particular way so in your brain
the place where you dream up actions I
want to move my thumb I want to move my
index finger I want to move my thumb on
my other hand those imaginary those
motor plans things that you're planning
to do they tend to they may not
originate here but at least they cause
that part of your brain to light up and
it's not an arbitrary sequence it's
actually lined up like uh where
neighboring body parts if you actuate
them or you actuate them with your
Motors your Muses light up neighboring
parts of your motor
strip um you'll not notice that there is
one part of the human anatomy or a few
parts that are not shown on here um the
parts that are shown larger here these
are the parts that are more sensitive in
which uh more parts of the motor strip
light up you can imagine what those
missing parts are and they have very
large uh they take up a lot of real
estate in the brain's motor strip okay
what does that have to do with language
and robots we'll see in a moment let's
keep going
here's a here's a very interesting
Neuroscience experiment in which they
put uh they put subjects into a brain
scanner and the human subjects were a
asked to just relax and just quietly
listen to random words being spoken uh
into their
ears those words were things like talk
lick grasp pick walk and kick let's look
at the words lick pick and kick they
sound very similar so you might think
naively that similar sounding words are
going to light up similar uh closely uh
parts of the brain of your brain that
are close to one another in your brain
similar sounding brains are likely to
light up regions that are similarly
situated near one
another it turns out that's not what
happened it turns out that the word talk
and lick which sound quite different at
least more different than lick pii and
kick the words talk and lick uh those
two words do light up two brain regions
that are very near one another in the
motor strip in that part of your brain
that would be covered by the strap of
headphones similarly the words grasp and
pick which also sound different light up
closely uh uh closely situated uh
regions in the brain and walk and
kick where in the brain are they
lighting this up they're lighting It Up
near the face related parts of the motor
strip and
specifically uh the mouth the mouth
parts of what's known as the motor
homunculus I'm sorry I forgot to mention
that um the homunculus has a very long
and entertaining history in neural
science and
philosophy um people often thought we
are conscious because there's a little
man inside of us uh who's directing what
we do problem with the mo the homunculus
theory of consciousness of course is
what's in the head of the homunculus so
the idea of the homunculus was kind of
laughed out of uh philosophy and
psychology in the early 20th century but
the neuroscientist had the last laugh it
turns out there is a little man or woman
or person uh inside your body and inside
your brain and they're right here this
is the motor homunculus
okay so as you're lying quietly if you
were to lie quietly in a brain scanner
and hear these words it seems like and
this is this is a bit of a stretch this
is just the data but if you then
extrapolate from this data it suggests
that when you hear the word talk you
imagine yourself talking you're playing
with motor plans things you might try in
reality we just finished a lecture
segment on Sim toore you do Sim to real
all the time not everything you dream up
in Sim uh makes it to reality so as you
hear the word talk you actually imagine
yourself talking as you hear the word
lick you think about yourself licking
when you hear the word grasp you think
of yourself grasping as I continue with
these next three words watch yourself
thinking pick walk
kick did you see yourself imagining
picking something up walking in or
kicking that's what pulva Miller and
fed's study seems to suggest so
Neuroscience is starting to suggest that
there is a very close connection between
language and action this is going to be
important for us because we want a robot
that can understand the language of a
large crowd and act accordingly the
crowd is going to the crowd in the
Twitch Plays robotics project as we're
going to see is going to try and collect
itively evolve robots to jump or uh jump
or walk or run or sit down or stand up
so the robot has to learn a connection
between jump sit walk turn and so on and
what to do it turns out that we humans
seem to be doing this all the time as
you're listening to language you are
imagining it is that language is
triggering motor plans in the motor
strip part of your brain it
seems uh we'll finish I think with this
today um there is another uh there is
another stream of uh evidence another
branch of evidence that suggests humans
have a very close Connection in their
heads between language and action and
this evidence is the ubiquity of
embodied metaphors in language uh George
LOF very famous uh
psychologist pointed this out that uh
people tend to think of mathematics and
poetry and language and chess as very uh
very formidable very laudable very you
know things to work towards to achieve
very difficult things that have nothing
to do with the body Western thought has
a very long history of denigrating the
body the body is dirty temporary prone
to damage and death but the mind and the
soul is pure and is
forever turns out that as we're learning
from neuroscience and psychology that's
not the case even non-embodied things
like language seem to have deep roots in
our bodies and you can see this by
looking at language
itself uh if there are any non uh native
English speakers that are listening to
this lecture uh you might find this
particularly interesting in every
language there are idioms or metaphors
that seem confusing um if you're in an
argument with someone and you're trying
to advance your case and the person
accuses you of jumping to conclusions
even if you're a non-native English
speaker and you've never heard this
idiom before most non-native English
speakers can figure out what it means
without the English speaker having to
explain what don't jump to conclusions
means what does it mean it means don't
jump to conclusions but what is being
jumped over
in an argument you have to have a chain
of reasoning right I there's proof for
this and this suggests this and there's
proof for this and this suggests you
have to make your argument as a series
of Stepping Stones you can't jump over
any of those chains in your logical
argument to the conclusion or else I
don't trust your conclusion don't jump
conclusions you might uh if somebody uh
if somebody's uh complaining to you
about something that happened last week
you might admonish them to not look back
in anger this one is
interesting why do we say look back
don't look back in
anger we also say I look forward to
seeing you all in class on
Tuesday in most cultures the past things
that you're angry about in the past are
behind you and things in the future like
seeing you all in class next
Tuesday that tends to be things that we
look forward
to why do we look back metaphorically to
past events we obviously can't literally
see things that happened in our past and
I can't literally see you all until next
Tuesday why is
that I'll leave you to think on that uh
and I look forward to seeing you all on
Tuesday you have a quiz due tonight
you're all working on your weekly
reports which are due by midnight Monday
night have a good rest of your week and
enjoy the snow


--- Evolutionary Robotics course. Lecture 21： Twitch Plays Robotics..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone welcome back
hope you all enjoyed the eclipse
yesterday let's talk a little bit about
the final project so hopefully Yesterday
by 11:59 p.m. you all submitted your
idea for your final project and you
thought a little bit about how to break
this down into four baby steps that will
get you there uh a couple questions that
came up inevitably about this process
what happens if you change your mind or
you get two we into your final project
and you find out that what you pitched
wasn't reasonable you absolutely can
change your mind just let us know when
you submit a given weekly
report type into the bright space
submission here's what I had planned for
this week here's what I've changed to
for this week for this reason two or
three sentences should be sufficient you
are not being graded on your ability to
predict into the future about what Will
and won't work in pi bullet what you are
being assessed on is your ability to uh
map out uh a relatively ambitious
project and break it down into pieces
and your ability to keep us in the loop
about what's working what isn't and so
on make sense okay use common sense here
we should be fine any questions about
things so far yes um how do you make the
joints
like like St
but just like make it so that they don't
like deach from limbs like there's a
significant amount of more tension that
actually keeps the limbs together okay
that's a good question so we haven't
talked about that uh simulating a joint
well can be tricky so there if there's
significant torque acting at the Joint
it can pull the pieces apart my first
suggestion is there's probably something
else going on your simulation that's
creating undo torque better to to reduce
the torque in the system as a whole then
try and Fiddle with the joints there are
ways you can make the joints stronger
but usually it the joints will generally
work well as long as there isn't
significant torque what is it that
you're doing that's exerting so much
force on the
um I have been making my robot jumps
like only by using revolutionary Force
okay so like when it's been like bending
down and bracing to jump it's like
bending its legs into like not into the
main body of the robot but bending it in
enough that like the front legs don't
like pull in fully with the back legs
separate from the body okay that sounds
like the kind of thing you want to come
see us in office hours about we can have
a look and try and diagnose things and
give you a a suggestion okay okay other
questions yes for the Milestones it's
only a text submission the Milestones
are a text submission if you want to
include a link that points us to a PDF
or your screenshots or videos as you've
been doing all along please do so so a
combination of text and pointers to
external resources is what we're looking
for sorry I should have made that clear
up front other
questions yes um also like what are the
other types of like that you can use in
the joints I saw that you have like
specifically that revolutionary as like
the type revolute joints meaning that
they revolve or it's it's angle there's
the other one which is a linear joint we
talked about this before so you can
create a piston in pi bullet where you
take two links and connect them together
with a linear joint and now forces
applied by that joint to the two links
that the joint connects will pull the
the links to towards one another or push
them apart that's a linear joint yeah so
remember uh when we're dealing with
physics engines and robots there's two
types of forces that we're talking about
there's rotational force force that's
trying to turn or twist something that's
called torque so a motorized revolute
joint the motor is applying torque it's
applying rotational Force to change the
relative angle between links if if you
use a piston or a linear joint that
motor the motor at a linear joint is
going to apply linear Force it's going
to change the relative positions of the
links rather than the angles between
them torque and linear
Force good and again uh it's not
immediately obvious how to implement
linear joints come and see me or the TA
and we can help you with that other
questions um you will notice on the on
the subreddit there's a pointer to tips
and tricks so there is a whole bunch of
these additional things uh that you can
add in you can change the masses of
objects you can uh include spheres
rather than rectangular solids there's a
bunch of stuff there if you haven't had
a look already you can browse through
there for
ideas okay uh I want to talk a little
bit about a andb testing this can be
particularly confusing especially if
your A and B variant of your algorithm
whatever you're proposing includes
different Fitness
functions let's look at an example let's
assume you've got the parallel hill
climber and because I don't want to
write out too much on the board let's
assume a population size of two so we've
got two parents and we'll just assume
whatever the fitness function is these
are the fitness values of the two
parents each parent produces a child the
child is better than or worse than the
parent we replace and so on and over
time we should see values doing
something like this right gradually
increasing o from generation to
generation and same thing for the second
parent okay I haven't said anything
about what the fitness value is but
let's assume that this is version a of
your code let's think about the Up Up
and Away project which is to get your
robot to jump maybe in Fitness variant a
here the fit uh sorry in variant a the
fitness function is the height of the
main body of the quadrad that's the
fitness function you're trying to use to
get your robot to jump and you get this
as some of you may have noticed
sometimes it works but sometimes
Evolution perversely instantiates
jumping in your robot in what
way standing on its tiptoes right so you
uh become disillusioned with the fitness
function that maximizes height of the
main body and you formulate a new
version of your code base variant B in
which everything is the same except you
change the fitness function to something
like maximizing the number of time steps
in which all four feet are off the
ground which means now your Fitness
function has become an integer value the
number of time steps for which
everything's off the ground so maybe
parent
one gets uh enjoys four time steps in
which the all four feet are off the
ground parent two three and you start to
get something that looks like
this which of these two algorithm
variants produce better jump
in we can't say because we have two
different definitions of jumping so AB
test is tricky if you're going to use a
function there are two options if you do
want to compare two different Fitness
functions you take something else that
isn't in A and B and use that as your
measurement for how well evolution is
evolving that behavior into your robot
it's a little tricky to see what that is
for jumping because we have two
definitions of jumping we have to come
up with something else like what for
example jumping seems like kind of a
simple intuitive thing you jump or you
don't but as we can start to see there's
different ways of actually measuring
jumping what makes for a good jump
Beyond just these two
things that's the maximum v z value is
this we're already selecting for this so
if we were to say we're going to look
across these two versions and see which
one produced better positive height of
the main body
which of these two variants do you think
is going to do a better job at
that than maximum height we're assuming
in this case we're not even measuring
the height of the main body just the
amount of time that all four feet are
off the
ground if we want to look see the height
of the main body it's going to be
algorithm AR variant a because that's
what evolution was selecting
for so we need to pick something
else are you asking what we should
change the fitness function to so that
it weighs both of them equally the way
we set up this experiment here is in
general we're in this experiment we're
interested in evolving jumping which
variant of our code A or B is going to
evolve better jumping for our
robot but we're in a tricky spot now
because we've already defined two
different ways of jumping and we're
asking which of these two algorithm
variants produces better jumping so it's
not fair to say well we'll use this
definition of jumping and ask which of
these two code bases produces that
version of jumping because this variant
will produce a better version of that
jumping than this so we kind of need
something like C something that is not
here and not here that most people would
agree is a good feature of jumping that
isn't obviously in either of these and
say that c is our version of jumping and
we want to see which of these two
produced a better version of that like
how far off the other feet how far off
the ground all four feet are right
that's a pretty good jump definition of
a high jump which is how far are your
feet off the ground the height of your
feet that would be an ideal C because
it's not immediately obvious that either
of these are selecting for that make
sense seems like kind of an odd way to
go about an experiment but for our
purposes that's what we're kind of
looking for yeah if your AB testing uh
does not have a difference in the
fitness function then you're okay so
let's imagine for example we're still
doing the Up Up and Away project but in
version a we're still selecting for the
height of the of the main body but in
algorithm variant a everything is
exactly the same except the body of the
robot in variant a we're going to uh
evolve for jumping in the quadraped and
in variant B we're going to evolve for
jumping in the hexapod in which case we
wouldn't have integers we'd be back to
floating Point
numbers
okay which is doing better at
jumping now it's a little more obvious
right so for those of you that are doing
AB testing in which the fitness function
is the same but you're changing
something else like the environment of
the robot or the body of the robot or
the cognitive architecture of the neural
controller of the robot or the mutation
rate or how mutation is done in the
evolutionary algorithm there's a whole
bunch of other things you could change
it's relatively easy to conduct an AB
test but if you're changing the fitness
function between A and B it's not as
obvious and if you get stuck come and
see the TA or myself and we can talk
about it make
sense okay all right question just one
small question sure project um is there
like a certain number of um children
during like each
like I was thinking about possibly like
increasing the amount of like
evolutionary variation I can get by
increasing the number of children that
each parent was like comparing itself to
to find like the strongest um
evolutionary Fitness of each of the
variations okay um and have you like
have
you applied much like like having like
multiple children for each parent and
like you found that there's like a
certain number of children that like
increases the fitness of the like robot
consistently that's a great question so
we've been talking about the parallel
hill climber which is a very simple
evolutionary algorithm you could for
example have each parent produce three
children or five children or 23 children
does that make a difference that would
be a great A and B test maybe you evolve
for jumping in the quadrip with the
standard parallel hill climber from
assignment nine and algorithm variant B
is you increase the number of children
that each parent produces and then you
try and answer the question you just
asked which is is there a certain number
of children more than one that over the
same amount of evolutionary time
produces greater Fitness that would be a
great final project good
okay okay all right back to uh our our
ongoing discussion about open problems
or challenges in the field of
evolutionary robotics we are going to
finish this discussion today with the
last open question in robotics which is
obviously if we want to make machines
that are useful and safe out here in the
real world with all of us we're going to
need to teach them how to be useful and
safe it's not very scalable to have one
person teaching or evolving behaviors
for a single robot then trying to cross
the Gap how do we construct a greater
algorithm that includes people and as
many people as
possible as you're going to see in the
Twitch Plays robotics project today we
have some evolving robots and very large
numbers of people that are directing
that evolutionary
process they are not writing down
mathematically Fitness functions they
are going to influence the evolutionary
progression of the robots using natural
language that's what we can assume most
people have in common and we are all of
us humans instinctual teachers whether
you know it or not it's in there
somewhere and the most intuitive and
most comfortable way for us to teach is
with natural
language but if we're dealing with
robots robots are embodied creatures and
they act they sense think and act so we
need to make a connection somehow
between language and action as we've
recently learned if you want to make
non-embodied machines like chat GPT it
seems like you can get away with just
teaching them with language since they
don't need to act but some of of us
would argue that there's something
missing there perhaps the way to go is
to connect language with action but
human language English Mandarin doesn't
matter it seems very far from the nuts
and bolts of physical embodied action in
the World poetry language mathematics
chess they are abstract non-touch things
that are very different from learning to
walk
right it feels that way to many of us
but thinking about thinking is
misleading so last time we finished off
exploring the
fact the fact that there seems to be or
we're learning about the fact that there
are many many connections between at
least with humans between language and
action uh if you watched the lecture
from last time you saw uh some of these
interesting brain Imaging studies that
have been done with the motor strips
this is the part of the brain that would
be underneath your headphone strap when
you talk to someone who's lying in a
brain scanner and you mention action
words those parts of the brain tend to
light up that was the pulva Muller uh
experiment from not that long ago so
this is kind of a recent finding there
is a connection between language as I'm
speaking if I use body related words
like talk lick grasp pick I am lighting
up parts of your motor strip right now
that correspond to grasp lick pick and
so on yes another interesting one is if
you like think a word in your head you
can usually like feel yourself saying
absolutely there are many con once you
start to think about it there are many
connections between language and action
which is good news for us roboticists if
we're going to start talking to robots
those robots are going to have to make a
connection between language and action
also but how how are they going to make
a connection between language and action
we're spending a few minutes now seeing
at least how these things are connected
in humans not necessarily how they
became
connected obviously our ancestors were
able to walk and walk and lick and grasp
and walk and kick long before language
existed action
was there long before so somehow
language must have got grafted on top of
language
yeah we ended last
time on a
cliffhanger with George Loff a very very
famous psychologist and linguist uh who
pointed out that there are many there's
much evidence in language about how and
this is a hypothesis still how possibly
language got started in humans or
primates because it was connected with
our
actions LOF is particularly famous for
uh formulating this idea of embodied
metaphors if you're a non-native English
speaker and you start to hear English
idioms like don't jump to conclusions or
Don't Look Back in Anger many non-native
English speakers can tell you exactly
what these idioms mean the first time
they hear them without having them
explain to them
why they're related to the physical
world not just the physical world our
relationship to it right Don't Look Back
in Anger our physiology our primary
sensory apparatus which is our eyes
point forward we were and arguably still
are apex predators for apex predators
it's very good to be focused on what's
ahead you don't necessarily need to look
around you because no one's trying to
sneak up on you you're an apex predator
right so our primary visual sense is
forward we tend to move in that
direction so if we're moving and we
literally look back what do we see we
see things that are in our recent past
same thing with looking forward to
future events I see something and it
becomes a part of of my future
experience there are hundreds if not
thousands of embodied metaphors in every
language group we're all English
speakers in this room so we're going to
play the embodied metaphor game in
English what are some other embodied
metaphors don't hold
back try and lean into
this it's not that hard you don't need
to tie yourself in
knots are you going to make me pull this
out of you let your imagination run away
don't let your run your imagination run
away or run
wild cat got your tongue falling behind
sorry falling behind falling behind I
bet you most of you are thinking about
that right you're probably falling
behind behind on all your projects and
tests this month
others
staying grounded staying grounded
great a bit of a reach well done pulling
at straws pulling at straws this one is
a is a combination of physiological and
cultural right drawing the Short Straw
that's a cultural artifact many embodied
metaphors are a mix some of them are
purely
physiological you should get in touch
sometime should get in touch sometime
great let's pick up the page
it gets easier the more you do
it thinking about thinking is misleading
language does not necessarily feel like
an embodied thing feels like a difficult
thing to
do something's burdening you something's
burning you yeah burdening burdening you
yes yes burdening something yes
absolutely I have a burning need to hear
more embodied
metaphors I'm tripped up I'm exactly I'm
Tri
up I want more I'm not going to take
this line
down did you have one ah
okay you probably had one it was
probably on the tip of your
tongue trying to think of something
that's like you staying in place okay
you're stuck at the moment right you're
stuck okay being rooted to the ground
being rooted to the ground
absolutely the flow go with the flow
sing upam swimming Upstream
excellent some of you may be feeling
very behind with all your coursework at
the moment is that making you depressed
are you feeling
down sure get ahead sorry I'm sure I'll
get ahead I'm sure you'll get ahead of
it absolutely stay ahead of
it why is depression associated with a
direction why is an emotion associated
with direction looking forward to and
looking back that makes sense it makes
sense why for future time for most
cultures it's ahead and for most
cultures the past is behind not every
culture actually there are some
exceptions to this why emotions why is
depression a downward thing not an
upward thing this might
be okay ah falling into a trap well
done depressed there I feel weigh down
you feel weighed down okay when I am not
depressed I feel lighter so
there's there's some sort of emotional
gravitational
force
it could be why is why is in many
cultures and again not every culture the
good place up and the bad place
down when you feel depressed you feel
low when you don't you feel lifted up
which came first heaven or the feeling
of a direction associated with emotion
this is not a religious studies class so
we will not answer that here today our
our Point here today the point I'm
trying to make or impress upon you is
there seems to be a very deep connection
between action and our ability to
understand language we seem to have a
common reference frame for grounding
language in our
physiology actually how our bodies are
made how we move and how our
relationship with the world changes as
we
move absolutely is
that
robot how you go about trying to do that
yeah okay how so perfect how would we do
this there seems to be all this evidence
of connections between abstract Concepts
from language like Prospect prospection
imagine mentally imagining what's about
to happen in the future that feels like
a very abstract thing and yet this
abstract building block of intelligence
the ability to think ahead seems to be
connected with our very physiology the
direction in which our eyes point and
the way we feel most comfortable moving
about in the world all the way into
things like internal actions right
internal organs right we were just
playing the embodied metaphor game I
wanted you to really put your heart into
it right how's that going to work for a
robot that doesn't actually have a heart
seems tricky if you have like different
input neurons that might be like
associated with possibly like different
actions H now we're getting somewhere
actions are possible we share that in
common with machines we can instrument
machines with sensory systems so maybe
we can train or evolve machines to
connect sensation at least in terms of
sensor values with
language that's exactly where the Twitch
Plays robotics project is going to start
I want you to imagine a quadrupedal
robot shouldn't be too difficult for you
to imagine shouldn't be too much of a
stretch for
you assume this quadrupedal robot has
four binary touch sensors in the four
feet and this robot is running about
it's in in its environment and my little
cartoon figure down here is meant to
represent how the robot's sensation is
changing over time no evolutionary
robotics at the moment just a robot
that's acting in the world and as it's
moving about it feels pressure on its
feet or it's it's getting plus ones from
the touch sensors in its feet and by
chance at some point just by chance
maybe it's equipped with a random neural
controller all four feet come off the
ground and the robot senses all four
touch sensors go to minus one at that
point in time and at that point in time
from somewhere the robot he's
JP the robot doesn't know what this is
it's just a random collection of symbols
recall the Chinese room no understanding
yet just four strange symbols happen to
come into the robot's neural
controller at the time at which all four
feet left the
ground the robot goes back to running
around it doesn't hear this and then
again by chance all four feet come off
the ground four minus ones and suddenly
the robot quote unquote hears
J again what can the robots start to
conclude from this experience as it's
repeated over and over and over
again just an association Syle a simple
Association from the robot's point of
view this symbol this symbol this symbol
and this symbol tend to be associated in
time with min-1 -1 -1 minus one a simple
Association nothing fancy at this at
this
moment this is known as the symbol
grounding problem problem meaning if you
have a whole bunch of symbols as we saw
before from a ma from a machine like the
Chinese room that has no ability to act
or do anything in the world the best
thing that this non-embodied machine can
do is still learn associations but it
can learn assoc iations between the
symbols of language and the other
symbols of language which is exactly
what chat GPT has learned to do and it
does it very very very well we now have
an example of something that doesn't
solve the symbol grounding problem these
symbols are not grounded in action in
any obvious way for chat PT symbols are
just associated in the sense of chat p
knows when these symbols of language
appear to humans humans tend to continue
on with this set of symbols chat PT can
predict the next token in a string of
letters or words or
sentences us we and possibly machines
have another way to ground symbols or
deal with symbols which is to ground
them in the so soil of sensor motor
experience for our cartoon robot here
it's learned an association between a
very small piece of language and its own
felt
experience so far so good okay if a
robot can do that imagine this quadruped
keeps keeps moving around and from time
to time uh as long as it's moving or
jumping or these values are changing it
hears the symbols m o v e m n t it tends
to hear these eight symbols much more
often than it hears these four symbols
as long as the robot is moving people
are saying that's movement that's
movement that's movement that's movement
the robot might start to learn an
association between JP and its touch
sensor values it might also start to
learn an association between these eight
symbols and its sensor
values and it might start to now learn
an association between these eight
sensor Val these eight symbols and these
four symbols that these four symbols
always occur whenever these eight
symbols
occur but these eight symbols sometimes
occur when these four symbols do not
occur there's an asymmetry here from the
robot's perspective people see that
there's types of movement that isn't a
jump but jump is is always a type of
movement so the robot is now not
grounding this set of symbols directly
in its own felt experience it's
grounding these symbols in these
slightly more embodied symbols so like
we just saw in the case of embodied
metaphors you can take any given word
from any language and you can start to
think about how embodied it is how how
directly could machine or an organism
discover an association between those
symbols and something that it does or
some invariance or some relationship
between itself and the
environment everybody see that if that's
possible it's possible that you could
make this recursive a slightly more
abstract term or like political movement
is now
metaphorically implying action but not
directly implying action there are
certain movements that might actually be
part of a political movement and then
socialism is a particular type of
political movement we're getting up here
into very very abstract terms that seem
quite a long
way from a direct felt experience so
this is still all a theory kind of makes
sense you can imagine a machine that
starts to learn language like jump and
movement Maybe harder to learn these
ones up here because obviously these
words are very far from direct felt
experience
right that's your cue thinking about
thinking is
misleading in this country for better
for worse there are two main political
parties it's a democracy of sorts when
you think about these two parties and
elections aside from Stress and Anxiety
what do you
feel going to leave political opinions
out for the moment when I say feel I
mean literally feel what does democracy
in a country in which there are multiple
political parties that are vying for
power what does it feel like how close
to actual physical experience can we
get like your body sort of feels like
tense tense why because because like
the there's a lot like sort of going
on beh a lot more behind the scenes that
you need to focus on rather than just
like a lot of like intuitive like
actions that we're like looking at like
every day okay maybe things behind the
scenes that's another embodied metaphor
other ideas there like a push and pull a
push and a pull you ever play play
tug-of War most people if you put them
in the brain scanner and you talk about
the two-party system in this country the
anxiety parts of the brain absolutely
light up but the parts of the motor
strip that are involved when people are
playing tug-of warar light up you
mentioned tensing up if you play tug-of
warar and your muscles are relaxed
you're going to lose right there is
something that involves or engages most
muscle groups when you're playing a push
and pull type game so push and pull
metaphors as you can imagine are
ubiquitous they're everywhere in
political
discourse things like politics seem like
an abstract thing far from the physical
body they are not or at least you can
make a case that they are not so it
seems like there is a lot of evidence or
possibility for grounding uh language
including socalled non-embodied language
in the felt experience of humans I don't
know about machines
we're going to focus what you're going
to see in the Twitch Plays robotics
project in a moment is machines that are
going to start down here whether we can
get machines to form associations
between embodied words and felt
experience and whether they can then
exploit that to understand things like
the push and pool of multi-party
politics we'll see questions so far so
good okay all right so uh this is a
project that came out of my lab it's
still running uh if you Google Twitch
Plays robotics you should be able to
find it and actually play Twitch Plays
uh robotics Twitch Plays robotics is
designed to enable robots to ground
symbols in their own felt experiences
it's a pretty complicated experiment so
we're going to break the description of
this experiment down into four stages
the robot's going to act the robot's
going to
observe how the crowd reacts with
language to what it did so robot is
going to have felt experience and it's
going to have symbols from the crowd and
it's going to try and learn associations
between between its actions and language
from the crowd and we're going to then
measure whether the robot successfully
learned to ground uh symbols in action
by asking the robot to
predict we're going to give it new words
and new actions and see if it can
correctly predict the other one this is
a common way to test whether machines
have learned something expose them to
General versions of what we think
they've learned and if they can
successfully deal with those unseen
situations they've learned okay here we
go all right let's start with uh act um
we have a twitch Channel called Twitch
Plays robotics everybody know what
twitch is do I need to explain what
twitch is one of the most popular
websites on the planet people typically
go there to watch people play video
games and sometimes type into chat to
other members of the chat or whoever is
playing uh the video game so we on our
Channel we have a video game which is a
physics engine that is evolving robots
people can type into chat and we are
going to capture that chat and store it
in a database so we've got an evolu
robotics experiment running we're
streaming it live to Twitch and we're
scraping whatever people say back to the
robots
Okay uh okay I'm gonna just zoom in here
we're gonna talk there's been many
versions of Twitch Plays robotics uh
over the years this was the original one
just to give you a sense of what this
looked like again I'm sure most of you
have seen or used twitch we have a live
video stream over over here a relatively
simple robot we gave the crowd the
following instructions if you want to
command the next robots just tell them
what you want to do in chat this is
where things are starting so from the
the average twitch users perspective
they're seeing this crazy simulation
over here and we're trying to suggest to
the crowd that they can come up with
things they might try and teach the
robotss at this point in time 10 uh
twitch users have voted to try and teach
the robot to crawl forward seven members
of the twitch Community uh have gotten
very tired of this robot so
they're threatening to Riot unless we
show them a different robot this is
twitch a bit of a chaotic place that's
okay uh what even is going on here so
close I don't even know what that means
okay at the moment luckily the majority
is voting for something they want to try
and teach the robots next crawl
forward from our perspective as the
investigators in this experiment that
made us optimistic that this might work
why useful instruction it's a useful
instruction this seems crawl forward see
seems like something that this simple
three-link two-joint worm might actually
be able to ground in its felt
experience so far so good okay all
right
okay at the moment at this point in time
in the experiment the crowd had voted on
so close as the thing to teach the
robots next this was some offhand
comment that some twitch person
mentioned I doubt this is some is a set
of symbols that this robot can probably
ground in its felt
experience we'll see okay all right I'm
going to show you a video now of this in
action this is the current version of
Twitch Plays robotics that's running uh
at the
moment
I'll direct your attention to the white
text at the top of the simulation here
people are now have voted to teach the
robot to be
big now they're asking the robot to
learn how to
move you'll notice that each robot has a
little symbol attached to
it this is the white cyan robot over
here this is the blue silver robot over
here here's the white white robot down
here the cyan yellow robot over here
these are the names of the
robots and you'll notice that someone
just voted for GB
GP to be better at whatever it was the
command that they got so let's follow
along what this user is saying
I'm going to back up for a moment in a
moment they're going to type in RR let
me back up
again they're going to type in RR in a
moment here's RR down here the command
is being big they're saying that RR is
bigger than
Jr back here so each of these robots is
collecting symbols the robots are do not
know what m o i
means but they're learning an
association which is whatever they are
whatever they're feeling they are more
of that thing than the other robot
is so far so
good
question it's a good point so in this
current version of the experiment they
do we're going to talk I just wanted to
give you a sense for what this what the
interface kind of looks like we're going
to spend our time talking about results
from this experiment where the only
thing the robots know is how well
they're doing at grounding s space c e
they're probably not going to be able to
learn any relationship between their
sensor values and that command that set
of symbols but they may be able to if
the symbols are c r a w space and so on
so far so good
okay okay so again I'll just show you
what people are typing in at this point
you can see a lot of people typing in
crawl forward craw crawl forward so at
this particular snapshot in the
experiment it seems we were lucky most
of the people on the stream at this time
seem to be getting the idea about what
we wanted them to do and they were
implicitly reaching consensus on things
that they might be able to teach the
robot they don't know how the robots are
being taught this they don't know
anything about neural controllers
presumably just that this is probably
more teachable than new robot or uh Riot
question show us two different
experiment yes
one one
is tress yes the relationship between
yeah so in this experiment which we're
going to talk about now they're voting
for what to teach the robot next and
they're voting I just haven't talked
about the voting mechanism yet you'll
notice that at this moment in time there
is the Violet robot on the screen we're
telling them that if they want to teach
this Violet robot right
now they should type in Violet robot yes
VY the robot is obeying the command so
close so close is the current set of
symbols that the robot
hears they should type in VN meaning no
The Violet robot is not obeying the
command so close that's the voting
mechanism so the robot is getting uh is
getting these symbols and it's also
hearing about whether or not the crowd
thinks it's doing the right thing for
those of you that are familiar with
reinforcement
learning the one of the most popular
topics in reinforcement learning at the
moment is reinforcement learning with
human feedback this is a version of
rlf robot the robots at this point have
absolutely no idea what crawl means or
so close means or jump means but they
might be able to start to form an
association between symbols and what
they feel if they hear something and
they generate a particular type of
sensation like they actually crawl
forward and they get onethird piece
which is
yes the robot hears jump and the robot
doesn't jump they they hear n the robot
hears jump and jumps the robot hears
yes the voting is the robot's ability to
complete this Association task it needs
to know if the sensations it's currently
generating by acting it's an embodied
agent it moves and generates sensory
information is the sensory information
that it's
generating what people would consider an
instantiation of those symbols an
instantiation of crawl
forward everybody see that so in the
Twitch Plays robotics project we're
going to look at these three different
types of data the sensation generated by
the robot the symbols that make up the
human generated
commands and reinforcement yes or no
does that sensation align with that
action okay so a little bit more about
this uh user interface uh you'll notice
at this moment in time we've got the
violent the Violet robot down here you
can see someone's typed in BN so there
was a blue robot just before this Violet
robot and this particular user is saying
BN did not obey the current command that
person repeats it again here so people
are voting yes or no whether the robot's
actions or Sensations are matching the
symbol okay that's quite a bit of detail
about about experimental design I'll
just pause for a moment any questions
about
that so far so good
okay
okay okay so let's look at uh oh
actually let me uh yeah let's let's talk
about the data set itself so we've got
this thing running and we're generating
thousands and over a few years we
generated millions of robots and neural
controllers through t
but we used just two robot body plans
two different robots the simple
three-link worm that you just saw and
I'm going to just jump ahead a little
bit this quadruped so we looked at two
different bodies this was actually one
big AB test and in the Twitch Plays
robotics project the question we were
asking is not just can robots ground
action in language
but do some bodies make it easier for
the robot to ground language in action
so robot a the simple worm robot B the
quadraped so far so
good okay let's go back to the data set
here okay so R Subzero r0 is the worm R
sub one is the
quadraped for each robot that robot was
shown to the crowd over and over and
over and over again and that tended to
elicit from the crowd a whole bunch of
seas these are the commands that the
crowd F the robot might be able they
might be able to teach the robot to obey
that command so some commands were jump
some commands were crawl forward some
commands were new robot or RI Riot what
other commands do you think the typical
twitch user generated for a
robot I'll give you a hint this was at
the beginning when twitch was just
getting going and there were no verbal
filters on Twitch at this
time I thought I knew every bad word in
the English language I was sorely
mistaken you'd be
amazed when you have a friend who comes
to visit whose uh native tongue is not
English what are the first six or eight
words you teach them you can probably
guess same thing here these robots know
way more about swear words than you or I
ever
will hard to ground that is it is it
hard to ground bad words we are not
going to enter into that discussion here
that's a black hole we'll never escape
from more embodied metaphors for you
okay other than those swear words what
else do you think they tried to teach
the robots
those were the most popular as you can
probably
imagine craw forward crawl forward so
among all the landmines of natural
language there were a lot of terms that
again gave us confidence that maybe this
experiment could actually work generally
speaking the crowd tended to converge on
embodied words things that these robots
from our perspective as investigators we
thought yeah there's maybe a chance some
other fun ones were um uh proved for
Matt's Last Theorem our robots have not
yet figured that one out one of my other
favorites was be
yourself is this let's assume this robot
is hearing be space blah blah right now
would you vote Yes or no right hand if
you think this robot is being itself
left hand if you think this robot is not
let's see if we have consensus okay most
people feel this robot is being itself
so actually maybe that is a groundable
word you know it's not up to us it's up
to the consensus of the crowd okay okay
so again just we're going to start to
use this notation a bit as we go forward
whenever you see r with a single
subscript that references the worm or
the quadrip whenever you see a c with
two subscripts i j whenever you see a
subscript C IJ the first subscript
denotes that command was sent to that
robot so command uh this command CI J
was issued to robot I so I can be either
zero or one maybe when people saw the
worm they tended to issue commands like
crawl and when they saw the quadraped r
sub one they issued commands like jump
or maybe not right the second subscript
is going to index different commands
swear word one swear word two swear word
three jump stay be yourself prove forat
Last Theorem however many commands we
got they got their own ID number and we
had those unique commands so far so
good question are these like reward
values at different times stuff uh good
question are these reward values no
reward yet we're just talking about the
robots morphology and the string of
symbols that they heard that's it we
haven't got to reward yet we'll get to
reward in a moment did you do any
filtering on the
command no filtering literally
everything was allowed for better for
worse this was a very interesting
experiment in many
ways as human investigators we wanted to
to try and introduce as little bias as
we could about whether or not these
robots could ground crowd generated
okay okay uh the the next piece of
nomenclature here is n with three
subscripts in the original Twitch Plays
robotics which we're talking about today
there was no Evolution during the stream
all we did was send one random neural
controller n for neural
controller to the robot one after the
other so Random sets of synaptic weights
that's all the robot was doing one
random neural controller after after
another we've got three subscripts here
the first one is I so this random
controller was sent to either the worm
or the
quadrip the second subscript J says this
controller was sent to robot I when it
was hearing the JF command so if let's
say I equals Zer that means this random
neural controller is running on the
worm perhaps this random neural
controller is running on the worm while
the worm hears
JP that particular
command and the kth subscript is just
that neural controller we might have uh
over the span of this experiment and we
probably did send more than one random
neural controller to the worm while the
crowd was trying to teach it to jump so
there might have been multiple neural
controllers generating sensor data while
the worm was being taught to jump so far
so good so we've got two word we've got
two robots hundreds of commands that the
crowd issued to the robot and thousands
and thousands and thousands of random
neural controllers that were run on the
robots so far so
good okay you asked about uh
reinforcement or reward last piece of
nomenclature here deep breath we got
four subscripts here s for reinforcement
signals we already used the r up here so
what does a reinforcement signal
mean if I showed you the worm and the
worm happened to be doing
this and the crowd had issued the
command
jump what would you type in y or
n robots doing this we should jump right
hand for yes left hand for no is the
robot obeying the command jump I see
unanimous hands going up I see nine
right hands going up so s i j K1 would
be set equal to nine nine members of the
crowd at that moment said yes the robot
is obeying the command jump I did not
see a single left hand nobody said no
the robot is not obeying the did you
have your left hand up oh no okay so s
Subzero here is set to
one for the kth controller that was
running on the worm that caused the worm
to do this while J is set to jump
on the worm robot so the K controller
extracted from the crowd nine a value of
nine for the re positive reinforcement
signal and a value of one for the
negative reinforcement
signal the two s's are integers number
of yes votes number of no votes so far
so good question so you say
nope the simulation never ends it's
actually been running more or less
continuously for nine years now we're
just running neural controllers one
after the other on these robots and as
we do we're Computing these values we're
we're pulling off a data set as we go so
this is this is quite different from
what we've seen in this course so far
we've got that's why this is drawn as a
continuous loop it just keeps going and
the database just keeps filling up with
this data RS and C's and n's and
s's we haven't done anything with this
data yet this is just the observe part
the robot is observing or we are
observing what we're getting back from
the
crowd so far so good okay all right so
now that we're armed with this data
set uh or let's actually let's actually
end by looking at what we actually got
so we've written a number of papers
based on this continuously running
experiment this is the the first bunch
of data that we scraped off this
experiment that we're talking about
today um it took place over a few weeks
and we had 424 different humans there
weren't many bots on Twitch at this
point there were a few so somewhere in
here there's probably some Bots but
mostly
humans robot evaluations so we did uh we
did 57,000 evaluations in about two
weeks where an evaluation is running one
simulation with one random neural
controller so we executed
57,000 random controllers on the worm
and the the quadraped over these two
weeks uh we noticed that uh for o for
6,388 there was at least one Observer on
the stream at that time again it's hard
to say whether it was a bot or a human
being at this time they were mostly
humans so about a little over 6,000 of
the controllers were actually seen by
humans we got
16,000 pieces of chat back from the
crowd during this two week period
okay among this uh among the 16,000 uh
8900 of those pieces of chat were
commands these were things that were not
by
BN uh VY VN we had a very specific way
to tell whether a piece of chat was a
positive or negative reinforcement s0 or
S1 everything else was considered a
candidate command even if it was a swear
word even if it was someone on chat on
chat saying what the heck is this thing
we saw a lot of people talking to one
another do you know what we're supposed
to be doing H okay thanks for explaining
I get it off we go we just threw it all
in a bin and we assumed this was valid
commands we didn't want to go in and try
and pick out what we thought were actual
commands of the 4 24 subjects that
actually typed something into chat uh
each person typed in on average 21
pieces of
chat um if you've ever watched a twitch
stream you'll know that there were a few
subjects in here who did all the talking
and the vast majority of these
424 people said one thing and then left
again that's
fine uh we we saw that among all the
8900 pieces of chat there were
266 unique
strings so most of this was repetitions
people typing in the same
thing uh this I've filtered out all the
swear words here for you the next most
popular thing was
JP which was typed in
385 Times by different members of this
Cod cour so this jump that I chose to
illustrate the concept of symbol
grounding was not arbitrary this was the
number one thing that folks thought they
could get the Lang the robot to ground
in action other than swear words second
most popular thing was walk forward
third most popular thing was move
forward fourth was run fifth most
popular thing typed in by chat was crawl
forward uh there are many anecdotes from
the tpr EXP experiment I'll share just
one more with you when this started
going we w we were obviously watching
the chat we saw a lot of chatter among
uh the people chatting on the stream at
one point somebody said oh there's a
bunch of scientists trying to teach this
robot trying to teach this robot
language let's teach it swear words but
I have a plan for how to get this robot
to actually learn swear words so we're
going to assume that these these
investigators aren't here at night so
come back to the stream at 3:00 a.m.
eastern time and let's make a plan for
how to teach these robots how to how to
understand bad words what do you think
the grad student and I did after seeing
that piece of
chat you can imagine we were there at
3:00
a.m. a bunch of people did show up on
the stream at 3:00 a.m. and they decided
on the uh on the four swear words that
they wanted to teach the robot and they
said whenever the robot robot moves
forward and this is the squar word type
y if the robot moves forward and it's
any of the other three swear words Type
n
brilliant if the robot moves backwards
and it's the second swear word that's C
the robot currently hears give it a y if
the robot moves backwards and it's any
of the other three swear words give it a
no I don't know who this person was but
they clearly had figured out what we
were trying to do
I grilled all my grad students at least
it wasn't any of my grad students that I
could tell so they had a systematic way
to figure out how to teach this robot uh
bad
words so we didn't know whether to be
depressed or optimistic at this point
right bad news they're trying to teach
our robots SAR words but good word good
news in the sense that they understood
what we were trying to do and they
actually had a pretty good systematic
plan for how to get the robot to ground
those words in action Poss probably not
the words we wanted it to ground in
action but seemed like it was
possible we thought that was the end of
the story turns out that there were the
good folks who also came to the 3:00
a.m. meeting they sent out a message
later saying good guys they they use
some gendered language good guys come to
the stream at 11: p.m. and I've got a
plan for how to counteract the bad guys
what do you think the grad student and I
did we showed at up at 11: p.m. M the
good guys I'm going to use that inare
scare scare quotes decided came up with
the following plan actually what do you
think the plan
was by definition the good guys are
always trying to foil the bad guys the
bad guys are trying to ground swear
words
well
OPP y
absolutely that's it they created a
spreadsheet and they said here's the
user handles we saw for for everyone
that was at the 3:00 a.m. meeting let's
consider these guys the bad guys
whenever you see them on the stream
whenever they type in Y type in N
whenever they type in N type in Y at
this point I reached out to one of my
social psychology colleagues on campus
Because I was completely over my head
there were more interesting social
dynamics going on in this experiment
than I could understand from my
professional point of view okay an
interesting anecdote but irrelevant to
our discussion today we're going to
focus on just jump in a moment yes did
it work were they able to their uh I
don't know I don't think there was
actually enough reinforcement either way
it's a great question we ended up
getting more total reinforcement for
these things and actually maybe that
might have been because of the good guys
it's hard to say um I don't think we
ever went back and actually
systematically looked but my feeling was
the good guys poisoned the data set
enough that the robots probably wouldn't
have been able to ground those words but
we never actually tested that good
question okay back to
JP we took uh JP and we focused on this
one could the robots learn an
association between JMP and the very
large numbers of y's and n's we
collected from tpr during jump okay
couple other things to note uh we got a
large number of yeses and NOS we got a
total of
7500 y's and n's I don't know whether
that was I didn't know at the time
whether that was a big enough number we
wouldn't be talking about this
experiment if it wasn't it is a big
enough number for these robots to learn
an association between these words and
their actions which we're going to see
in a moment
uh let's see uh of the evaluations all
of these random controllers that people
saw a little more than one of them
received a yes or a no so what does that
mean that means most of the neural
controllers got zero yeses or NOS either
people didn't feel like chatting or they
couldn't decide if the worm is going
like this but staying in place is this
crawling I don't know maybe yes maybe no
maybe you hesitate from making a vote at
all it's exhibiting the crawling motion
but it's not actually crawling so maybe
yes maybe no some controllers got back
two y's and 0er NS or two n's and zero
y's or one y and one n some other
controllers that just happened to be run
on the robot when there were a lot of uh
people on the stream got 17 yeses and
three NOS or 27 Nos and three yeses or
problematically 15 yeses and 15
NOS that's what the data distribution
tended to look like the average human
subject typed in about 18 yeses or NOS
throughout this two we
period proportion of positive
reinforcement this o as you're going to
see in a moment is a number that r es
between minus1 and +
one for a single
controller a value uh of O equal + one
means unanimous
yeses that controller got three yeses
and Zer NOS or 33 yeses and zero NOS an
O of minus one means that controller got
1 n and zero yeses or 271 n's and zero
yeses a controller that got uh a
controller that got 17 yeses and 17 NOS
would have an O of zero so what is an an
average o of 0.28 tell you about the
crowd got more yeses than NOS kind of
interesting I don't know whether that's
a good thing for us or
not okay we've got two minutes left so
let's just start to talk about the learn
part jump was the most common command we
heard so what we did in this part of the
experiment is we took all of the ends
that were run on the
robot whenever the crowd issued jump so
we've got this very large data set that
I just walked you through we're taking a
subset from that data set we're pulling
out just the subset of controllers that
ran on the robot when the robot heard
jump and then we further filtered out
those controllers to controllers that
were running on the robot when the robot
heard jump and we got back at least one
reinforcement signal s Subzero here I'm
sorry about the font here s0 plus S Sub
one the absolutes added up to more than
one we got at least one yes or one no
for that controller running on the robot
when it heard
JP so we've got the actions of the robot
we've got the symbols that it
heard uh we've got action we've got
language and we've got s we've got the
reinforcement signals that we hope are
going to allow the robot to learn an
association between what it felt
literally what it felt and
JP we'll leave things there for today
you have a quiz due tonight you're
working on your second weekly report see
you all on
Thursday


--- Evolutionary Robotics course. Lecture 22： Twitch Plays Robotics contd..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone let's go
final projects weekly reports grappling
with physics engines how's everything
going questions comments verbal
abuse verbal abuse go ahead what's the
difference
between Robotics and reinforcement great
question okay so last time when we were
talking about Twitch Plays robotics I
mentioned in passing re enforcement
learning with human feedback lots of
terms here let's start with the L
learning implies modifications to
synaptic weights usually it implies
nothing else sometimes it's also meant
to be modification of synaptic weights
and learning rules uh in synapses
sometimes it's learning synaptic weights
and the activation functions in
neurons sometimes it's used to mean
optimization or change to cognitive
architecture but usually that's it
that's the boundary of where learning
ends so learning compared to Evolution
what's the main difference at least from
our
perspective changing the body as well so
lectures 2 through 26 inclusive we're
going to finally get to what makes
evolutionary robotics particularly
distinctive or unique compared to most
other approaches to robotics where the
physical structure of the of the
autonomous machine is fixed and we are
learning something about its control
policy or all of machine learning and AI
which tends to focus on learning changes
to synaptic weights the underlying
implicit philosophy which I'm trying to
make explicit for you all in this course
is the assumption that if we want to
create autonomous and Ma and safe
machines here in the real world we need
to think carefully or automatically
design both body and brain together
which again is sort of the underlying
idea of the much older concept of
embodied cognition that's the difference
so the reinforcement in reinforcement
learning for those that know
reinforcement learning what does the
reinforcement part mean of reinforcement
learning reward and Punishment reward
and Punishment which is usually a single
number
which is again not unlike a lot of what
we've seen in all of the evolutionary
robotics experiments we've talked about
in this course we're often boiling down
the quality of the behavior of the robot
to a single number how far it moves to
the right how well it shakes a block up
and down you name it that's not always
true when we talked about the
transferability project which I
apologize we weren't here in person for
but in the transferability project we
saw
multi-objective optimization in which
the objective function which is
measuring the quality of the robot and
its Behavior there were actually
multiple numbers that we were trying to
optimize simultaneously often in
reinforcement learning there's a single
number which is how good or how poorly
the robot or the or the AI model is
doing it whatever we want it to do
that's not always the case does that
answer your question okay all right any
other questions about the final project
things that you're struggling with I
have reviewed uh I have reviewed all of
the those of you that are taking the
course for graduate credit I reviewed
all your final projects and given you
back feedback everything looks uh good
one thing that I saw mentioned in many
of the projects was wanting to do uh
Collision detection between multiple
robots or the differentiable robot
trying to manipulate an object
in the differentiable assignments
obviously you are writing your own
physics engine from scratch and we have
a minimal Collision detection and
resolution algorithm for the undergrads
what's just to give them an update on
what's going on there uh in the
differentiable assignments you're making
a mass spring robot meaning the robot is
made up of a whole bunch of Point masses
masses that are placed at particular
points in
space and then we're
connecting neighboring uh masses
together with springs and adding Motors
to make the Springs increase and
decrease in length Collision detection
at the moment is just whether or not the
center of any of the masses passes below
the ground plane this would not be a
collision this would be a collision when
this occurs you're applying a force to
push the object back up or ignore or
canceling out anym pushing into the
ground it's about as simple a collision
detection and resolution algorithm as we
can imagine if you I I think one or a
few of you propose trying to do a swarm
in the differentiable simulator which is
perfectly
fine how do you detect collisions
between this robot and this robot and
resolve those
collisions any
ideas if you can cast your mind back to
lecture six or seven where we talked
about physics engines
ideas
C of rad okay we could look we could
look to see whether uh these two objects
have collided and if the distance
between any pairs are less than 2 R the
radii of these circles then you've got a
collision which is pretty good but what
happens if you get to this
situation looks like a collision to me
but it is not detected by your Collision
detection algorithm other
ideas you could also like simple you
just have like just call like just
Define Center of this that triangle and
make a circle around it and those kind
of like make them all like one a circle
each okay you this is a good idea uh
perhaps this is based on the idea of
collision boxes which we actually saw
when we talked about physics engines a a
great idea also a little bit problematic
there are edge cases in which it's not
going to capture certain things but a
good a good start okay the point I
wanted to make is this is not trivial
there is a whole literature in uh in
computer graphics and physics engines
research about exactly this how do you
detect and resolve collisions
you don't have a lot of time left in the
semester so allow me to make a
suggestion which is modify modify the
radi of the point sources to be just
large enough that they're always in uh
they're always touching their neighbors
that's not always going to be true
because the length of these Springs is
sometimes changing but you can easily
set the radise so most of the time these
objects are in collision with one
another which makes collisions with
other robots relatively easy going back
to what Nate mentioned you can just look
to see whether any pair of objects one
from one robot and one from the other
have a distance of less than two R then
you can count that as a collision and
apply a resolution which is to push them
apart you can either add those forces to
the objects to the points themselves or
can add those forces to the spring you
can assume there's a force that's
pushing the Springs apart it doesn't
really matter just some suggestions for
those that are wrestling with Collision
detection and resolution in the
differentiable
simulators okay any other tips and
tricks I can offer anything else that's
problematic at the
moment going once going twice okay all
right so back to lecture uh we are
trying to finish up our SEC our long
section here on open challenges in the
field and I was walking you through the
Twitch Plays robotics project last time
which is an attempt to try and scale up
Robotics and in and scaling It Up by
involving more and more humans in
directing using human feedback to direct
how robots evolve I realized that there
was actually a video example of twitch
embedded in the schedule so just to
refresh your memory of how this works
here's an example of Twitch Plays
robotics running we expose the crowd to
the worm and the quadruped we invited
the crowd in the upper right panel to
propose things that they thought they
could teach the robots and you just saw
one chatter vote for crawl forward which
seems promising and down here if I speed
this up a little bit you can see that
their vote to teach the robot to walk
forward has now been sent to the robot
and the Violet robot we are trying to
determine whether it is walking forward
and we will see in a moment that a
couple people voted for no The Violet
robot is not walking forward okay you
can go and watch this video snippet it's
embedded in the schedule so just as a
reminder for how the Twitch Plays
robotics project works this is what the
crowd
saw and as a reminder of the data set
we've got these two robots R subz the
worm R sub one the quadraped we're evalu
the crowd is posing a whole bunch of
commands plain English to the robots for
each one of those commands that was sent
to the robot some of these commands
collected uh some of these commands on
the robot we were running that robot
with a whole bunch of random controllers
so the ends are random sets of Random
synap weights that were sent to the
robot while the robot was quote unquote
hearing a particular set of commands and
for some of these random controllers
that were running on a robot under a
given command the crowd provided a bunch
of reinforcement either yes or no we
tallied up all the yes votes and stored
that as an integer in S Sub one and we
tallied up all the no votes and stored
that in s Subzero that's the data set
okay just to remind you for where we
were we reviewed some of the statistics
about what we got back the most common
command issued by the crowd was jump so
in the results we're going to see now
you're going to see how and whether the
robot managed to ground the symbols J MP
in its own sensor motor experience okay
I ended last
time by mentioning this filtering step
down here among all the 56,000
controllers random controllers who ran
on the robot we took out the subset of
random controllers that ran on the robot
when the crowd was issuing the command
jump to the robot and then we further
chose from there the subset of
controllers that were issued on the
robot when it heard JP and somebody
there was at least one vote the sum of
the no votes and the yes votes was
greater than zero at least one yes vote
and at least or at least one no vote so
far so good okay so now we have in hand
a bunch of controllers we went back and
ran all of those random controllers on
the robot and this was offline the the
users were not the crowd was not seeing
this we collected all of the sensor data
that was generated by those random
control rers and we took just touch
sensor information and stored it in a
binary Matrix so you can see here for
the worm the worm is made up of One Two
Three Links in the binary Matrix we have
one two three
columns each row corresponds to one time
step in the simulation and we just
recorded whether or not that touch
sensor was firing here it was zeros and
ones and your Cod base I think it's
minus one and plus one doesn't really
matter so now for every random
controller that was executed during jump
for which we have some feedback from the
humans we also have this felt experience
this is what the robot felt when the
crowd was saying yes you're jumping or
no you're not Jing so far so good
okay okay sorry just to orient you we're
on stage three of this four stage
project in stage three here we're going
to try and get the robot to learn a
relationship between what it felt the
command and how the crowd
reacted
okay okay
sorry having problems navigating this
morning okay
ah we'll get
there okay all right for the worm there
were a total of
1,038 random controllers during jump
that received at least one piece of
sensor uh reinforcement
feedback so for each one of the we have
a
1,038 of these binary matrices the worm
robot had
1,038 unique
experiences and for each of those
experiences we take all the positive and
negative reinforcement and we collapse
this down to a single uh a single value
which ranges between minus1 and plus
one an O of minus one is uniform
negative reinforcement
zero yes votes three no votes or zero
yes votes 17 no votes
unanimous negative reinforcement an O of
plus one is unanimous positive
reinforcement zero NOS 14 yeses zero NOS
131 yeses that's an O of plus one so an
O of zero is
a neutral right split votes four yeses
for NOS 17 NOS 17 yeses so we have
1,038 o values that correspond to each
of the
1038 uh binary
matrices so far so good okay so let's
have a look at the moment let's have a
look at the relationship between the
each o and its corresponding
T okay
on the vertical axis here you can see
that the vertical axis ranges between
minus1 and + one and on the vertical
label here it says normalized
reinforcement signal so this is O over
here you'll have to trust me there are
1,038 Green Dots here so each dot
corresponds to the result of one random
controller running on the worm
robot T is a matrix so so on the
horizontal axis here the grad student uh
Joey who worked on this project she took
that uh touch sensor Matrix and
collapsed it down into a single number
which is the proportion of time that the
robots spent on the ground for those of
you that are working on the Up Up and
Away project this should start to sound
familiar how do you think Joey collapsed
this uh binary Matrix down into a single
number percentage of times spent on the
ground we've got three columns for each
of the three body parts that make up the
worm and a thousand rows that correspond
to the Thousand time steps in the
simulation the number the number of time
steps the number of rows that are all
zeros exactly right so the proportion of
all zero rows in that t
Matrix that becomes a single floating
floating point value
between zero and one and she plotted
that on the horizontal axis here now
Joey the grad student has stepped in and
she's made an assumption about the
robots felt experience she came up with
this way of collapsing the binary Matrix
so we're cheating a little bit we we
want to keep humans out of the loop but
we wanted to see for ourselves first
whether we could see any relationship
between the behavior of the RO robot so
the further to the right the points are
the more time the robot spent on the
ground and the vertical axis which is
the way in which the humans provided
feedback to that
behavior is there a
relationship see some of you sort of
squinting and may maybe
nodding what's going on here
did the 434 people we got feedback from
were they just Bots were they just
typing things in at
random coration line drawn through here
the data I'm very confused by the number
of
one okay there's lots there's lots to
see here in this
figure
so we plotted this trend line here
although it's a little difficult to see
there is a negative correlation here
generally speaking the further to the
right a point is the further down that
point tends to be you can see there's
kind of a cluster down here and another
cluster up here not so many points up
here and not so many points down here a
little bit of a negative correlation is
this good new good news for us
investigators or bad
news this is good
because people
say not they didn't the more the robot
jumped the more of the proportion of the
time it's spent on the ground the more
negative feedback that crowd tended to
give the more often the crowd was saying
no you're not jumping so the fact that
we could fit this line and it was a
negative slope that's what we were
hoping for it worked of course it's not
a perfect correlation if it was a per
sorry it's not a perfect
anti-correlation if it was a perfect
anti-correlation what would you expect
to see in this
figure it's not so you don't see
it
perfect diagonal you'd expect to see all
the green lines along some uh diagonal
with negative slope that's definitely
not what's going on what a surprise
humans tend not to always agree uh with
one
another Nate mentioned he was confused a
little bit about the fact that most of
the O's most of the summed reinforcement
was either a perfect one or a perfect
perfect minus one and there's also kind
of a cluster here at zero why why not a
more uniform spread along the vertical
axis think about the humans that are
involved in
this few vs few votes so for the vast
majority of these th a little over a
thousand controllers there was usually
only one piece of reinforcement either
there was only one person on the stream
at that time or only one one felt
sufficiently emboldened to offer a yes
or a
no kind
of like it's kind of jumping but
everyone else say yes so I'll just say
yes because everyone else great
observation anecdotally we saw a lot of
that during times um on the stream when
there were quite a few people on it we
would see things like yes yes yes and
then one person would say no and the
others would say why did you say no and
the person would typee in why they
thought it was no and then sometimes
they would change their vote you
definitely saw chatter among the uh the
Chatters and sometimes they would change
their vote seemingly in response to peer
pressure again this is all anecdotal
somewhere we have the raw transcript of
every single chat and everything that
everyone uh said scrubbed of any uh
personal details all anonymized if
you're interested shoot me an email I
should be able to dig it up if It's a
Wonderful document to read okay so this
was at least this was us sort of doing a
sanity check again baby steps like your
final project making sure that there
might actually be a pattern here for the
robot to learn an ability to ground this
symbol in its own felt experience and to
ground it Guided by human
feedback
okay these were the or so controllers
under jump for the worm we had about the
same number of random controllers
executed on the quadraped for the same
set of symbols jump what's going on in
the case of the
quadropad different set of controllers
different body plan same set of
symbols no idea whether this was the
same set of humans or not what's going
on there's a lot more neutral ones a lot
more neutral ones I think you're right
could be here they might just be a
little bit more spread out
possibly uh shifted to the right so
unfortunately when we plotted the
horizontal axis down here the grad
student did not keep the same horizontal
range this is a a rookie mistake when
you plot everything if you create
multiple plots for us please make sure
to keep the horizontal and vertical axis
ranges about the same for exactly this
reason often we want to look whether a
pattern stays the same or differs across
multiple figures little hard to do here
because of the shift in the range of
values on the horizontal axis so
apologies you're going to have to do a
little bit of more a little bit more
cognitive work here this morning
so one non- difference one thing that is
the same is there's a little bit of
anti-correlation again it's not very
strong but it's there so that's good
news that means that for at least two
different body plans there seems to be a
relationship between human feedback and
the felt experience of the
robot other patterns you've
noticed top there's not as much of a
clump in the top
left
yeah a little bit of a weaker
anti-correlation
ground absolutely so the points for the
quadruped tend to be shifted a little
bit further to the right why do you
think that
is harder for this morphology to jump
yep exactly
okay imagine uh imagine that the robot
had actually run some machine learning
algorithm not a machine learning
algorithm had run an algorithm that
found this anti-correlation between its
own experiences between all the
horizontal positions of these points and
the vertical positions of these points
every time the robot hears
JP and has this particular
experience the crowd says actually
uniform
negative and over here and over here so
imagine the robot has now discovered
this particular line what does JP mean
to the
robot some of you may have been
following the dis public discourse
around whether chaty PT understands
language let's have the same discussion
about our worm robot here does it
understand what jump
means and if it
does what does JP mean to the
robot stage to the left of this graph
you mean for the robot okay okay that's
idea spend as little time on the ground
as possible how does the robot know to
do
that make your touch so there's
something about points being further to
the left seems to correlate or have
something to do with JP but what exactly
does it have to do
with
JP what does JP mean to the
robot I tend to put scare quotes around
all these things understand predict mean
no scare quotes today what does it
really mean to the robot literally still
random controllers these are still
random controllers absolutely there's no
Evolution here there's a little bit of
learning it's learned that there's a
relationship between the horizontal
position of each of these controllers
and the vertical position of these
controllers it's not
arbitrary that hasn't happened yet true
good point yes sorry this line however
we whatever we want to call it it's
found this
points and the vertical points this is
just linear regression if you want to
call that learning or not we'll say the
the robot has run linear
regression on on this data to which it
has
access let's say the robot is still
thinking about
jump and it executes yet another random
controller and that controller causes it
to spend o 40% of the time on the ground
the robot just does something
arbitrarily and it's able to now place
that point horizontally it says okay
that particular controller caused me to
spend 40% of the time on the
ground no humans
around what is the robot thinking at
this point how does it estimate the
vertical position of this
point based on the line so it has this
line the robot has discovered that there
is a
anti-correlation between the rightward
position of the point and how far down
it is the robot spends 40% of the time
and uses this line to try and reason
about
jump the robot
predicts that the point would lie here
on the line if you were able to ask the
robot
now what would it tell you about this
particular Behavior it just
performed probably a jump uh it would
say probably a jump but we're not quite
there yet right we're trying to stay
grounded in the data it's got JP it
spent 40% of the time on the
ground getting closer it did a good job
how does it know that it did a good
job three it says if there were people
around more often than not they would do
this if the robot runs a random
controller and it spends 100% of the
time on the ground what would the robot
tell you about that
controller relative to
jump if there were humans around they'd
give more than unanimous negative
reinforcement whatever that possibly
means yeah if you've ever spent any time
around dogs they'll do something and
then they'll look at
you and you can sometimes see in their
eyes they know they know how you feel
about what they did yeah so for this
robot trying to keep things literally
and metaphorically grounded for a moment
if we want to try and talk about ju we
want to talk about the relationship
between
JP the literal felt experience of the
robot touch sensor data jump and touch
sensor data and quantitative human
feedback the robot can determine that
there is a relationship between these
three things and again you can form your
own opinions my opinion is that that is
what jump means to the robot that is
understanding jump it's maybe not a
profound understanding but the robot can
more or less tell you or try to show you
it knows what JP means by doing a bunch
of things and making predictions about
human feedback or social repercussions
of its
actions everybody see that you don't
necessarily need to agree with me we can
all disagree about what it means to
understand language that's a different
discussion this is the one of the
embodied approaches to trying to
understand language or enable robots to
understand language
questions
comments differing
opinions ask like you trying to get the
robot like I think about the robot would
get itself to like the highest jump
number and they like oh jump I'll just
keep redoing that number you know like
they right
eventually it it could absolutely right
it could try and act on its knowledge
here we're not trying to get the robot
to jump we're just trying to see whether
the the robot could discover or find a
relationship between these three things
symbols sensory information human rep
social repercussions to its actions yeah
it's jump according to Joey the grad
student right Joey determined that jump
means the proportion of time for which
the robot spends on the ground as we
talked about last time in the up away
project there are other human
definitions we could come up with
jumping and you can see from the actual
vertical Heights of these points the
humans here also don't agree about what
counts is jumping and doesn't and isn't
jumping yeah so so it's a question about
our goal so our goal here was
this we maybe we could have done that we
wanted we wanted to try and introduce as
little bias as possible the moment we
make a fitness function for jumping and
evolve robots for that jumping function
then it's the crowd deciding whether or
not that's jumping and they either agree
with us who wrote down the Fitness
function or not there's still bias here
again because of Joey's decision about
how to collapse this Matrix we're going
to remove that last bit of bias or at
least the last bit we can see in a
moment there's one more data there's one
more set of results I want to show you
but I just want to make sure we
understand what the our goal was here in
this project symbols sensation social
feedback yeah okay so if you're willing
to entertain the notion that
this line the fact that there is an
anti-correlation between touch
information and O normalized human
feedback is it the same is the
understanding of jump the same for the
worm and the quadruped do both of these
robots I'll put the scary quotes back on
do both robots understand J JP in the
same
way does it mean the same thing to these
two robots
given the definition of understanding we
just provide
it I see some of you doing this South
Indian nod right kind of kind of yes
kind of
no why kind of yes kind of no I also
agree kind of yes kind of no see the
same Trend but the data points are all
different absolutely so again if you
were able to ask these robots and you
can't ask them but if you were they'd
say yeah mostly we agree it's an
anti-correlation between the amount of
time we spend on the ground and the
number of no votes we get back but we
disagree on the uh on the y- axis
intercept of these lines if you look at
so this this anticorrelation here
intercepts a little bit above zero this
one intercepts more more a little bit
higher it's not much but it's a
difference we I found this interesting
because it immediately means for these
two robots jump does not mean the same
thing now that's either a quirk of the
particular humans that
reinforced this robot and the particular
humans that reinforced this robot maybe
it's an artifact of the fact that they
were running slightly different
controllers maybe it's an artifact of
the fact that they have different
bodies maybe it's a little bit of all of
the above we don't know we haven't done
that study
yet for me the more interesting outcome
would be because of their
bodies in retrospect maybe that's not so
surprising if you have a different body
plan jumping is going to mean different
things to different people or different
things yeah so far so good any questions
about this particular set of
results okay last bit and then we'll
move on to collective
intelligence as I mentioned Joey has
introduced her bias here by her
definition of what jumping is the number
of rows in the T in the binary Matrix
that are all zeros let's try and remove
Joey's
bias the next thing we're going to do
here is we're going to actually do some
learning so back to Cam's comment here
we created a very simple neural network
this is not a neural network that's
controlling the robot that part's
already done we've got the thousand
controller neural controllers for the
worm about another thousand random
neural controllers for the quadrip we're
going to create a little neural network
here that has three input neurons and
one output neuron with one recurrent
connection so we've got a total of four
synapses which means we need four
weights W for synaptic
weights we're going to take each of the
Thousand binary touch sens sensor
matrices which remember have three
columns corresponding to the three touch
sensors in the robot and a thousand rows
corresponding to what values those touch
sensors had at each of the Thousand time
steps in the simulation when the robot
was running that controller we're going
to take each of those 3 by, matricies
and push them through one of these
random neural networks
we got a lot of random neural networks
on the go now we've got the Thousand
random controllers for the worm thousand
random controllers for the quadrip one
random neural network that's going to
digest each of the
Thousand binary matrices from the worm
row by row we take the first row of the
first binary Matrix plug it in propagate
down to the output neuron where we're
going to get some value between minus1
and + one we used the 10h activation
function which is going to make sure
that this value when we read it out is
between minus one and plus one so far so
good we take the second row in the first
random controller plug that into the
input layer push it through this neural
network and because of the recurrent
connection it updates the output value
of this neural network take the third
row push it through fourth fifth sixth
sth thousandth row push it through this
neural network and when we're done
pushing all thou the Thousand rows of
one random neural controller through
this network we read out this value and
I'm sorry it's hard to see here we're
going to interpret this value as o Prime
what do you think o Prime
means this is kind of shorthand from
machine learning what is O what do you
think o Prime
means resp the predicted crowd response
exactly so in my little cartoon example
here let's assume for that random neural
controller the crowd gave back an actual
o of minus point8 whatever that is seven
down seven no votes and one yes vote
mostly folks believed that for that
particular controller the robot was not
jumping the prediction of this neural
network which is the robots neural
network this is its this is the social
part of its brain if you like it's
trying to learn how to predict how the
crowd's going to respond to what it
did in this particular random neural
network it makes a prediction of
0.25 pretty far from minus8 remember all
these O's and O primes range between
minus1 and plus one this random neural
network has low social intelligence it
has not predicted the crowd very well so
far so good okay we are not changing
these four synaptic weights we're
leaving them as they are we're going to
take the second the second binary Matrix
for the worm reset the output neuron
refresh everything
push it through again get a second o
Prime push the third binary Matrix
through get a third o Prime push all
1,28 random controllers or all
1,28 uh Sensations through this neural
network and we have
1,038 o primes and we have a, and 38 O's
what do you think we do
next
not quite
close the mean error calculate the mean
squared error calculate the error or the
difference between each o Prime and O
which gives us back 1,038 errors and
then as Nate mentioned we're going to
take the mean of all of those errors on
average how well or how poorly did this
part of the robot's brain its social
intelligence due at predicting how the
crowd would respond to all 1038 things
that the robot did you can imagine that
for four random synaptic weights error
is quite High it doesn't do very well so
we could either use reinforcement
learning or an evolutionary algorithm
doesn't matter uh in this experiment I
think Joey just used an evolutionary
algorithm like you're doing in your
assignments she evolved population
of length for vectors she evolved
populations of synaptic
weights she was evolving using a
particular Fitness function what do you
think that Fitness function
was what do we want this neural network
to
do minimize error right so we're going
to evolve a whole bunch of sets of
synaptic weights searching for a set of
synaptic weights that minimizes means
squared err that this neural network
gets better and better at predicting
social uh human feedback for more and
more of those 1038
behaviors
okay hopefully most of you are wondering
how well did it do how low could we get
that error what I just described is the
training phase we're training this part
of the robot's brain to have high social
intelligence which is low mean squared
air between the op primes and the
O's we get some mean squared
air2 let's say what does that mean what
is point2 mean is that good
bad I have no
idea so in like in most machine learning
experiments we're going to do one last
experiment or one last
test called testing we actually didn't
train this network on all
1038 uh binary matrices we picked a
random subset of them and set them aside
and only trained this network on the
remaining binary
matrices and then after training after
we had tuned these four synaptic weights
we're going to take those held out or
hidden sets of uh binary matrices feed
them through here and get o primes so
we're going to take this trained part of
the robot's brain and we want to see how
much Social intelligence the robot
actually has the robot's going to play
back some of the things that it did it's
going to feed into this trained Network
a bunch of these heldout binary matrices
and how are we going to know we're going
to we're going to get something back
here how are we going to know whether
this network was trained well or not
what would we expect to
see
corly it predicts o correctly but
correctly
how low error low error compared to what
how how low does it need to be to be
able to say yes the robot has actually
learned something about the relationship
between what it did and how the crowd
responded let me flip the question
around for you let's imagine that
training failed these are just all
synaptic weights the robot didn't learn
anything it couldn't find any this
network could not find any relationship
between all the t's and all the O's if
you then took this failed neural network
you don't know that it's failed but you
took it and feeded in new tees that it's
never seen
before what would you expect to get out
here what would the O primes look like
compared to the O's over here what error
would you expect to get during testing
if nothing was learned during
training
similar similar or Worse let's try and
be quantitative here now we want to be
able to say with confidence did this
thing learn or
not
random errors would be higher than a
random
guess of
R the errors of a random guess would be
higher right so if this thing hasn't
learned anything you would expect that
it's going to spit out o primes
arbitrarily between minus1 and + one
comparing that to the O's you would
expect a difference of about one if
you're making random guesses between a
value of minus one and plus one and I'm
picking a value between minus one and
one you have no idea what value I've
picked we played this game over and over
again my o would differ from your o
Prime on average by a distance of about
everybody see that
intuition so if this mean squ a if the
differences between the predicted o
primes in the actual O's in the testing
phase are less than one on average then
this thing has learned
something so far so
good okay let's have a look okay all
right let's have a look at this set of
data over here for the simple robot this
is the worm
robot uh green is the actual
experiment and you can see that on
average the error between o Prime and O
was 42 again 42 is a very auspicious
number in our community this was extra
good news for us
okay uh here's the permuted control and
the random control we just talked about
the random control imagine a neural
network in which we intentionally set
all four weights to be random values it
actually guesses the difference is
actually about 47 not a distance of
one something's up what's
up the actual votes AR the actual votes
the O's themselves not the O primes but
the O's are not uniformly distributed
between minus one and one they're
they're very far from that as we saw so
that's a statistical discussion not
relevant to our purposes for now doesn't
actually matter what the valid the
absolute error of random neural networks
is all that matters is that the
predictions of the trained neural
network is lower the error of the
predictions is lower than the random
control uh you can go read the paper we
did a second control the test called the
permuted control we're not going to talk
about that generally speaking green is
lower than blue and red which is our
signal that that neural network that we
just talked about this one is able to
learn a relationship between what the
robot did and how the crowd
responds without us having to make an
assumption about
jumping asterisk kind of we're still
assuming jumping has something to do
with touch information can't get rid of
bias completely but there you go
okay same thing for the complex or
quadrupedal robot it's able it if it's
the one that's training this neural
network this little part of its brain it
can in theory learn a relationship
between what it did and how the crowd is
likely to
respond questions
comments okay we were just talking about
bias plenty of my bias here if we want
machines to understand language or
understand anything about operating here
in the real world with us the best way
in my personal opinion you form your own
opinion is that understanding has to be
grounded in the social part imagine an
autonomous vehicle that suddenly
experiences a surprising event and it's
got to try something new it's far beyond
its training
experience My Hope for that autonomous
vehicle is that that in the few seconds
that it's quote unquote deciding what to
do in this new surprising environment it
is quote unquote thinking about how
humans will feel about what it did in
retrospect in order to act safely in the
real world in my opinion for machines
they need to be able to predict how
people are going to feel about what they
are about to do our dogs are not very
good poker uh players they don't have
good poker f faces you can see it on
their faces they're doing something and
they have a pretty good prediction about
how you're going to feel about what
they're doing social intelligence okay
again that's just my two cents on the
issue
cam has gained this really deep
understanding of these high Lev symbols
and how they interact with it's not
grounded in body interaction but
question mark maybe it is grounded it's
still an open question right not not in
this way but maybe indirectly chat GPT
is inheriting an understanding of humans
and their world not not quite clear yet
in my opinion sorry could we like more
clearly grounded taking that
understanding whatever it is throwing it
in a robot and then trying to ground it
maybe
after understand of Sy great idea make
do do your chaty PT thing have it learn
relationships between every word on the
internet and every other word and then
expose it to sensor motor experiences
and see if it can find a relationship
between what it's learned up here among
the symbols on the internet and what it
feels in the real world
maybe do we do this with our
kids do it the opposite way around right
maybe we have no choice just the way
things go whatever humans are doing it
seems most likely they're doing some
maybe not this but they're learning
something about what they do and what
how mommy and daddy or the caregiver is
going to respond and kids very quickly
get very good at making predictions
about that and then later they start to
read books and go to the library and
read the
internet should we do it which way
should we do it it's not clear does it
matter maybe it doesn't matter okay it's
an interesting time to be thinking about
these Concepts obviously we're in the AI
High summer who knows to be determined
maybe some of you will figure this out
okay all right that's enough about
Twitch Plays uh Robotics and that also
concludes our discussion about all of
the open challenges in the field
obviously there are many we've got uh we
got 20 minutes left so we are going to
dive into the penultimate uh theme of
the course which is collective
robotics like humans for robots there
are many tasks that are difficult or
impossible for a single machine to
perform so for many applications of
Robotics it seems more desirable to
deploy a large number of machines that
can collaborate and cooperate to perform
that task compared to one big complex
machine what might some of those
applications be
where does a swarm of robots make more
sense than one big complicated
machine large if you got a large area to
cover makes obvious sense you'd like to
have a large number of machines other
situations replication of a lot of
things at the same time so if we want to
parallelize effort absolutely yep good
point you want redundancy what do you
mean by wanting redundancy
robem robot rest the
robot achieve absolutely so doing
something over a very large spatial
scale doing things in parallel doing
things robustly if any one member of the
Swarm fails for whatever reason the rest
of the Swarm can carry on just from
those three observations hopefully you
can start to uh appreciate that there
are many many many tasks for which large
numbers of robots are more useful than
one there's no free lunch there's always
a cost what is the cost of Designing
training and deploying large numbers of
simpler machines compared to designing
training and deploying one big complex
complicated machine what's the
cost eff Effectiveness what do you mean
by Effectiveness so like if the robot if
you have a lot of robots but they're too
simple you might not
get great point right we might make them
too simple they just they're not
effective yep what other costs are at
play here material cost do a bunch of
them expensive absolutely so NASA loves
the concept of collective robotics
obviously they have literally a lot of
real estate in this solar system to
explore L they would love to send a
million Rovers to Mars they can't
because you can't put them all in a
rocket right material cost volumetric
cost how much literal 3D Volume does a
robot take up weight and so
on great point the one flaw that takes
out all the machines the other thing
that's scary about deploying very large
numbers of things is that they all have
a common Achilles heel right we I
thought we learned this lesson early on
with computers that a virus uh that can
attack and bring down one operating
system by definition can bring down
every other instance of that operating
system unfortunately we still seem to be
developing Technologies in which there's
only one or a couple of operating
systems in play not a good way to do
things right we've created a
technological monoculture we have a
large number of these things that all
inside look and act almost identically
not a very good idea there's a cost to
making large numbers of things one of
them is making them two similarly makes
the Swarm as a whole vulnerable another
good hidden cost other costs of swarms
imaginary sense exact term
like uh when like a fish has like a
thousand babies like not a lot of them
will survive but like a few will make it
because they're all a little bit
different absolutely right so maybe back
to material costs we might deploy a
large number but most of them fail it's
very wasteful effortful thing to
do why do they need to
communicate
okay maybe so I'm sort of giving away
the punchline here once you get to a
certain level of sophistication in a
collective entity either a group of
humans or insects or machines it usually
makes sense for them to
communicate although I will give my
usual warning here thinking about
thinking is misleading what Collective
tasks actually require explicit
communication which can get away with
implicit communication and which require
no communication at all I just wanted to
pose that question to you we will come
back and tackle that question uh next
week when we get to lecture 21 the issue
of communication obviously communication
can be helpful in very large collectives
we are part of an 8 billion uh
Collective and we tend to communicate
explicitly amongst ourselves not all
large collectives explicitly communicate
or at least not that we're aware of okay
we're going to talk first in lecture 20
coordination doing something
collectively together more easily than
one doing it alone and then we'll talk
about communication next week okay all
right so let's start with coordination
and swarms
obviously lots of examples of this uh in
nature here are starlings doing what
staring
do best which Starling is in
charge wouldn't it be great if humans
could do this large coordination no
one's in charge we haven't quite figured
this out yet but clearly it's possible
okay uh flocking in Birds schooling in
fish hting in land organ landbased
organisms it's ubiquitous in nature
mother nature has re
discovered Collective Behavior over and
over and over again the cells inside
your own body coordinate they are
themselves a collective for the obvious
reason that coordination is a good way
to do things often it makes sense for
large numbers of simple things to do
things collectively than to try and do
them on their own much fodder here for
biological inspiration for us trying to
create large numbers of machines that
coordinate their efforts we're still not
that good at it yet okay but we're
working on it here's one of the places
where we started to work on this um this
is work by Craig Reynolds uh who back in
the 1980s he was a computer Graphics
researcher wanted to create computer
Graphics a very simple animals
coordinating their actions so he
simulated some very simple animals these
little triangles these later become
became known as boyss boid D if you
Google boid or boids you'll find all of
this work there in an individual boid it
is simulated inside a simulator this is
1980s no physics engines existed so
Craig had to write all of this himself
for each individual boid in the Boyd
swarm it had a a circle of sensation it
could see a certain distance around
itself and at every point in time each
boid looked inside its circle of
sensation and noted the relative
position of any of its peers that were
inside the sphere so in this example
here the green boid knows that it has
three of its peers on its
left in this particular example here
this different boid at a different point
in time no knows that there are six
peers surrounding it each boid knows the
relative position of all of its
neighbors inside the sphere sensation
and it also knows the heading of all of
its peers that's the little line
emanating from the front of the
triangle at every point in time the boid
was trying to update its new position
and its new orientation how did each boy
decide what its new position and new
orientation was first uh each void would
run three separate functions the first
sub uh function is the separation
function it would compute the relative
positions of its peers and steer or
alter its orientation so it would point
away from its
peers so it's updating comes up with a
little Delta for its orientation it's
going to try and turn away from its
peers before it moves it also runs the
alignment
function which computes the average
heading of all of its peers and the blue
line here represents the mean or average
of all of its peers headings and it this
function returns another Delta in
orientation another suggestion for how
to change orientation so that the
robot's orientation at the next time
step will more closely approximate the
average heading of its peers so an
individual peer has run separation gives
back one suggested change in heading it
runs alignment gets back a second
suggestion in a change of heading and
finally it runs cohesion which again
gives back another Delta which is steer
towards the average position of all of
the peers so we've got three Deltas in
orientation after the boid has run all
three of these functions combines them
sus them and takes the average and then
updates its heading
accordingly every boid runs exactly
these three functions at every time step
in the simulation so far so
good this is the
result again you'll have to excuse the
1980s Graphics here this was
state-ofthe-art at the
time
who's in
charge no one's in
charge why do the boids flow around the
cylinders in their
environment
uh kind of so it's if obviously if you
have a pillar on your left you cannot
have any peers over here if you've got
these peers over here the cohesion
algorithm is going to pull you towards
your peers the boids all view anything
in their environment as a peer they're
very social everything is part of the
flock so they're also being crowded by a
whole bunch of individuals over here
it's not a whole bunch of individuals
it's the cylinder which is causing it to
try and separate or move away from that
cylinder as well right the boids are not
very bright this is all they do they
don't distinguish between cylinders
peers this pier that peer with these
very very simple rules placed into a
large number of these boids you get
relatively
sophistic sophisticated Collective
Behavior
this was shocking at the time and for
some people it's still shocking to see
you can get these relatively elegant
Collective behaviors from relatively
simple rules when you watch the
starlings are a very large school of
fish you immediately realize no one is
in charge but it's easy to start to
think that whatever they're doing is
pretty
sophisticated maybe not remember the
lessons of Valentino brenberg and the
brenberg vehicles often we overthink
things maybe what starlings are doing
and mackerel uh and wilderbeast and so
on are maybe not as complicated as we
think they may not be running this in
their heads but this seems to be enough
to get things that look very much like
hering flocking uh and
schooling okay so this was the 19 uh
this was the
1980s and there we
go I mentioned Craig Reynolds was a
computer Graphics researcher he started
to share his results with other computer
Graphics professionals some of whom
worked for Disney and in the 90s we
started to see movies like
this any movie you watch today that has
any large uh simulated crowd scene it is
running that computer algorithm that
generated that clip for that movie
somewhere down in the depths of that
computer algorithm is the Boyds
algorithm this was the beginning you can
layer on as you can imagine it's quite a
modular uh algorithm you can start to uh
add on other nuances to how each
individual uh in the uh swarm Alters Its
Behavior did we miss it already when the
Wilder beasts are coming down the Box
Canyon they flow around this spur of
rock you know why that particular scene
is in this movie
now okay
okay huge impact on the computer
Graphics community and uh Film Community
as you can imagine also an impact on the
robotics Community this was again a
wakeup call that if we want to colle if
we want to create Collective Behavior
maybe we can write down these uh these
simple functions it turns out in
practice that doing this is tricky not
that easy so what surprise in the 1990s
some Evolution and roboticist came along
and said let's evolve these
functions against a fitness function
that doesn't reward for the behavior of
an individual but rewards for the
behavior of a group so what we're going
to see uh starting today and then into
next week is an evolutionary robotics
experiment where they're going to evolve
behaviors for individuals in a
collective and reward or provide a
fitness value back to the group as a
whole perhaps not great from a public
relations point of view but these
roboticists chose Collective hunting so
here we go all right one of the reasons
why it's useful to work in a group if
you're a hunter is your prey is pretty
canny uh you'll remember I included this
slide to remind us of Alexander's book
on the principles of animal Locomotion
and also our discussion about how the
fact that brains tended to evolve to
orchestrate motion everything that the
brain does ultimately can be traced back
to evolutionary pressures for us to
coordinate how we move about in the real
world tell me about lions and Thompson's
gazel why do Li hunt as a pride rather
than as an
individual absolutely so imagine this
particular lion and this particular
gazelle and let's assume that this lion
is deprived of its Pride there's no
other there's none of its peers around
it's got to bring down the gazelle on
its
own what are the chances if you were
this lion and you were extremely hungry
you don't have time to wait to go find
your pride what do you
do a window catch it you've got a 4C
window to catch it so what do you do you
either know consciously or
subconsciously about how much time you
have what do you do you're the lion Sak
you sneak up on it we were just talking
about dogs and you want to have cats at
home they're very good at getting low
and sneaking up on things for this
reason so so this is just meant to
illustrate again there are certain
things that are just difficult to do on
your own literally if you can bring down
the gazelle in less than four seconds
knock yourself out if you can't or
that's a rare thing to do you have an
alternative strategy available to you
which is try and recruit your peers to
work collectively but how how do you
work collectively okay so we just spent
some time on the actual serengetti plane
in Africa in this paper from 1996 we're
going to travel to a virtual serengetti
that looks like this we've got 2 minutes
left so I'll just introduce uh the
playing field here we've got this plane
and we're going to evolve behaviors or
these researchers are going to evolve
behaviors for these four Lions and the
fitness a single number that we're going
to apply to all four Lions is how well
they bring down this virtual gazelle in
the virtual cere Getti plane again this
paper was published in '96 four years
before physics engines so these
researchers created their own very
simplified uh physical environment
simulated physical environment they plac
the four lions at random positions on
this 15 by 15 unit long uh virtual plane
they placed the gazelle at a random
position on this
plane what happens if the gazelle or the
lion gets to the edge of this plane
plane I don't know falls off the edge of
the world so these researchers took this
virtual serengetti plane and they folded
this two-dimensional sheet so that the
long top half came into contact with the
long bottom half so we now have a tube
and then they took that tube and bent it
so that the two ends of the tube touch
and we now have a donut or a toroid so I
want you to virtually imag I want you to
imagine four of these virtual lions
running on the surface of this toroid
same for the
gazelle like us they now live in a world
that has no edges they can run forever
everybody see that okay good mental
image to leave you with today you have a
quiz due tonight you're working on your
final project have a good rest of your
week see you Tuesday


--- Evolutionary Robotics course. Lecture 23： The evolution of teamwork..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone uh I don't
have any updates about the final project
or weekly reports everything going well
any tips or tricks I can help you
with no okay so uh we're going to dive
back in to lecture material uh in a
moment but before we do um one of the
many perks of being a professor is every
once in a while I get to embarrass my
students today is one of those days your
uh student Pier here cam Bowski uh I
think has discovered something pretty
interesting in the last few days he
pulled an all nighter last night trying
to get this submitted to a
conference I went to bed at midnight
went to bed at midnight not an all
nighter okay not quite we don't have
time to talk about this figure I think
it's super cool it's not about robotics
but it's related to many of the things
we've talked about in this class if
you're interested talk to cam well done
cam
okay all
right back to robotics all right we are
uh working through our short segment on
uh collective intelligence in robotics
as in nature there are many tasks uh
that confront organisms that are
difficult or impossible for an
individual to do on their own but if
they can figure out how to coordinate
and in some cases explicitly communicate
they're able to do something together
that's beyond the ability of any one of
them so as roboticists that leaves us
with the research question how how
exactly do you design or in our case
evolve autonomous machines to
autonomously coordinate their actions to
do something that's beyond the ability
of any one of them we saw arguably where
these ideas started to take root back in
the 1980s when we looked at some of the
work from Craig Reynolds and his Boyd's
uh algorithm where there is no one
leader we have a large number of
independent
agents and they are uh active they
working collectively by running
basically the same program all of them
are running the same program which is a
combination of these three functions
which continuously updates the
operations uh of each individual we
ended last time by looking at uh another
study from about 10 years later uh and
this is arguably an evolution robotics
experiment but again pre physics engine
era no real physics engine here we have
a very very simple two-dimensional plane
that's been uh curved so that the two
long ends touch and then that tube is
curved so that the two ends of the tube
connect so we have a toroid and we have
four virtual lions that are going to be
running around the surface of this
toroid and a gazelle that is going to be
trying to escape from them on this
infinite toid none of the five can fall
off because a toid has no edges so far
so
good uh as usual we're going to see an
evolutionary algorithm that's going to
evolve behaviors for the four lions and
you can probably guess what the fitness
function is going to be the fitness
function is going to reward for minimal
distance between any one of the Lions
and the gazelle at the end of the
simulation that's a single floating
Point number a distance between the
closest Lion and the gazelle and that
number that Fitness is not assigned to
any one lion that Fitness value is going
to be assigned to all four Lions even
those lions that were nowhere near the
gazelle when the the closest lion
actually did bring down the gazelle so
this is something we haven't seen so far
before in all of this course so far
we've seen selection acting on
individuals selection being darwinian
selection what we're going to see in
this word today is a form of group
selection where evolution is favoring or
not favoring not an individual but a
group this is a very controversial
subject in evolutionary bi biology might
have come up in a biology class you've
taken why is group selection such a
controversial
topic any
ideas that's the
LEL in reality good question so is that
the level that selection works on or is
the group the appropriate Target of
selection it seems obvious well obvious
to many of us when you hear about
darwinian Evolution it makes sense
things that I do well or poorly affects
whether or not I survive long enough to
actually reproduce Offspring and
assuming those individuals my Offspring
inherit my pros and cons they're likely
to to uh inherit the same kind of
selection pressures so it seems obvious
but what exactly is it about me I I
don't act alone I have brothers and
sisters and cousins and parents and
grandparents and friends and foes and so
on which also
influence whether or not I live long
enough and survive long enough to
produce Offspring so is it just me
that's the target of selection is it
myself and my siblings myself and my
siblings and my cousins myself my
siblings my cousins my friends
everybody else what exactly is the
target of
selection you can also look inward is it
all of me that is the target of
selection arguably for many of us
there's just one cell in our body that
actually goes on to become our Offspring
the rest is temporary so is all of this
the target of the selection or is it
just our gametes where exactly does the
pressure of dar wian selection uh come
to bear it's a controversial topic it's
beyond the scope uh of this class but
again for those of you that are
interested in the biological aspects of
what we're talking about it's
interesting to read up on group
selection one particular form of group
selection that is not so controversial
is kin
selection if my siblings do not have
children but they help me raise my
child my siblings benefit from an
evolutionary point of view even though
they're not producing Offspring feels
like a bit of a catch 22 if you don't
produce Offspring how are you possibly
benefiting from an evolutionary point of
view absolutely right so a sibling that
doesn't have offspring of their own but
helps raise the The Offspring of their
sibl siblings benefits evolutionarily
because they're helping half of their
genes for most species it's half of
their genes propagate into the Next
Generation so not so controversial but
again brings us back to the Target of
selection so maybe the sibling wasn't
actually the target of selection to
begin with maybe it's just the genes
that make up the sibling that is
actually the target of selection doesn't
matter whether I survive or my siblings
survive as long as our genes
collectively survive so maybe we
shouldn't be thinking about the
individual as the target of selection we
should be thinking about genes as the
target of selection gets gets tricky
sometimes this idea of genes actually
being the real targets of selection and
not individuals is known as the selfish
Gene
hypothesis you've probably heard of this
before Richard Dawkins was the
originator of this idea also very
today what we're going to look at or
what we've been looking at in this
course so far is sort of the traditional
view of selection the individual
organism or the individual robot
produces offspring in proportion to how
well it survives and does whatever it is
we want it to do what we're going to be
looking at today is kid selection as
you're going to see in a moment these
Lions share genetic material and they
all benefit collectively or fail fa to
benefit collectively not based on how
well any one individual in the in the
group does but how well they do together
in this case and bringing down the
gazelle so far so good okay all right so
uh let's talk a little bit now about the
evolutionary side of this as I just
mentioned we're going to evolve behavior
for the pride of lions we are not going
to be evolving uh behavior for the
gazelle we're going to fix the behavior
behavior of the gazelle one more uh
biology uh side note I want to make is
if we were evolving the behavior of the
gazelle we'd be considering
co-evolution obviously as Predators
evolve to be better at what they're
supposed to be doing the general fitness
of all of the prey starts to go down the
chance of producing Offspring becomes
less for the prey there is strong
selection pressure acting on the prey to
evolve uh Escape behaviors of the
Predators if they do if the praise start
to increase in Fitness they get better
and better at avoiding the Predators
what happens to the general fitness of
the Predator
population down this this is
co-evolution right your Fitness you as
an individual of a group is no longer
dependent on just what you or your group
does but now also on what other groups
are doing you might remember back to the
beginning of the course when we
introduced this idea of the fitness
landscape so as a population is uh
experiencing genetic change over
Evolution that cloud of points is moving
horizontally in the fitness landscape
and if the Fitness of those individuals
is generally going up that's them
climbing a slope in their Fitness
landscape the fitness landscape is sort
of this metaphorical mathematical
landscape that helps us visualize or
think about evolution in a
co-evolutionary process we no longer
have a fitness landscape because the
height of Peaks or the depths of troughs
do not stay constant over time as the
fitness of predators goes up the fitness
of prey goes down as the fitness of prey
goes up the fitness of predators goes
down and you have a fitness sea now you
have waves that are going up and down
that's
co-evolution there are co-evolutionary
robotics experiments in which we have
two sets of evolving populations
competing against one another we'll see
this in about uh towards the end of the
course in about two weeks from now today
we're not looking at co-evolution we're
looking at a version of kin selection
the behaviors of the Lions are Going to
evolve we're going to fix the behavior
of the
gazelle uh good question didn't we see
coevolution already when we were seeing
co-evolution of the simulators and the
and the robot
behaviors yes yes you're right in a in a
way that's a form of co-evolution we
have a population of simulations and a
population of controllers it's kind of
co-evolution we're going to see a
cleaner more obvious version of this in
two weeks when there's two populations
of robots competing against one
another okay
okay all right oh I already mentioned
this so the Savannah is
toroidal but obviously I'm not going to
draw this as toyid we're going to look
at two-dimensional uh we're going to
look at two- dimensional images okay
let's talk about the behavior of the
gazelle first first this is fixed this
this is the behavior of the gazelle B is
a is stand for Behavior it's a two it's
a vector of length two this length two
Vector dictates how the X and Y
coordinates of the gazelle is going to
change from the current time time T to
its new position at TT + one so you can
think of b as an an arrow that is
pointing out of the gazelle at time T
and it's pointing in the direction in
which the gazelle is about to move at
the next time
step okay so what is how do we compute
this Vector for the gazelle at each time
step it's a sum over a whole bunch of
vectors that are taken from a set of
vectors and these vectors are the
vectors that connect the gazelle to each
lion so we're going to sum up over four
vectors we're going to sum these four
vectors together and use that to compute
the new uh heading of the
gazelle why the minus sign in front of
the summation
symbol absolutely right look where all
the lions are in general take the
average of all of those vectors and head
in the opposite direction
very simple but probably a pretty good
thing to do you'll notice that this is a
weighted sum each time we add a vector
to the sum before we negate it we divide
by the length of that
Vector why this is a slightly smarter
thing for the gazelle to do the gazelle
could simply take the average of its uh
distances or and and directions from the
Lion's and head in the opposite
direction it's not what the gazelle does
it takes the weighted Su
why absolutely so in my little cartoon
visualization here L1 is the closest
lion which means the magnitude of this
Vector is the least magnitude among
these four magnitudes so when we divide
by that least magnitude that magnifies
the influence of this
Vector on the direction in which the
gazelle moves everybody see that okay so
to sum up the math here at every time
step the gazelle is going to sense all
of the Predators and react most strongly
to the ones that are closer to
it okay let me just back up for I'll
leave that up there actually there's one
more uh normalization term here which is
we're computing Max
here Max
what what's W and H here do you
think
Max it's not the max distance it could
move
kind
of it's not the boundary conditions
because there are no boundaries on the
too in the toid but you're getting close
what does w and h stand for do you
think width and height it's the width
and height of the rectangle before it's
turned into a toid so it's a little
confusing we're dealing with the
toid we take the width and height
and then we take the Pythagorean
distance of the diagonal of half
that so here's here's half W half the
width of this sheet and here's half the
height of the sheet and
here's Max this is the
length of the
diagonal Max what
very close the maximum distance not that
necessarily can
see it's the it's the furthest the
gazelle can possibly be from a lion on
the toroid right it's hard to think
about distances on a toroid if we were
to put the gazelle and the lion forget
get four Lions just one lion we put the
gazelle and the lion at any two points
on the toroid how far can they possibly
be from one another it's this it's Max
so what we're actually doing if you
think about it in this cartoon this
carton is
wrong this is not the distance that
connects the gazelle to L4 you can
probably tell by eye the length of this
Vector is longer than
Max so that's not really L4 is actually
closer to the gazelle on the toroid than
it looks from this Vector here yeah it's
actually probably something like up
Northwest of the gazelle and wrapped
around and L4 is actually quite close to
the gazelle so we're normalizing by this
term based on dist es on the
toid just just a reminder that we're not
dealing with a sheet we're dealing with
a toid but this is the most important
thing for our purposes move away from
the Lions and wait your decision based
on who's
closest the length of the vector that
connects right length of the gazelle
lion Vector let's say yeah absolute
absolutely it does so there's a little
bit of normalization here but for our
purposes just a reminder we're dealing
with the Tor so far so good okay let's
keep going okay that's the gazelle
relatively straightforward the behavior
of the Lions not so straightforward
we'll spend a couple minutes on this
slide uh let's go to the title of this
paper for a moment evolving teamwork so
obviously we're going to be evolving
teamwork for the Lions and coordination
among Ong the Lions they're going to
actually the lions are actually going to
coordinate their behavior to try and
bring down the gazelle using genetic
programming and we saw genetic
programming way back at the beginning of
the course when we were surveying
different kinds of evolutionary
algorithms an evolutionary algorithm is
the umbrella
term evolutionary algorithms is the
umbrella term for a whole bunch of
algorithms you've implemented a genetic
algorithm in your in your projects
arguably a parallel hill climber is a
type of evolutionary
algorithm we talked briefly about
genetic programming that's distinct from
other kinds of evolutionary algorithms
for a particular reason anybody remember
what made genetic programming
distinct that the one that enes the
absolutely which is exactly what we're
going to do here so in gene in genetic
algorithms like in your code the data
structure uh the data structure that
encodes the behavior of the robot or
codes the phenotype is usually a vector
in your case it's a vector that encodes
the synaptic weights for the neural
networ that drives the behavior of the
robot so the behavior of the robot is
the phenotype and the Gen and the
genotype is a vector of Weights in
genetic programming no matter what the
phenotype is the data structure for
storing the DNA or the
genotype is a tree we're going to be
using genetic programming we're going to
see genetic programming being used in
this experiment so if you were to look
inside the heads of the of the Lions you
wouldn't see vectors or neural networks
you would see trees we're going to use
trees to evolve the behavior of the
Lions okay what exactly do these trees
look
like as you mentioned we're going to
start by building a random tree for each
Lion in each Pride we're going to be
evolving populations of things what are
the things we're going to be evolving
we're going to be evolving behaviors for
uh Pride a pride of lions and we're
going to have a tree that encodes the
behavior for each lion so inside each of
the four Lions there's going to be one
of these trees to start an evolutionary
algorithm we usually start with random
genotypes in your case random vectors of
floating Point values in our case we
need to start by creating a random tree
as you mentioned I used this metaphor at
the beginning of the class of having a
bag of operators and operand the things
that we can use to build a tree the
building blocks if you like this is the
list of operators and operand that we
can use to build the behaviors for our
Lions the oper the
operand have zero arguments associated
with them and all of the operators here
have more than zero arguments associated
with them so here's some familiar
operators plus and minus here's some
slightly less obvious operators we'll
talk about these in a moment so let's
imagine we take these three operand put
them in our bag and these 1 2 3 4 5 6 7
8 nine operators uh operators also put
them in the bag we have a total of three
things three operands nine operators we
shake up the bag and then we reach into
the bag and pull out one of these 12
things at random and let's assume by
chance I happen to pull out this operand
called
last and I put that in the top of my
empty
tree I I happen to grab an operand
rather an operator that operand has zero
arguments so there's nothing that last
need to execute it doesn't need any
arguments it's done it's happy so we're
done building a tree we just built a
tree at random it's a one node tree we
take this one node tree and drop it into
the head of lion one we also drop it
into the head of L2 drop it into the
head of L3 and drop it into the head of
L4 so far so good okay we take we're
going to now simulate our swarm our
swarm of lions our pride of lions so we
take G the gazelle and drop it at some
random position on the toroid take each
of the four lions that have this in
their head and drop those four Lions
also at random positions on the toroid
and start the simulation we turn the
simulation on the gazelle looks at all
the other
lions and in indicates that at the next
time step it wants to move in Direction
B so far so
good what direction do all four Lions
want to move
in each of the four lions at this first
time step in the simulation execute this
function what do the Lions want to do at
the next time step
they want to go in the direction that
they moved at the last time step but
it's time Step Zero they don't have they
didn't move in a direction at the last
time step so on the first move of the
first time step this function returns a
random Vector so all the lions move in a
random Direction the gazelle moves away
from them and at the second time step of
the simul the gazelle looks again at all
the four lions and heads in the opposite
direction what do the four Lions
do Emily they just keep running they
keep running in the direction that they
ran at ran in at the last time step how
do you think this particular pride of
lions does at Bringing Down the gazelle
probably not very well right so whatever
the we're going to calculate the fitness
at the end of the simul
and I don't remember if they mention
it I think they I think they updated the
simulation 15 times I think there were
15 time steps in the simulation so at
the 15th time step you can imagine that
the distance between G and the closest L
was quite large we set the fitness of
all four lions or we set the fitness of
this thing to one over that distance the
larger this distance the lower the
fitness of this lion pride Behavior so
far so good okay we're running genetic
programming so we've just evaluated the
fitness of the first uh behavior for the
pride of lions in the population but
remember in an evolutionary algorithm
we're always evolving a population of
things so we go to the next tree random
tree in the population we don't have
that tree yet so we've got to construct
this second tree in the population at
random so we throw last back in back
into the bag we shake it up and in this
case let's assume that we by chance
happen to pull out the addition operator
the addition operator takes two
arguments so we need to now randomly
construct the two arguments that are
supplied to plus let's assume uh let's
assume that I pull out Rand now from the
bag and this one takes one argument so I
need to fill something in here let's say
I pull out from the bag at random the
gazelle operand and over here I pull out
the random Direction
[Music]
Rand Rand dur operand I have a second
random
tree I reset the position of G and the
four Lions I drop them at five different
random positions on the surface of the
toroid make four copies of this and drop
a copy of this into the heads of each of
the four lions and then start the
simulation again what do the Lions do in
this
case we've got to evaluate this tree
inside the head of the first of the four
Lions roughly in the direction of the
gazelle roughly in the direction of the
gazelle all right let's see let's visit
gazelle down here this is an operand
that returns a vector from The Lion to
the gazelle so I'm L1 I've got a
particular Vector that connects me to
the gazelle
this node returns this Vector this
Vector gets supplied to this function
random this is a function that acts on
vectors all of the operators here are
vector
operations you know so this Vector
operation
randomizes the magnitude
of the original Vector so maybe Rand
makes this Vector a little bit shorter
by chance could have also made it longer
same direction but slightly different
magnitude
this operand over here returns as you
would imagine some random
vector and then this Vector operation
sums these two vectors which actually
gives a very very small
Vector looks like to me yeah this this
is the direction that L1 moves in we
take this exact same tree and we now
evaluate it for
L2 the second lion does this identical
tree that's in the head of the second
lion does it return exactly the same
vector or a different
Vector I see most of you shaking your
heads no right
this is
different yeah it's different for the
different Lions so they're all running
exactly the same strategy in their heads
but the Lions can behave differently not
unlike what we saw with the boyss right
they're all running exactly the same
program but produce different
Behavior so far so good okay let's say
by chance we apply the exact same we
apply apply the exact same Fitness
function to this pride of
lions and maybe they do a little bit
better than this pride of lions this one
was pretty poor maybe this one does a
little bit
better we evaluate the third tree or we
evaluate the behavior of the third Pride
running the third tree we evaluate the
behavior of the fourth Pride uh running
the fourth random tree and so on in our
population of
100 random trees which is 100 random
behaviors for lion Prides what do you
think we do as we move from this first
generation of genetic programming to the
Next Generation have a question
sure you say like a random tree do if
you encounter like tree number three in
the same as tree number
97 great question so what happens by
chance if
there happens to be by chance this tree
in the population as well does it get
exactly the same
Fitness why
not we started we start every simulation
with different random initial conditions
which are the initial positions of the
lion so maybe
not but this is still a pretty crappy
solution so it's probably Al Al going to
be low right so even if we have
identical genotypes in the population we
don't necessarily get identical
phenotypes which in this case is the
behavior of the pride and therefore
these two genotypes do not necessarily
get identical Fitness values identical
twins here in the real world don't
necessarily always have the same number
of offspring that are equally successful
right just because you get the same
genetic role of the dice doesn't
necessarily mean you're going to have
the same outcome in life but assuming
that your genome dictates more or less
your chance evolutionary chances uh in
this world you're going to get similar
values over in general so far so good
okay all right so we finished designing
a fitness value to every pride of lions
and we're going to move on to generation
two how do we move from generation one
to generation two what do we need to do
which is what we've done in every
evolutionary algorithm we've seen so
far I'm picking up my Eraser this is a
strong
hint delete the ones that have low
Fitness and make randomly modified
copies of the
survivors when we talked about genetic
programming what does randomly modified
copies look like if this is the child
that I just produced from this parent
it's identical to the parent we choose a
node at
random we delete what's in there we
reach back into our bag of three
operands and nine operators Shake It Up
and pull something else out like for
example uh if do
product this one is a little more
complicated it takes 1 2 3 4
arguments I'm getting a little bit lazy
here so instead of putting actual
operators and operands here I'm just
going to put Vector one vector 2 Vector
3 and Vector 4 because in this form of
genetic programming every node in every
tree always returns a vector right these
are all vector operands and operations
so let's assume in my cartoon example
here these are the vectors that these
four nodes return for one Lion at one
time step in the simulation what does
the dot product what does this
particular Vector operation
do evaluate the first and second
arguments okay we've done that we've
evaluated the first and second arguments
so we have two vectors in hand if
they're dot product okay pause take the
dot product between these two vectors if
the dot product of these two vectors is
greater than or equal to zero and let's
assume in my cartoon example here that
the dot product between these two
vectors is greater than
zero then evaluate and return the third
argument so we take this vector and
return
it if the dot product between these two
vectors have been less than zero then we
return the
vector returned by the fourth argument
up to this
node everybody see that it's just
another Vector
operation okay all right all right so
that's how we can construct and
evolve behaviors for a pride of lions
it's hard to to hold all this in your
head let's try and construct from
scratch a behavior for a single
lion you're the lion you're very hungry
you're motivated to pick carefully from
set what do you do
bad right you're really hungry you don't
have a lot of time to think head for the
gazelle I'm sorry I forgot to mention a
little detail here which is going to be
important for you as a hungry lion the
gazelle at every point in time travels
three units or three length
units it travels three length units in
this direction
the
Lions I hope it says it here oh yeah the
Lions only travel one
unit not unlike our actual lion right
gazel in real life and on our virtual
serengetti travel faster than the lion
chasing the the gazelle seems like a
good thing to do the gazelle is
Overjoyed that you have chosen this
strategy it can easily evade you this
ain't going to cut it
other
ideas
okay not so easy is
it it's a trick question there there is
nothing really you can do if you're if
you're on a perfectly infinite perfectly
flat plane and your competitor can run
three times as fast as you can what can
you possibly do right not much so the
investigators in this case have kind of
created a non-level playing field here
no pun intended in favor of the gazelle
if there's one lion if there's four
Lions suddenly there's more opportunity
for the lion pride everybody see that
it's not clear what that opportunity is
but there probably is something that
they can do as a group that's beyond the
ability of any one
lion
okay let's have a look they're going to
as we just said they're going to run
genetic programming and evolve these
trees for four lions and see over
evolutionary time how well does the lion
Prides how well do the lion Prides
evolve to bring down the gazelle that's
experiment one or experiment a we spent
some time last week talking about AB
testing creating two similar algorithms
and then comparing how well they do
consider this algorithm
a this is algorithm B it looks and acts
exactly like algorithm a we're going to
use genetic programming we're going to
encode the behaviors of lions as sets of
vector operations but we're going to
throw four
additional operand into the bag the
thing that we can construct the
behaviors for Lions let's have a look at
them one of these operand remember
they're all Vector operands is a vector
that uh starts at the lion nearest the
gazelle and connects to the gazelle so
in this case it's probably this Vector
that starts at L1 and points to the
gazelle
the second one vector Opera we're going
to look at is that the the lion pride is
going to have available to it is a
vector from The Lion that's running this
tree in its head I'm lion I that
connects me to my nearest lion so I have
access to this
Vector our lion means right hand lion so
I'm a lion and I'm heading in this
direction or I was heading in this
direction at time T I'm Computing my new
heading I need a new Vector at time t +
one our line is going to return the
vector that connects me to the lion
that's immediately on my right if I
start doing a clockwise sweep from the
direction in which I headed last the
first lion that I hit in my clockwise
sweep that's the lion that's immediately
on my right if I if I hit this node in
my behavior tree L lion I do the same
thing I take the direction that I was
heading in uh last time step and I start
a counterclockwise sweep and th this
operand now returns a vector that
connects me to the lion that's
immediately on my left yeah my left my
right my distance to the gazelle this is
things from the Lion's point of view the
lion am that's
running that's running this tree in its
head when I'm sensing the world and I'm
interpreting my sensation relative to me
on my right on my left that's known as
dietic
sensing when you're having a
conversation with someone and you talk
about the person that's on your left or
your right that's you communicating the
results of you interpreting your
sensation
dietic what's actually coming in is
obviously just Blobs of color and motion
and light and dark you interpret that as
things out there in the world and then
as a last step you may interpret those
things out there in the world relative
to
yourself we've actually seen this
concept before this idea of thinking or
reasoning about objects and things and
people out in the world relative to
yourself where did we see this concept
pop up
before minim the minimal cognition
experiments yes what specifically in the
minimal what phenomenon in the minimal
cognition experiments was it what was
the name for this thing about reasoning
about how I relate to things in the
world the robot that see the motion of
arm
or uh Rel like that it they are moved or
whatever kind of but not quite related
to this concept that I'm fishing
forces affordances
right how do we know that a chair is a
chair in kindergarten we're taught that
a chair has four
legs this one doesn't it's got five legs
those have four legs it's not really so
much about the geometry of things out
there in the world it's how we relate to
to them as these lions are pounding uh
along the virtual serengetti plane they
are sensing or they can sense other
things out there they can sense G the
gazelle and they can now sense my
leftmost lion my rightmost lion things
that are relative to themselves this is
dietic sensing so in algorithm B we're
going to construct random trees but
we're now going to pull operands and
operators out of a bag that contains not
12 items but 13 14 15 16 items so the
evolutionary algorithm has additional
options it can build or evolve behaviors
for the pride that incorporate dicc
sensing if it's helpful to the pride if
not evolution is going to
delete is going to delete trees that
contain dietic sensing and evolution is
quote unquote choose not to use it it's
not helpful so in algorithm B the
investigators are in essence asking a
research question if we want to evolve
Collective behavior for robots is it
helpful for them if they're doing
something collectively to deter to
determine what to do based on dietic
sensing or
not everybody see that so
far okay that's
variant B third and final uh algorithm
variant is variant
C where they're going to take the base
set they're going to take the 12 items
in the bag and throw in a 13th 14th 15th
and 16th item and run genetic
programming again evolve behaviors for
the pride exactly the same Fitness
function everything else is exactly the
same in this case evolution has the
option to construct behaviors for the
Lions using name based
sensing good question why is this any
different from dietic sensing let's have
a look at these four Vector operand as
always these new operand return a
vector in this case L1 returns a vector
that emanates from me the current lion
that's running this to Lion
one every time I move that Vector
changes like most likely changes because
my position relative to L1 probably
changes let's just check in with our
intuition that we understand what's
going on imagine all four lions are
running this
program how does this pride of lions
move towards Lions one and two what
happens if you are lion one or two
toward each other go towards each other
let's start with an even simpler one
this tree let's take this tree and drop
it into the heads of all four lions and
turn on the
simulation what is L1 what does actually
lion one do when L1 runs this in its
head stay still stays still right when
L1 executes this
program it returns this Vector when any
of the other three lions run this
program it Returns the vector that
connects them to L1 everybody see that
okay so back to Abby's question about
what is the difference between name
based sensing and dietic
sensing anybody have any ideas if you're
evolving behaviors for a lion pride
using this stuff what kinds of behaviors
might you get compared to evolving
behaviors for the lion pride using this
stuff
more
like not one single
lead could be could be getting close
right think about any team sports that
you've ever
played what depending on the sport it
matters what sort of makes sense some
sports you rely on who's on your right
who's on your left who's in your field
of view who can't you see so you
therefore know are behind you that's
dietic sensing right versus I'm paying
attention to number 14 or I'm basing
what I do based on the person who's
playing front forward I'm not much of a
sports person so you have to forgive my
sports references here right I'm G to
pay attention to what the go the other
players goalie is doing and not worry
too much about what everyone else is
doing that's name-based sensing maybe
not name but there's a specific player
or individual on the team or on the
other team that you're paying attention
to what different kinds of strategies
does this give rise to as you pointed
out one one thing you tend to get in
dietic sensing is similar Behavior
within the group which means they're all
kind of doing the same thing not
necessarily executing exactly the same
change in position at every time step
but doing generally the same thing
that's generally less true in name based
s
in I
mean already
mentioned I would imagine this would
rise TOS where individual would have
their own set position
they their own set position that they
play and like Ian the role role within
the team okay now we've entered new
territory in our uh in our study of
collective intelligence what is this
phenomenon that we're talking about now
we've heard several different synonyms
for
it specialization division of
labor for various reasons I'm the one
that usually comes in and stands up here
and does all the talking it's not me one
day and then you the next day there are
classes like that but that's not this
class right for certain under certain
circumstances it makes sense for certain
people to specialize to do certain
things and others to do other things
when we're trying to do something as a
group like trying to keep the
civilization running some people teach
some people learn and then those rules
switch division of labor if you look
across the animal kingdom and you look
at various species that attempt uh
Collective Behavior like us and many uh
insects in some cases you do see
division of labor and some cases you
don't it gets complicated sometimes it's
helpful sometimes it doesn't I haven't
shown you the results of of of algorithm
c b or a yet what do you
think do you think group think or sort
of the starlings approach where there's
sort of a cloud of similar Behavior
going on within the pride is that a good
thing to do or does it make sense
for some of the Lions to specialize
here that's the question so it's
possible that Evolution could evolve
specialization among the Lions do you
think it makes sense in this task four
lions running on the surface of a donut
trying to bring down a gazelle
could be could be right maybe it makes
sense it's not possible to hide on this
troid because there's no obstacles but
but ambushing sneaking up on maybe maybe
I don't know about you but when I first
came across this study before I actually
read the results I wasn't I wasn't sure
I I put my money on the fact that this
was wasn't the way to do it this wasn't
sufficient the Lions didn't have enough
information to coordinate Behavior but
it wasn't clear to me whether these
lions were going to evolve to be better
at Collective hunting than these
Lions let's see okay before we look at
results there's one other Wrinkle In
This experiment we need to deal with
which comes back to this issue about
group fitness as I mentioned within this
pop within the population of genetic
programming we' got a population of 100
trees each tree is going to control the
behavior of four Lions the most obvious
way to do this is to take each tree out
of the GP population out of the genetic
programming population and clone that
tree three times so we have four
identical copies of those trees and drop
those four uh clones into the four lions
and off they go that's the easiest thing
to do
but there's other things we could do
like for example this which
is when we create a tree in the
population we actually at the root
create an empty
node and then create four trees B below
and then we start filling in these nodes
by reaching into this bag at random what
this does is it sort of simplifies our
life because there's now one tree for
the entire
Pride the first subtree down here
dictates how L1 is going to move the
second subtree dictates how L2 is going
to move and so on what's the potential
benefit of encoding the behaviors of the
lions like this then like this
exactly right here it's kind it's even
with name based sensing and dietic
sensing it might be hard for the Lions
to specialize if it does make sense for
one lion to go to be offense and the
other three to be defense or flushers or
whatever it is hard maybe to evolve it
so let's evolve this but if we have a
population of trees that look like this
here's one random tree in the population
here's a second random tree in the
population here's a third random
tree assuming by chance these three
trees survived their respective Prides
did relatively well at Bringing Down the
gazelle how do we make children from
these we could make a randomly modified
copy of each we could treat these as
three parents and make one child from
each of these three parents or we could
try and combine
behaviors from
different parents so this is sort of an
odd form of sexual recombination we're
going to create one child one strategy
for one Pride that combines strategies
of individual lions from the three
different parental
genotypes everybody see
that for those that right for those that
remember neat this is a little bit like
the neat
algorithm it's also inherits one of the
problems the problem that neat was
designed to
solve checking your short-term memory
here what was the problem neat was
solve
comb the data itself the data itself
you're you're combining clumps of data
but you're taking them out of context
maybe L1 which is actually uh which is
actually donating Its Behavior into this
Pride maybe L1 actually did do very well
maybe L1 was actually the lion that
brought down the gazelle in this
parental Pride but it only did so with
the support of its siblings L2 L3 and L4
and so the behavior for L1 has now
become the behavior for L2 in this new
Pride but l too is surrounded by
different differently behaving Partners
it's kind of lost that behavior this is
another form of the competing
conventions problem comes up a lot in
machine learning in general right we're
sort of combining useful stuff into a
new algorithm this algorithm over here
the behavior for the pride but taken out
of context so the idea was kind of cool
let's allow special ization to make it
easier for specialization to evolve in
this Pride but we got the competing
competing conventions
problem the investigators realized that
and they made a little bit of a tweak to
this which they called restricted
breeding which is L1 could only donate
Behavior to another one to an L1 in a
child Pride we're still L1 the the new
L1 is still working inide of Pride with
an L2 from another parent so it's not
great but l1s donate their genetic
material to other l1s and l3s only
donate their genetic material to l3s so
over evolutionary time it looks like the
evolution of specialization might be
easier in restricted breeding compared
to these two algorithm variants
so far so good okay so again we got a
lot of moving pieces here we have
algorithm a b and
c and we now have three different ways
of propagating genetic information from
one generation to the next we'll call
these variants X Y and
Z we can combine these things ax a y a z
BX b y y b z CX Cy CZ which gives us
nine algorithm
variance why would free breeding be
better at
specialization up
here allows more specialization than
cloning so in cloning the Lions can
still move differently but very
difficult for them to actually over
evolutionary time evolve a specialized
Behavior right you can really see it in
restricted breeding you could imagine L1
over evolutionary time from child to
child to child to child L1 gets better
and better and better at sneaking up on
the gazelle based on what its other
three partners are doing and L2 L3 and
L4 get really good at sneaking up
indirectly around the gazelle you could
imagine specialization starting to
evolve more easily in restricted
breeding than the other two yeah Okay so
we've got nine algorithm variants for
each of those nine algorithm variance
they're going to do 100 evolutionary
runs they're going to evolve Prides of
lions 100 times they want to see on
average for all of the three different
algorithm variants a B and C and the
three different ways of
constructing the Prides X Y and Z on
average how well do the Prides evolve to
bring down the gazelle as if that's not
complicated enough they introduced
variant
101 and
12 okay what are 1011 and 12 they're
just simpler versions of the algorithm
these are known as the controls
these are sort of
Baseline how well on average can the
algorithm do and then how well do these
nine algorithm variants improve on these
simpler ways of doing things algorithm
uh variant 10 here just evolve one lion
as we've already seen it's probably not
going to do very well but let's run this
uh this algorithm 100 times and see how
well one lion evolves to bring bring
down the gazelle Let's uh execute 100
simulations in which there's just a
randomly moving
lion and let's run a 100 simulations in
which there are four randomly moving
Lions these are the three
controls for these three controls we're
going to get back floating Point numbers
how well on average a single evolved
lion got to the gazelle how well a
single randomly move moving lion got to
the gazelle and how well four randomly
moving lions got to the gazelle that's
going to give us a basine what is that
distance actually mean and then do any
of these nine variants evolve lions that
get closer to the gazelle than this
that's why it's called a control right
we're controlling our expectations here
how how much better can we
do okay these are details uh details of
the evolutionary Alm we're running short
on time I don't think we need these okay
apologies that's a long leadup to the
results they don't look fancy no fancy
graphs here we're just going to uh look
at the Matrix
directly let's look at the three
controls down here here's the one
evolved Lion on average the random lion
uh the evolved lion gets seven length
units away from the
gazelle I won't go back and show you the
visualization that's about as bad as you
can do that's the gazelle showing off
the gazelle is about as far from the
single evolved lion as the gazelle can
possibly get on the toroid so evolving
behavior for a single lion does
nothing you'll see that this number is
not that different from this number one
random ly moving lion gets about as
close to the gazelle as one evolved lion
does so how bad can things get this bad
this number we're starting to calibrate
our understanding of what these length
units mean on the toroid if we put four
random Lions on the toroid and have them
move at random they do
better how how can four randomly moving
Lions do better than one randomly moving
lion the gazelle's always moving
away cover more space they just cover
more space right the Lions they're
moving randomly so they're spread out
more or less across the toroid so the
gazelle can't help but being a little
bit closer to one of
them so as long as there are four Lions
on the donut we want to see whether any
of our nine algorithm variants can do
better than
4.41 get closer than 4.41 units away
from the gazelle yeah okay here's our 1
two three four five six 78 n results
from our nine algorithm variance the
immediate thing that should jump out to
you about all nine numbers
is they're better than random they're
better so evolving behaviors for four
Lions
using this set this set this set or
evolving them like this or like this or
like this any combination or permutation
of these things does better so we
already have a conclusion to the title
of the paper which is yes we can evolve
teamwork and coordination among a group
of admittedly simple robots acting
together first uh first conclusion from
the set of results okay all right among
all the nine algorithm variants here
which one did the
best restricted name based restricted
okay so let's go and look at name
based so name based is when the Lions
actually uh modulate their behavior
based on actual other Lions I'm going to
do what I do based on what L2 is doing
not based on what the rightmost lion in
my line of sight is doing so evolving
specialization
helps and name-based restricted breeding
this form of breeding down here produces
the best so again this is an early study
no YouTube videos I'm afraid we can't
actually see the behavior of the Lions
of what they're doing but you should be
able to conclude from the fact that this
number is the lowest number among these
set of nine
numbers generally what's going on
generally what is going
on what are the Prides of lions evolving
to do in this particular algorithm
variant absolutely right what however
this pride is bringing down the gazelle
there is the Evolve the evolution of
specialization and sorry specialization
and different
differentiation and coordination right
that's the name-based sensing part it's
not one of them saying listen I'll go
get the gazelle the three of you just do
whatever you want I don't care it
doesn't matter right that's not
coordination that's not teamwork there
is specialization and coordination going
on here
somehow
best G's pretty fast right the best that
any lion ever did in all of these
experiments was get almost there it
grazed the back hoof of the gazelle
right these Lions still go hungry the
investigators made things really hard on
the Lions the gazel travel at every time
step three times faster than the Lions
this is a tough task yeah okay
uh I think we're going to leave question
number three here again in the interest
of time we're a little bit behind I'll
leave this for you to think about so in
this early study this was basically a
proof of concept about how how you could
recruit evolutionary algorithms to
evolve Collective behavior for
autonomous machines hopefully we don't
want to evolve Collective behavior for
machines to actually do group hunting
but if you wanted to you can the the
other interesting Fallout from this
study was there are particular ways to
evolve Collective behavior for machines
that are better ways than others and
interestingly it kind of makes sense
from what we see in nature for better
for worse for humans that are trying to
coordinate the actions of eight or nine
billion members we tend to have
specialization we haven't yet figured
out how to act like starlings and
coordinate our Behavior with no real
specialization as the starlings show us
it is possible to coordinate Action
Group action with not a lot of
specialization of behavior but at least
in our species in many of insect
population in many insect species and in
these virtual lion populations Evolution
opts for or decides to evolve
specialization teamwork
coordination okay specialization
teamwork coordination are
great but there's still more that you
can do as a team we've got these lions
running around and they're looking at
what L1 L2 and L3 are
doing that's
coordination but they still went
hungry what else could we give the lions
that would give them a little bit of an
edge that would facilitate their ability
to evolve coordinated action
communication right humans can do a lot
when you're doing a group sport you're
usually running and you're out of breath
you don't have the ability to actually
communicate we do a lot of this implicit
coordination I infer what my teammates
are about to do based on what they're
currently doing based on my memory of
what they've done before but even though
I'm out of breath often you'll see pro
athletes signaling to each other as
they're working right there's a real
pressure if you want to coordinate
complex actions in a large group to
explicitly communicate information we
only have two minutes left so I'm just
going to introduce the second
study the second study in our study of
collective robotics in which we're again
going to look at an evolutionary
algorithm that evolves uh that evolves
Cooperative action in a group but also
allows the individuals to evolve commun
iation and possibly verging on
language let's see
okay we're doing things not
chronologically uh at the moment we're
going even further back in time to 1991
this is a very very old study I love it
it's a classic okay the evolution the
title says it all the evolution of
communication we're back to pre physics
engine uh world so uh uh worlds so again
we're going to look at a donut this is a
discrete donut so we've got a donut and
it's divided up with grid paper so we've
got a whole bunch of unique grid points
we've got a total of 200x 200 or 40,000
empty squares on this toid and instead
of four lions in this case we're going
to have
1600 agents and at the beginning of
every simulation that you see here we're
going to drop these 1600 agents into
some of these empty
squares and a new Twist on an
evolutionary robotics experiment
actually an old twist but for us new
that we haven't seen before these
individuals are gendered 800 female
agents 800 male
agents they have different abilities to
sense think and act
we'll leave things there for now you
have a quiz due tonight you're working
uh you're going to start working on your
third weekly report see you all on
Thursday thanks


--- Evolutionary Robotics course. Lecture 24： The evolution of communication..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone Let's uh get
started I don't have any updates about
the final projects any questions
about details of physics engines I can
help
with nope okay all right so we are going
to finish our discussion today about
Collective robotics how do we go about
automatically designing autonomous
machines that coordinate their action
or if implicit signaling and
coordination is not sufficient are able
to communicate amongst themselves
explicitly if it's useful so we're going
to see today in lecture 21 the evolution
of
communication okay couple of new items
in this experiment which I introduced
last time this is the first time that
we've seen uh we've seen gendered agents
we have a total of 1600 agents that are
operating on a toroid like before in
this case we're going to be operating
with a discrete grid so the male and
female agents can move from one grid one
point to the
other there are going to be different
sensor motor capabilities for the two
groups the quote unquote females are
going to be deaf and immobile they do
not move but they can emit signals into
their
environment males are blind they cannot
see but they can
hear they cannot signal and they are
mobile seems like a whole bunch of
arbitrary choices this particular
experiment it was uh the investigators
were investigating a bioinspired
approach to evolutionary robotic so
they're incorporating various aspects
from different species and they're
setting up a situation as we'll see in a
moment in which communication may or may
not
evolve
okay something that is familiar for all
of these 1600 agents each one is going
to be equipped with a neural network
controller the cognitive architecture of
the neural network controllers for the
males is identical to the cognitive
architecture for the neural network
controller of the females in all cases
every agent has three layers in its
neural network a layer of sensor neurons
a layer of hidden neurons and a layer of
motor neurons we have synaptic
connections between input to hidden
hidden to hidden hidden to Hidden and
hidden to Output same thing down here
the moment we see a hidden layer in
recurrent connections what does that
tell
us memory if it's
useful
okay okay the sensor neurons and the
motor neurons are going to play
different roles in the females and males
because they have complementary and
different sensor motor abilities let's
have a look at the female Network which
is up here I apologize for the small
font it might be difficult to read back
here at every time step of the
simulations we're going to see in a
moment the values that are applied to
the input layer of the female's neural
network is the position and orientation
of the closest male in her visual field
the females can
see this is their visual field wherever
a female is she can see up to two units
to her west east north and south so if a
male enters her visual range the posi
the relative position of that male
male uh the relative position and
orientation of that male will be fed
into the input layer of the female's
neural networks she can
see in this example here for this
particular female there is a male that
is to her Southeast and that male is
facing south that information is fed
into the input layer up here those
directions uh the POS relative positions
and headings are binarized we don't need
to worry about the details about
how so like your like your robot with
binary touch sensors this neural network
is also receiving binary values that are
dictated by what the males are doing in
her visual
range in the case of this particular
female here there are two males within
her visual range the relative position
and heading of the closest male is
what's supplied to this female's uh
input layer of her neural network
controller so far so good okay at each
time step of the simulation then we then
propagate those input values through the
neural network in the way that we've
seen many times before and the values
arriving at the output layer for the
female are translated into her mating
call the females uh are immobile but
they can see and they signal so they do
not move but they emit mating call which
is a binary Vector so there's an
activation function sitting inside of
these motor neurons which bizes these
values so the mating call of all the
females we're going to see in this study
is simply a binary
Vector
okay the male Network which again has
the ident identical cognitive
architecture the input layer of the male
network is the mating call of the
closest female to that male if the male
is within her range so for example in
the case of this particular male here
this male is actually in uh is in
hearing distance of two females this
male uh in the in this particular
experiment they would flip a coin and
this male would either hear this female
or this female let's assume we flip a
coin in its heads so whatever the output
Ma call is of this female that binary
Vector is copied into the input layer of
that male's neural network
controller males can
hear so far so good
okay uh and if the if a male is outside
of any female's uh visual range like
this male and this male the input to the
neural network controller for this male
is all zeros same for this male so far
so
good question what was the purpose of
making
of what what is the purpose again it
seems like an arbitrary choice there's a
lot of uh there's a lot of biologically
inspired terminology here daam mobile
signaling mating
call where do you think this is all
going it's okay if you're not sure yet
the actual
signal the the title for this study is
the evolution of
communication let let me finish the
output layer of the male Network and a
couple pieces might start to fall into
place the male hears if it's within
hearing distance of a female hears a
mating
call as always we propagate the values
the input values arriving at the input
layer for the male neural network
controller we propagate it from the
input layer to the hidden layer and then
from the hidden layer down to the output
layer and the output layer for the male
contains four neurons and again I
apologize for the small font but you can
see down here they are not binarizing
the output layer they're just leaving
the raw values that arrive at these
output neurons the raw weighted sum
there are four motor neurons for the
males and those four motor neurons are
are associated with the four actions
that the males can perform or motor
Primitives which we've heard of before
males can either stay still they can
move one unit forward in the direction
they're facing or they can turn 90 de to
their left or they can turn 90 de to
their right in this cartoon example down
here I don't know why they didn't just
draw the fourth motor neuron we've got a
value
of-4 in the first neuron 22 in the
second neuron and 78 in the fourth
neuron we look at those four those four
values and we determine which is the
larger in this case it's 78 so the
fourth motor neuron has the highest
magnitude value that fourth motor neuron
is associated with the fourth action so
this particular male at the next time
step will turn 90° to its
right if we took the same male with
exactly the same set of synaptic weights
and that male heard a different binary
Vector in its input layer you might get
a different distribution of values at
the output layer and perhaps now the
second neuron would have the highest
magnitude value and that second motor
neuron is associated with the second
action which would be move forward
males here and are mobile they also
don't signal all they do is act okay and
he guesses about where all this is going
now we've seen some parts of this
experiment so far some are familiar
we've got a whole bunch of Agents
they're all being controlled by a neural
network we update that neural network at
every time step so the females sense
think and act the males sense think and
act what's the missing piece or pieces
we haven't introduced
yet we don't have a fitness function we
don't have a fitness function yet any
guesses about what the fitness function
might be given all the loaded
terminology sorry is it just that
the is it that assumtion is a
male that's exactly what it is in all of
the evolutionary algorithms and
evolutionary robotics experiments we've
seen in this course so far reproduction
is kind of glossed over we have a
population of vectors or trees like we
saw last time with our virtual Lions we
got a whole population of things we have
a fitness function that assigns values
to all of those uh to all of those
things we delete the ones with low
values we make randomly modified C
copies of the survivors with higher
values and sometimes we combine genetic
material from the survivors when we
randomly modify that genetic
material it drives biologists up the
wall whenever they hear an evolutionary
algorithm there are many many of those
details that are obviously have no
counterpart in
reality as far as we know we are not uh
trying to satisfy a fitness function we
propagate our genetic material based on
mating and producing Offspring so in
this evolutionary uh robotics experiment
we're going to see today it's an older
experiment it's from 91 but arguably
it's more biologically realistic than
any other study you're going to we're
going to see in this course and pretty
much in anything that's been published
since they put quite a bit of effort
into this study to making the
evolutionary part as biologically
realistic as
possible make
sense okay so the there is actually no
Fitness function really there is a
population we've got 800 females and 800
males males that find females th those
male female pairs are going to produce
more
offspring than males and females that do
not find each other so what do you
think's going to happen to the males and
females that do not find each
other they're going to die off and over
evolutionary time what do you think
generally is going to
happen males and females that are able
to find each other produce offspring
that find can find each other they're
going to inherit that ability to find
members of the opposite sex that's it
there's no Locomotion No Object
manipulation in this study
whatsoever if you're a male and uh there
is evolutionary pressure acting on you
to find uh female mates and if you're a
female and there is evolutionary
pressure acting on you to attract mates
to you with mating
calls what is a generally good strategy
for the females and males over
evolutionary time
to have meaningful mating calls a random
female neural network when supplied with
information about nearby males will emit
a random binary Vector strictly speaking
that binary Vector has no meaning yet
it's randomly generated by a random
neural network a neural network with
random synaptic weights you take that uh
semantic free that that binary Vector
that has no meaning associated with it
and you plug it into a male neural
network which also has random synaptic
weights the male is going to move at
random what is the meaning of that
meeting call there's no
meaning yet right okay so that's where
we're going to start with we're going to
distribute 800 males and 800 females at
random on our
toroid the females are going to start
emitting random signals and males are
going to hear those signals shouldn't
even call them signals going to start
emitting sound the males are going to
hear those sounds and they're going to
do something at random we're starting
with no language no meaning no
communication whatsoever the question
that these investigators asked was was
will the will communication evolve yes
or no in this very simple study and if
it does evolve what does that
communication look
like okay again since we're talking
about this study you can probably guess
that the answer to the first question
will language or will communication of
all the answer is yes okay so let's have
a look okay uh so mating itself let's
talk about that we sort of already
figured this out so if a male as it's
moving about on this discret grid
turning left moving one unit forward
turning right turning right turning
right moving forward staying still and
so on if a male ever moves into the same
uh cell as a female we take each male
and female parent we make a modified
copy of each of them there's no sexual
recombination here so this this is kind
of a strange thing lots of biological
detail in this study except kind of the
whole point of mating which is to
combine genetic material in this case we
take the male parent the female parent
we make randomly modified copies of
their controllers so now we have a male
offspring the son and we have a male a
female Offspring the
daughter the male and the daughter
overwrite some other male and female
Elsewhere on the toroid at random so
some other male is chosen that male is
deleted and the position of that that
recently vacated cell the Sun the male
offspring is copied into that cell and a
random female is chosen she is deleted
and the daughter is placed into that
recently vacated
cell we then take the male uh we take
the male parent and the female parent
out of the cell that they're co-occupy
in and place them at random locations on
the toroid into random empty cells
that's a mating event pretty
straightforward so far so good so that's
it there's no Fitness
function let's see what happens okay A
Very Old study so we're going to have to
look at tables today not the most
interesting thing to look at we're going
to learn how to read these tables
in this first study they restricted the
width of the output layer for the female
Network to just three neurons and they
restricted the width of the input layer
for the male Network to three
neurons that means that any female could
admit any one of eight quote unquote
mating calls she can sing the song 0000
or sing the song 001
010 and so on make sense okay so they
put 1600 agents at random on the toroid
and then they just started to update the
simulation at every time step of the
simulation they evaluated all 1600
neural network controllers and the
result of those 1600 evaluations was
that a female emitted one of these eight
songs at random these are random neural
networks and males tended to do things
at
random they updated the simulation again
second time step evaluated all
1600 uh all 1600 neural networks again
and again and again and again during any
one of those time simulation time steps
if a male and female entered the same
cell they reproduced and they just ran
the simulation forever there's no
Generations in this uh experiment we're
not starting the simulation over again
and rerunning the simulation it's just
one long simulation in which Evolution
proceeds quite different from what we've
seen so far make sense okay so this
snapshot is the state of the world after
100 time steps of the simulation during
those 100 time steps they look to across
all 800 females and you can imagine on
on average those 800 females over those
100 time steps tended to emit these
eight songs with equal probability right
there's no reason why one female would
admit would emit one the females would
emit one song more than the
other every time they did every time a
female emitted a song and there was a
male nearby they looked to see what the
male did in response resp to hearing
that song and they looked at that across
all 800 males over the 100 time steps
what happened in all the cases in which
a male heard the song
0000 what did the males do on
average turn
right turn right uh 38 uh 38 times move
forward they moved forward 25 times
turned left nine out of times Stood
Still 28
times during the same time period the
same 800 males uh 19 of them moved
forward when they heard this 25 of them
turned right when they heard this and so
on what are the males doing on average
in response to the females during these
first 100 time steps on the toroid
is it what you
expect yes
why they're moving randomly right
they're they're controlled by random
neural networks pretty much a quarter of
the time males do one of their four
actions that's it right so this is a
sanity check this is what you would
expect from all the descriptions we've
given of the experiment so far no
evolution of mating no evolution of
communication no nothing yet this is the
starting
point this is after 5,000 time steps of
the same simulation what's
changed something's starting to happen
they almost never stand still they
almost never stand still why not they
meaning the males males never stand
still they have evolved to not stand
still anymore
standing
still absolutely as a male you can be
guaranteed that if you stay in the same
cell you're not going to find a female
females do not move they do not teleport
if you want a mate you got to
move what else is
happening looks like they spend most of
the time just kind of moving in a
straight line so they only turn like a
couple times to sort of rout themselves
most of the time they're moving forward
as a male turning 90° to the left or 90°
to the right you're also guaranteed not
to find a female for better for worse
there's lot of lot of metaphors to human
males and females in this I will not
crack any jokes in this lecture here you
can draw your own conclusions for the
males at this point they have evolved to
go forward not stay still not turn left
not turn right
that's the best thing for the males to
do under these conditions what do we
mean by these
conditions is this the best possible
thing for the males to
do we're only talking about the male so
far this doesn't this table doesn't tell
us anything about any Evolution that's
occurred among the female population has
anything occurred among the female
population do you think at this point in
evolutionary
time I see a couple of nods and a couple
of shakes of the head so a little bit of
disagreement thoughts um there's
slightly different distribution for
turning right and turning left implying
that the signals have some bearing on
whether they turn right or turn left
maybe maybe if you look across these
three columns the distributions are not
identical now that could just be noise
in the data right this is still still
very early on in EV in The evolutionary
history of this pidal world as we see as
we'll see in a moment we're still in
primordial times here so maybe it's just
noise maybe the females have not evolved
to signal yet but there are some
differences so maybe certain songs are
starting to influence male Behavior
maybe so far so
good here's
7500 time steps into the evolutionary
history of this planet what's
happening if the females were starting
to evolve signaling it's lost on these
particular 8,000
males they are clearly now ignoring any
difference if there is any in the
distribution of signals emitted by the
females go straight I I know I know one
of these investigators but I never got
around to ask him I would imagine when
they saw this data they were probably
pretty depressed this does not look like
the kind of place in which the evolution
of communication is going to occur looks
like a failure to
me
15,000 time steps later so we've jumped
further into the future
what's
happened asso certain signals with
turning left or right they've learned to
associate certain signals with turning
left or
right almost perfect no learning going
on just a reminder that learning means
that during the lifetime of an
individual its synaptic weights are
changing this is evolution so throughout
the lifetime of a male or female however
long they live on this grid their
synaptic weights never change so they're
evolving the males are evolving to to uh
selectively do certain actions when they
hear certain
songs again these these tables are only
reporting statistics about the males it
doesn't say anything about the
statistics of what the females are doing
can you guess what do you think the
females are doing on average
if you were to look around this time
across all 800 females for a 100 a
thousand time steps do you think the
distribution of these songs would be
uniform probably not why
not most of the time the FES are
probably go straight until they're like
in alignment with uh the females might
want them to to move straight we we'll
put mentally put scare quotes on
everything as we go but generally
speaking probably yes there is obviously
an evolutionary benefit for the males
presumably to per to turn right when
they hear one1 and to turn left when
they hear one0 that seems to be an
evolutionary benefit for the males so
there must also be some evolutionary
benefit for the females as well which
is for all we know it's for the females
to emit one1 under certain conditions
there must be certain conditions of the
male uh of males relative to the females
in which females telling the males to
turn right makes sense in the sense of
it will bring the male to the female and
from the female's perspective there are
also situations
in which it makes sense for her to emit
the song
one there are conditions under which she
quote unquote knows to emit one
one0 and she quote unquote knows that
will cause the male to turn left and
that that will likely lead to a
reproduction
event okay what conditions are these
good observation here's an example of at
this point
uh in evolutionary time what's going on
so just to summarize what we've just
seen at the very beginning as we would
expect males wander at random and
females signal at random we should
probably just say emit sound signal
implies that there's some meaning to the
sound at this point there is no meaning
associated with these eight binary
vectors males that stood still or turned
left or turned right and stayed in place
tended to go extinct
and were out competed and out evolved by
males that evolve to move in straight
lines and ignore any potential
signals however after a a significant
period of time the evolution of
communication started to occur males
started to evolve to turn when they were
on the same row or column as the female
so here's our female sitting down here
and they've shaded in same row same
column for the feale female they noted
the investigators noted at around this
particular time when a male moved into a
female's territory and came into contact
with any of these shaded cells whenever
a male uh entered the same colum or the
same row as a
female she tended to emit one of these
two signals much more often than she
would otherwise remember that the
females can see they know where the male
is relative to themselves and
orientation okay uh that started to
happen for some of these shaded cells
and then over evolutionary time around
this time females started to emit those
signals more often for more and more of
these shaded uh shaded
cells is this the best that the males
and females can do do you think
what's the optimal strategy
here it's a very simple experiment not a
lot going on
here but it turns out that there is the
potential for some relatively
sophisticated uh Collective Dynamics
here
okay think about it we'll come back to
it okay let's just pause for a moment
and have a look at some actual data
again I apologize for the quality of
these Graphics here uh what we just
looked at is the test experiment this is
their algorithm a and we're going to
look at a control their algorithm B you
can think of this as AB testing again so
again I apologize this is going to be
hard to hard to read
here test is this particular curve
here and in test here the horizontal
axis is evolutionary time usually in all
these experiments in this course we've
looked at so far evolutionary time on
the horizontal axis is measured in the
number of generations the number of
times we update the state of all the
individuals in the population in this
experiment remember there's just one
long simulation measured in time steps
so they ran this single simulation for
60,000 time steps and on the vertical
axis they measured on the vertical axis
they measured for all 800 males the
average time between reproduction events
so at the beginning way back at the
beginning here males found females on
average after about
270 time steps by the the end males were
finding females on an average of 40 time
steps clearly the evolution of
coordination between males and females
has increased in this
study in the control experiment shown
here algorithm variant B they me they
made one change and one change only
which is that the males were deafened
when they copied the binary uh when they
copied the binary Vector from the output
layer of a female neural network
controller into the input layer of a
male neural controller they permuted the
binary
values so basically the male could hear
but it was garbled what the male was
hearing which means of course that what
the male did was also garbled not
surprisingly by the end of
evolution the these males that cannot
hear very well it takes them longer to
find
females the difference between these two
curves is proof that the males and
females have evolved communication the
females have evolved the ability to
quote unquote know when to emit what
signal and the males have evolved the
ability to know what to do when they
hear what signal that obviously cannot
happen in the control study because the
males can't
hear makes sense seems pretty clear
what's going on
here during this period the deafened
males are actually doing
better how is this
possible how do we explain
this it's not noise it's real if they
rerun this experiment over and over
again with males that can hear and males
that are deafened during the early days
of Evolution tion the deafened males
tend to mate more often with
females they can still evolve to not
stand still which they do like the males
did that could hear the males that could
hear also evolved to not stand
still but there seems to be an actual
Advantage for the deafened males early
on it like At first um hearing actually
provides noise that stops
like like the randomness is detrimental
at first until the hearing evolves be
effective the randomness if it's
detrimental then this curve would be
above this curve these males are hearing
garbled
information but they do better at least
for a little while what's going
on is it like the idea that like before
you can succeed you have to fail like
it's like they're trying to be going for
but they like don't know exactly to do
yet we're you're on the right track
right there's something that's going on
they obviously the the males that can
hear are failing before they s succeed
and actually the same for the
females true but again that's also true
in the original experiment the females
are are starting to evolve the ability
to
we got to try and explain why the de and
males have an
advantage because
only best they can do is to move
constantly in a straight and it's a lot
easier to do that if do that for
everything than if you have a bunch of
different signals that you have tool
specific behaviors absolutely right so
this is a an important reminder that
communication which our species is very
good at and clearly has utility it's
useful there's no free lunch everything
comes at a cost communication and
language is very costly from an
evolutionary point of view what do we
mean by cost what what is the cost of
communication it takes a really long
time to get it right it takes a really
long time to get it right why why does
it take so long to evolve communication
is not a trivial thing we are not the
only species that's capable of language
but there are few species on this planet
that are and arguably one of we're one
of the better ones at it it's not easy
not easy in the sense that there's a
cost it takes Evolution a very long time
why what specifically is so difficult
about language there's kind of like two
moving pieces two things communicating
and then trying to make those
Communications uniform across like all
of the different members of the
population so that any member from like
the females M calls can be interpreted
by like any member
absolutely right you said it perfectly
right at the beginning right there's two
pieces of the puzzle in any
communicating species the emitters have
to evolve to consistently emit signals
under under certain conditions and the
receivers have to evolve the ability to
interpret those signals appropriately
Evolution has to get both pieces in
place simultaneously a little bit of
both pieces in place simultaneously and
then ution can improve on it from there
but you got to get both pieces at once
any as any aspect of phenotype any
feature any behavior that requires
getting more than one thing right at
once is obviously very difficult for
evolution to do because
mutations have to improve both things
simultaneously most mutations as we've
seen and you probably seen firsthand in
your uh assignments mutations tend to
break things right and if you're trying
to establish or improve two things at
once the probability of a mutation doing
that is exceedingly low it's very very
low so just to concretize this idea
let's go back to this specific case of
one female who has started to evolve the
ability to emit a signal that causes
males to turn
left when any male comes into contact
with any of these shaded cells
otherwise assume that that female emits
the signal that means just go straight
so imagine this female is actually
alternating between just two different
songs either go left or go
straight what should the males do under
those
conditions they should listen and obey
go straight and when you get to one of
these cells turn left a male coming into
this female's territory from her
Northeast traveling west a male coming
in this way touches this cell the female
emits the signal turn left let's assume
the male obeys and does turn left what
does the female say next or sing
next what should she sing
next go
straight great made
event imagine another male same
situation comes in from her Northeast
traveling west hits this cell she says
go left and the male turns right the
female probably says you're other right
your other left right there's no
guarantee and actually it's quite likely
among 800 males that those males are
going to interpret those signals
differently right so for this female to
produce enough female offspring that
emit the right signals under the right
conditions there has to be she has to
attract enough males to make that
convention that beginning of language
start to propagate through the
population it's got to take a it's going
to take a large number of rare events
for those kinds of things to happen make
sense this is yet another example of
thinking about thinking is leing
language feels so easy to us I'm talking
I see some of you writing even if you're
not writing I assume you're interpreting
and understanding what I'm saying
language is effortless for us it is very
difficult for the individual it takes uh
human children a very long time to
master language and there are relatively
few species on this planet capable of
language It Is by no means an easy feat
is it is it easier more difficult to
evolve like the emitter receiver sort of
structure versus one where both parties
can Adit and receive great question so
in this case receivers are only
receivers they're not emitters and vice
versa that's a great question I don't
think anybody's tackled that you could
take this codebase as a starting point
and add some additional output neurons
to the males so that they can also sing
and you could add some additional MO
neurons to the females neural networks
to allow them to move and see what
happens great great idea hasn't been
done yet
okay that conventions will
conventions CH we saw one
ass yes are
those great question so conventions
right so in this world at this
particular
time it seems that 101 means turn right
and 110 means turn
left is that a historical accident did
that just happen based
on mutations in the history of
this
population or is it not a
convention is there something uh is
there something specific about
one1 if we were to re re Rewind The
evolutionary tape for this experiment
and go back to 16,000 random controllers
and run it Forward
again do you think you would always see
one Z1
evolving to mean turn
right of course not why would you if we
rewound our evolutionary type and and
ran it Forward again and re and we as a
species rediscovered the concept of
historical accident would we always
spell it h i s or would we spell it or
would we spell it of course not language
is always a the the specific symbols
that make up language are probably the
best example of historical contingency
in evolution or are the development of
culture completely arbitrary so in this
case where like the only instruction
that are really important is either turn
left or turn right would this not have
evolved quicker if the binary Vector was
only like two digits long to the okay
great so the investigators made some
decisions here like uh they uh set by
setting the number of possible signals
the females emitted it took in this case
15,000 time steps for communication to
start to evolve your question was what
would happen if we reran The
evolutionary tape but now females could
only emit four possible songs only two
motor neurons for the female and only
two sensor neurons for the males would
evolution of communication evolve
earlier later or not at
all it's a great question we're actually
going to see they did a second
experiment in which they did exactly
this they restricted the songs that the
females could sing we'll see in a moment
what happens but before we see what
happens what do you think
happens we're restricting if we restrict
the number of songs that the females can
sing and that males can hear we're
restricting the communication Channel
there's only four possible things that
the emitters can say to the receivers or
send to the
receivers what about if we widened this
the communication Channel what if what
if it were what if we uh expanded the
output female output and male input
layer to four neurons there's now two to
the four possible songs that females can
emit will communication evolve earlier
later not at all
thoughts it's not so obvious I don't
think feel like intuitively like you you
be kind of teally losing information if
you sniff that signal but on the same
hand it seems like a of comor problem
like the more potential signals there
are the harder it be to like pick up
actual signals intool that great great
point right you said losing information
right we haven't talked too much about
information in the Shannon sense in this
class yet information meaning what is
the number of possible things that can
in theory be communicated in this case
there are eight possible things that can
be
communicated clearly that was enough for
uh for Behavior to evolve here given
this distribution what are the fewest
number of songs do you think females
should have access to in order to evolve
communication I see a lot of people
holding up three right turn left turn
right go
forward could we get away with two why
two
yes uh true good point right so the mes
instinctually at this point and this is
not historical accident if you rewind
the evolutionary tape and run it again
the males generally will evolve to move
forward right there is a strong
Universal reason for them to all other
things being equal move forward you've
got it almost right there's this one
Quirk of the experiment which is that
when a male enters a female territory
the males can't help but hear whatever
she's singing so even
z0000 is going to influence what the
males do so there is implicit selection
pressure for the females to emit a
signal that the males interpret as go
forward right the males can't close
their ears and just go forward so the
female has one of the one of the songs
she has to evolve the ability to sing is
something that causes or keeps the males
moving forward we need one other which
is to turn do we need the females to say
turn left and turn right
no especially it's a toid so if they
just turn One Direction eventually
they'll around uh yeah but it's a very
big
toroid it's massive right 40,000 so if a
female sings to a male and that male
leaves her signaling territory it's
unlikely that that male is going to come
back around anytime soon there's 40,000
cells on this
toroid absolutely I I had a great uncle
who came from the old country years ago
he learned to drive uh when he was
middle-aged um I grew up in a big city
he learned to drive in a big city was
terrified I remember as a kid driving
the car with him this was not a fun
experience he came up with a great
strategy which is just never turn left
everywhere he went everywhere we drove
in the car in a grid like a huge big
city you can in theory get anywhere you
want to go by making a right and in the
Western Hemisphere driving ditions are
turning right is less scary than turning
left took us forever to get certain
places but I always thought it was kind
of crazy as a kid and then 30 years
later I learned about this experiment I
thought maybe not so crazy after all the
females and males can get away with
evolving a language in which there are
just two words go forward and turn X it
doesn't matter whether X evolves to be
left or right if a man enters this
territory and the female Only Knows to
sing the song Turn left how should she
use the two songs that she has a male is
coming in from her Northwest traveling
East and hits this
cell what is she say or what does she
saying uh the male is facing this way so
left male's facing north she sings left
again the male is facing west she sings
left a third time now the male is facing
self and now she sings go forward go
forward right in theory you can get away
with two symbols in this language how
does that compare do you think to uh
females evolving the ability to sing
three different songs go straight turn
left turn right is there an advantage an
evolutionary advantage to these two
languages I would expect the simplified
one would evolve faster but the average
number of moves would be slightly higher
because there's a couple extra
instructions that need to be received
before they can reach the female
absolutely just turn right directly
that's it the left forward language
probably evolves quicker because there's
fewer things that the fem there's only
two things the females learn need to
evolve the ability to emit and there's
only two things that the males need to
evolve to interpret correctly but it's
an inefficient language because in the
example we just looked at the male and
the female waste two time steps in which
it's guaranteed that they are not going
to going to mate
yeah wouldn't it be kind of less likely
if if we're starting with like random
we're starting with like random
probability of of each thing wouldn't it
be less likely to land on three lefts in
a row than it would be to like I I just
I feel like like saying that it's that
it would arrive at the solution faster
like the ability to turn right is
actually pretty unlikely though got it
possibly it might actually be harder for
the females to evolve that because
there's a greater number of conditions
she's got to keep uh right in order for
the mating event to happen same thing
with the male right so maybe yes maybe
no a lot of the research questions that
arise from this experiment which we're
discussing it's not so obvious yeah
which
makes from my perspective makes makes
this evolution of language interesting
evolution of communication interesting
very very simple setup but a lot of Rich
Dynamics can start to occur here
okay okay all right uh we just talked
about this I think but let's just go
through it here we've got a female down
here again I apologize on the very small
font here there's a male out down here
outside of
her uh uh visual range she cannot see
this male she is singing
0000 here in panel a at the next time
step panel B the male as males tend to
do in this world moves forward and
enters her visual range she sees the
male and switches from singing 0000 to
singing 1 01
in panel C it seems like the male is
ignoring that signal the male continues
doing what he was doing before which is
moving straight in a Northerly
Direction in panel D the female suddenly
switches from singing 101 to singing
001 and the male's Behavior immediately
changes the male heard and interpreted
that signal as turn right and the female
in panel a goes back to singing
101 what's going to happen at the next
time step which is not shown in this
figure the male is going to move
straight because we know that this male
moves straight when he hears
one1 okay a successful mating event
here's the example we just saw we just
talked about a minute ago malea uh
entering from the Northwest from the
female's Northwest perspective traveling
East
the female is emitting 1 1 011 1 01
one1 and the male turns left she keeps
singing
one1 and the male keeps turning left
turns left again when she when it when
the male turns left for this third time
she changes back to 011 which the male
interprets as go
forward okay all right so we have seen
now that at least when the females can
sing eight different songs the evolution
of communication can occur but it's now
occurred to us that there are different
possible languages that can evolve under
these conditions so the second
experiment we're going to look at now is
something you mentioned a few minutes
back what happens if we restrict the
communication channel of the female so
that she can only emit four possible
songs and the m s can hear those four
possible songs so we're going to rewind
the evolutionary tape we're going to go
back to
16,000 random agents they all have
random neural networks we're restricting
the output layer of the female and we're
restricting the input layer of the mail
and we leave everything else the same
and start it
up okay this is what things look like at
the very first time step in the
simulation takes a little bit to wrap
your mind around what's going on here
you'll notice uh you'll notice all in
all of these little Bunches of numbers
here there's a number to the left of the
colon and a number to the right of the
colon let's have a look at the number
that's to the right of the colon there
are four digits these four digits
correspond to the four possible songs
that the females can emit
uh in this case it turn again the males
have four possible uh actions so it
turns out that there were a few males
that when they heard whenever they heard
the first of the four songs whenever
they heard the song 0000 the males did
zero which is stay
still the second digit when males heard
this second song song 01 the males did
zero also which is go forward and some
of these males when they heard the third
song they did one which is go forward
and some of these males when they heard
the whenever they heard the fourth song
they did three which is turn
right there were four males the number
to the left of this colon among all 800
males there were four of them that did
this so each grouping of numbers here is
representing a particular subset of
males that and the number to the right
of the colon tells you exactly what
those males did under all four
conditions make sense everybody see how
to read this okay so let's just check
our intuition let's jump at random to
another one let's have a look at this
one here so in this first time step
there were 11 males that did this
distribution of things these things when
they heard those four female songs there
were uh six males that Stood Still
whenever they heard the first of the
three songs and went forward when they
heard the fourth
song again I apologize for the small
font but if you scan your eyes over all
the numbers to the left of the colons
you'll notice that across this ENT
higher table there's a more or less
uniform distribution of things that
males do in response to female
songs everybody see
that okay all
right here's what things look like after
8,000 time steps what's
happening again this is only sh us
changes in behaviors among the males
doesn't really tell us anything about
changes among the behaviors of the
females um it seems like there are some
competing conventions competing
conventions okay how are there competing
conventions here there are competing
conventions here what are they on the
right there are a bunch of like I you
can not necessarily space but you can
see like there are kind of similarities
between some of them there's
similarities at this point at the
beginning there's no male tribes right
all males are doing all the different
things you could possibly imagine the
one thing that should obviously jump out
to you 8,000 times steps later is the
male male Behavior tends to be much more
uniform the ways in which males respond
to female
songs has shrunk
I've highlighted the largest grouping
here what's going on among this tribe of
547 males looks like they just always
move forward except for Oneal just turn
right exactly so you'll notice to the
right of the colon here there are three
ones so for three of the four songs the
males go forward and for the second
female song these particular males only
turn right these males like my great
uncle they never turn
left also none none of the big ones I
guess the exception of 7 the 74 to the
right of it like the 323 and a lot of
the 7s only have two most of them aren't
using all three some of them are using
two or using two of the four motor
Primitives that are available to the
males some are using three some are are
using two or responding to two out of
the four female songs and some are
responding to three out of the four
female songs where are the males that
ignore female songs
altogether are they on
here what would the four digits to the
right of the colon look like for the
group of males that ignore what females
sing 1111 1111 does anyone see one 111
on
here where is
it four above ah here we go here we go
thank you very much right so these males
no matter which of the four songs they
hear they always go forward there's 70
them among these two groups among these
70 males and these 547 males who do you
think's got a sunnier future
it's already it's already starting to
become obvious right these
males okay so we keep going all right
let's fast forward through evolutionary
time here's the state of play after the
same simulation 10,000 time steps later
there is now a growing group up here I'm
going to flip back and forth between
8,000 time steps
10,000 time steps 8,000 10,000 8,000
10,000 keep an eye out for the
1113 what's
happening they've evolved kind of
similarly to 6
except
s we've got a competing conventions
thing going on there's this growing
number of groups of males that uh change
what they do based on the fourth song
and there is a very large group of males
that's been around for a while now that
changes what they do or at least they
suppress their default Behavior which is
to go forward when they hear the second
song this is a little off but is this
like process of mapping the songs to
like a is that
grounding is that grounding great Point
yeah what do you think is this a version
of grounding from the M's perspective is
this an example of grounding the symbols
of language 00 0 01 one 0 and one0 in
the soil of sensor motor experience
I mean the language is their sensor
experience all they can do is all they
can do is hear and act based on what
they hear they can't help but ground the
symbols in sensor motor experience
because for the males and actually also
for the females it's a matter of life
and death yes absolutely if you were to
ask one of these males what 01 means the
male is not going to say well I 01 tends
to come before one one and one1 whenever
I encounter a female that's what chat
GPT in the non-embodied AI models do
they'll tell you what a symbol means by
telling you that that symbol tends to
come after a bunch of other symbols it's
not grounded in the soil of sensor motor
experience if you were to be able to ask
a male what 01 means the male would tell
you it causes me to want to turn left
and when I
uh when I go with what feels right I
tend to produce
Offspring yes it it's definitely
grounded in sensor motor experience
great
observation okay so again we're looking
at only what the males do but we should
be able to infer or you should be able
to infer from this that the fact that
there are so many of these males around
must mean there's an evolutionary
advantage to this behavior and also an
evolutionary advantage to this Behavior
Behavior therefore there must be two
groups of females one group knows how to
attract and mate with the 1311 males and
another group of females that knows how
to attract and mate with the
1113 males everybody see
that okay is this it we now see not just
the evolution of communication we see
the evolution of two different languages
simultaneously inside the same evolving
population there are no mountain ranges
on the toroid it's not that these two
groups are physically separated they're
moving and mixing all the time they just
don't literally speak the same
language evolutionary pressure is
continuing to act on the on the males
and females there is exerting
evolutionary pressure
is there anything else that the males
and females or The Descendant the male
and female descendants of these males
and females might evolve to
do so I see one
of also the
ability okay one itic
this one there there were 74 members of
this male tribe now there's only 42
another auspicious number so normally
I'd say that like the next step would be
to evolve the ability to turn the other
direction but clearly that doesn't seem
to be something that evolution is
pushing forward not at this point in
time yep good
observation this seems this group seems
promising the males turn right in
response to signal 2 and left in
response to Signal 4 and we know that
there are two groups of
females that are emitting songs two and
four because that seems to be working
for these males and song number four
tends to be working for this group of
males if you were a male
descendant in this population at this
time from your perspective as a male
what might you want to do might want a
response if you're if you're a female if
you're a female descendant in this
population at this
time what do you want to be
doing you're a female among females some
of whom know to S to emit signal to
under certain conditions and another
separate group of females that know how
to emit song four under a different set
conditions what evolutionary pressure is
now starting to build on the female
population the ability to do both the
ability to do both at this point in time
there is evolutionary
pressure uh there there are two po
subpopulations that have evolved in this
larger population they're both monol
linguists the males and females in both
group groups speak the same
language let's see what happens okay
10,000
12,000 at 12,000 we've got 1313 males
somebody mentioned 1313 males they seem
to be responding correctly to both
female groups how do we know that we
know that because these males turn right
in response to song two
and this big male tribe tells us down
here indirectly that there are male
females that know uh how to sing song
two to attract males that turn right
when they hear song two there's
potential here for these males and these
males also quote unquote know that there
is another group of females that know
how to turn how to when to sing song for
to attract males that turn right when
they hear that song
so this is 12,000 time steps have a look
at this particular tribe
here 20 members of this tribe at time
128 members of this tribe at 12,000
what's happening to the other two
monolingual
tribes I'm going to advance this slide a
couple more slides what do you think's
going to happen who are you rooting for
here they're probably like L numbers
as here's
14,000
16,000
20,000
30,000
40,000 if you're not on du lingo I would
highly recommend that you do
it's one take away from this lesson
today is is it pretty rare that when
when you're training that it like even
like that it actually converges on one
result well would happen if you rewound
The evolutionary tape and you ran this
experiment all over again this
particular experiment in which there's
only four possible female sigal what do
you think would happen would the entire
population evolve on
multilingual uh receivers and
multilingual emitters this is another
item here right we know that the males
have converged what's going on with the
females there's one uniform population
of multilingual females all 1600 females
are multilingual there is no longer a
population of this many monol linguists
and this many other monol linguists how
do we know that that's the case
we're inferring that from this
data biling males respond the bilingual
the bilingual males can respond
correctly they can they can mate with
monolingual females of one group and
monolingual females of the other group
and they can mate with any bilingual
females if there are any
that's clearly an advantage for the
males is there an advantage for the
females to evolve to be
bilingual
why because until the male population
does converge it's going to
increase absolutely at this point in
which every single male is bilingual now
among the female population it doesn't
matter you can only emit song one and
two or only a mid song one and four and
you'll with equal probability attract
these particular
males but as these during this
evolutionary period you're more likely
as a female to be able to attract these
males or these males or these males if
you speak two languages a monolingual
female during this evolutionary period
can only capture males from one of these
three groups not from all three groups
there is selection pressure acting on
both the female and male populations at
this point not just to evolve
communication but to evolve to be
bilingual in this
case okay we've got one minute left in
class back to your question what do you
think would happen if we Rew rewound The
evolutionary tape and ran it Forward
again would we get the evolution of
monol linguists followed by the
evolution of bil
linguists I would guess probably yes for
the fact that it's the only way you go
you would end up converging on monist is
there was just like one really dominant
language
possibly possibly but not
quite look at what the males are
doing these incredibly fit males and
this is the only thing the males ever
do is is this the optimal solution for
the males and the
females I see some of you shaking your
heads no why not how do you know this
isn't optimal they can only turn One
Direction they can only turn One
Direction my great uncle strikes again
good solution but not an optimal
solution a lot of amazing things going
on here but evolution is a satisficer
not an Optimizer Evolution has converged
on a pretty good Sol ution but it's
inefficient it would be great if males
actually were able to turn left and
right in response to a lot of different
signals yeah is our language the most
efficient language there is could I have
communicated everything I communicated
to you this morning in less than 75
minutes probably yes I don't know how
but probably yes is there any
evolutionary the number
step is there any evolutionary pressure
in this experiment absolutely there is
evolutionary pressure to reduce the
number of time steps between mating
events absolutely there's very strong
evolutionary pressure in this experiment
evolution of language and language
obviously a fascinating topic we could
teach a whole class on this we're going
to put a pin in this for now uh you have
a quiz due tonight you're working on
your final project have a good rest of
your week see you on Tuesday


--- Evolutionary Robotics course. Lecture 25： Evolving bodies and brains..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
all right good morning everyone the end
is in sight we are going to crack open
the final theme uh of this course
evolving physical structure and neural
control policies for auton autonomous
machines simultaneously evolving bodies
and brains which is what the field of
evolutionary robotics was set up in the
first place to do so it's taken us a
while to get here but we're here before
we talk about evolving uh and brains
let's talk a little bit about final
project uh most of what I've seen from
most of you looks like you're making
good progress people are being good
about managing expectations breaking
ambitious projects down into reasonable
weekly bite-sized chunks revising those
weekly work packages when things don't
quite work out as you expect them to all
looks good uh I saw a couple of you this
week about the mass patch so on the tips
and tricks page there's a bunch of
things you can sort of add to pyro Sim
pyro Sim is among many things a shield
that is meant to shield from you all the
nitty-gritty details of the underlying
physics engine which is pybullet
nitty-gritty details like this has
anybody actually looked at a urdf file
or an SDF file I think I forced you to
do so in assignment one or two uh a
point about the mass
patch Pyro
by default assigns a value of one as a
mass to every link that you create your
robot from so if your robot is made up
of nine links it has a mass of nine just
a reminder that in most physics engines
including Pi bullet there are no actual
units so each uh link weighs one one
what one kilogram one pound doesn't
matter for our
purposes the mass patch uh uh challenges
you to add a little bit of code to pyrro
sim that opens up or exposes this
particular parameter to your own code so
you can change the Mass properties of
your robots some of you are working on
bipeds one way to make it easier for a
biped to walk is to make the feet
heavier some of you are making a
baseball robot uh if your robot weighs
the say has the same mass as the ball
that it hits what happens when the robot
hits the ball with its bat
doesn't go very far doesn't go very or
the robot goes plenty far and the object
doesn't necessarily Go Far So for many
of you altering Mass distribution makes
sense the formatting of these urdf and
SDF files is that numerical parameters
like mass for example needs to be
surrounded in quotation marks why is
that the case I have no idea that's just
the way piy billot works so in the uh in
uh for example Mass urdf dopy the part
of pyro Sim that writes out the U urdf
file or writes out the mass part of the
urdf you'll see that by default this
part of pyro
Sim just writes out this string right so
a default Mass uh of one so we could
alter this to do the
following and then put whatever Mass
value you want in there but now we've
lost the double quotation marks an easy
mistake to make I saw that a couple of
you made it you need to do something
like this fidgeting with formatting it's
a bit of a pain but there you go okay
there's other a couple other places like
that in the patches and the tips to tips
and tricks if things aren't working it's
usually because you've altered pyro Sim
so that it no longer writes out a
compliant urdf and SDF file if you're
getting that kind of error have a look
and if you're still stuck come and see
frya or myself and we'll get you unstuck
okay any other questions about things in
the final
project yes when you're initially
starting simulation is there any way so
like you have two cubes is there any way
to have it start like slightly offet
turn yes okay so how do you set the
initial orientation of uh objects in
your simulation you can so let's see it
should be in here
somewhere yeah here it is okay so again
we're looking directly at a urdf file
and so I am highlighting all of the
information in a urdf file that
describes how a link works so here's
link open link close link everything in
here specifies physical properties of
the link again pyro Sim is hiding most
of these details from you
let's see if you can read The Matrix
directly here which what material inside
this highlighted formatting do you need
to change to change the
initial
orientation of a
link just as a reminder remember that
what the physics engine is doing for you
what py bullet is doing which sits
underneath pyrosim what pybullet is
doing is Computing all of the forces
that are acting on every link and
updating the position and the 3D
position and the 3D orientation of the
object but in some cases you might want
to start with a particular
orientation you can actually alter this
code or have pyro Sim alter how it
writes out this code to set the initial
orientation of a link where is it in
here rpy parameter it is absolutely the
rpy parameter rpy stands
for close you're on the right
track roll pitch and Y roll pitch and Y
that's it you'll see that when you
create a link at the moment the default
is zero roll zero pitch zero yah and I
always forget which is which this is one
of them this is one of them and this is
one of them that's how right so go back
and have a look at the mass patch which
allows you to expose Mass to uh initial
to initial settings do exactly the same
thing but for roll pitch and yaah and if
you figure it out let me know and I'll
add it as a orientation patch to the
subreddit other
questions could you go into more detail
about what you're expecting for the
Milestone Force AB testing okay sure uh
what we're expecting okay what we're
expecting in uh deliverable for is
preliminary evidence of your AB testing
what does that mean so uh FR or I are
going to grade your deliverable for what
are we looking for we're looking for we
understand what your version a and
version B is hopefully we probably
already know what that is from your
previous three deliverables but make
that
clear and then what we would like to see
is a series of screenshots or a video
demonstrating algorithm a and algorithm
B in operation is there something that
we can see that demonstrates the
differences between a and
b what we are not looking for in
deliverable 4 is for you to prove that a
is better than b or B is better than a
that's what you're going to attempt to
do during the exam period demonstrate to
us that one is better than the other or
that there is no difference between a or
b hopefully what doesn't happen for you
in the final project is I don't know I
did one run of a and one run of B and
they're kind of they produce kind of
similar Behavior but a little bit
different I don't know whether a is
better than b or B is better than a or
there's no difference between them yeah
we're hoping that you collect enough
data to present to US during the final
project and I'll we'll talk about that
next week we'll talk about the final
project uh oral presentations next week
but for Milestone 4 can you show us that
you've got a and b up and running and
the idea is between deliverable 4 and
your oral presentation I guess that's
about a week's time you're going to let
this cook away on your laptop or
whatever computational resources you
have and then try and prove to us a is
better than b b is better than a where
there's no difference between a or B for
some of you the it'll be relatively easy
in the fourth and final Milestone to
show us visually that there's a
difference between variant A and B
because for some of you a is the
quadruped and B is the hexapod we can
see it it's pretty straightforward for
others of you it's not going to be so
obvious because maybe you made changes
to the cognitive architecture of the
robot so what's okay what's okay and
deliverable for is show us some
screenshot and some video and you might
also show us your terminal so print out
some statements so that we've got some
data or FR or I can see what the
difference is between A or B it's up to
you to figure out how to show us that
you've got a and b working and that they
whatever the difference is between A and
B you make it visible for us make
sense okay any other questions about
that okay so let's see where are we now
Tuesday next Tuesday week from now I
will go through exactly what's expected
for the oral presentation and the
written report for the final
project okay all right so uh as promised
this has been a long time coming we are
going to talk for the remainder of this
course about expanding an evolutionary
algorithm so that it can simultaneously
tune so that can simultaneously tune the
physical structure and the neural
controller of your robot
several times in this course we brought
up the difference between learning and
evolution generally speaking in nature
and in robotics and machine learning
learning implies changes to a neural
network or changes to the controller of
a robot but of course Evolution doesn't
work that way Evolution doesn't respect
our boundaries Mother Nature
simultaneously and is continuously
tuning and tinkering with all aspects of
the phenotype of organisms the idea the
philosophy behind evolutionary robotics
is that if we want to create autonomous
and safe machines it's not enough to
just come up with an idea for a physical
structure and then train a neural
controller for it and hope for the best
in the long run if we want to create
autonomous and intelligent machines we
need to find ways to autonomously
optimize physical structure
and the behavior of the machine itself
that is a particular stance that may or
may not be true I work in the field of
evolutionary robotics I happen to
believe that's going to be uh how things
are going to go in the long run you
don't necessarily need to believe me
what we're going to do in lectures 22 23
24 and 25 is look at how to do this how
do we expand an evolutionary algorithm
to optimize brain and body
simultaneously okay all right so uh as
you can see here we're going to look at
uh we're going to look at the evolution
in brains and bodies of four different
classes of robots traditional rigid
robots today like the ones you're
familiar with rigid links that are
connected with rotational joints the
robots you're going to see today look
very
familiar uh next time in lecture 23
we're going to look at soft robots where
we no longer assume that we have rigid
links connected by rotational joints
we're going to look at Blobs of soft and
rigid material and we'll discuss Le
discuss in lecture 23 why you might want
to do so why might you want to create or
automatically design soft robots final
week of the course we'll look at uh
evolving the bodies and possibly the
brains of robots that are built from
biological rather than technological
components these are biological robots
or more commonly now known as xenobots
and finally in leure 25 we'll look at
arguably not an evolutionary approach
but a way to try and optimize bodies and
brains of robots without having to uh
fall back on random trial and error can
we remove the randomness in evolutionary
algorithms and uh design bodies and
brains automatically in a more
computationally efficient
manner okay let's start with rigid Ro
robots as we've done several times in
this class we're going to go way back in
time to the early
1990s here we
gool
performas Sim environment swimming speed
is used to determin survival most of the
are results from independent Evolutions
some develop strategies similar to those
in real lives once they evolv multiple
copies of these creatures can be made
and simulated together in the same
environment the next group of creatures
were evolved for their ability to move
on a simulated land environment with
gravity and friction some Simple
Solutions with just two parts were found
some seemed like they could use some
assistance While others were fairly
efficient such as this growing life
Behavior here is an odd cousin of the
previous a mutation caused you to
Tumble some creatures evolve to
incorporate contact sensors in their
Control
Systems here is another inchworm like
creature that tends to go in
circles this was actually a creature
first evolved for its ability to swim in
water then later put on land and evolved
further a successful sidewinding ability
resulted here is one with a Hopping
style the protrusions on its arms seemed
to help prevent it from tiing over this
was the fastest with a successful
Galloping like
stride this group was evolved to their
jumping
ability this group was evolved to their
ability to adaptively follow a red light
stores the resulting creatures are now
being interacted with us moving the
light source around as the creature
behaves this one seems to flail randomly
but somehow still manages to approach
the light Perhaps it is mean to move the
go away just as it arrives here is one
that has the color
like depending on the direction the life
you can adaptively swim up or down very
well this final group of creatures was
evolved to their ability to compete for
control of a green h the closest to the
cube at the end of a simulation is the
winner here a strategy first arose was
simply tumbling towards the
quebe then one learned to block out his
opponent but then later one learned to
overcome the obstacle by climbing over
it some pined down their
opponents some covered the cube with
protective arms
others simply unfolded onto the
cube the success of a strategy is often
highly defendent on the opponent here is
a hockey cling creature which takes the
cube away and wins by a large margin
here are two similar hockey strategies
battling it out with appropriate
gestures this crab life creatur walks
well but often continues fast the que
and instead seems to prefer beating up
on his
opponent against the arm the crab seems
to simply walk
away a successful strategy is this two
arm technique that swipes quickly in
from the side and moves the cube over to
a second
on these are the final rounds of
competition amongst the overall
finally the Seeker arm goes against the
side swi but the cube is just Out Of
Reach we spent a little bit of time last
time talking about parallels between
those agents and human behavior same
thing here right why go after the cube
when you can just beat up on your
adversary okay
observations from those videos before we
dive into the
details what did we just
see was really impressive for 1994 um
but uh robots assembled from rinear
blocks kind of free form join to each
other in varying
environments absolutely right so you can
see clearly the body plans are being
evolved along with the neural
controllers of these robots absolutely
state-of-the-art for
1994 well well ahead of its time other
observations from what you just
saw two parts to the video obviously in
the first part we were looking at
individuals uh individually evolved
robots what did we see in the second
part aside from robots beating up on
each
other competition
where did that competition come
from coolu co-evolution so we'll see
towards the end of today's lecture
another Twist on an evolutionary
algorithm which is instead of evolving
one population of Agents why don't we
evolve two populations of Agents where
the fitness of any one individual in
this population is a function not only
of what it does but what the individuals
in the other population are doing when
they interact with that individual
that's co-evolution okay let's talk
about the technical details of what we
saw uh just now uh as Nature's mentioned
this was work well ahead of its time uh
I mentioned that physics engines weren't
invented until 2000 1994 here this is
clearly a physics engine and a pretty
sophisticated one at that this was the
work of Carl Sims a computer Graphics
researcher um Carl was hired by uh was
hired by a company called thinking
machines back in the late 80s and early
90s just a little bit of computer
history for you here this was an attempt
to create the first parallel
supercomputers we'll see the connection
machine uh in a moment this particular
computer was designed to have multiple
processors inside and those processors
could talk to one another
sounds familiar it wasn't just the
software here that was ahead of its time
also the hardware on which this
evolutionary robotics experiment was
conducted thinking machines Corporation
as they were developing this computer in
the late 80s early 90s were thinking to
themselves well it's an awesome computer
it's got huge compute but what would
anyone ever do with it why would you
need to have a whole bunch of things
being computed in parallel
the CEO of this company saw some of Carl
sims's early computer Graphics work and
some of these virtual agents and
realized if you want to try and evolve
populations of these things like
populations of organisms evolve in
nature wouldn't it be great if each node
in this machine were dedicated to
simulating one of these creatures and if
so we could simulate a whole population
of these creatures
simultaneously so you can see early on
here in the early 1990s a lot of the
basic assumptions of how we now go about
evolving robots in silico and then
transferring them to reality we laid
down in this initial
experiment
okay all right so uh the connection
machine here uh the particular machine
that was used was the connection machine
five which had uh 1024 cores and it had
a peak speed of 131 gig flops per second
back in the early 90s this is a Mac Pro
from a few years ago now when I made
this slide 91 gigaflops per second so
this big machine here had about the same
compute as most of your laptops at the
moment not bad actually for the early
1990s all of the experiments that you
just saw that Carl ran on the cm5 Carl
used a population size of 300 so had
about 300 uh robots being evolved in
parallel and evolved it for about 100
generations and that took about three
hours on the cm5 at that time so not
that different probably from what you're
doing right now just on a much much
bigger hunk of metal uh if you go back
and watch Jurassic Park one of the nice
things about the cm5 is it had these
nice flashing red lights on it and you
can see that actually in the control
room room of Jurassic Park in the first
movie What are the red lights
representing do you
think aside from just a nice Bell and
whistle to help sell CM FS they actually
had a functional
purpose what do you think it meant when
all the red lights were off or all the
red lights were on is it Ram maybe how
many red lights do you think there
are too many to
count a thousand 24 why did you think
that absolutely right so at a glance you
could tell how efficiently the machine
was being used so it was actually set up
for Diagnostic purposes uh and some
Hollywood exec passed through the
connection machines offices and said
that's awesome we need that in our new
movie that we're making about
dinosaurs okay all right so that's the
hardware let's talk about the software
now we're going to talk about the
genotypes and the phenotypes in Sims
experiment here just as a reminder
genotypes is the blueprint right all of
the encoded information about in our
case in all the experiments we've seen
in this course that genotype contains
some information about the robot in your
assignments your genotype probably is
still a string of floating Point values
which specifies the weights of the
synapses inside the controller which is
inside your robot there are many many
parameters of your robot like for
example the masses of the links that are
not encoded in the genotype the
phenotype is the thing that's built from
the genotype built from the blueprint
again in this course the phenotype for
us has usually been the geometry of the
robot how it moves and its controller so
phenotype is sort of this umbrella term
for the thing produced by the
genotype the genotype again can specify
more or less of the
phenotype some aspects of the phenotype
is specified manually upfront by us and
we turn some of those phenotypic
parameters over to the genotype or
encode them in the genotype and let
Evolution figure out what those
parameters should be
yeah okay that's the genotype to
phenotype what we haven't talked about
too much in this class yet is the GTP
map I think I've mentioned this in
passing a few times now the genotype to
phenotype map is the algorithm or the
mapping or the process or the function
the verb the thing that transforms the
genotype into the phenotype in the case
of us biological organisms that mapping
is
fantastically complicated it's devel
usually referred to as development the
way your genotype influences you as a
single cell into the thing that's
sitting here in the room with us
today simulating that whole process in
silicone nobody's figured out how to do
it yet because it's fantastically
complicated question number one how do
we do it question number two should we
do it if we want to automatically uh
design autonomous and safe machines do
we need a fantastically complicated
genotype to phenotype map nobody knows
yet but in this experiment today we're
going to see the most complicated g2p
mapping we've seen so far in this course
and you just saw it produces some pretty
sophisticated results not bad okay so
let's start with the genotype uh
remember that this is encoding some
information different genotypes we've
seen in this course encode genetic
information in different data structures
we've seen strings of floats we've seen
trees whenever we talked about genetic
programming genetic programming is that
particular class of evolutionary
algorithms that tends to encode
genotypes in trees today we're going to
look at genotypes that are encoded as
graphs a graph is made up of a series of
nodes the circles that you see over here
and edges that connect nodes together
that's a graph the genotypes in The Sims
work are particular types of graphs
nested directed multi-graphs so we'll
unpack each of these three uh adjectives
as we go but for now we're going to
think of these genotypes as graphs and
the phenotypes again hopefully look
pretty familiar to you strictly speaking
they're trees there is some root node
root link if we were to do this in
pyrosim uh and a series of links that
are connected to parent links with
rotational joints nothing uh nothing out
of the ordinary
here this particular mapping the way
that we're going to turn these graphs
into trees is a recursive algorithm we
haven't gone into the details of exactly
how this mapping happens yet but you
should be already able to see some
there's some visual hints here about the
recursive nature of this mapping how is
it
recursive what does it mean to have a
recursive genotype to phenotype
map phenotype influences the genotype uh
that the phenotype influences the
genotype that could be the case it's not
the case here a good
guess the graph has self connection the
graph has self connections we're going
to walk through this GDP map in a moment
and as we do we're going to walk through
this graph we're going to read out this
blueprint in a recursive manner some of
these links are going to bring us back
to places we've been before and as we
walk along this graph this graph because
it's a blueprint is going to tell us how
to build stuff and as we build stuff
we're going to get things that have self
similar structure
what do I mean by selfsimilar
structure the recursiveness of this GP
mapping is going to tend to produce
phenotypes that have certain features
they tend to look self
similar what does that
mean look the
same at different scales they look the
same at different scales right so if we
look at just this part of this phenotype
we get this little y structure and then
if we zoom in a little bit more we see
that same y structure again zoom in
again we see that little uh we see that
y structure again and so on this is
self- similarity or depending on the
phenotype it can be a fractal structure
you zoom into human physiology or the
physiology of most every organism it is
also self
similar if you were to look at your own
vasculature system at the at the whole
body level it looks like a tree a whole
bunch of big trunks pumping blood into
smaller branches if you zoom in on any
part of your vasculature system you see
smaller and smaller branching all the
way down to the molecular level
self-similarity tends to be ubiquitous
it's everywhere in uh organism
phenotypes
let's just connect this back for a
moment to our discussion about hypernet
and cppns compositional pattern
producing networks you remember that
evolutionary algorithm would paint
patterns into an AR a space of arbitrary
Dimension that GP map the GDP mappings
that was built into cppn that mapping
was designed to also produce self-
similar structure or bias Evolution
towards symmetry repetition
and so on so the art of creating a good
GP map is that a random genotype a
random blueprint doesn't necessarily
produce a random collection of Parts it
tends to produce phenotypes that have
particular features and typically these
maps are designed to produce typical
features that we also see in nature like
for example symmetry in our species the
left side of our bodies tend to looks
like the right side of our body if you
look inside us you tend to see self-
similar structures and so on
constructing a good gep top map is a
very difficult thing to do it's still a
bit of a a uh black magic a black art
Dark Art it's not so obvious to see how
to do it this particular one is
complicated and seems to work well one
of the reasons why seems to be is that
when you
populations of these things populations
of these genotypes they tend to produce
self similar
structure remember the video that you
just saw you actually saw perhaps
without realizing it a lot of examples
of phenotypes that had self-similar
structure in
it like what what did you see in the
video that looked in retrospect self-
similar crab the crab how so was
symmetrical two
arms absolutely it was symmetrical not
necessarily self-similar self-similarity
is not necessarily the same thing as
symmetry you can have something that's
symmetric but not self-similar you can
have something that's self-similar but
not symmetric but yes one of the things
that this GTP mapping gives you in
addition to self- similarity is uh is
symmetry actually you can see it here
all three of these phenotypes are
bilaterally symmetric
there was that kind of worm you can go
back and look at the video and every
segment of that worm was a little bit
smaller than the segment in front of it
if you kept zooming in on pairs of those
segments that made up that worm you'd
see this you'd see the similar pattern
at every scale a big one followed by a
slightly smaller
one okay all right so let's have a look
at how this uh let's have a look at how
this works let's dive in now and look at
some more detail of the genotype as I
just mentioned the genotype is encoded
as a graph a graph is a series of nodes
and those nodes are connected with
edges in these particular genotypes in
these particular graphs they are labeled
every node and every Edge has a bunch of
numbers associated with it that's the
blueprint that that's the
information okay let's have a look at
some of the labels some of the numbers
that are attached to each and every node
in the graph there are three numbers
attached that describe the body part
Dimensions they describe the length and
width and height of the block that
should be built whenever we visit that
node you'll notice that these nodes have
little names associated with them
this is meant to be a reminder to the re
reader that each
node describes how to build a single
link if we want to build a single link
we need to know what the length and
width and height of that rectangular
link is we'll come back to the Joint in
a moment we'll come back to some of
these nodes we're going to have to jump
around a little bit in the description
of this genotype okay so let's start to
actually execute this G top map let's
imagine that this little node or this
little graph is sitting inside a
population of graphs we have a
population of these genotypes we need to
take each genotype and turn it into a
robot we need to turn it into a
phenotype how do we do that we start by
visiting the root node in the graph
there's one one particular node which is
sort of
arbitrarily dict uh denoted as the root
node we go there first and inside that
node we find three numbers length width
and height we build a link of exactly
specification and now we we leave this
node and we travel along bo uh all
outgoing
edges here we
go okay we would typically do this in
parallel but for the sake of this
morning let's do this uh one one after
the other so we just built this
particular link here using the
information that's inside this node we
travel out along this link or this Edge
and edges also have a bunch of numbers
associated with them there's a bunch of
labels attached to each and every Edge
in the
graph those labels tend to be
Deltas we just left this node and we
just created we just created a node of a
particular length width and
height so when we leave when we leave
that node we're going to take all of
that information with us we're going to
carry that information in memory and
these numbers are going to tell us how
to alter those numbers there are three
numbers associated with an edge that
tell us how to change the scale they
change us they tell us how to change the
length width and height into some new
length width and height which we'll call
L Prime W Prime and H Prime so far so
good okay uh we talked about 3D
orientation a few minutes ago we're also
going to take with us roll pitch and yah
which perhaps at the beginning is just 0
0 0 there's another three numbers
associated with this Edge a fourth fifth
and sixth number that tell us how to
change the orientation of that object so
we get a new rooll a new pitch and a new
yaw so far so good there is a seventh
eth and Ninth number that tell us how to
change the 3D position of the center of
the link that we just
built so far so good okay let's pull
back a little bit and think about the
intuition of this we visit the root node
we build a link we travel along edges
and as we do these nine numbers are
changing when we finish traversing The
Edge we arrive back at some other node
or possibly the same node When we arrive
at that node we have a length width and
height we have an a roll pitch in ya and
we have a new XY
and
Z drop a link we create a new link so
every time we visit a node we create a
new link everybody see that so far so
good okay obviously we need some joints
as
well when we are sitting at a node
you'll notice that there's a bunch of
joint parameters as well but this is a
little confusing a node is telling us
how to build a link the node is also
telling us how to build a
joint but a joint requires two links
right how do we interpret this
information that this node in the
genotype in the blueprint is telling us
how to build a joint but a joint that
connects what to
what do you
think let's go back to the beginning of
this GDP map we started here at this
node and we just
built a single
link there's information that's telling
us how to build a joint how do we build
a joint we don't even have two links yet
we only have
one Ah that's it so this very first link
that we build we ignore the joint
information but as Emily said when we
leave a node we know what we just built
we just built this one we travel along
the edge and as we travel along the edge
we come back to this node or another
node and we build
another we build another link so we just
built a link We remembered which one we
just built and now we're sitting at this
note again now we take this information
which tells us how to connect the link
we just made with the link we just made
previously everybody see that okay so we
just built the trunk we went along this
left Edge and we built this left
Branch pause we just built this trunk we
simultaneously at the same time we went
along the left link we also went along
the right
link this link also has information
about how to change size orientation and
position and those nine numbers over
here when we come back here tell us how
to build a
different link the right
Branch so we've visited this node three
times and we've traveled along two edges
so
far so far that's given us a phenotype
that's made up of 1 2 3 links and one
two
joints everybody see how this is going
okay so a lot of information to throw at
you I'll just pause for a moment
questions anything that's
confusing question yeah maybe we haven't
gotten into to yet but in the edge
labels have we spoken as what reflection
is is that we haven't we'll get there
there's some additional labels that we
haven't talked about yet we'll get there
in a minute Nate
what it means to Traverse all of the
edges from a single node like in these
cases they're all symmetrical so it
makes me wonder like is what you do on
the left automatically on the right
absolutely not it just in this
simplified example yes but the Deltas
over here the the instructions about how
to change uh size orientation and
position those nine numbers don't have
to be the neg these nine numbers over
here don't need to be the negatives of
these numbers over here they could be
nine completely different numbers which
would produce a very it would produce a
nonsymmetric
tree but that tree would still be self
similar because this thing is still
recursive everybody see
that okay good observation any other
questions or observations before we push
on yes uh all uh creation happens before
even simula absolutely right so good
point so the genotype to phenotype
mapping is just telling us how to
construct the thing the robot in the
simulation we haven't even simulate we
haven't even sent this thing to the
physics engine yet we just talked about
creating urdf files the physics engine
needs to it the the physics engine needs
a blueprint it needs information about
what to build it's a little confusing
this blueprint is building this thing
which in turn becomes a blueprint that's
interpreted by the physics engine right
we're going to take this thing in a
moment we haven't got there yet and put
it or Sims is going to put it in his own
physics engine ah I forgot to that
reminds me of a detail I forgot to
mention Sims wrote this physics engine
himself from
scratch you'll notice that there's some
Ray tracing
Shadows are these necessary for
simulator an incredibly talented person
these are one of these human beings that
was sort of ahead of their time a lot of
a lot of details in here that we don't
necessarily need this was the first
physics engine ever made built by
hand I don't know about you but I would
love to see the code of this physics
engine good luck I've asked Carl a few
times he's pretty tight liit about it if
anyone manages to convince Carl to uh
show us the code I would love to hear
from you
okay sorry bit of a discursion there
other questions comments before we push
on okay let's talk uh let's talk a
little bit about the rest of these
labels the rest of them are kind of
optional they're kind of bells and
whistles the most important ones are
what do we build how do we create the
joint and how do we alter what we build
as we travel along these edges as long
as you get that part you're good okay
all right let's talk about these
additional labels which again are
sitting on each and every node we know
which two links to attach together
that's built into this GTP map but how
exactly do we build that joint there's
an additional uh integer here which
tells us which kind of joint to build we
could connect this link to this link
with a hinge if the genotype tells us to
do that rotational joints that you are
all now very familiar with the genotype
might instead tell us to connect those
two links together with a ball in socket
joint some of you have tried to simulate
or approximate this now in your final
project what do you think joint limits
means different physics engines have
slightly different words for things
you're all experts on physics engines
now what does joint limits mean do you
think it's the C like offset from near
position absolutely right so for
building a hinge joint does it have wide
limits or narrow limits
the genotype is again dictating some
features now of the joint
itself okay let's talk about this one
recursive limit this one is kind of
interesting there is a number uh there's
an integer sitting inside every node
it's an integer that's interpreted as
the recursive limit let's go back and
have a look at this genotype when we
first start interpreting this genotype
we visit this node it tells us to build
this trunk we go out along both outgoing
edges simultaneously which means we come
back to this node a second then a third
time which causes us to build this and
this
node for each of those second and third
visits we go back out another two times
and another two times which causes us to
build this then this then this then this
this is the recursive part right if we
kept going we would build a tree of
infinite depth we'd have a tree made up
of infinite lengths which of course
would kill your physics engine so like
any recursive algorithm which is exactly
what we're looking at this GTP map is a
recursive algorithm we need to give it
some way to know how to stop every time
we visit this node whatever this
recursive limit integer is when we leave
that node we decrease that integer in
the node by
one if we ever arrive back at this node
and RL equals z we stop the traversal of
the
graph okay we've got this genotype which
is a graph we've got a whole bunch of
numbers labeling each node and we got a
whole bunch of no numbers labeling each
Edge we haven't talked about simulation
yet we haven't talked about the brain of
this robot yet and we haven't talked
about the evolution of these robots yet
once Evolution starts running once we
start evolving populations of these
genotypes what do you think happens to
these numbers inside these
graphs what is evolution going to do to
these
genotypes tweak them tweak them them
being
what all the different parameters a
mutation can hit any label on any Edge
or any
node in addition there are two
additional mutational operators there
are two additional ways that the
evolutionary algorithm can mutate these
genotypes mutations can fiddle with all
of these numbers and it can also and it
can also what do you think those two
additional mutation operators
are abs absolutely not add a body part a
body part is part of the phenotype
mutations don't act on phenotypes they
act on genotypes a mutation can add or
remove an edge or add or remove a node
which often has the result of adding
removing Andor modifying one or more
body parts that's the phenotypic impact
of a mutation to the
genotype yeah what happens if a mutation
let's take this genotype right here
imagine this genotype survives and
produces an identical copy of itself a
child graph and o one and only one
mutation event occurs which is a
mutation hits the recursive limit inside
this single node and it increases the
value of this recursive limit Let's test
our intuition or let's test our
understanding of this GDP map what's
between the child phenotype and this
parent phenotype you're going to get
another branches add
to branch of absolutely in the child the
recursive limit is higher which means
when we translate the child's genotype
into its phenotype we're going to
Traverse through this uh graph
recursively one more time or One More
Level which is going to to sprinkle as
you mentioned a series of uh pairs of
Twigs on the end of this tree we're
going to get a slightly more arborized
child compared to the parent if the
mutation instead had randomly decrease
this recursive limit the child would
have less branches than the parent yeah
one way of building up your
understanding of how this this
particular GDP Map works or any GDP map
is to try and visualize what happens if
the genotype changes what kinds of
effects of phenotype Could
Happen okay let's play this game one
more time let's take this parent
genotype it produces an identical child
uh graph and now there's a mutation to
uh the change in scale on one of the
edges let's imagine a mutation hits this
Edge and it hits one of these three
numbers it Alters the delta in
scale how does the child look different
from the parent this one's a little
trickier what's going to be different so
it depends on what direction it changes
okay but it's children branches on it's
just on one Edge this Edge it's the
mutation hit this Edge right so let's
say the Delta it it makes the delta is
going to make it that the branch is
proportionally larger okay you're going
to end up with one side of the tree
that's going to be heavier looking than
the other because each branch is
only different is different by a
different amount that makes you got all
of it right except one little piece
you're absolutely right let's assume
that the mutation increased the Delta of
the scale it's telling this new Branch
to be a little bit bigger relative to
the parent to to this link than it was
in the parent you mentioned the left
side of the tree it wouldn't be the left
side it would be each branch the left
one would be bigger among every pair of
branches among this pair the size of
this link relative to this link is going
to be different in the child than in the
parent and this branch is going to also
be different in size compared to this
one this one is left
unchanged so a mutation has changed one
number in the genot y but that has
affected more than one number or more
than one part of the phenotype this is a
complicated genotype to phenotype
mapping same goes for you if you have an
offspring and there's a mutation that
hits one nucleotide in your genetic
instructions there's just one change in
your set of genetic instructions
compared to your offspring that is
unlikely to affect just one and only one
part of your Offspring GP maps in nature
and here don't work that
way
question the way
theive would there be a way
to it's GNA sound weird would there be a
way to have a variable number of
recursive edges at each time the not is
visit so like could you have it that
there's
the option of either three branches or
two branches great question so imagine a
phenotype in which the left side of the
tree only has a depth of
three but on the right side of the tree
there's a depth of four for example
that's a particular phenotype what would
be a genotype that encodes that is there
a genotype that encodes that it's a
great it's actually a very good
question hard for this setup to do it
not impossible but it can be done we
could also make a change to the genotype
to phenotype mapping I've explained to
you how Carl came up with this GDP map
but we could make an alteration to this
GDP map to make what you just said
easier for evolution to do how how might
we do it would it be instead of having
it loop back have two more noes like
those back each other we could we could
start to build more nodes and more edges
to approximate this depth three depth
four tree it'll work but it's a little
bit inelegant we're adding a lot of
stuff to the genotype can we make a just
a slight change to how this whole thing
whole works that this would still
produce a depth three depth four
tree ones Bingo move this label this
integer from the nodes to the edges if
we have an RL label of three sitting
here actually no that's still not going
to work that means the left pair of
branches is always going to be shorter
than this one but I think you're on the
right the right track that's that's the
way we think about GTP Maps exactly
right we made a change to the overall
GDP map we moved this label from a node
to an edge and that alters the kinds of
phenotypes we tend to get with these
genotypes I think it might be fun to
have edes that have a probability of
being ah
okay absolutely right we could we could
make this a probabilistic recursive g2p
map all of these numbers represent
probabilities of things happening more
often or less often than others
great lots of ways we could do that what
would you tend to see in the phenotypes
do you think if you had some
probabilities Incorporated in the
genotype or would happen happen to the
phenotypes in general see more variation
in their designs absolutely right so in
this tree every single branch has
exactly the same depth right uniform if
it was probabilistic that would no
longer be true that might make it easier
for evolution to evolve robots that do
whatever we want them to do or maybe
harder for evolution to evolve robots to
do whatever we want them to do another
issue we haven't touched yet about GDP
Maps is do they make it easier on
Evolution or harder on Evolution to
produce whatever we want Evolution to
produce another open problem in the
field nobody knows you come up with yet
a different g2p map is it going to make
things easier or harder no one
knows other
questions okay let's keep
going somebody mentioned the reflection
uh uh the reflection label down here it
doesn't say it here this is a binary
label it's either zero or
one as we're going through here and
we're executing these Deltas the way
that we build things the reflection can
sort of flip things around as we
continue
building I think that Carl threw it in
although he didn't say explicitly in the
paper I think he threw it in to make it
more likely for phenotypes to have
symmetry hard to say it's not too
important for our purposes what about
this last one
terminal only flag it's called a flag so
for computer scientists that's a that's
a strong signal that this label is a
binary
number what does it do what does it do
and why did Carl throw it in do you
think it's a label that's sitting on
edges every Edge has one of these to
Flags that's either zero or one sitting
on that
edge I can
think the not joint it lets it lets not
the node it's the the thing that's
constructing the phenotype our program
our program instruction coun or whatever
that's sitting on a particular node or
Edge it's telling it go along this Edge
or don't go along this outgoing Edge it'
be really useful to have like a a claw
tip at the end of your arm you could say
oh leg leg leg and when you run out put
a absolutely terminal only flag here so
if the terminal only flag is set to one
that's the edge saying stay away from me
do not travel along me build whatever
you need to build and when you're
sitting in a node and you're cons
considering traversing along me you're
only allowed to Traverse along me when
nodes uh when the nodes recursive limit
is zero once you've reached the
recursive limit of building something
now now you're allowed to follow the
edge and build whatever you arrive at on
the other side of the edge Carl probably
threw it in thinking that for some of
these creatures it would be good to have
a unique structure at the end of some of
these appendages a claw a head a foot a
hand who
knows okay all good okay all right let's
again test our understanding of this GDP
map I've left on the right hand side of
the slide for you all the
labels and uh all the node labels and
all the edge labels I want you to take a
minute you can do this yourself or turn
to a neighbor and talk it over pick one
of these robots and think about can you
write down a genotype maybe just the
nodes and edges that's likely to produce
phenotype I'll give you two minutes to
think on that see if you can write down
some of the genotypes for some of these
P phenotypes and then we'll see what you
came up with
pen and paper might be useful
here some are easier than others
okay let's start with the 10,000 ft view
here which of these 12 phenotypes do you
think has the simplest
genotype simple meaning the fewest
number of nodes and
edges eight why
eight it's like the snake it's linear
back on you only need one Edge and
one possibly that you could get away
with one node one Edge for eight maybe
although I see a little bit of structure
in this robot that says maybe
not what's that 10 is the easiest 10 is
the easiest okay I here vote for 10
Emily
seven eight if you look if you squint
you can sort of see there's one two
three and then one two three and then
one two there's a little looks like
there's a couple of kinks in here hard
to say my vote is with seven
as well we have one node we imagine that
there's one node that tells us how to
make the
head and one outgoing Edge and I'm not
going to write down all the labels for
this one but one that says to change the
leg the decrease the length decrease the
height and decrease the width by a
little bit build something a little bit
smaller then a little smaller and a
little smaller and a little smaller I
would bet that you could probably
construct by hand a genotype and fill in
all the node the node labels and the
edge labels here that would produce
something that looks quite a bit like
this anyone tackle any other
robots what might be a genotype for
number
six how many nodes and
edges uh for six I thought you know I
like starting in the bottom center Cube
that would be one node and that loops on
itself like to make the three Center
ones and then it has I'll call this
segment yeah and then there's another
node that does little wings and from
each Center segment there's two edges
that could go to
that we'll make a node called Wing node
I think you're right this something like
this would probably build something that
looks like this
everybody with with me so far okay okay
so let's go back for a moment and talk
about the actual name for these
genotypes now we're ready to unpack this
term we now know why it's why why these
genotypes are graphs they're made up of
nodes and edges it's a directed graph
meaning that all of the edges have an
arrow associated with them they have a
direction we know when we're at a node
we know which of the edges are outgoing
edges and for that node we also know
which are the incoming edges so we've
got a directed graph on our hands if
you've ever taken a complex systems
course or a math course youve probably
come across directed graphs before
what's a
multi-graph you can have multiple edges
between the same pair of nodes we now
see why it kind of makes sense to have a
multigraph and makes sense when you're
going to create different versions of
things to Not Duplicate the genetic
information it's in there but the Deltas
alter how you build those things does
this mean that mod like you can just do
one absolutely this GTP map has been
around for a very long time many people
have used it used versions of it because
among other things it's modular a
mutation to any label of any no or any
Edge may impact just one part of the
body maybe just the head and leaves
everything else
alone or
alternatively a mutation to a node might
or to a label might affect many or all
parts Evolution can decide how modular
or or how non-modular to make these
genotypes we actually dedicated an
entire lecture to an evolutionary
algorithm that was designed to be able
to increase or decrease the modularity
of the phenotype same same thing here
but in a very different way yep good
observation okay we've unpacked two of
the adjectives here directed and
multi what about
nested have deliberately hidden this
last one from
you these genotypes as you're going to
see in a moment are also nested what do
you think that means first of all just
in general they make different graphs
inside each other inside every node of
these graphs there is another graph
inside this node is a series of nodes
and edges which we haven't seen yet what
do you think those embedded or nested
nodes in edges do they're in the
genotype what haven't we discussed
yet absolutely
okay here's a genotype on the left which
looks more or less like exactly this and
you'll notice this is a nested graph
there are nodes and edges inside
individual
nodes each each nested node so we're
going to talk about nested nodes and
then just
nodes each nested node dictates how to
construct part of the neural controller
for this robot all we've seen so far is
how the genotype genetically encodes the
body now we're seeing how the genotype
also encodes the brain along with the
body if you thought this GDP map wasn't
complicated enough here we go okay so
each nested node dictates some part of
the body and each nested
Edge these uh these thin arrows in this
picture denote how to build some other
part of the body we've got nested nodes
and nested edges how do you think these
two things
collectively uh dictate how to construct
the neural controller of the robot
strong hint nested nodes nested edges
telling you how to build the
brain which does
which we've drawn and seen many neural
network controllers in this class and
they tend to be drawn
as as graphs as nodes and edges each
nested node has information inside it
also has labels that tell the GDP map
how to build a
neuron and every Edge nested Edge tells
the GDP map how to build a
synapse okay you'll notice things like
uh wave absolute Sawtooth
wave we're we're visualizing here some
of the labels of the nested nodes these
names are meant to be strong hints again
about which feature of neurons these
nested nodes are
encoding
sorry not Behavior we're just talking
about neurons yeah wave absolutely a
waveform but not about the behavior
activation function the activation
functions each nested node here has many
labels associated with it and their
details we're not going to get into one
of those features is what is the
activation function inside the neuron
that's
constructed so far so good okay nested
edges that specify how to build a
synapse these nested edges have one and
only one label attached to them what is
it do you
think a nested Edge tells the GDP map
how to construct a synapse inside the
robot and there's one number associated
with that nested Edge what is that
numbered
encoding syn weight the synaptic weight
in this class the only feature we've
talked about for synapses is their
weights yeah that's
it I don't remember uh oh it's so s uh
Sim came up with a very large number of
activation functions oh ITP is
interpolate not a very common activation
function what's he doing here he threw
in every activation function he could
possibly think of and just sort of is
telling Evolution here you go if any of
these are useful when constructing the
brains of these robots knock yourself
out okay we've got two minutes left so
let's get over the last intellectual
hump of understanding this GTP
map uh sorry two more I want to talk
about so we see um there are some of the
labels inside these nodes are j0 and J1
these are this is a little confusing
these are joint sensor
neurons some of these embedded uh some
of these embedded nodes are telling the
GDP map how to build hidden nodes hid
sorry hidden
neurons some of these nodes like these
two are telling the GDP map how to build
sensor neurons these are sensor neurons
that as the name implies are attached to
the joints and these joint sensor
neurons uh detect and Report out the
angle of the joint these are
proprioceptive sensors we've seen these
called angle sensors we've seen these
called propri acceptive sensors for Sims
these were called Joint
sensors there are also two motor neurons
here these motor neurons are sending out
motor commands to the two
ectors again another synonym for
Motors in
robotics this node down here this is the
wing node this node is visited four
times 1 2 3 four
times when we're traversing this
genotype which means we visit this node
four
times what can you tell me about the
neural tissue or the bits of neural
network controller in these four wings
if we were to crack open any one of
these Wings what would we find
inside do you think
would we find no neural material some
neural material what would it look like
what would we see
inside like the right half of that diam
have inps for the joint position outputs
for the motor position and those would
be duplicated for each of the Wings
they'd be duplicated inside each of
these four wings you'd find this four
neuron neural
circuit this is a peripheral nervous
system bits of the brain that are in
different parts of the body we have
neurons and synapses in our arms and
legs and in our spine that's your taken
all together that's your peripheral
nervous system and then we got a whole
bunch of neurons and synapses
centralized in one part of our body
that's the central nervous system we'll
end here today these robots can also
have pns and CNS which we'll talk about
next time you have a quiz due tonight
you're working on your final project see
you Thursday


--- Evolutionary Robotics course. Lecture 26： Soft robots..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay I'm glad you're all able to find a
seat this
morning let's dive in uh I don't have
anything to report in terms of the final
project any
questions so far so
good yes
um how
like well how many like Generations do
you recommend like
runal good question so how much how many
generations what population size how
much evolutionary effort to put into
proving a is better than b b is better
than a or there's no difference it
depends on what your A and B is what I
suggest you do uh is run for a few
generations of your variant a and a few
generations of your variant B and see if
there's a difference if there isn't keep
going so what does it mean to stop and
keep going
uh there's an idea in software
engineering about checkpointing so that
you're able to write out every synaptic
weight of every individual in the
population to a file and then read it
back in so you can alter your code so
that it starts up in one of two modes if
it starts up in mode mode one it starts
with an initial random population of
solutions mode two it reads in all of
the individuals from a file and
continues on from there make
sense okay um if you're going to do
checkpointing a very uh useful a useful
python library is the
pickle Library you can tell pickle to
save a data structure to a file if you
give it a dictionary it will write out
everything in that dictionary to a file
and you don't have to worry about how
it's doing it and then alternatively you
can read back in a pickled file So
reading pickling makes reading and
writing an entire population to dis very
easy yeah better to do that then to run
variant a for 100 generations and then
you run out a time and then you run
variant B for three generations and it's
hard to tell whether a is better than b
b better than a or there's no
difference other questions or comments
cam for uh for the differentiable
assignments has anyone figured out a
better way to do Collision detection and
resolution yes I've seen in many of the
F in the weekly reports people are
playing around with different Collision
detection and resolution Solutions I
would ask your question in the
subreddit and for those listening at
home if you have a better way to do
Collision detection and resolution in
diff Lots posted to the subreddit and we
can share notes is there something in
particular you're looking for in the
Collision detection
resolution no Mass point to ground or
mass point to mass Point yeah Mass point
to ground Mass point to ground okay
okay
okay other questions or
comments okay so um next Monday you're
going to be submitting your fourth and
final weekly report and then you got a
whole week to work on the oral and
written reports for your final
project next Tuesday on next Tuesday in
class I will talk about what that oral
report and written report should look
like uh and what exactly we're going to
be doing during the final project during
the final exam
period all good okay so uh back to our
final theme of the course where we're
starting to look at evolutionary
algorithms now in which we're widening
The evolutionary algorithm so that
whatever is in the genotype the
blueprint of the robot there are
parameters that specify aspects of the
brain and the body so we're looking at
evolutionary algorithms that evolve body
and brains simultaneously which of
course is what actually happens in
nature but as we saw last time it's
complicated it's not so easy to create
an evolutionary algorithm that is able
to simultaneously make evolutionary
improvements to the physical structure
and the neural controller of the robot
and we're going to dive back into
lecture two in a moment which is
arguably the most complicated
evolutionary algorithm we've seen in
this class Carl Sims came up with a
relatively complicated genotype a data
structure for encoding body and brain a
not that difficult phenotype we've seen
that before rigid robots made of links
and
Joints but a pretty complicated genotype
a phenotype map we've got a relatively
complicated algorithm that TR that's
Translating that genetic blueprint into
the phenotype the robot and we almost
made it all the way through the GP map
last time we'll finish that off today
okay that should take us for uh that
should take us through the next half
hour or so and then we'll dive into
lecture 23 where we're going to again
look at another evolutionary algorithm
that also evolves bodies and brains but
this time for soft robots
rather than rigid robots Okay so back to
Carl Sims uh this is uh an experiment
which in many ways was ahead of its time
back in
1994 many generations of grad students
have tried to reimplement uh Carl Sims
to more or less varying success myself
included not not an easy thing to do
okay okay so just to refresh your memory
we're looking at genotypes which are
encoded as nested directed
multigraphs and the phenotypes pretty
familiar things we've seen before uh
links connected by joints okay we saw
last time that as we read out a genotype
every time we visit a node in the
genotype we create a link and when we
travel along an edge to another node
When we arrive at that new node we
create a new link but that new link is
going to have a different
XYZ a different length width and height
and a different role pitch and Y A
different orientation relative to the
link that we just created previously and
those Deltas in those nine numbers XY Z
LW and RP and Y are encoded in labels on
the edges everybody kind of remember how
this goes okay we ended last time by
looking at the by looking at the nested
part of the genotype inside every node
in the genotype is another collection of
nodes and edges these nested nodes and
nested edges specify how to build the
brain inside the body of the robot in
the example we were looking at last time
we have this particular node here uh
which has a self connection this outer
node here tells us how to build this
piece and this
piece this node out here tells us how to
build this fin this fin this Fin and
this fin how did I know that this node
builds these two pieces and this node
builds these four
pieces it doesn't explicitly say but
there's some strong hints in the
genotype just the structure of the graph
one recurs into itself and actually
branches
and the others are just terminal
absolutely so this has a self connection
this piece looks quite a lot like this
piece so however we build this piece
there's some Deltas that cause us to
build this piece and then we've got two
outgoing edges every time we build this
node we build two
copies of this node I see two copies of
two things branching off from this thing
that's the hint in the genotype that it
builds the the phenotype not strictly
necessary but just helping us to build
an intuition for how this GP Map works
okay so these nested nodes every single
one of them correspond to a neuron so
whenever we build one of these four fins
we're going to visit this outer node
four times every time we're going to
also drop one two three four five six
neurons inside this fin so we've got six
12 18 24 neurons so
far some of these neurons are hidden
neurons and the little symbol inside the
neuron specifies what activation
function to put inside that
neuron the J's here correspond to sensor
neurons these are sensor neurons that
are going to sit on the two joints j0
and J1 inside the fin why two joints and
every in most of what we've seen so far
in this course we've got a link like
this link and then another link like
this link and we connect them together
with one and only one
joint these neurons are specifying that
their sensor neurons sitting on two
separate joints
inside this link what do you think that
means nonfunctional
maybe maybe one of them is nonfunctional
other ideas it's not specified here but
we can try and
guess might be two degrees ofed rotate
andap up and down absolutely right so
you look at a fish wi uh fish uh fin a
lot of them that are active do something
like this if you have our shoulder joint
is three degrees of freedom one two and
three you can get away with with
something that also has two degrees of
freedom that's what this is meaning in
here so whenever they create a fin and
attach it back to this main body they're
attaching it with two rotational joints
one that does this and one that does
this okay there are also two motor
neurons which in this paper are called
eector neurons uh unfortunately
terminology in robotics isn't
systematized so some people talk about
Motors some people talk about actu
some people talk about affectors they
all mean the same things it's the thing
that applies Force to the
joints so we've got six neurons in here
and at every time step that we simulate
this virtual creature we're going to
take the two values arriving at these
two neurons and treat those values as
desired angles Supply them to the joint
and the fin is going to start to swim
relative or move relative to the main
body so far so good okay there are also
three hidden neurons that are placed
inside the main body so we had 6 12 18
24 plus another three in here 25 26 27
and again when we build this point this
part we're going to drop another copy of
these three neurons in here 28 29 30 so
so far this genotype has dropped 30
neurons throughout the body of this
robot this becomes the peripheral
nervous system for the robot you also
have neurons and synapses distributed
throughout your body including in your
periphery your fingers and toes all the
way throughout your body this robot also
has a central nervous
system where is that specified in this
genotype
it's the piece that's left inside the
genotype there is it one special node
it's the one that's shown as a dashed
line here this is just the central brain
of the robot so after the body is built
like we see here and after we as we've
been building the body we've also been
dropping neurons and synapses to build
the peripheral nervous system and just
before we're done finish the finishing
building the phenotype we've almost
finished this mapping operation very
last thing we do is we look inside this
one special node inside the genotype
graph and we make one and only one copy
of everything we find inside this
special node so in this case these three
hidden neurons here they don't really
have a location inside the body doesn't
really matter
what else can you tell me about the
peripheral and central nervous system in
this robot how is the peripheral and
central nervous system wired up they're
not
disconnected values are flowing through
this neural network throughout the brain
of this robot some of the signals coming
in to the joints are flowing into the
peripheral nervous system and into the
central nervous system and then back out
again
where
how these neur
are NE
not yeah not not all of the it seems
like all of the nodes except like these
j z and J1 noes have like an input Edge
that's directly NE good good observation
so these two sensor neurons have no
incoming edges which makes sense the
values that are incoming to the sensor
neurons are values that are incoming
from the sensors the angle of joint zero
in that fin so here's a good place to
start We Are simulating One Time step of
simulating this virtual creature at that
time step we take the two angles of the
two joints in this particular fin which
gives us two floating Point numbers drop
them into j0 and J1 and now those two
floating Point numbers are going to
start to spread through the peripheral
nervous system of the robot let's follow
some of these Trails let's take uh J1
here we can see there's an outgoing Edge
or synapse that goes from J1 to
e0 you'll notice that this particular
arrow is inside this
node so the value arriving at J1 is
influencing the value of e0 the value of
this motor neuron inside this fin the
value has not that this flowing of
information from sensors to Motors has
not left this particular link this is
still all part of the peripheral nervous
system if you touch a hot stove you will
suddenly notice that your hand has
removed itself from the hot stove before
you've even realized that you've done it
for a very good reason there there are
in you synapses that connect uh senses
in your fingertips to muscles in your
arm for exactly that reason there are
certain situations in which you want to
be able to move your arm in response to
what you feel in your hand faster than a
electrical signal can tra can flow from
fingertip up through your spinal cord to
your brain and back down again that
takes on average a little less than
two10 of a second for many things like
putting your hand on a hot stove it's
too slow yeah so in this particular case
this robot is capable of reflexive
action things that are happening in in
the joint in that body part influence
how that body part moves flowing of
information through the peripheral
nervous system let's go back to J1 for
for a moment if you squint you'll notice
there is
also an outgoing synapse that flows into
here what's Happening Here
we have a motor oh sorry we have a
sensor signal that is Flowing along a
[Music]
synapse there like the same sensor
signal is heading towards the like inner
neural system of the robot as well as
the
reflexive absolutely it's flowing out
and into the central nervous system into
the brain of the robot and if we're now
at ITP ITP is short for some kind of
activation function so this neuron in
the in the central brain is also
receiving signals from other parts of
the body and then sending an outgoing
signal back down into a hidden neuron
inside the fin of this virtual
creature but remember that there are
four fins we've created
this little local neural circuit this
part of the peripheral nervous system
we've created four identical copies in
these four different
fins so what's actually happening in the
phenotype of this robot is values are
arriving at the sensors in all four fins
and in each one of these fins there's a
copy of J1 and for each of these four
j1s there are four synapses flowing into
one and only one ITP neuron in the brain
of the
robot that ITP neuron has four identical
outgoing synapses that connect to the
plus the four plus hidden neurons one in
each of the four
fins everybody see
that okay we're spending quite a t a lot
of time on this this is the most
ambitious most complicated GP map we've
seen so far
okay okay any questions about that
before we push
on okay uh I don't think we need to go
into a detailed explanation of all the
different activation functions okay here
is a roll out of the brain here is what
we just talked about but now we're
looking at the phenotype and not the
genotype you can see that there is one
one one 2 3 four copies of j0 four
copies of J1 and so on I'm going to skip
back and forth here here's the central
brain saw wave and ITP and we see at the
top one copy of Saw wave and
ITP and that's
it yeah here's the full brain for this
creature there's its body there's its
full Central and peripheral nervous
systems
okay done finished talking about the GDP
map all
good okay all right so couple other
things in this experiment let's talk
about the evolutionary algorithm for a
moment we have a population of graphs
remember that the genotypes are encoding
graphs any one genotype in the
population may have more or fewer nodes
more or different uh edges and so on it
occurred to Carl as he was coding up
this experiment if we have two surviving
genotypes into the next population and
they're going to produce Offspring how
do you do it how do you take two graphs
that have different structure and
combine them in a way that produces a
new graph that produces a child that
hopefully inherits good aspects of the
behaviors of both parents where have we
heard this
before we've got two surviving parents
we want to try and cut their genotypes
in half and glue the two halves together
and hope that we get a child that is as
good if not better than both parents
where have we heard this
before neat absolutely neat was invented
several years after this paper so this
is uh this is an investigator a very
talented investigator struggling with
how do we incorporate some of these
things from Evolution that we know are
useful sex uh was invented by mother
nature for a very good reason there's an
evolutionary Advantage for any
population that can figure out how to
combine genetic material from from
parents that live long enough and
therefore are fit that live long enough
to produce Offspring here's a couple
ideas that Carl came up with take the
genotype for parent one take the
genotype for parent two you can already
see that the nodes in both parents the
number of nodes is different and the way
in which they're wired up is different
Carl just took them all and strung them
out in a one-dimensional line so it
starts to look like a vector and then
simply walk from left to right and at
every step in the walk from left to
right flip a coin Heads Stay with the
same parent stay where you are and just
copy genetic information so we start
here we copy this node into the child we
copy this Edge into the child we get
here we flip a coin Tails Tails tells us
to move to the parent and the other
parent and start copying genetic
material from that other parent into the
child heads Heads Tails switch to the
other parent move to the other parent
and copy that genetic material from
parent one
and then we fall off the right hand edge
of parent one and we're done very very
simple to implement does this guarantee
that the increase the probability that
the child is going to inherit the right
genetic material from both parents
probably not right probably not okay so
let's try and do something a little
smarter let's come up with a
different recombination operator let's
add this to our evolutionary algorithm
The evolutionary algorithm can now uh
randomly choose to graft genetic
material from one parent into another
how does that work same thing take two
surviving parents at random string them
out in a one-dimensional line and like
uh in standard crossover start at the
leftand edge of parent one and start
walking from the left to the right and
as you do copy all the nodes and edges
you uh encounter from parent one into CH
into the child keep flipping a coin
heads heads Heads you stay with parent
one
Tails whatever node you're currently
sitting on follow an outgoing uh follow
an outgoing edge here so we're going to
jump from parent one to parent two and
keep copying all the rest of the
material from parent to very similar to
crossover but we're sort of grafting
some material from one parent onto the
genetic material from another we're not
jumping back and forth from parent one
to parent two we stay with one and when
we leave parent one and arrive at parent
two we stay there and we copy the
remainder of the genetic material from
parent 2 does that increase the
probability that the child is going to
inherit the Best of Both Worlds from
both
parents I don't know my experience with
crossover operators probably
not okay all right so we've talked about
the genotype the phenotype we've talked
about the genotype the phenotype map
we've talked about the evolutionary
algorithm we're going to evolve
populations of graphs as usual we're
also going to have mutation operators
sometimes we grab a single parent we
copy all the nodes and edges but then we
randomly modify some part of the graph
we add delete or modify an edge we add
delete or mod mod ify a node we modify a
parameter inside one of the nodes or we
modify one of the parameters associated
with one of the edges mutation mutation
mutation every once in a while we do
crossover remaining thing is the fitness
function okay last time we saw a video
of several experiments that Carl ran
with his evolutionary algorithm we saw
some very familiar things like
Locomotion you can probably guess what
the fitness function for that one was
it's exactly the one you're probably
using right maximize the X component of
the robot along the ground or maximize
the Y component of the robot along the
ground we also saw some videos of robots
evolved for
jumping maximize the Z component away
from the ground and then we finished by
watching robots competing over a common
resource this one's a little trickier
because to EV evaluate the fitness of
two robots we're going to pit them
against one
another ver it might have been hard to
hear the audio but the narrator was kind
of explaining in plain English what the
fitness function was in this
experiment what was
it it was
the the like ending location of the cube
and like how close it was to the body of
the robot trying to grab it absolutely
so how close was the cube to one of the
robots the closer the cube from the
point of view of this robot the closer
the cube is the higher my fitness is but
remember it takes two to tango here what
about the other
robot what's its
Fitness I've managed to capture the
block and pull it towards myself
I'm minimizing the distance between the
block and myself my fitness value is
going up what's happening to the other
robot it's going down yeah so this is
the first time we've looked at a
co-evolutionary system in which we have
two
populations one population of graphs
another population of graphs and every
time we run a simulation we take one
robot from the first population and one
robot from the second population put
them in this Arena together and let them
literally fight it out and then at the
end of the simulation we assign one
floating Point number to robot one which
is its Fitness and we assign a different
floating Point number to the second
robot and put it back in its
population yeah okay so we can try and
write this down mathematically uh
there's different ways you could do this
this is sort of the simplest thing I can
imagine let's imagine we have robot one
over here and robot two over here I want
to compute the fitness of robot one the
fitness of robot
one is going to be set to D let's start
with this term D2 minus D1 what's the
intuition behind D2 minus D1
the greater the magnitude of D2 minus
D1 the higher the the fitness for robot
One D is going to stand for distance so
when we're talking about distances a
distance is always a positive number so
D1 D2 D1 and D2 are always going to be
positive numbers maximize the distance
of the opponent minimize distance
exactly right so in order for F1 to be
high you want D2 to be high and D1 to be
uh as low as possible right so I want to
minimize my distance I'm robot one from
the cube I want to bring it towards
myself and I want to maximize your
distance if you are a robot 2 away from
block the denominator here is at
normalizing term so we can kind of
ignore that for the
moment good question it's not specified
in the
paper it's not specified in the paper if
you go back and watch the video you'll
notice some of the highly fit robots
will just put their hand on top of the
block and not really seem to do anything
else which I interpret as a strong hint
that it's not the center of mass it's
it's probably minimizing the distance
between any one of my body parts and the
block but who knows maybe it doesn't
matter yeah so when you when you obtain
a position from PI bullet it gives you
back the XYZ of the center of the object
good point this can this can matter
depending on what your final project
is if you for whatever reason in your
final project or whatever is that you're
doing you want to actually get the
position of some you know the corner of
this Cube for example just create a
second small link put it there attach it
with the joint and get the XYZ of that
link if it matters for your project okay
same simulation but now we're looking at
robot 2 we got to compute Fitness and of
course its Fitness is symmetric robot 2
wants to minimize its distance from the
cube and maximize robot one's distance
from the cube not that complicated a
fitness function but remember that we're
using a fitness function to compute
usually different values for both robots
in the population and my value is not
dependent just on what I do it depends
on what you do also that's what makes it
a
co-evolutionary
experiment okay uh all right so that's
the fitness function let's just talk
about the simulation for a moment pretty
straightforward we put a cube at the
origin we place uh robot one on the left
side of this dash line we put robot two
on the right side of this dash line and
then you'll notice it says creature one
starting zone and it's got this other
dashed Arrow here uh diagonally pointing
up and
away what do you think this is all about
seems like an odd
detail when we use the GTP map and we
make the body of the robot of robot one
for example we place robot one in this
starting zone but it has to be to the
left of this line and underneath this
diagonal
line why seems like a odd detail to
add the taller I am the heavier I
am pretty much any brain I could
possibly have as long as it tips me
forward I've got the block and if I'm
big and heavy enough I might also manage
to knock you out of the way bonus points
for me you can get you can be absolutely
confident that Sims probably ran this
experiment without this and got perverse
instantiation just a reminder that
perverse instantiation is everywhere for
most of the experiments we've seen in
this class it's hilarious but when
you're writing a control policy or
training a control policy for an
autonomous car not so hilarious this is
a a ubiquitous and unsolved problem in
robotics and
AI okay okay so if we're going to run
this
co-evolutionary experiment what that
means again is we're going to have two
separate evolving
populations how do we actually team up
how do we choose which two robots to put
into the arena together to accurately
assess how good actually in general is
creature 2 at capturing the cube and
keeping any other aders Neary any other
possible creature one Away From the
Block we want to evolve a robot that's
good at capturing the
Block in general not just against that
particular other robot how do we do
it let's start uh Sims actually tried 1
two 3 four five six seven different ways
of competing robots against one another
let's start with panel a here this is
the easiest thing the easiest thing is
actually don't even bother creating two
different populations just create one
big population of random graphs of
random
genotypes take robot one and two put
them in the arena compute their Fitness
take them out put robot one back into
the arena and compete it against robot
three then simulate one in four one and
five one and six one and 7 one and one
100 then two and one two and three two
and four you do every pairwise
competition which means you're going to
actually put every robot in the in this
in the population back into the arena n
times if n is the size of your
population so instead of getting back a
single floating Point Fitness value for
each robot you're going to get back a
value of n Fitness values how well that
Rob robot did actually sorry n minus one
how well did that robot do against every
each of the other n minus one robots in
the population take all those n minus
one values take the average and that
floating point value is the fitness of
that robot it's how well it does against
all the other
adversaries do that for all the all the
robots in the population delete those
that have a low fit low Fitness and make
randomly modified copies of the
survivors simple clean
efficient and exhaustive what's the
problem with this why didn't Sims just
start stop with
that it's inefficient sorry I said it
was efficient it's not efficient why is
it inefficient you have
absolutely so I don't know how long it
takes you to run one generation on your
laptop if you have a population of 10
you got to simulate 10 robots if you
have a population of 10 in this
situation how many simulations do you
have to
run 0 90 right exactly so it's uh it's
exhaustive in that you get a really good
not an estimate you get an actual value
of how well each robot does against
every other robot takes a lot of
computational effort so can we do
better how about B same thing we just
have one population for the moment but
now we're going to randomly choose one
robot and randomly choose one of the
other n minus one robots compete them
against one another put them back pick
another two robots without replacement
meaning we're not going to choose the
original two that have already been in
the the arena so every robot in the
population is only going to enter the
arena
once how many simulations do we need to
run in this
case we have a population of 10
robots five right much more uh much more
efficient we're going to run this
evolutionary algorithm much faster
what's the problem
not enough information maybe not enough
information right so if robot 7 beats
robot
2 great robot 7 has a higher
Fitness is robot 7 good in general at
capturing the cube or is it only good
against robot 2 so we've passed March
March Madness already now but we can do
the bracket approach pick two robots at
random and compete them against one
another another and the winner of each
competition is sent back into the arena
against the winner of another
head-to-head
competition it's going to take a few
more than five simulations how many in
case if our population size is n how
many simulations do we need to run now
see some of you calculating in your
heads on average n minus n minus one
right so we've got to do n over two
simulations to start with and then n
divided by four and then n divided by 8
and then n divided by 16 two simulations
two SIM sorry we compete the two
semi-finalists against one another and
we're done n minus one okay all right
little more
inefficient a little bit more
advantageous compared to B
why because there's a focus on
like increasing the overall Fitness
rather than just like increasing the
Fitness in like thisse sort of
fashion yeah that's part of the
explanation
so think about the winners of this
tournament right the winners have to go
back into the arena several times so
we're getting a better and better
estimate of the actual General ability
of the winners what about the
losers you don't get very much
information it could be that
unbeknownst to us the second best robot
in the population by second best meaning
that it can actually take down every
other robot currently in the population
except one other robot it's the second
best robot and in the lottery it gets
teamed up with you can guess who the
best robot gets knocked out of the
tournament the second best robot gets
knocked out of the tournament in the
first round and once the tournament is
over that's second best robot is
possibly going to have a very low
Fitness value compared to the fitness
values of all the other n minus one
individuals in the population so what's
going to happen to that second best
robot as we move from generation I into
generation i+ one it's probably not
going to produce any Offspring so it's
efficient but we could be losing
potentially good genetic
material
okay the uh in D here Sims came up with
something else which he called all
versus best in the all versus best case
in generation zero where you have random
genomes you don't know anything about
the fitness of these n genomes you do
this you do all versus all so you get a
very good estimate of how good everybody
is in
general in the Next Generation you take
this individual which has the highest
Fitness in the population and compete it
against every one of the other n minus
robots pros and cons of this
approach it's efficient relatively
efficient we're only doing n minus one
simulations what's the intuition behind
the all versus best strategy
here you have to know which one's best
you have to know which one is best so
it's kind of a con right we need to
exhaustively evaluate the
best what's the advantage of this
compared to for example tournament
selection
here the disadvantage of the tournament
is that second best individual can get
knocked out of the population quite
quickly you giv everyone a chance to be
the best everyone gets a chance to
compete against the champion right we
know we know the fitness of the champion
pretty well we've estimated it pretty
well so if any of these do better
against the champion that's a pretty
strong signal that that other Contender
is also pretty good right in all four of
these cases at the end of the generation
we always end up with one floating point
value for each robot in the population
if for example in this generation this
Contender outcompetes the current
champion it becomes the champion at the
Next Generation but it is now going to
be paired up against every other
individual in the population it has to
this Contender who is now the new
Champion has to enter the arena n minus
one times in the Next Generation so
there's going to be more selection
pressure exerted on this new Champion to
vet to ensure that it really is that
good okay that's one way to do
things Sims also did three additional
experiments in which it was not just one
population but he created two
populations in E he took each individual
from one population and competed it
against all n over two individuals in
the other
population and then did that for each of
the N individuals so this is a
computationally
expensive uh exercise but also gives us
a pretty good estimate of the fitness of
every individual in the population so
pros and
cons f is the same as B here very
computationally efficient but we don't
have a good estimate of how good or how
poor in general each robot is so he
redid All versus best between the
species we've talked about a to AB
testing quite a bit in this class now
this is AB B CDE EFG
testing Sims tells us in the paper
although he didn't provide evidence to
support his claim that he got the most
interesting robots when he used G so all
of the robots competing against the cube
that you saw in the video those were
produced in this all versus best between
species co-evolutionary
algorithm yeah okay all right so we saw
the video which showed us some anecdotal
evidence of how well these robots did
here's a little bit of uh here's a
little bit of quantitative data you can
see we've got four panels here these
four panels correspond to four
independent evolutionary runs using G
we're going to co-evolve two populations
of robots for a number of generations
stop Rewind The evolutionary tape and do
it all over
again in each panel here the horizontal
axis shows us evolutionary time so from
zero to 100
generations and the vertical axis shows
us Fitness ranging from about 0 to two
so a fitness of two is I capture the
block and it's more or less touching my
body and the other individual is two or
three or four or five body lengths Away
From the Block it's about as good as you
can do in this
situation tell me about this first
evolutionary run what's happening
between the black population of robots
and the gray population of robots
they're alternating they're alternating
so during this evolutionary period the
black robots were a little bit better at
capturing the block compared to the gray
robots but then as some due to some
result of mutation and possibly
crossover some gray individuals started
to evolve that could outwit the
strategies of the black robots and those
new gray strategies started to spread
throughout the gray population and now
on average the gray robots were out
competing the black robots there was a
little bit of a tussle here and then the
gray robots were in the ascendency again
when you have co-evolving populations
you tend to get these Cycles all the
time I want you to think for a moment
about a predator species and a prey
species let's assume that the Predators
for whatever reason happen to be quite
good at capturing prey what's going to
happen to the population of prey if the
Predators are very
good they're going to start to die off
which means what's going to start
happening to the
Predators they'll start growing
like increased rate as long as like the
population of is able to sustain them
possibly it's not the population of pray
is dropping so what happens to the
Predators they start to drop less
Predators less Predators they're not
doing so well they're having a hard time
bringing down prey because they's simply
just less prey less Predators means
there's a little bit of less
evolutionary pressure on the prey
there's not that many predators around
at this moment in evolutionary time so
pray that start to produce Offspring in
which those
Offspring avoid the predators in
different
ways May survive it's a little bit of
it's a little bit of risk because the
prey from an evolutionary perspective
was trying different strategies but okay
because there's fewer Predators around
it's a safer time in which to
evolutionarily innovate and maybe some
of those prey will hit on a strategy
that works pretty well they start
evading the Predators they start
producing more offspring more prey what
happens to the
Predators they start to go up you tend
to see fluctuating or oscillating
numbers of predators and prey in most
co-evolutionary systems either out there
in nature or in our virtual world here
you get this oscillation of back and
forth you see that a little bit here
what's happened in the third
evolutionary
run what happened here
bad news for the gray population what's
going
on this is something you tend not to see
in nature this is unnatural unnatural
how any
ideas they just
develop a way of what you
way better than the absolutely the gray
Grays are so sorry the the black robots
are so good at capturing the block and
keeping the gray robots away that if we
were to look across the gray population
they all have Fitness of zero they're
five or more body lengths Away From the
Block no matter what the gray
individuals seem to be doing from a
mutation point of view or an
evolutionary point of view they can't
get anywhere near the block so Evolution
comes to a halt in the gray population
nothing seems to be working this par a
gray parent that has a fitness of zero
maybe it produces two or three
offspring that all have a fitness of
zero Evolution can't make any progress
in the gray population this is unnatural
because of course if this happened in
reality the number of gray robots would
start to become less and less and less
and if the black robots actually are
dependent on the gray robots and there's
less and less of them like in the
Predator prey example we just gave black
is going to start to come down yeah so a
little unnatural and then again in this
fourth evolutionary trial we see a lot
of back and forth between the gray and
the black
population questions comments yes but if
there is always a back when it's a good
moment to St exactly so once we get into
a co-evolutionary system the very the
very idea of Fitness becomes problematic
what does it mean to stop what does it
mean for uh a black robot to have a high
Fitness value or a gray robot to have a
low Fitness value the fitness is still
defined it's mathematically defined like
this but what does it mean what does a
fitness of
1.2 actually mean
biologists tend to have a problem with
evolutionary algorithms and evolutionary
Rob robotics because they point to
Nature and say what's the fitness value
of all the organisms out there there
isn't some absolute metric way of
measuring
quality
yeah okay so to answer your question I
don't have an answer there is no good
answer hard to
say that being said coolu evolutionary
algorithms can be useful because they
tend to produce individuals if you do it
in the right way they can produce
individuals that are good irregardless
of their environment regardless of what
else is going on in their environment
because individuals in a co-evolutionary
population that survive for long enough
they've seen a lot of different things
they've been exposed to a lot of
situations so in The evolutionary
algorithms literature there are several
papers that show that a co-evolutionary
algorithm can actually produce at the
end an individual that is good in
general if you do it in the right way
but doing it in the right way can be a
little
tricky other
questions okay that concludes our
discussion of the first attempt to
evolve bodies and brains in rigid robots
we're going to look at a more recent set
of experiments that evolves bodies and
brains for soft robots before we look at
the evolutionary algorithm used to
evolve soft bodies and
brains why would you want to design soft
robots at
all let's start with the why before we
get into the what and the how what's so
great about soft
bodies they don't just like they aren't
just like directly impacted by like
every single
like every single like sort of small
force that could impact them can be like
absorbed and not just like completely
throw off the trajectory of like the
current like movement patterns or like
how they're like deciding to act in a
certain situation absolutely great point
from the perspective of the robot being
able to literally cushion a blow is a
good thing from the robot's perspective
it doesn't necessarily need to react to
everything that happens to it a soft
robot's soft body can absorb literally
absorb forces from
outside without affecting the behavior
of the robot that's good news for the
robot what about the
thing that is impacting the robot can
also be good news for the thing that's
impacting the
robot like
us yeah soft robots check generally are
a little bit safer for humans to be
around than a rigid robot that's made of
metal and sharp plastic and and all the
rest so from a very simple human robot
interaction point of view if we're going
to increasingly populate our world with
autonomous machines and we literally
bump into them it would be good if
they're
soft other advantages that are not so
obvious I it kind of allows for
essentially complex friction so they can
like pick stuff up without breaking it
absolutely there's a reason why your
fingertips are more soft than other
parts of your body it actually
facilitates Behavior having a being
built from soft material can be
helpful we have Endo we are we have
endoskeletons skeletons inside us we are
rigid on the inside and kind of soft on
the outside for very good reasons
smaller organisms like insects it's the
opposite rigid shell and soft insides
which makes sense for them at their size
scale other advantages of being soft
compared to being
rigid a
l op I think
their arms around all kind of different
absolutely so remember our discussion
when we talked about leg when we talked
about Locomotion the four deata one of
them is
robustness what is the range of
environments through which you can still
get from point A to point
B have a look at this organism it's
inside the let think about the inside of
the glass cube as point a and outside
the glass cube as point
B here's the hole in the glass cube
think about any possible organism you
could put inside this glass box if it
was us we wouldn't do so well one
advantage of being soft when it comes to
Locomotion or motion or displacement
which again is the building block of
most cognition soft-bodied organisms and
particularly this soft-bodied species
is the Undisputed champion of maximizing
the robustness a ACC axis of those four
deata have people seen this video
before no shortage of cool octopus
videos on YouTube this is my favorite
we wouldn't be watching this video If it
wasn't able to do this but even watching
the video it's hard to imagine that it's
going to pull this
off it's having trouble right at the end
anybody know
why not soft there's a part of it that's
not soft one part of the octopus is not
soft which
part the beak still got to eat and for
the octopus it's mostly mollusks if if
you're completely soft and you want to
eat a clam that's closed you need
something rigid one piece and you can
see how that one piece is actually a bit
of a literally a bottleneck in this
example right so there is evolutionary
pressure acting on this species to be
soft for the reason you just saw but
there is additional selection pressure
acting on the species to say you still
have to eat and your current diet is
mostly made up of mollusks here you can
see evolution trying to strike this
balance between soft and
rigid
okay from a robotics point of view this
could also be very useful why would we
want to have soft robots that can
navigate through very narrow
apertures we can't well we can't yeah so
why would we want a machine to do so go
places things that we go places that we
can't
coming all the way back to robotics
generally speaking we would like to
create robots to do the 4ds jobs that
are D D D or D anybody remember what the
4 DS
are
dangerous uh they're all good point
that's a fifth D they're all difficult
dangerous they're difficult because
they're dangerous difficult
no dirty
dirty dangerous dirty think about all
the jobs you really don't want to do you
don't want to do dangerous jobs don't
want to do dirty
jobs dull dull anybody have a summer job
like cleaning dishes at a
restaurant not great dangerous dirty
dull what's the fourth one
I don't know if any of you are
homeowners I am every once in a while
the pipes clog up in the house you just
want to get in there and figure out
what's in there what's stuck what do I
need to
do the distant parts of the plumbing in
my house are distant usually when we
talk about robots and distant jobs it's
Mars you know it's somewhere out there
the real distant things are things like
Drainage
Systems increasingly
the most distant thing is the vascul
system in the brain of a of a intact
human being there are terrible terrible
things that can happen to you in which
it would be great if we could get a
small machine into the vasculature
system inside the brain to have a look
around and literally just kick out
something that's clogging it not unlike
drains in a house that at the moment is
the most distant job known to the human
race distant in the sense of it there's
a long way to go to get there it's also
dangerous I don't know about dirty but
there you go so some of the reasons why
from just a purely engineering
perspective we would like to create
robots that are literally soft how do we
do it okay as you would imagine in this
course we're going to do it by evolving
bodies and brains of soft robots in
simulation and then transfer them to
reality so the first thing we need is a
physics engine that can handle soft
bodies one of the innovators in the
space is Professor Cheney who teaches
the evolutionary algorithms class uh in
the fall this is how uh Nick got his
start showing first of all that you
could evolve bodies and brains for
robots and you can guess what the
fitness function was in his 2015 paper
evolver robot to do exactly what you
just saw the oct us doing in Nick's 2015
paper he was using a particular physics
engine that we're going to spend a
moment talking about now this is uh Vox
Vox
CAD we've uh in this course you've seen
Pi bullet which R which simulates rigid
bodies for the grad students you've seen
Tai Chi which allows you to simulate
robots in a particular way where you can
track gradients this is a third class of
physics engines which are designed to
handle soft bodies how does Vox CAD
simulate soft bodies the hint is in the
name itself it's going to approximate
the body of soft robots using a whole
bunch of Cubes or voxels
three-dimensional volumetric pixels
voxels this is uh simulating materials
by breaking them down into a very large
number of small things
in this case these small things are
going to be voxal is known as a finite
element method if you've ever taken an
engineering class you'll often come
across this idea very very difficult to
simulate this thing so divide and
conquer don't simulate this thing
exactly as it is approximate it with a
larger and larger number of smaller and
smaller things yeah okay so Vox craft is
a form of a finite element method we've
got a finite number of these kinds of
elements you're GNA we're going to see a
bunch of movies from Vox Cad and soft
robots what you're seeing is a whole
bunch of these voxels that's the
graphics behind the graphics well here's
an example of the graphics here you'll
notice that these voxal have different
colors what do you think the the colors
are trying to tell us
why did the creator of this simulation
color some of these voxal one color and
another
color different
materials all voxels in a Vox CAD
simulation are not created equal each
voxel is going to have a slightly
different material property and we'll
see what those material properties are
in a moment for our purposes is if you
look carefully the red voxal are a
little soft and the blue voxels in the
middle are
stiffer okay all right so let's take
these one two 3 four five six and
there's a seventh voxel inside that you
can't see and let's shrink the size of
these voxal for a moment 1 2 3 4 5 6
seven Vo
what's going on during each time step of
the simulation of this thing you'll
notice that each pair of neighboring
voxal is attached by this flexible Blue
Bar these flexible blue bars are not
shown in the graphics they're hidden
we're going to just increase the size of
the voxels until they're all touching
one another when you run the simulation
you see a bunch of these twisting
turning
voxels what's really happening in these
is these blue bars between neighboring
voxal are twisting and
turning you'll notice that there are uh
two labels attached to each bar these
are physical parameters of These Bars
we'll talk about what these two
parameters are in a moment there are
also some physical uh physical
parameters that are being computed
by the physics engine on the voxel
itself the first one are forces we've
seen this before when we talked about
physics engines all of them or most of
them usually boil down to this the
physics engine figures out the forces
that are acting on every object the
physics engine knows the masses of the
object
the physics engine knows the forces
acting on each object it knows the
masses of each object so it can figure
out the acceleration of every object and
therefore the physics engine can update
the position and orientation of every
object let's to build up our intuition
assume that for this middle voxel here
there is one and only one force acting
on that voxal force of gravity this
voxel is being pulled down if it wasn't
connected to to these other six voxel
what would be what would be the
acceleration of that voxel where's it
going it would start to accelerate
downward at 9.8 m/s squared right so
nothing too surprising here we've seen
this before but this voxel is not
disconnected it's connected by these
blue beams to its six
Neighbors so as this inner as this inner
voxel starts to experience the downward
pull of gravity that's going to start to
also pull on this blue bar that connects
it to the voxel above
it this blue uh this blue connector here
is a
spring Springs require uh a couple of
numbers to specify how they work the
most important one for our purposes is
the stiffness of the spring which is
represented in this picture here as K so
I'm going to just pop out of this for a
moment and we're going to jump over to
uh Wikipedia for a
moment here's a spring over here and the
spring is experiencing a force pulling
it
down as this Force acts to pull the
spring down the spring is obviously
going to start to elongate and we can
measure the amount of displacement here
the amount of displacement in proportion
to this
Force okay so we can think about
different kinds of Springs that are
experiencing the same Force let's
imagine that this spring is made up of a
very very very thin metal
wire what can you tell me about
displacement pulling downward on a very
weak spring what's going to
happen for this Force displacement is
going to be high right okay now imagine
a string that's made of adamantium
infinitely strong metal and we pull
downward with any Force you like what
happens to the displacement it's zero
let's take this force and this
displacement and arrange it as a ratio
if we have an infinite strong strong
spring we know the denominator which is
displacement is always going to be zero
so for that spring made of adamantium it
has a stiffness
of infinity it's infinitely stiff yeah
if for whatever Force we pull
displacement is infinite we have an
infinitely weak spring that spring has a
stiffness of zero everybody see that
okay so for our purposes K is going to
describe how these blue beams which are
in essence Springs
operate when we start evolving these
things The evolutionary algorithm is
going to evolve
k for this inner this inner voxel which
is being pulled down by gravity If
evolution gives this particular spring
if it assigns it a low what happens to
the in
oxil what's its
a it's going to accelerate downward has
low stiffness if evolution happens to
give this particular spring a high value
of K and gravity is still acting on this
Cube It's going to resist it's not going
to pull down right okay you'll notice
there's a second number here uh there's
a second stiffness value
here these two sets of stiffnesses are
actually vectors of length three so
there are two length three vectors
associated with each and every spring
let's start with k here I we just talked
about if something pulls downward on the
spring if something is trying to stretch
the spring or alter alternatively
compress the spring it's going to resist
more or less
by the first of the three numbers inside
K if something actually pushes the
bottom of the spring left or right the
spring is also going to resist according
to the second value in this K Vector if
something pushes it forward or back it's
going to resist more or less so when I
we talk about pushing or pulling on a
spring there's actually three ways in
which we can perturb a spring try
compress it extend it push it left or
right or push it forward and back and
for different values for different
floating point three different floating
Point values for K it's going to
differentially resist those forces so
far so
good this second set K subf is another
set of three numbers that also dictate
the behavior of the spring how do you
think pitch rolling pitch roll and yah I
can grab the top of a spring and the
bottom of a spring and I can I always
forget one of them is roll one of them
is pitch one of them is yaah actually as
I hold the bottom I can roll pitch or
yaah the spring and then these three
numbers dictate how it's going to resist
those three things so for every spring
for every pair of connected voxels there
are six numbers which evolution is going
to a set that dictates how those two
voxal move and rotate relative to one
another as various forces act on
them
including collisions between themselves
if the spring compresses and those uh
those two voxal are being smooshed
together they will resist being smooshed
and Pull
Apart everybody see
that any questions about that okay I
think this is a good place to pause for
today you have a quiz due tonight you're
working on your final weekly report have
a good rest of your week and I'll see
you on Tuesday


--- Evolutionary Robotics course. Lecture 27： Soft robots contd..en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay let's dive
in where has the time gone one more week
to go um we are going to talk this
morning about the final
project um we'll go through the actual
document my apologies a little boring to
read along together but I just want to
make sure we're all literally and
metaphorically on the same
page okay let's do that now actually um
so there are two components of your
final project both of which are due to
be submitted on bright space uh a little
less than a week from now by Monday by
11:59 p.m. you're submitting two uh
elements to Bright space a written
report covering what you did for your
final project and a 2 and a half minute
YouTube video which is going to be your
oral presentation which you will talk
over and narrate live here at class
starting at 7:30 in the morning next
Tuesday again I don't pick the exam
times so apologies for that okay so um
by 11:59 p.m. on Monday please find in
bright space the written report
submission and you will be uploading one
PDF document please make sure it's a PDF
document minimum length four pages
double space 12o uh font and in that
written uh in that written report you're
going to review the results of your AB
testing for us so what are you currently
doing hopefully what you are currently
doing now is testing two versions of
your uh of your final project variant a
and variant B and you are looking for
one of three possible outcomes by next
Monday at 11:59 p.m. either you're going
to have evidence to support the fact
that a is better than b or you're going
to have evidence that b is better than a
or you're going to have evidence that
there is no difference between a and b I
hope for you you don't get the fourth
outcome which is here's how Fitness
improved with variant a and here's how
Fitness improved with variant B is a
better than b b better than a no
difference who knows so what whatever it
is you're doing between now and Monday
make sure that you collect sufficient
data to try and prove one of those three
outcomes okay let's imagine maybe this
morning this is the data that you
currently have in hand you've done one
run of the parallel hill climber or the
hill climber or whatever evolutionary
algorithm you have and you have Fitness
plotted of the parent in the population
or parents in the population over some
number of generations and you've got
Fitness on the vertical axis for you
maybe a greater value of Fitness is
better perhaps a lower value of Fitness
is better doesn't really
matter what do you do if this is the
current result you have you've done one
evolutionary run of a one evolutionary
run of B and you're currently sitting in
the fourth box which we don't want you
to be in which is you don't know whether
a is better than b b is better than b or
there's
difference hopefully this is a
no-brainer for longer run it for longer
okay now
what did you just change
something we could change something then
you'd have C on your hands we're still
trying to test a and b you run it more
time run it more times yeah so hopefully
at this point you your final project
doesn't require too much brain power
from you just collect more data but it's
a good question what kind of more data
is useful you could run it for longer
you could go back and do a second run of
variant
a sorry a second run of a so starting
from an A different initial random
population of robots you evolve a again
now you've got one run of a a second run
of a one run of B we do another run of
B and get
this is a better than b is B better than
a there's no difference between them or
fourth outcome we don't yet
know we don't know we don't know yet so
what do we
do let's do run night run here's a third
run of b a third run of a just collect
more and more replicates I realize not
everybody has the same uh laptop with
computational ability so it's not
perhaps not immediately clear how much
data you can collect assuming you have a
relatively robust laptop you can set it
up to collect data overnight how many
nights are there between now and Monday
that's how many runs you can get
how many generations do you run things
for it may be that at the beginning
there's clearly no difference but with
enough data you start to see that in
general a tends to be better than B I
cannot tell you it depends on what your
A and B is it depends on what your
evolutionary algorithm is it depends on
how hard your Fitness function is
difficulty meaning how difficult is it
for the evolutionary algorithm to start
to make progress uh on your on your
Fitness task if you're not sure come and
see me or the TA later this week and we
can talk about it that's what you're
currently doing okay so that's what I
mean in the document by you are
currently performing AB testing by
performing multiple runs of A and B
allowing each to run for the same number
of generations when you eventually try
and defend the claim next week that a is
better than b for example in this case a
is better than
b uh we want to have the same population
size and the same number of generations
you want to have allowed The
evolutionary algorithm the same amount
of computational effort for a as it had
for B right that's fair if we ran B for
twice as many generations that's a
little bit of an unfair Advantage for
your variant
B okay uh you're then going to generate
visualizations to try and Visually prove
to us which if either variant produced
better robots this is not a statistics
class so you don't necessarily need to
provide eror bars or confidence
intervals if you know what those are
that's a statistical method for really
strengthening your claim that one group
is doing better than another a set of
Fitness curves where we can see that
generally a tends to do better than b
for example this would be visual proof
of what whatever your claim is assuming
you have enough data yeah okay all right
so that's that's generally what we're
looking for as you're performing your AB
testing this week I suggest you write
your written report along with your uh
your collection of data so you're not
writing your written report all at the
end your report should contain four
sections about one page per section
points will be deducted for poor writing
quality we want to make sure you
communicate your ideas clearly to us
okay let's go through these four
sections first section should describe
your goals what projects or projects did
you tackle during the deliverables how
did you create a and b from that project
what was the question you tried to
answer in my cartoon example here for me
perhaps a was the
quadraped that you have at the end of
assignment 10 and maybe B was a hexapod
and I wanted to see which one could my
evolutionary algorithm evolve a faster
gate for when we finish reading the
first page of your report it should be
pretty clear to us What A and B is it
should be pretty clear to us that it's a
fair comparison between A and
B when I created my hexapod I could have
created my hexapod to be 10 times the
size of the
quadruped when I evolve controllers for
that quadruped and that hexapod guess
which one's going to going to do
better the hexapod because it's 10 times
the size it's more likely to cover more
ground that's an unfair comparison so
when you're describing to us what your A
and B variants are how much detail do
you give us you give us enough detail to
understand what A and B is and you give
us enough information about variant A
and B to hopefully for us to conclude
that it's a fair
comparison make sense
okay second section or a second page
should describe implementation details
how did you code up your deliverables
and your a Tob test what was your
strategy please here describe in words
do not copy and paste code Snippets yeah
for some of you this implementation
details might be relatively
straightforward so in my case I added
two legs both legs had the same number
of degrees of freedom as the legs in the
quadraped each of the two joints in each
of the two additional legs in the
hexapod have the same joint axes as the
as each leg in the quadrip it's not
going to take me a page to describe all
that for some of you your variant a andb
requires more explanation you're going
to need at least a page to describe it
we're not necessarily looking for
exactly a page of implementation detail
if it's less than a page you can provide
us with more detail in some of the other
sections
okay third section third page should
provide some results from your ab test
most importantly you should demonstrate
that Evolution did in fact occur show
that an evolved robot did better than a
randomly generated robot that's the
first piece of evidence we want to see
in your results have a look at my
cartoon example here did Evolution
occur did the quadruped evolve
to move further than random randomly
generated controllers for a I see a lot
of you nodding your heads how do you
know what is it about this picture
that's convincing you that Evolution did
in fact occur Fitness value Fitness
value went up right how much does it
need to go up in order for us to
conclude that again that's up to you the
more replicates you have of your runs
the easier it is to see you might get
into a situation where it's very ult for
evolution to make progress you might get
a fitness curve that looks like this did
Evolution occur hard to say you do a
bunch of
runs and if they all tend to look like
this this means that yes there was a
little bit of evolutionary Improvement
it wasn't much but there was some right
this difference Here is known as the
effect size and
statistics so if your effect size is
small meaning it's hard in your case for
your evolutionary algorithm to increase
Fitness you're going to need to collect
more data to prove to us that Evolution
did in fact occur
alternatively If evolution is able to
make quite a bit of progress you don't
need a lot many replicates to be able to
prove that Evolution did in fact occur
so many of you have asked myself in the
TA how many replicates of a and b or how
many runs of A and B I need to do our
answer is always we don't know it
depends on what your final project is
okay so that's the first thing we're
looking for in your uh
results then we want to see did one
variant do better than another or did
both produce about the same quality uh
of robot or same quality of behavior
okay so what we've been drawing here
Fitness curves how Fitness changes over
evolutionary time this is probably a
necessity this is is something we're
going to want to see you can in
additionally include some of the many
other ways of visualizing what your
evolutionary algorithm did that we've
seen throughout this course when we talk
in the lecture on legged Locomotion we
looked at one of my old projects where I
included some Fitness graphs which which
didn't show how Behavior improved over
evolutionary time it showed what
evolution produced what what did the
gate actually look like uh in those
legged robots we saw some philogenetic
trees so this shows in a PO an evolving
population of robots how are they
related are there different species that
evolve are there Extinction events that
occur how much variation is there in the
behavior or possibly the morphologies of
the robots in your evolving
population okay visualizations of how uh
robots evolved in one environment due
when they're exposed to new environments
some of you are evolving your robots
over flat ground and then transferring
it into environment in which there are
obstacles on the ground or there's
rugged terrain how would you visualize
that uh how would you visualize
robustness how well or how poorly do
evolv robots evolved in one environment
do when they're exposed to a new unseen
environment
okay and because we're roboticist we
love to see cool screenshots of your
robots what they look like how they move
also fine these are all these are all
optional visualizations I would consider
Fitness curves necessary it's going to
be hard for you to prove what we want to
see in this section without Fitness
graphs for those of you that are
comfortable with Statistics and know how
to compute confidence intervals and P
values knock yourself out we're happy to
to review those those as well if you
don't know what A P value is you don't
know what confidence intervals are
that's fine we're not expecting it try
and convince us with more
data in origin of the species Charles
Darwin there is no P value anywhere
there is no Fitness curve in that book
anywhere how did Darwin convince us
about what was going on out
there hopefully some of you have
actually read the book a lot of
anecdotal evidence a lot of anecdotal
evidence when in doubt drown the reader
which in this case is me or the TA in
data the more data the better yeah
okay okay like I said grades will be
detu deducted if it's unclear whether a
was better than b b was better than a
and there was no difference between A
and B I'm sorry I realize I'm being
repetitive here we want we don't we
don't want you to try and get the
quadrad to do better than in the hexapod
that's not the game we're playing here
you're trying to reduce the chance that
you're going to end up with uncertainty
at the end I don't
know all good any questions about any of
that okay fourth and final section uh of
your written report you're going to
verbally demonstrate to us that you
thought carefully about your
deliverables and your ab test what was
surprisingly difficult what was
surprisingly easy what did you learn
along the way of your final Pro project
about physics engines evolutionary
algorithms how to conduct an A A Tob
test tell us what you learned uh I
realize some of you are taking other
courses there are other things that are
impinging on your time and attention and
possibly on the computational resources
of your laptop so we're taking all of
your work with a grain of salt but if
you did have another year to work on
this project and I gave you access to
the
supercomputer what would you do with it
how would you take your initial test and
redo it in a better way with more data
what did you learn how would you do it
better the next time what new features
would you want in pyro Sim to make
things easier again you're not using the
most high-powered physics engine so a
lot of you had ideas that were difficult
to embody in the physics engine you had
available what aspects of this
hypothetical expanded project do you
think would be relatively easy and which
would be
difficult okay that's what we're looking
for in the written report any
questions uh what style does it have to
be like do we have to write it like
paper style H uh not paper style the
format that's written here that's all we
want to see okay yep doesn't M latch
Word document doesn't doesn't matter
formatting but at the end we want a four
page PDF double space 12o font if you
run long that's okay okay we're happy to
grade a five-page PDF a six-page PDF
please don't send us a 20page PDF Fria
and myself also have a lot of things
going on next week keep it within reason
speaking of paper formats I will say
that I've seen uh several weekly reports
that look like they could become actual
new results that have not yet been
reported in the robotics literature if
you think you have something like that
on your hands uh come and see me you
might also see an email coming from me
or fra indicating we think you might
have a paper on your hands we would love
to help you expand some of your your
final projects into actual Publications
over the summer or next fall if you're
still going to be here um we're happy to
do that let us
know okay there are 60 final projects so
it's hard for us to keep track of
everything that's going on if you think
you have something promising let us know
okay written report worth 7% of your
final grade second part is the oral
presentation which is also worth 7% of
your final grade the YouTube video which
is the tangible part of your oral
presentation you need to submit it to
Bright Space by 11:59 p.m. next Monday
okay what are you submitting to Bright
space you're submitting a URL that is
going to point to a public YouTube video
it needs to be public at least for
Monday night night and Tuesday morning
so that we can stitch it into a YouTube
playlist and that playlist will play
here in class Tuesday morning okay there
are 60 of you in this class we have 2
hours and 45 minutes on Tuesday morning
for the final exam period that means
each and every one of you has no more
than 2 minutes and 30 seconds to orally
present what you've been doing over the
last month not an easy thing to do okay
if it's 2 minutes and 23 seconds okay if
it's 2 minutes and 37 seconds okay if
it's 2 minutes and 41 seconds not okay
we got to get through 60 of these oral
presentations in 2 hours and 45 minutes
so my apologies in advance we're going
to be very strict with length limits
with your oral presentations Fair okay
all right so what are you going to be
putting into this 2 minute and 30C
YouTube video you're going to be
including four sections so do the math
that's not a lot of time for each of
these four sections these four sections
are going to correspond to the four
sections we just talked about in the
written
report okay and again part of the grade
for your oral presentation will be
Clarity of communication you are going
to be tempted to try and shoehorn as
much possible information as you can in
2 minutes and 30 seconds to the point
where when you present it orally here in
class no one's going to catch any of it
because you're going way too fast
Clarity of communication you can go back
and review what we just said in the four
sections we're just looking for those
things make sure those four basic
elements are in this 2 minute and 30
second video okay I'm not going to
repeat those four sections as a reminder
the third section is arguably the most
important one this is the results
section you're going to have to convince
Us in probably about 45 seconds or less
that Evolution occurred and that a is
better than b or B is better than b a or
there's no
difference in a video there's a much
better way to convince us of this
quickly than a fitness curve show
us uh show us uh show us a video of show
us a video of an evolved behavior and
show us a video of a random behavior and
even better show us the two videos and
don't tell us which is which if the
evolved behavior is clearly better than
the random behavior all of us should be
immediately able to see it in about 10
seconds or less right if you're evolving
jumping you know jumping when you see it
if you're evolving fast forward
Locomotion you know it when you see it
if you're evolving proning we'll know it
when we see it yeah so like in the
written report during this section
you're trying to convince us visually
that Evolution actually worked The
evolutionary algorithm was able to
improve F uh Fitness better to show us
with a video than a static plot
okay same thing uh same thing when you
then try and convince us about A and B
show us another pair of videos which is
your best evolved a and your best
evolved B if you're trying to convince
us that a evolved to move faster than b
again we should be able to see it if we
see a quadruped that's moving visibly
faster than an evolved
hexapod we should be able to see that in
about 10 or 15 seconds and you've
convinced us of that
fact if you have any time remaining in
your 45 seconds for this section
show us a visualization to further
convince us like Darwin kill us with
data show us as much data as you
can but try and keep the verbal
explanation as short as possible if
you're verbally racing through these 45
seconds we're not going to be clear on
what we're looking at or what we're what
you want us to take away from your
videos or
image make sense okay this is kind of
the core of your contribution in your
fin fin project we're all
clear okay all right when you shoot this
video make sure that there is no sound
because when you submit this Silent
Video Monday night Tuesday morning
you're going to get up here in class in
the front of the class for 2 minutes and
30 seconds and you're going to verbally
narrate over your video there on the
left you see the random uh robot
behavior and here on the right you can
see the evolved Behavior now you can see
an evolved a on the left and an evolved
B on the right and as you can see B
evolved to jump higher than a that's
what we're looking for in the oral
presentation okay when you're making
this video by now you've obviously
created a lot of videos but you might be
composing multiple videos and multiple
images into your 2 minute and 30 second
uh video lots of screen capture and
video creation software out there I like
OBS it's free it's platform independent
and it's It's relatively easy to use but
we don't care use whatever you like um
no points will be deducted per for poor
video if you end up recording everything
on your phone and stitching the videos
on your phone together into a two and a
half video a two and a half minute video
that's fine we're not giving extra
points for production quality here but
if you do just make sure that the
quality of your video is good enough so
that we can see whatever it is you want
us to see in the video if you're trying
to show us that b jumps higher than a
make sure the video quality is good
enough that we can actually see that
remember that we're watching this video
on this screen and some of you are going
to be sitting in the back row so make
sure uh make sure things are large don't
create a video that takes up this amount
of real estate on the screen those
sitting in the back are probably not
going to be able to see it make
everything big if you do print any text
on the SL slides make it big make it big
okay all good all right by 11:59 p.m.
upload it to YouTube make it public not
for kids whatever it is make sure that
when we click on your link in bright
space we can see your video you're going
to upload your video to YouTube and then
copy and paste the URL into the into the
bright space submission
our long-suffering teaching assistant
Fria she is going to after midnight on
Monday start to stitch all of these 60
videos into one long playlist she's
going to do this between midnight and
7:30 in the morning on Tuesday FR is
going to be very tired at this point her
attention span is going to be relatively
low when she gets to your name in the
list and if she doesn't see your
submission in bright space she's going
to leave a blank slot in the playlist
and go on to the next one and you will
receive a 0% for your oral
presentation so there is no late policy
for submission of the oral presentation
for obvious
reasons you all heard that okay all
right all right that's Tuesday that's
Monday night let's talk about Tuesday
morning all right come to class 7:30
a.m. on Tuesday I will bring donuts and
coffee you bring uh your ability to
narrate for two and a half seconds over
your YouTube video Fair all right I will
post Tuesday Morning uh I will post on
the schedule and I will also write it
all out here on the board who is
presenting at what time please come to
class at 7:30 a.m. assuming that you may
be the very first one to present present
because you may be the very first one to
present if you are the very first one to
present please do stay for the entire
two hours and 45 minutes there will be
free coffee and donuts for you please do
your fellow students uh the uh the um uh
the um compliment of staying watching
what they've done all of you have done
some really amazing work I promise you
there are some hidden gems in these 60
final presentations
you're going to want to stay to the end
and see all the great work that your
fellow students have done okay at 7:30
in the morning I am going to press play
on the you on the playlist that frya is
going to create and then we are not
going to stop the playlist the playlist
is designed to run for 2 hours and 45
minutes don't worry I will build or FR
will build into the playlist two
10minute breaks at the hour mark and the
2hour mark Fair okay we've done this
several times now but it requires all of
us to do exactly what's written in this
document so everything runs smoothly the
train is going to leave the station at
7:30 in the morning and if you're not on
it you're not on it fair okay all right
like I said I will make the oral
presentation uh schedule available I'll
I'll embed it in the course schedule and
write it up here on the board for
Tuesday morning
again we're not going to stop the
playlist so when the student before you
in the list starts speaking please come
up to the front of the room and stand on
the far side of the screen so you're
immediately ready to go when the student
standing here finishes presenting her 2
minute and 30 second oral presentation
she will come around this way sit down
the next speaker will immediately come
here and start speaking as his video
immediately starts to play we are not
going to pause the
playlist Fair all
right okay uh like I said in order to
keep on time videos will play one after
the other with no pause in between two
10-minute breaks uh this means when your
video starts you should start speaking
immediately if you run long I'm going to
bring a long hook and I'm literally
going to pull you no I won't but if you
run long I will cut you off so that the
next student can start so practice
practice practice you have an you only
have a 2 minute and 30 second video so
in 20 minutes you can practice eight
times in a row it won't take you long to
memorize your narration get it down pat
watch yourself with the clock and you'll
be you'll be fine years ago I was
invited to give a talk at MIT the talk
was 30 seconds long and they put you up
on stage and they shut off the mic and
shut off the lights after 30 seconds
after you were done so I practice my
talk on the way on the 3 and 1 half hour
drive down to Boston with my
long-suffering wife in the car she had
to listen to this presentation every 30
seconds for three and a half hours this
happened about 15 years ago if she was
here she could probably narrate it for
you verbatim practice practice practice
it won't take you long to memorize it so
that you can keep to exactly two minutes
and 30 seconds okay
again I wish we had more time but we
don't so due to time constraints if you
have a question about one of your fellow
students presentations please go up and
ask them your question during the breaks
or after the final presentations end
you're all suffering through physics
engines and evolutionary algorithms and
robot neural controllers you should all
compare notes please do chat about what
worked and what didn't work amongst
yourselves during the breaks and after
the presentations all right final Point
here which I probably shouldn't even
have to mention uh please practice
collegiality during this time there will
be a temptation to tune out two hours
and 45 minutes is a long time to sit and
listen to
presentations uh I know you're all going
to be very tired next Tuesday you got a
lot of other demands on your attention
you've all put a lot of work in it uh a
lot of creative work so please practice
coll collegiality extend your fellow
students the respect they deserve by
watching and engaging with their
presentations by asking them questions
after and please do stay until the end
okay any questions about all that
crystal clear on what we're doing next
week okay
great all right so back to the last two
lectures of the class lectures 24 and 25
we're working our way through the final
theme of this course where we're looking
at investigators that broaden their
evolutionary algorithm so that
evolutionary algorithm was optimizing
VAR various aspects of the physical
structure and neural control policy of
the robots we looked at Carl sims's work
way back from the
90s on Rigid robots we got partway
through lecture 23 last time looking at
evolving bodies and brains for soft
robots we uh spent some we ended last
time by talking about the physics
underlying the particular softbed
simulator that is used in the
experiments we're about to see and this
is uh uh this is Vox crafter Vox CAD
just as a reminder everything we're
seeing in the simulations we're about to
see are a whole bunch of collections of
Cubes inside pairs of neighboring cubes
they are connected by a spring or if you
like you can think of it as a semi-
rigid beam each beam has associated with
it two sets of three tupal two sets of
three numbers the first three numbers
describe how the spring or the beam
resists pushing and pulling shearing
pulling or pushing and pulling forward
and back three numbers uh that are
determining how the spring resists
changes in X Y and Z between the pair of
Cubes that are attached by that spring
that's linear
stiffness sorry linear stiffness the K
subf here are a second set of three
numbers that dictate how that beam or
that spring
resists uh uh ya pitch and roll the the
pair of connected cubes twisting or
rotating relative to one
another we can set for any one of these
beams those six numbers to make it more
or less resistant to any one or more of
those six numbers everybody see that so
you could have for example one pair of
Cubes attached by a slinky something
that basically allows the two cubes to
move almost completely independently of
one another and simultaneously inside
the same soft robot made up of all these
cubes this Cube and this Cube could be
attached together with a steel girder
something that completely resists or
almost completely resists any change in
position or orientation of the connected
cubes relative to one
another so coming back to the simulation
here what are you seeing here among the
Red Cube
and among the blue cubes tell me about
linear and rotational
stiffness you obviously can't see the
beams let alone the actual parameters
associated with these
beams what's going on
here the darker colors the blue in the
middle has higher stiffness
and the red ones are connected with
stiffer beams or Springs everybody get
how this physics engine works okay all
right uh you can play around with it we
set up a a website for it uh this is
sort of the modern version of Vox cads
now called Vox craft because of course
we need to uh nod to Minecraft here it's
got a relatively easy to use uh
front-end user interface you can
actually in interactively construct a
robot so no evolutionary algorithm here
you can manually uh drop cubes into the
simulation let me speed it up a little
bit you can see someone creating a bunch
of connected cubes here and they've
chosen a particular color on the right
the color is telling the simulator how
to connect pairs of connected uh voxal
how strong or how weak to to make the
beams that connect pairs of connected
cubes you can see them laying down one
layer after another uh red is flexible
here and blue is
stiff they're setting some other
specific material properties of the
simulator of the
robot okay now they're going to simulate
the behavior this robot in the physics
engine tell me about the controller
inside this
robot we haven't said anything about the
controller yet we've only been talking
about how to simulate the physical
structure of this robot you're all now
experts in neural control of robots what
do you think's going on
inside this robot how is it being
controlled
Vol there's some volumetric oscillator
we've seen lots of oscillators now in
the neural controllers of these robots
those oscillators are also known
as CP cpg's Central pattern generators
so this is open loop control there is a
sinusoidal pattern that is being fed
into this robot no sensors and as cam
just said there's some volumetric change
so we've seen a lot of robots now with
rotational joints we've seen Wheels
we've seen little rockets on the space
invader robots from minimal cognition
now we're seeing a different form of
actuation there are some forces being
applied inside this robot that are
causing volumetric changes in this
robot what's going on here do you think
we've got this sinusoidal pattern that's
going up and
down what is going up and down when we
saw actuated rotational joints up and
down meant flexion and extension when we
looked at wheel wield robots higher or
lower numbers meant a faster or slower
spinning wheel when we saw the Rockets
higher or lower numbers meant more or
less Force being emitted by the rocket
what does higher or lower mean here in
the in the central pattern generators
I'm guessing higher is expanding and
lower is Contracting you're getting
there expanding and Contracting of
what bingo so in the user interface it
looks like it's drawn so that it looks
like the the cubes themselves are
increasing in decreasing in volume
that's just sort of the visual
representation of what's actually going
on under the hood which as you said is
those values in the cpg are setting or
changing the resting length of the
Springs that's one more detail of
Springs we I don't think we've mentioned
yet or we might have mentioned in
passing Springs have stiffness they have
damping they resist pushing and pulling
and twisting Springs also physical
Springs also have a resting length if
nothing is pulling or pushing or
twisting on them they will come to rest
at a default length I should have
brought an actual spring with me today
if we just put it on the table and
measured it it would have a length
that's its resting length
if we take a spring and cut it in half
and put a little piston in the middle
and that piston can expand and contract
we are in essence increasing or
decreasing the resting length of the
spring so in the robot you just saw in
the video the cpg is increasing or
springs that connect neighboring voxels
together that's how actuation occurs in
the soft robots that are simulated in
Vox cab everybody see that
okay okay so now let's have a look at
some actual uh let's have a look at some
actual experiments as always we're going
to look mostly at
simulation but we have actually done
some recent work it's only a couple of
years old now where we actually built a
physical version of some of these
evolved soft robots in the physical
robot hopefully as you can see there
aren't Springs or beams connecting
neighboring cubes together these are
actual soft Hol cubes I have two of them
in my office on the other side of this
wall and of course I forgot to bring
them to class this morning my apologies
hopefully you can see from the images
here these are soft Hollow voxal they're
just filled with room temperature air
they're made from silicone so soft
rubber they're a little bit softer than
a bicycle tire basically you'll notice
there are some tubes that are coming out
of a couple of these voxels this is the
resting state of this little 1 two 3
four five voxal
robot we are neither pushing air in nor
pulling air out of this or this voxel
this this robot is at
rest same robot a few seconds later uh
off to the side there's a little hand
pump that a graduate student is holding
and they are pushing manually pushing
air into these voxels in exactly the
same way that you pump air into a
bicycle tire nothing fancy here on the
engineering
side here we are pulling air out and you
can see that the voxels decrease in
volume and they also B
a little bit this is a it becomes very
quickly a relatively complicated
physical material not easy to cross the
C tooreal Gap here we're working on it
okay so here's simulated softbots we've
just talked about how we simulate them
and here is how myself and my colleagues
are trying to instantiate them in
reality ongoing work
okay here is an attempt to build the
quadrip that you all are familiar with
now we can't seem to rid ourselves of
radially symmetric quadrupedal
robots you'll notice that there is
hopefully you can see there's just one
cable coming off here there is one grad
student one cable who is pulling and
pushing air into this thing and you
notice that more than one voxel is
expanding and then Contracting in volume
how what's going going on
here what's going on inside the robot do
you
think the individual
connect we got a whole punch and when we
started to put all these voxal together
we punched holes in a few of them took
two voxels that had facing holes little
bit of epoxy glue and stuck them
together so this robot has a vasculature
system when it inspires when it pulls
air into itself or it has air pushed
into itself that pressurized air starts
to flow through some of the holes in
neighboring voxels they don't all have a
hole in them but where there is that
pressurized air flows through the body
of the robot and you see it almost
literally
breathing it's not enough pressurized
air to get this thing to move again
we're working on
it
okay I will show you this uh sped up
video here what you're going to watch is
an
attempt an attempt by my former PhD
student Sam krigman to actually make uh
one of these soft physical soft robots
from scratch he just poured what's
called dragon skin into that cup it's
liquefied silicone which at a higher
temperature starts to set and solidify
here he is pouring some of this uh Li uh
dragon skin or this silicone soft rubber
in its liquid form into this little uh
mold it's going to cook it for a little
bit it's now heated up the pink dragon
skin that's in the mold has solidified
he's putting in a little bit more
liquefied dragon skin
spin it around a little bit to evenly
coat the five faces of uh each of the uh
wells in this mold exacto knife now that
the silicone has solidified he's going
to cut them out and we're going to have
a whole bunch of Cubes that have five of
their six
sides he's gluing them together and
we're now going to hole punch he already
hole punched a hole connecting some of
the there we go connecting some of the
neighboring voils together so here
here's Sam creating the vasculature
system for this soft
robot take a little bit more liquefied
dragon skin silicone create an even
layer of
it and now he's going to create the
sixth f face for these four
voxels add a little bit more for good
measure release it
from the remaining dragon skin put a
little uh air tube inside seal
everything up with more dragon skin
which solidifies into soft rubber
silicone put a few valves
on and there you go I will play the last
bit again slow
down sorry
and it walks kind
of
okay if you go to the Vox craft uh
website you to can build physical soft
robots all of the materials to do this
cost about 150 bucks you can get them
all from Amazon so if you're looking for
a do-it-yourself project this summer
there you go okay all right so assuming
we can evolve soft robots and then in
the not too distant future successfully
transfer them to reality why would you
want to do it so let's have a look at
the evolution of soft robots now um
Professor cheni here this is some of the
work he did as a graduate student we
just talked about the final project and
demonstrating or how to demonstrate
whether Evolution has occurred here you
go among these two gifts which is the
evolved
robot hopefully you can see it's the one
on the top you'll notice that whatever
this evolutionary algorithm is doing
it's able to alter the 3D geometry of
the robot it's placing some voxal in
different positions and you'll see some
of the voxels have different colors
which is always a reminder that the
underlying beams connecting those pairs
of neighboring voxal together are
stiffer or softer so color represents
material
properties okay how do we actually do
this Nick used this particular kind of
neural network that you see on the left
to paint the 3D geometry and material
properties onto these voxels what kind
of neural network is
this a compositional pattern producing
Network you remember we introduced cppns
which create a phenotype this is the
genotype over here is the phenotype over
here in this case we want to paint a
pattern into three-dimensional space so
we have this empty Cube we visit a bunch
of points inside this Cube and in this
case there are two output neurons for
the cppn the first output neuron
whatever that value is we round it to a
value that's either zero or one so the
first output neuron from the cppn is a
binary output neuron as we visit each
point in this Cube and feed in the X and
Y and Z coordinate we'll ignore the D
here for uh for our purposes today we
feed in X Y and Z if the value that
arrives at the output neuron is zero we
don't place a voxal there if we visit a
point inside this empty Cube we feed in
its XYZ coordinate and the output is a
one we do place a there so this cppn is
going to drop voxal inside this empty
Cube to construct the 3D geometry of our
soft robot while the cppn is dropping
cubes the second output neuron is
rounded by an activation function that
rounds that value to an integer that is
either 0 1 2 or three there are four
possible values for the second output
neuron
we are going to paint one of four colors
onto each dropped voxel and those four
integers are dictating the material
properties of that
Cube more specifically that that value
is dictating the stiffness or softness
of the beams that connect that voxel to
whatever neighbors that voxel
has so far so good okay so the
evolutionary algorithm that you're going
to see in a moment Nick started by
creating a population of random cppns
cppns with different cognitive
architectures different synaptic weights
he took each one of those cppns and
allowed it to construct something like
this and then took that structure and
dropped it into Vox CAD which simulated
how well that soft robot did at moving
from left to right should be pretty
familiar at this point okay here we
go all right uh what you're going to see
in a moment is a visual representation
of what these four colors do I'll just
pause this here for a
moment okay uh let's look at the blue
ones
so uh the light blue here is called Soft
support so these are soft voxels which
means any of the beams or Springs that
leave a light blue voxel do not resist
pulling or pushing or twisting by its
neighbors very much this is passive and
soft material this is not unlike uh fat
or other passive soft tissues in your
body they are pulled and pushed by other
things in the body of the soft robot
dark blue voxels here are hard support
these are voxels every a dark blue voxal
that you're going to see in a moment all
of the beams that leave dark blue voxels
those beams strongly resist any pulling
and pushing by neighboring
voxels red uh red and green
voils they have medium stiffness but
they also contract and
expand in this
case the cpgs that are going to exist
inside these soft robots the cpgs are
changing the resting length of the beams
leaving the red voxels and the cpgs are
also altering the resting length of the
green
voxels ah sorry
you'll notice that the red and green
voxels whenever a red voxel gets bigger
a green voxel gets smaller and
alternatively when a green voxel gets
bigger a red voxel gets
smaller so red and green are both muscle
but they're increasing and decreasing in
opposition to one
another we've actually seen that idea
already in this
course what what is that it's a type of
Bio inspiration here that's coming from
a particular detail of muscle physiology
that we've already talked about in this
class anybody remember where did we see
this
before do you remember the
anthropomorphic arm that was trying to
distinguish between spheres and
elliptical
objects what do you remember about the
muscles inside that arm
there were seven joints inside that arm
but there were 14 motor
neurons like the muscles can only pull
so they were in opposite direction mus
muscles can only pull so if I want to
push or extend my arm how do I do it
that's
Agonist Agonist and
antagonistic muscle groups so you can
see you can literally see when the red
and green
voxels when the red and green voxels
when one of the red red voxels is
increasing in volume it's pushing
against its neighbors and at the same
time any green voxal are going to be
pulling on its neighbors so Nick made
available to The evolutionary algorithm
the ability ability to create Agonist
and antagonistic muscle groups if it's
helpful for the task of evolving soft
robots to move from left to
right here are some examples of evolved
robots here's one with uh dark blue
which is bone and light blue is passive
soft
material there's red and green so you
can see Agonist and antagonist there's
red and green again Agonist
antagonist there's just one giant ball
of muscle no bone no soft passive
tissue obviously the fitness function
here was to evolve Locomotion from left
to right let's actually watch one single
evolutionary
run here's the best cppn in the initial
random population here's the best cppn
at the second generation best cppn at
the third generation
and so
on you'll notice as we move forward in
evolutionary time we're jumping from
generation to generation and we're
seeing what pattern the most fit cppn in
the population is able to paint at that
point in evolutionary
time what's happening aside from
producing a very entertaining showreel
of robots here
What observations can you make about the
evolutionary process at least in this
run seems to be turning the
muscle perverse
instantiation kind of the task here is
to move from left to right as fast as
possible if you're able if you can be
built if you can be built from muscle
bone and and soft tissue you might as
well just be a all of muscle generally
speaking you'll see there are a few
solutions that still retain a little bit
of bone passive stiff material the dark
blue some of them actually do rely on
soft tissue here the light
blue but most of the time it seems The
evolutionary algorithm converged on Big
Balls of
muscle you can see the usefulness of
Agonist and antagonistic muscle groups
here it generally makes sense that when
one part of your body is pulling the
other part is pushing or at least when
one part is Contracting the other part
is
expanding
okay okay so that's how or at least one
way to evolve soft robots why would we
want to let's switch from the how to the
why we saw one reason why you might want
to evolve or automatically design into
deploy soft robots last time soft robots
can often get into places that are
difficult or impossible for rigid robots
to get so there's a very boring clear
obvious engineering reason to make soft
autonomous machines rather than rigid
autonomous machines but there may be
other less obvious reasons why you might
want to
make uh soft rather than rigid machines
here was our an attempt to demonstrate
one of those more subtle reasons why
soft robots might be advantageous over
rigid robots you might remember a rigid
robot from a few lectures back the uh
the evil starfish here if we eventually
want to deploy autonomous machines here
in the real world that work literally
alongside people those machines better
be able to handle surprise well when
they inevitably encounter something they
never saw during Evolution or during
training they want to be able you want
them to be able to adapt quickly and
easily you don't want them to do
something completely unexpected in the
case of the rigid robot when something
uh unexpected happens like for example
physical injury it loses one leg there's
one and only one way in which a rigid
machine can adapt to that kind of
surprise what is it
you're a rigid machine and you suddenly
lose one of your four legs what do you
do you have to retrain you retrain to
move in a different way yeah okay for
organisms that are unfortunate enough to
lose a tail or lose a limb they have
other options available to them what are
they they don't necessarily need to
retrain to figure out how to Hubble
Along on less legs although that is
still an option there's an additional
set of
options if you're made from soft
materials what is
it not so obvious right it's not
something actually that humans do very
well you readapt your structure you
readapt your structure not just your
brain you don't necessarily ret train
your neural controller to move in a new
way you can also adapt your physical
structure itself what are some examples
of that how can you adapt your physical
structure what's the most obvious way
you lose a
limb grow it back grow it back we don't
do it that well at least not in our
human form there is a eye-opening set of
studies about uh children that uh very
young children that unfortunately stick
their finger in a fan and lose the tips
of their fingers below a certain age
they grow them back so humans are
capable of a little bit of regeneration
but not that much so this is a little
bit of a digression but from a Soft
Robotics point of view if something
truly unexpected happens to a soft
robot it has more options available
about how to readapt to deal with
surprise they can adapt their control
policy they can learn how to move
differently or they can adapt their body
or both so in this particular study I'm
going to show you here that was the
question we asked if we Evol if we
create an evolutionary algorithm that
can alter body or brain and we then
injure a four-legged robot like cutting
off half of one leg or cutting off all
of one leg what does evolution do does
evolution leave the body alone and
retrain or re-evolve the controller or
does evolution change the body or does
evolution do
both here's a robot that's been cut in
half here's it running its pre-injured
controller doesn't work doesn't move
very
well that's kind of the best this robot
can do that's a pretty severe injury if
you lose half your
body oops what happened
here Sor right where did we get to
okay okay
there we
go okay here's a four-legged robot
that's going to suffer arguably an even
Grievous a more Grievous injury which is
we're going to cut off all four
legs and after cutting off all four legs
The evolutionary algorithm can adapt the
controller or the
Body Evolution chose in this case to
regenerate the lost legs at least as
best it
could not that that is necessarily the
best thing uh not necessarily that's the
best thing to do but again if we want to
create capable and safe robots here in
the real world we want to give them as
many options as possible to recover from
the completely uh
unexpected not surprisingly if you're a
soft robot it evolves the ability to
regenerate here's a different strategy
in this case again we cut off half of
the robot's body after seeing the
previous uh version of the previous
video we felt pretty confident what we
would do what the evolutionary algorithm
would do in this case it would either
figure out a way to retrain this
controller to get this two-legged robot
to move or The evolutionary algorithm
would figure out how to expand some of
the voxal to quote unquote regrow back
the two legs it's obvious what it's
going to
do thinking about thinking is misleading
in this case The evolutionary algorithm
chose to
retract the the uh remaining two legs
and revert to uh away from legged
Locomotion to an earlier form of
locomotion which is
remember our discussion about
Locomotion Mother Nature's pre preferred
way of
evolving uh strategies for organisms to
move from point A to point
B
peristalsis what you're watching is
actually the same neural controller that
controlled the four-legged robot so the
evolutionary algorithm found that it
doesn't actually need to change the
neural controller at all all it needs to
do is permanently change the resting
length in the feet to retract or shorten
those beams and that produces a wormlike
body which the controller that was
previously producing four-legged
Locomotion in a four-legged machine that
controller now produces peristaltic
Motion in an angua form or worm like
body for us at least this was a very
confusing result about the
interdependency between body and brain
uh from a technical standpoint are you
allowing it to change the material uh
the materials that every box is using
when Adry yeah great point no we didn't
allow it to stiffen or soften the
material but it would be great to redo
this experiment in that case the only
option available to The evolutionary
algorithm was tune how the cpg affected
the the the voxal the increase and
decrease in
voxels or change the permanent resting
length of the Springs make some of the
voxal permanently smaller or permanently
bigger okay so just our contribution to
the uh thought experiment about why we
might want to create soft machines
okay one other uh a couple other just
sort of smaller experiments I wanted to
demonstrate when we created this soft
bodied simulator uh we redid an older
CPU softbed simulator rid it for gpus
which allows us to simulate a very large
number of voxels once we had a GPU
accelerated softb simulator we asked
ourselves what's what could you do if
you could make make a robot from a very
large number of voxels
I don't think we're very imaginative for
us it's always quadrip heads in this
case it's quadrupeds all the way down
you can go check out some of our other
uh fractal robots on fractal robots.
github.io again aside from the answer
because we could why might you want to
evolve fractal
robots here's our attempt to answer this
question you'll notice on the left we
definitely have not worked out all of
the Kinks in our softbed simulator here
in this case we are evolving bodies and
brains for robots again we're setting
the 3D geometry and the material
properties uh of this little robot here
the fitness function is to move from
left to right as always in this form but
we evaluated uh each genotype twice the
genotype is a cppn that produced this
phenotype we measure the fitness of this
phenotype of this robot then we take the
same cppn the same genotype allow it to
reconstruct rebuild the structure but
put them put that structure together in
the same
way and how well does that fractal
version of this robot do at exactly the
same task which is move from left to
right
in this case you can see that this
particular cppn doesn't do a very good
job it discovers a robot that does well
on its own but when it's fractally
composed it does not do very
well here is a second fractal
robot a different genotype a different
cppn that's going to paint a soft robot
which again you see uh on the left here
and then the way in which that cpn's
paint that cppn paints individual voxal
we ask it to paint the same structure
again but now instead of painting with
voxels it's painting with
this this is a robot that is made up of
these robots in the same
pattern and we get a little bit of a
better result it's not ideal but that
same robot has the same structure at one
scale as it does at a different scale
and it has similar Behavior at different
scales so this robot is uh structurally
self-similar it has the same structure
at different scales and it is
functionally self similar it does
similar things at different
scales make
sense again aside from the fact that you
can do this why might you want to do
this why might we want to task
evolutionary algorithms with designing
fractal robots robots that can be
structurally composed together in
similar structures at different size
scales and when you do they do the same
thing uh yes that's part of the answer
it's kind of modular we've got a whole
bunch of these things and we can slot
them in but why specifically do we want
structurally and functional structural
and functional self-similarity do you
think why might this be
useful could it be like real world
manufacturing for real world
manufacturing why is this helpful for
real world manufacturing well it's
repetitive tire is easier to make if
it's repetitive it's easier to make so
as long as everything's made from the
same small set of Parts much easier and
more cost effective to
build but how does this help us with
again the long-term vision of making
capable and safe machines here in the
real
world one of them breaks
ORS oh we're getting kicked out say that
again a little bit louder if one of the
parts
breaks you get the net Behavior if one
part breaks off kind of but specifically
why fractal um you could reconfigure
them and have to R through something
else you could reconfigure them and have
them do something else in this case
we're after the opposite configure them
in the same way over and over again to
make a bigger and bigger robot and it
keeps doing the same
thing if we can get Evolution to design
a small robot that cleans up all the
garbage here maybe we can put a 100 of
them together outside and clean up all
the garbage on the quad do the same
thing clean up random detrius but at
different size scales who knows we'll
see our final class on Thursday we will
talk about xenobots you have a quiz due
tonight you're working on your final
project see you on Thursday


--- Evolutionary Robotics course. Lecture 28： Biological robots (xenobots).en ---

WEBVTT
Kind: captions
Language: en
align:start position:0%
okay good morning everyone welcome to
the last class we've made it we've
almost made it we have one more class
next Tuesday bright and early 7:30 in
the morning yes uh yesterday on Tuesday
I went through all the expectations for
the final project written report oral
presentations stand up on the right
right side of the screen move to the
left side of the screen we don't need to
go over any of that again I don't think
please review all that material in the
recorded lecture from Tuesday uh
Tuesday's recorded lecture if you're not
clear just again a final reminder we've
got 60 presentations they are all
awesome we're going to try and get
through we will get through all of them
in two hours and 45 minutes as long as
everybody keeps to length limits submits
publicly viewable YouTube videos at the
right place at the right time and so on
so please do your part to make sure
uh we run a well oiled machine Tuesday
morning any questions or anything that
wasn't clear from last time uh in the
report if our plots are too big for
example like you put them in appendix
you can put them in an appendix that's
that's fine if you've got a lot of if
you got a A lot of visual results to
report that's fine let's keep the pros
to about four pages please and thank you
yes the video can just have no audio the
video should have no audio um I will
mute things anyway so if you want to add
a soundtrack knock yourself out but we
will not hear it
yes yes like you said for the second
part of the report you want to like Des
like describe our code want likeo code
like how you want describe uh you you're
describing the functionality how you
implemented things where did you make
changes you can include pseudo code if
you want we just want you to try it
assume we don't remember exactly how you
did things it's probably a pretty good
assumption because there's 60 view so
highlevel view what were you trying to
do so we're about to read the results
right you're a and b and we want we are
going to try and assess whether it was a
fair comparison is the hexapod 10 times
bigger than the quadrip if so probably
the hexapod is going to win in your ab
test so give us enough description to
understand how you attack the problem
how you implement it describe for us
enough detail to see that it is a fair
comparison between A and B that level of
detail if you want to include pseudo
code that's fine use common sense what
we don't want to see is here's a
screenshot of our code doesn't mean
anything to us yep the
presentation the or the oral
presentation no the oral presentation is
not a scroll through of your PDF it is
the opposite right you you want to in
your two minutes and 30 seconds show us
what you did don't tell us what you did
so video uh Fitness plots footprint
graphs fog genetic trees as much V not
as much but focus on the visuals right
this is just true of Vis of verbal
communication and science Communication
in general right you could create a
slide Deck with a whole bunch of bullet
points and read them off right I have
tried to not do that in this class
you've sort of seen how I've tried to
communicate to you a lot of information
visually verbally my the oral
contribution is a complement to what's
on the
screen um when showing how the robot can
evolve um you're recommending like a
blind comparison that we could do
between like the different groups and
like maybe like a control if the control
was not
like if it was like just evolved for
like less like like smaller amount of
time on like not as like specific of
like the conditions of your robot or
like a fitness function would that be
like a fair comparison or does it like
sort of have to be trained in like the
same number of generations to actually
have a that's a good question so it's a
question about what makes for a good
control so you were trying to achieve
something in your final project look I
achieved it how do we know that you
achieved it usually it's the robot is
jumping better it's walking better it's
hitting the ball better better than what
right the what is the control what
counts as a good control for the
purposes of this class A control is a
random controller show us two videos
simultaneously one with your robot being
controlled by a random controller so a
random set of synaptic weights and the
other video same robot same task same
physics engine but it's being contr
controlled by the most fit controller or
the most fit robot body that your
evolutionary algorithm
found and if we can tell without you
telling us that's what makes it a blind
test if we can tell which is the evolved
and which is the random that's pretty
good evidence that your evolutionary
algorithm actually did something it was
able to improve Fitness significantly
above what you would find in the initial
random
population isn't the go have that
difference between the A and okay right
so basically there are two pairs of
videos we really want to see in your in
your presentation right the first pair
is what I just described show us that
your evolutionary algorithm worked
whatever it was whatever that
evolutionary algorithm was did it
improve significantly over random
behavior and random robots the second
pair of videos is here's some robots
from a here's some robots from B and if
the result or the claim you're trying to
defend is a is better than b then the
same thing we should be able to
immediately see that a is jumping better
than b or a is running better than b
whatever it is if that's your claim if
your claim is B did better than a then
obviously we should see the behaviors of
B are better than the behaviors of a it
is also fine in your oral presentation
and your written report to defend the
claim that there is no difference
between a and b The evolutionary
algorithm improved behavior in a and
here's proof that Evolution made
progress here's proof that Evolution
improved things in b as well but there's
no difference between a and b that's
also fine it's the fourth outcome you're
trying to avoid which is here's some
behaviors of a and here's some behaviors
of B and it's really hard to tell
whether one is jumping better than the
other I don't really know whether what I
put into my variant B of my code
actually made it easier for The
evolutionary algorithm to evolve jumping
walking hitting whatever it
is make
sense so pictures the pictures count
for I think you can put it in an
appendix if you want if you've got you
know a couple of figures then that's
fine if it's in the body of the four
page PDF but if you've got you know four
6 8 10 figures that you want to
reference in your document put them in
an appendix and reference it reference
them in the main body of your
report that fine so again we're assuming
that not everyone has the same
high-powered laptop you want to be able
to do enough Evolution so that there's a
difference between random behaviors and
evolved Behavior so it doesn't need to
be a smooth curve the way you would get
a smooth curve is if you did 10
independent Trials of your evolutionary
algorithm you rewind the tape run it
again with a different random population
you get a second Fitness curve rewind
the tape third curve rewind fourth
rewind Fifth and if you average all of
them the more of them you have the
smoother the curve you're going to get
but if your laptop is uh entering its
golden years you might not be able to
get as many so you might have a more
rugged looking or discontinuous Fitness
curve that's okay as long as the end of
the curve wherever it is 10 Generations
100 Generations a thousand Generations
as long as it's significantly higher
than where you started in the initial
random population in generation
zero there are no recommendations in
this class about how big your population
should be how many generations you need
to run it for it's up to you it depends
on what you're evolving and what you're
evolving it
on other
questions okay there were a couple good
questions about the format of the oral
presentation how to do this well again
I'm I'm just going to repeat what I just
said uh I think most of you have
probably never given this short an oral
presentation before 2 minutes and 30
seconds is a surprisingly difficult
thing to do as the document as the
instructions for the final project say
there's a lot you need to communicate to
us all in two minutes and 30 seconds my
advice is write out verbatim exactly
what you plan to say it'll probably be
if you read what you just wrote in your
draft it's going to be more than 2
minutes and 30 seconds I'm going to
guess go through your uh text everywhere
you can replace two words with one do so
then go back do it again do it again
tighten your oral delivery of what
you're going to say until you get it
under two minutes and 30 seconds and
then practice practice practice practice
someone was asking about whether there's
going to be a timer in this class there
is not we're going to run a YouTube
video so the only thing we'll see is
your video and I'm I apologize there's
no clock in this room i' bring one but
in my my personal experience trying to
watch a clock and mentally estimate
where you are in your presentation and
speed up and slow down you don't have
time to do any of that conscious
processing in two minutes and 30 seconds
the only thing you have time to do is me
memorize what you're going to say and
practice it so that it's two minutes and
30 seconds so you don't have to
consciously think about timing and
presentation while you're speaking you
will not have time
okay that being said as you make your
oral presentation if you want to put a
few visual cues in there to remind you
of exactly where you are and what you
need to say that's fine too but again
please try and resist putting a whole
bunch of bullet points and then reading
off those bullet points for us as you go
yeah okay another good suggestion was
how to make uh how to make this 2
minutes and 30 second presentation I
suggested uh OBS it's a good way to
record a bunch of videos you can get the
timing down to 2 minutes and 30 seconds
you can make a slide deck and embed
videos in the slides and then Advance
those slides as you're
speaking and screen record that with no
audio and then you know that the
advancing of the slides matches what you
want to say verbally yeah just a couple
of strategies suggestions anything else
about how to prepare this oral
presentation
no okay all right so we are finally at
the final lecture for this course we are
continuing on our theme of evolving
bodies and brains we started in the mid
90s looking at Carl Sims evolving bodies
and brains of rigid robots we moved
forward into uh the last four or five
years where professor chinii and some
others have started to evolve bodies and
brains for soft robots we looked at how
to evolve bodies and brains of soft
robots we looked at the why of soft
robots why you might want to evolve and
deploy autonomous machines that are made
up of soft and rigid
components today we're going to look at
evolving biological robots which have
now become known in the popular uh press
as xenobots some of you have probably
heard of xenobots before so I've sort of
given away the punch line already but
going back to sort of the overarching
goal of evolutionary Robotics and
Robotics in general we would like to
deploy autonomous and safe machines out
there in the world to work and play
alongside us to do the many many things
that humans would prefer not to do so we
want to create autonomous capable and
safe machines what properties would we
like those machines to have other than
being autonomous capable and safe
cheap okay great what else robust robust
excellent
okay uh disposable disposable
great we've been deploying machines out
there in the world for about 300 years
and we're starting to reap the negative
benefits of doing that right it would be
better if we could figure out a
different way if we do want to deploy
large numbers of machines out there in
the world maybe we can do it in a better
way than we've been doing over the last
300 years other features you would like
of future autonomous
machines scalable what do you mean by
scalable with manufacturing you're able
to make one consistently or you're able
to scale the size scale down the size
different situations okay okay SC so
scale scale up literally the size larger
smaller we might want to scale the rate
at which we manufacture things to bring
down the
cost okay that's fine uh
manufacturable what
else how could you make autonomous safe
capable machines that are cheap robust
disposable scalable manufacturable and
still are not in retrospect going to be
something you don't necessarily want to
put out
there fail safe what do you mean by fail
safe
that likely Lo of failure will not be
disasterous okay okay is that something
different from
robustness kind of so robustness in
engineering generally means a machine
can keep doing what it's doing in the
face of adversity wear and tear all the
rest resilience is a slightly different
idea and
the the evil starfish project that I
worked on years back we called it the
resilient machines project because
robustness is often not enough good news
for us we are robust but also resilient
you've got a current strategy for how to
get through your day and it works for
most days tougher days you kind of tough
it out you keep doing what you're going
to do but every once in a while you wake
up and you face a day for whatever you
usually do just is not going to work so
you come up with a plan B that doesn't
work a plan C you get creative about
making your way around truly unexpected
events so yes things that fail well fail
softly that are resilient with would be
a good idea okay is that good can we go
ahead and make machines that have all
these properties and we're
okay okay
good good point right so robustness
resilience and reliability they're
almost the same thing but slightly
different right hopefully with these
three Rs maybe we're capturing that sort
of thing where we can kind of trust
these machines to do the right thing
autonomously that in retrospect when we
see how they adapted to unforeseen
circumstances we kind of look back and
say yeah that was sort of the best thing
the machine could have done I would have
done something similar if I was in that
situation we good anything else we're
missing okay
um you mean the machine itself to
reproduce it okay we could add it let's
put it down to man manufacturable we can
crank out very large numbers of the same
kind of
thing let's some anything
else intelligent okay yes all
right the original threes de were uh
autonomous safe and capable capable
intelligent again maybe the same thing
maybe slly
different you can tell I'm still fishing
right okay we have used state-of-the-art
or next Generation evolutionary
algorithms gradient descent we've
designed the heck out of this thing we
now have an autonomous capable safe
cheap robust disposable scalable
manufacturable resilient reliable and
intelligent
machine would you eat it would you
swallow it ahuh okay for better for
worse I some of you drinking out of
plastic uh cups this morning you're
ingesting some stuff right now that and
we're starting to learn is maybe not
great for us so although a little tongue
and cheek not
quite what are we
missing sorry edible edible
absolutely there is a branch of Robotics
called edible robotics
absolutely how about bio biocompatible
in
general maybe biocompatible fits into
well not quite
disposable how about
biodegradable how would you
want swap or something maybe you don't
want it to degrade can we let's say can
we gain rational control control over
how biodegradable it is depending on
where we're going to deploy it it should
degrade under these conditions not under
these we spent a lot of time in this
class uh occupying the past we've looked
at what's been done in robotics in the
'90s 220s we're now starting to think
about where we might want to go with
robotics in the years to come and I'm
obviously hope hopelessly biased but as
we're going to see in a moment my hope
is that Xeno Bots are the beginnings of
moving in this direction of a new way of
thinking about deploying machines
yes excellent okay so navigatable inside
the body so it's definitely got to be
bio I misspelled that
biocompatible you might have something
that's biocompatible and biodegradable
but you still don't want to put it
inside your body why not
but human body T to consider a lot of
things
that absolutely so what are we missing
now we're getting really specific you
actually are going to eat it or it's
going to be injected into you now you
really want a safe machine
uh could release radiation
okay okay okay biodegrade safely yes
okay well we haven't mentioned anything
about how we're going to make these
robots yet we're only trying to make a
wish list of what we would want for
future autonomous safe and capable
machines haven't said anything yet about
what we're going to make these robots
from what we want actually what we want
them to do the fitness function the
objective function the neural controller
haven't said anything about that yet
just what do we want and maybe what do
we not
want be Med functional okay to do what
we intend inside the body and able to
control it Behavior once it's beened
absolutely right so we want it to be
clinically functional we want it to do
whatever it is we're going to do you're
going to swallow a pill which isn't
really a pill it's a robot and it's a
brenberg vehicle it's going to be
vehicle what was it to be the lover it's
going to sense something inside the body
on its front left and front right and
it's going to swim upstream to follow
that signal that it that it senses
inside the body what might be a signal
you can imagine from a clinical point of
view you would want it to sense and
smell so there is a another branch of
Robotics called intelligent drug
delivery which is exactly that
intelligent drug delivery which is
exactly that idea you swallow something
but it is an active material it is going
to smell or sense the macro molecules
the proteins the stuff that is given off
by a cancerous tumor when we introduced
brenberg vehicles at the beginning of
the course I said imagine a rotten piece
of fruit in the back corner of the room
fruit flies will find it lots of
organisms are able to sense it takes
about two sensors two Motors and two
wires in two Dimensions to create a
machine that will move or swim upstream
following a source we could do that
here maybe this is our clinical Target
this is what we wanted to do find the
cancerous cell the drug go the uh the
robot goes to that cancerous tumor and
then extracts some very small blades and
starts spinning those blades to churn up
the cancerous tumor sounds like a
perfectly good solution to
Me Maybe not right we've been we've seen
some hilarious examples of perverse
instantiation in this class it suddenly
becomes much less funny when we're
thinking about clinical applications of
Robotics you definitely do not want an
autonomous machine operating inside your
body to fulfill whatever the fitness
function was in whatever way The
evolutionary algorithm found to do
so we haven't solved perverse
instantiation yet so this is still
probably sci-fi for the moment but maybe
not for much longer what else do we need
to add to this list to help repress the
probability of perverse
instantiation an off button an off
button okay yes well how would what
would we call
this like a um like something that can
set like all of the edge weights to zero
so that that's a way of instantiating
the big red button turning it
off
terminable the Terminator did something
for all of us roboticists right you got
to remember somewhere there's got to be
a big obvious red button when you're
watching cool robot videos on YouTube
watch the robots and usually you can see
somewhere on it there is a literal big
red button if the robot starts doing
something wrong it should be usually is
relatively easy for someone to step in
and
just turn it
off you swallow something not so obvious
how to make sure that it is easily
terminable something definitely we want
to have on this list not so obvious to
know how to do
it okay right we saw a few uh we saw a
few lectures about the evolution of
signaling and communication if we can't
literally touch the machine or directly
touch the machine how do we communicate
a termination signal great Point again
unsolved problem
termination whatever it is it should be
either a literal or figurative big red
button what does the big red button
mean stop right even a non-expert if
they're operating near the machine they
know nothing about robotics it should be
immediately obvious how to stop the
thing right pretty much everyone in the
western world that has any bit of
Education or uh knows when you see a big
red button and you press it usually the
thing will stop right but what does that
mean for some machines that are a
millimeter in diameter and they're
operating inside the body what would be
it's not going to be a literal big red
button not not so obvious not so
obvious okay let's come back to
something that I think Emily was
mentioning we want to put something
inside the human body and the human body
has been evolved for 3 point over 3.5
billion years to get rid of
intruders we are considering creating
Intruders what else do we need to add to
this
list what's
that oh adjustable adjustable you mean
we would adjust the
machine yeah okay possibly would that
help us make sure that the body doesn't
reject what we're trying to put into it
maybe it might help have to be a to
Rob what's the easiest way to convince
your body that what is inside it is
you make a robot out
of you okay so there is an immune
challenge as well for the clinical side
of this how are we going to make a
machine Let's assume this clinical
application that is capable autonomous
safe all these things biocompatible
biodegradable and your body does not
reject
it now we can start to think about how
are we actually going to evolve design
such a machine and what are we going to
make it from we are probably not going
to make it from all the things we've
seen in this course so far Metals
Plastics Ceramics batteries sensors
Motors the thing that the human body
pretty much every other organismal body
hates above all else is very small
amounts of metals Plastics and so
on uh this sounds interesting but how
are you going to get over all the
ethical concerns that people might raise
like all the regulations because a lot
of people might completely against
absolutely not only will they be against
it they are already against it so all of
this is science fiction
however some of it is becoming science
fact so let's go into the how we might
do this and then we'll come back to the
ethics how would we ever get over the
social and Regulatory hurdles that this
Vision want this one possible vision for
future autonomous machines presents to
the public
okay all right there's lots of different
ways to introduce the xenobots here's
one we've seen this machine already
we've seen a lot of rigid machines uh in
this uh in this class
already we want to make it we want to
make the machines resilient whatever it
is they're going to do when we deploy
them out there in the real world they
are going to be faced with surprise
they're going to be faced with unknown
unknowns things for which the
programmers or the roboticist did not
create contingency plans for so in the
case of traditional robots if something
truly unexpected happens they have one
and only one set of options to adapt to
that unknown
unknown which is to alter their neural
controller they can alter their behavior
how they move given whatever has
changed soft
robots soft robots have a different
option which is once they experience
something that is unexpected
they have two sets of options available
to them they can adapt their neural
controller to try and recover from
what's whatever has happened which in
this case is physical injury or they can
alter their physical structure to adapt
yeah they've got two options available
to them so we've looked at uh rigid
machines made of metals and Plastics
we've looked at soft robots last time
that are made from rubbers and silicones
soft compliable
materials what about a robot that's made
from biological components rather than
technological components this is
obviously not a robot or maybe it's
obvious you're looking at a very early
tadpole so a machine arguably that's
made from a very large number of
biological components which in this case
are genetically
unmodified
cells okay we're going to look at an
experiment from two of my biology
colleagues uh Doug Blackiston and
Michael Levan at toughs this has nothing
to do with xenobots nothing to do with
robotics we're going to now visit
biology for a moment and view biology
from the point of view of a
roboticist what would happen if we
started to try and build machines to
address all these desiderata but instead
of building building them from metals
and silicone we're going to think about
building them from cells why might we
want to do that because we might get a
lot of these things for free question
are biolog robots there are now and
we're going to see one today
yes okay so we're thinking about trying
to build robots from cells cells are an
interesting candidate for a building
block for autonomous machines are they a
good Choice bad choice let's see this
study I think is interesting in that it
suggests why you might want to build
robots from cells or that you might be
able to build robots from cells this is
a very early frog tadpole uh Doug
Blackiston has genetically modified the
DNA of this tadpole so that is
genetically blinded it grows from birth
Without Eyes ethics has already been
mentioned already a lot of ethical
components to what we're going to talk
about this morning genetically altered
tadpole to grow blind it has no eyes
where you would expect eyes to be but
Doug has uh ectopically
rearranged
ectopically ectopically rearranged some
cells in this tadpole so ectopic it
means take stuff from one place and of
an organism and put it some somewhere
else Doug took ey precursor cells this
is a type of stem cell which generally
speaking shows up in the tadpole here
and here and eventually become
functional eyes but these particular
stem cells have been ectopically placed
into the tail of the tadpole seems like
an odd thing to
do this ectopic surgical rearrangement
of tissue in this uh tadpole not only
did not kill the tadpole but as this
tadpole gradually developed into an
adult frog the eye precursor cells
started to mature and develop into an
actual eye which you can see starting to
appear here this eye started to send out
neural processes or synapses that were
looking for
something the nerve cord and the nerve
tissue in the tail also started to send
out
synapses and they they connected during
development and as the tail receded this
tadpole grew into a perfectly healthy
frog with an eye in its butt you got to
love science right okay Not only was
this a healthy frog that had no eyes on
its front and one on its back when Doug
would wave uh would wave something at
the back the Frog frog would react in
the way you would expect if it was a fly
the it was a picture of a fly the Frog
would start to turn around and face in
the direction of the fly if it was
something big and shaking like a
predator the Frog would tend to move
away a functioning eye in a place you
wouldn't
expect how is this possible why did this
happen plasticity plasticity plasticity
can you be a little bit more specific
what do you mean by plasticity so the
body is actively trying to make
something
functional unusual
circumstance absolutely so uh later
today I want you to saw your laptop in
half and then ectopically rearrange
it do the same thing with your car your
drone your cell phone any machine on
this planet does not seem to have this
capability so this is just a very
dramatic example but if you think about
it of course there's examples all over
the place that cells are a pretty
interesting candidate for building stuff
from because under many circumstances
these cells seem happy to be or happy in
quotation marks to be rearranged which
is kind of interesting so about five
years ago uh uh Doug and Mike and myself
received some joint funding to take this
idea and say well if you can rearrange
genetically uh if you can rearrange frog
tissue manually so Doug came up with the
idea to take stuff from here and put it
here could we instead task an AI with
coming up with ways to ectopically
rearrange frog tissue to come up with
something that is different from a
normal
frog okay that's where the idea for the
xenobots started
okay all right so let's talk about the
how now a lot of these pieces are going
to look actually quite familiar to you
five years ago when we started uh Doug
Blackiston told us he was able to
liberate two types of cells from very
early frog embryo so not actually a
tadpole but something that's a little
further along from an egg very very
early frog embryo he could extract from
those eggs
a whole bunch of frog skin cells like
your skin cells those individual cells
or small patches of frog's skin are
passive and soft you can pull and push
on them and they deform in response to
those
horses Doug told us that he could also
pull out of that very early frog embryo
a second cell type which are uh heart
muscle
cells these are small cells
that when put together those cells will
tend to increase and decrease in volume
starting to sound
familiar so we decided let's see if we
can get an evolutionary algorithm to
figure out how to put these two types of
cells together to produce something a
machine that is made up of just frog
skin cells and just frog heart muscle
cells and we're going to try and get the
evolutionary algorithm to figure out how
to put these two building blocks
together to do something what do you
think we wanted that thing to do what
have we seen a thousand times in this
class
already
Locomotion our old trick right let's try
and get something that just walks along
the bottom of a petri dish filled with
room temperature fresh water which is
where frogs are happiest you got a
little a little dish filled with room
temperature fresh water and we're going
to put something inside it that's going
to settle to the bottom of the dish and
then walk along the bottom of the of the
dish so this is like us trying to sink
to the bottom of a swimming pool and
then walk along the bottom of the
swimming pool that's what we wanted to
do yep so same Fitness function we've
seen before we're going to apply this
Fitness function to an evolutionary
algorithm which in turn is wrapped
around a physics engine coming back to
aby's question we're going to see that
this is a an adapted physics engine for
for this
purpose okay what is the evolutionary
algorithm we borrowed Nick's uh
evolutionary algorithm which is evolving
populations of networks evolving
populations of cppns which stands for
compositional pattern producing
networks in this case uh everything is
more or less the same but instead of the
cppn placing voxal of four different
colors inside an empty Cube the cppn is
going to be restricted to only be
capable of placing voxal of two
different colors inside this empty Cube
light blue and these are red green voxal
we're going to use red green to so that
we can see them these voxal increasing
and decreasing in volume so far so good
questions okay so just a recap our
evolutionary algorithm is going to
search over the space of all all
possible ways of placing frog skin cells
and frog heart muscle cells to produce
something that moves as quickly as
possible in about 10 seconds in our frog
tissue physics
engine yes um did you find like when you
were designing this experiment that like
having soft tissue cells was like
beneficial to like um like increasing
movement because I know that like um you
were talking about with like Nick
Cheney's study how like they like a lot
of the different models like evolved out
of using soft tissue or like hard bone
instead of just using muscle great point
so good idea is what's going to happen
when we run this evolutionary algorithm
is it going to discard or make as The
evolutionary algorithm going to make
less and less use of passive soft tissue
which is frog skin cells and make a big
ball of frog heart muscle tissue are
we're going to get the same result as
Nick saw with his soft and hard
simulated voxal or we going to get
different we're going to see who knows
right okay so we don't know yet what
we're going to get but let's pull back
again and remember sort of what the big
picture of what we're doing we're taking
uh although the although these were
genetically modified frog cells to
genetically blind the frog in this case
in this case the Frog cells are
genetically unmodified these are just
100% natural frog skin cells and frog
heart muscle
cells how many of these do we already
get for
free no matter what the evolutionary
algorithm comes up with a big ball of
muscle something that's 99% skin and 1%
muscle we already get uh we already get
this we get this we get this there's one
thing we were missing from this
list carbon
neutral these frog cells as they're
growing in the egg they're absorbing
carbon when these cells eventually die
and degrade back into the environment
they break down into things that are
mostly carbon they put the carbon back
out into the environment so if we
discount all the compute that we're
going to use to design these xenobots
and how we manufacture them the xenobots
themselves by definition are going to be
carbon
neutral so far so good okay so depending
on our yard stick we're already kind of
ahead of the game no matter what the
evolutionary algorithm comes up
with
okay all right let's have a look at the
itself nothing too surprising here we're
starting with a population of random
cppns I think uh Sam krigman who was my
PhD student at the time who set up this
physics engine and this evolutionary
algorithm used a population size of 100
so at the beginning we have 100 random
cppns you're looking at what the first
three random cppn in that population of
100 Produce we've seen cppn a few times
in this class now it's not surprising
this is what they tend to do so here's
one cppn painting mostly frog skin into
this hollow cage and a little bit of
heart muscle tissue this one is
producing a big ball of muscle this
third cppn is painting about half skin
half heart muscle tissue okay there was
a question about the physics engine you
can see immediately or I hope you can
see imediately that this physics engine
is 99% Vox CAD it's what we talked about
last time voxels where neighboring
voxels are connected by a flexible beam
and that beam resists pushing and
pulling and twisting and yawing and
rolling pretty much what we saw last
time with a few additional details put
on top and these are biophysical details
things that Doug knows about frog cells
and these were things that Doug told Sam
who was building the physics engine some
additional details about how frog skin
and how frog heart muscle cells behave
the
biophysics of these two cell
types you can see that this video looks
a lot like the videos we saw last time
with the soft robots but there's a few
details that already should look
different to you which are hints about
the biophysical the added biophysical
details that Sam added in what do you
think they might be
um are the are the cells able to act
like extremely independently like they
look like they're acting pretty
independently right yeah how what is it
what is the visual cue here that they're
acting independently independent how
like with the different squares
activating like very separate to their
neighbors like there's it seems almost
like there's sort of some pattern but
that may have been like an evolved
pattern like over time but like the
individual like cells look like they can
sort of act on their own absolutely
they're acting on their own which cells
are acting on their own the heart cell
the heart cells are acting on their
own
Contra they're expanding and Contracting
independently it's a little difficult to
see but the heart muscle cells when
they're green they're getting bigger and
when they're red they're getting smaller
so they're getting bigger and smaller in
volume and they're doing so
independently can we be a little bit
more specific independent
how what is changing within these cells
or Within These voxels that's
independent from their
neighbors seems like
of the phase is different right remember
when we talked about Agonist and
antagonistic muscle groups when one is
increasing one is
decreasing that's a phase offset right
that one's getting bigger one's getting
smaller one's getting smaller one's
getting bigger things that are in Phase
get bigger together smaller together
here you see random phase offsets it's
not that there's one group that's always
getting bigger when another group is
always getting smaller which is we what
we saw last time in Nick's Soft Robotics
experiment each of the heart muscle
cells in each of the three robots here
has its own random phase offset Sam
deliberately put that into or added that
to Vox CAD to match a particular
biophysical detail that Doug
communicated to us so Sam and I were
trying to learn the physiology of frogs
at the beginning of this project and so
when Doug told us that he could work
with heart muscle tissue we knew enough
to know that heart muscle cells
generally speaking when they're put
together they synchronize their actions
so in you in your heart all of the heart
cells and I wish this for you for the
rest of your life that they stay
synchronized all the cells decrease in
volume at the same time they all
increase in volume at the same time and
when they're placed together in a shell
in the shape of your heart all those
Contracting cells cause your entire
heart to contract which pumps the blood
out and when all the cells expand your
cell your your heart incre your entire
heart increases in volume which pulls
blood into the heart that's what makes a
heart a heart you want these cells to
synchronize same thing in a Frog as a
frog embryo grows into an adult frog
these heart uh muscle cells go to where
they need to go they connect to their
neighbors and they communicate somehow
remember our discussions about
communication they need to communicate
and they all decrease together
communicate and increase together as we
were starting to put this experiment
together it dawned on us that of course
the cppn is going to paint or put frog
heart muscle cells in patterns and into
into 3D shapes or
distributions that don't exist in the
natural frog so we asked Doug the
obvious question what's going to happen
if you rearrange heart muscle cells will
they still synchronize or not and Doug
said
I don't know no one's ever done this
before so what should we do what should
we have done at that point when one of
the biophysical details is uncertainty
for any one of these ways of arranging
frog heart muscle cells the biologists
can't tell us whether or not they're
going to synchronize so what do we tell
the physics
engine like you want to reward it to
synchronize but I'm guessing you don't
just want it to like only be told to
synchronize so that it just like
synchronizes no matter how that like uh
messes with the other functionality of
it a good thought we could try and build
synchronization into the fitness
function but the physics engine The
evolutionary algorithm doesn't know what
pattern will produce synchronization
except for one pattern which is an adult
frog cell adult frog heart so we can't
we could put in the fitness function but
it's just it's meaningless to The
evolutionary algorithm what you want to
avoid is the evolutionary algorithm
exploiting something in your simulator
that doesn't match reality absolutely if
you don't know what's going to happen in
reality you should leave it out random
absolutely so remember our discussions
about the Sim tooreal Gap there's a big
Sim tooreal Gap here we're going to try
and make robots out of frog heart muscle
cells there is much that is unknown
about those cell types especially when
they're rearranged
so the lessons from the simal literature
that we looked at says when in doubt
leave it out or make it random or make
it as hard on the evolutionary algorithm
as possible so that it can't exploit
things that aren't going to exist in
reality we do not want this evolutionary
algorithm coming up with an idea in
which it thinks the cells are going to
synchronize but they won't in reality so
Sam deliberately made things hard on the
evolutionary algorithm by randomizing
the phase offsets of every frog heart
muscle cell that that was simulated we
assumed the worse assume that these
cells no matter how they're arranged
will never
synchronize so we've given the
evolutionary algorithm a pretty hard job
it's got to build a reliable machine
something that reliably moves from left
to right along the bottom of the petri
dish but it's going to build that
machine out of unreliable Parts partly
unreliable unreliable in that they're
not necessarily going to work
together great question are we taking
into account the viscosity of the water
look at these videos what do you think
there's a pretty strong hint
here it's a little hard to see but these
things are settling slowly on to the
featureless white plane so yes we
reduced gravity viscosity is a little
bit higher there's some additional
details beyond the biophysics the
physics of walking along the bottom of a
pool of a swimming pool yeah so there's
a bunch of other subtle physical details
that we put on top of Vox CAD but
actually not that many it's most mostly
Vox CAD that we're looking at here are
the like levels of like these blue boxes
is sort of indicating like um where the
water level might be like in the
physical world or like oh no that that's
just the graphics left over from Vox cat
that's the blue sky at the limit of the
featureless white plane completely
irrelevant but good observation do you
have to feed the cell continu oh great
question do you have to feed these cells
okay hold on to that question we'll come
back to that where's the where's the
battery coming from where's the power
coming from to drive all this we we'll
come back to that in a moment in a few
minutes okay so here we go so just again
to think about this design problem one
way to think about this or ground your
intuition is imagine you were tasked
with building a boat just a boat that's
going to float down the river you're
going to get to place human rowers in
the boat you can have as many rowers in
the boat as you want you can design the
3D geometry of the boat in any way you
want the the trick is that when you put
these human rowers in the boat they're
just going to do their own thing they
are not going to synchronize and you
want the boat to go straight a very
difficult non-intuitive design problem
which is exactly the kinds of problems
that evolutionary algorithms tend to be
good at solving so far so good okay all
right here we go so uh you just saw the
first three cppn from the initial
population of 100 cppn we're evolving
these things to walk along the bottom of
the petri dish you can see that none of
these three are moving from left to
right if you squint really really really
hard you'll notice that this one
actually moves about 1 millimeter to the
right this one is actually doing a
little bit better than this one and this
one so in the Next Generation The
delete the cppn that produce this delete
the cppn that produce this and make
random modified copies of the cppn that
produced this I'm not even going to show
you the video you know what's going to
happen you're going to start to evolve
things that move further and further to
the right like for example this thing in
the upper left I don't know if turning
off the lights will help a little maybe
a little
bit the little Rainbow squiggle
underneath shows you how this thing
moved blue is where it started and then
this red thing moved moved moved to the
right and ended up
here they're all
red what does that mean h sorry this one
is the end of one evolutionary algorithm
Sam then rewound The evolutionary tape
created a different population of 100
random cppns ran it for another couple
hundred generations and at the end got
this most fit robot ran the evolutionary
the third time fourth time 100th time so
you're looking at the best robots from
100 evolutionary runs what
happened they didn't synchronize so it's
a little it's a little confusing because
they're all shown in red you see red
what do you not
see there's no it's all like muscle it's
all muscle right evolutionary Alam said
no problem create a ball of
muscle we took this to Doug Doug said I
can't build it I'm sorry there's no way
I when I'm going to try and actually
ectopically rearrange these tissues for
various reasons we won't go into this
morning can't do it I can't make a ball
of muscle so we already failed to cross
the Sim to real Gap we had
manufacturable on the board here
somewhere Doug can't manufacture it
can't even make it let alone see whether
it matches simulation so Sam went back
and added a term to the fitness function
that constrained things so that the
evolutionary algorithm had to include
frog skin cells and this is what we
got all of these things in the simulator
you just saw they all move from left to
right we sent Doug all 100 MP4s we sent
him all 100 videos he went through all
100 said I can't build that can't build
that can't build that can't build that
turns out that five of these 100 Doug
said I think I can actually build these
okay we're close now at least we can try
to cross the simeral Gap so far so good
okay so let's uh let's watch Doug try
and build this one down
here okay here we go might be a little
difficult to see we've got some muscle
on the bottom and we have some soft skin
top okay here's that robot in action
there was a question before about
whether the soft passive skin is useful
the answer is
yes how is it
useful it's helping this thing move from
left to
right is it like a weight it's a bit of
yeah I guess actually maybe yes maybe
maybe the just this passive weight on
the top helps keeping it on the
ground how else does it help we can see
the heart muscle cells on the vental or
the bottom part of the this thing
whatever this thing
is and skin on the upper part the dorsal
part how is the skin
helping it gives the SE the H the heart
cell something to hold on to you'll
notice that the heart cells are doing
their thing they're getting bigger and
smaller they're pushing down and back
back on the floor which is good right
that's causing a little bit of forward
Force but these are all random forces
these forces are pushing down into the
floor but these forces are also pushing
up and into the soft tissue on the
top that soft tissue is absorbing all of
those forces coming up from below and
it's kind of averaging them out and
supplying those forces back down so this
is a little hand wavy but somehow the
Frog S soft Miss muscle tissue is
averaging the random forces from the
motors from the heart muscle tissue it's
helping another example of sort of
embodied cognition here the body is
helping with what we want this thing to
do so far so good okay so Doug saw this
video and said I can build it here we go
um okay here we
go you're looking at a bunch of frog
eggs here uh Doug is injecting uh a
little bit of a chemical that's going to
determine cell type it's going to make
it easier for him to see inside these
eggs where the skin cells are and where
the heart muscle cells are
this is him pulling off the vitaline
membrane so some of the stuff he doesn't
want so I'm going to skip quickly over a
bunch of these videos this is Doug
starting trying to get at the two Lego
bricks the two types of building blocks
that he's going to use to do this we're
looking down through the microscope with
Doug the uh um the magnification here is
such that these things that you're
looking at are about 2 millimeters in
diameter so these things would be just
visible to the naked eye these tiny
pliers and calipers are about 1 mm
across uh if you ever meet Doug do not
give him any coffee or Coca-Cola no
caffeine it's got very very steady hands
this is not an easy thing to
do
okay uh as the title implies here he's
removing the animal caps there's a lot
of biology terminology today you don't
need to remember all this terminology
he's removing about the top tenth of
each of the cells which is where the two
types of SK uh cell types are that he
wants the skin cells and the heart
muscle cells this is where they tend to
be uh crowded at this particular part in
frog development Tim still trying to get
at the two building block types of
building blocks he
needs here's two uh you're going to see
two animal caps in a moment hopefully oh
sorry 1 2 3 four five six animal caps so
he's pulled off the tops of six eggs and
that white stuff you see those are
individual frog
cells gives you a better sense of the
scale of magnification that we're
looking at
here he's getting rid of the animal caps
themselves here and
leaving uh the actual stuff he wants the
frog skin cells and frog heart muscle
cells
he's now pulled all of these into a very
very small syringe and he's now going to
inject these cells back into a different
Petri B dish where he's going to
actually start building this xenobot
here the this dark circle that you just
saw this is a small concave well in the
bottom of the petri dish so all of these
cells are settling into this dish I'm
going to skip over this
one this video is sped up quite a bit
you'll you can clearly see the
individual frog cells here cells quote
unquote don't like to be alone there's a
little bit of random motion but they're
also seeming to be autonomously clumping
together imagine trying to build robots
or machines out of Parts where the
individual parts are like helping with
the construction they want to work with
you rather than against you this is
preliminary Visual Evidence already that
we're in very different territory here
we're building from components that sort
of want to help with what we're doing
again scare quotes around all of that
okay this is pulled back a little bit
this is about 2,000 cells again sped up
you can see the cells don't like to be
alone they're pulling back
together this is later in the process
so cells at this stage in development
are quite sticky imagine taking a whole
bunch of masking tape and rolling it up
into balls so you've got a whole bunch
of balls of masking tape and then
throwing them into a big concave dish
and shaking that dish a little bit
they're all going to glom together into
a big ball of sticky uh
spheres this is sort of the raw material
the block of marble into which Doug is
now starting to carve away or remove The
Unwanted material you can see this very
small uh forceps on the left and this is
a micro cauterization device on the
right which is a fancy way of saying
it's a very very small uh Car cigarette
lighter it's a very small hot wire that
burns away this unwanted material you
should be able to see a little cross
pattern here this is Doug making the
four little stubby legs in the bottom of
this thing he's eventually going to take
this thing and turn it right side up and
put it on the
ground I'm showing you a few snapshots
from the the manufacturing process here
we're skipping over a lot of other
parts remember that Doug is trying to
build this from skin and heart muscle
tissue and there is a particular
distribution of heart and and skin we've
got heart muscle tissue on the bottom
half and and skin tissue on the upper
half so when Doug was dropping these
cells into this concave dish he
sprinkled down a a little thin mat of
heart muscle cells another layer of
heart heart heart skin heart skin heart
it's like him making a big hero sandwich
you can layer these two different cell
types and then scrape away The Unwanted
material that as of three years ago or
four years ago was the best way Doug had
to try and build what the evolutionary
algorithm came up with so far so
good
okay okay here's him putting the
finishing touches on things he's
scraping things
away scraping away a little bit of The
Unwanted material this xenobot now is
about a millimeter across imagine
looking through the microscope at a
poppy seed and with your own hands
holding very very small tools you were
trying to scrape this pattern into a
poppy seed not an easy thing to
do okay Doug Sam Mike and I took a very
deep Collective breath Doug took the
xenobot turned it right side up put it
on the bottom of the petri dish and
turned on the
camera and this is what we got
the physical xenobot doesn't quite look
like the simulated xenobot it doesn't
quite move like the simulated xenobot
but it was close enough to walk along
the bottom of the petri dish from left
to right you probably know by now there
are many other xenobots that did not
cross the Sim to real Gap but as Doug
got better at building these things and
Sam improved The evolutionary algorithm
to evolve these things things we started
to produce more and more of them that
could cross the Sim toore
Gap but maybe Doug cheated and put the
petri dish on a table that was tilted to
the right maybe this thing is actually
just walking downhill or sliding
downhill how do we know that it's
actually the xenobot that's moving from
left to right and not some feature of
the environment we were talking about
control
experiments uh at the beginning of this
morning's lecture we spent quite
actually one of the hardest parts of
this experiment was thinking about
what's a fair control how do we prove
that this xenobot is actually walking
from left to right because of the heart
muscle tissue on the vental surface and
skin on the dorsal
surface we eventually came up with the
idea take the xenobot and place it on
its back if we place it on its back and
it's still Walks from left to right then
it's not the xenobot that's doing the
walking it's something else else in its
environment that's producing left to
right travel maybe the table table is
tilted or maybe there's a very slight
current inside the room temperature
fresh water that's pushing the thing to
the right remember it's a poppy seed
lightly floating on the bottom of a
petri
dish okay so here we go you're going to
see this is the physical xenobot right
side up
and in a moment when the video switches
you're going to see Doug has reached in
and flipped the xenobot on its
back okay there it is sorry on uh up
right side
up and in a
moment you're going to see it placed on
its back exactly the same xenobot in top
and bottom it no longer moves from left
to right so we can conclude from this
that the the reason this xenobot is
moving from left to right is because of
its 3D geometry and tissue
distribution questions comments yes did
you know
what yep yep yep good
question this act from our perspective
left to right but really move in this
direction relative to the Xeno
remember dietic sensing relative to whom
to the xenobot that's how as long as it
moved this way was fine if we took this
thing and rotated at 18 180 degrees you
would expect it to move in that
direction uh if you were to take this a
bit further because right now you're
embedding the controller with like the
cells also muscles for example okay like
but bodies don't like that you have
brain cells some bodies have brain cells
we need to resist neuro chauvinism in
this class right yes some do but if you
were to create something that that's
more complex that then how would you go
about that would you have to also if you
wanted to create something with brain
let's say great question yes okay so
hold on to that for a moment I see we
have two minutes left so let me spend
one minute concluding the class and then
one minute where is this all going we
have reached the end of evolutionary
robotics I have very much enjoyed my
time with you I hope you have enjoyed
the class obviously this isn't the end
we will see each other again on Friday
but I just wanted to take a moment to
say I very much enjoyed my time here I
hope you've enjoyed the class as well do
remember to get everything in on time by
uh Monday night so that Fria can get
everything ready for us Tuesday morning
for those of you that are graduating I
wish you all the best in whatever you do
next for those of you that are coming
back Next Year look forward to seeing
you all again okay that gives us 60
seconds to talk about where is this all
going my short answer is who knows for
me at least it's can we make autonomous
and capable and safe machines that also
do all of these the answer may be yes
the answer may be no you asked
specifically about could we create
xenobots in which there are is neural
tissue
inside I will tell you that we have a
very long list of to-do items things we
want to do making neur robots is near
the top of this
list I'm recording this lecture so I
can't actually talk about things that
we've already seen in the lab that we
haven't published
yet you can guess what some of these
things are everything you we've seen
this morning is making things out of
frog skin cell out of frog cells you can
imagine one of our uh big burning
questions immediate imately after we saw
this was possible is can you make things
out of can you make biobots out of
different cell types taken from
different organisms what other organism
do you think was at the top of our list
about two years
ago exactly you can go Google anthr
robots anthr robots anthro for human
anthr robots uh members of the Levan lab
published a paper about anthr robots
earlier this year or later late last
year so anthr robots are now a thing and
we would break tons of regulations but
in theory we can make an anthr robot
from you give it back to you and you
could swallow it and experience no ill
effects okay maybe a good place to end
today thank you all good luck with the
final preparations on your final project
see you here 7:30 in the morning on
Tuesday you have a quiz due tonight
